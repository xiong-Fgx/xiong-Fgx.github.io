<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>【前端 4】盒子模型</title>
      <link href="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/"/>
      <url>/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>页面布局的三大核心：盒子模型、浮动、定位</p><p>布局的过程：</p><ol><li>先准备好相关的网页元素，其中元素基本上都是盒子Box</li></ol><h1 id="盒子模型的组成部分"><a href="#盒子模型的组成部分" class="headerlink" title="盒子模型的组成部分"></a>盒子模型的组成部分</h1><p>盒子模型就是将HTML页面中的布局元素看作是一个矩阵的盒子，即装内容的盒子。</p><p>CSS盒子模型封装周围的HTML元素，包括：边框、外边距、内边距、实际内容。</p><ul><li>margin（外边距）</li><li>border（边框）</li><li>padding（内边距）</li><li>content（实际内容）</li></ul><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/无标题.png" alt="盒子模型示意图" style="zoom:75%;"><h2 id="1-border"><a href="#1-border" class="headerlink" title="1. border"></a>1. border</h2><h3 id="1-1-基础写法"><a href="#1-1-基础写法" class="headerlink" title="1.1 基础写法"></a>1.1 基础写法</h3><pre><code class="css">div {    border-color: #00ffff;    border-style: double;    border-width: 5px;}</code></pre><p>可以看出，边框可以设置的属性有三个，这三个属性可以进行简写，并且三个属性的顺序没有要求。</p><pre><code class="css">div {    border: 5px solid red;}</code></pre><p>此外，还可以只设置单个边框的属性，比如上下左右这四个边框的属性可以分别设置。</p><pre><code class="css">div {    border-top: 1px solid red;}</code></pre><h3 id="1-2-三大基本属性"><a href="#1-2-三大基本属性" class="headerlink" title="1.2 三大基本属性"></a>1.2 三大基本属性</h3><ul><li><p>粗细 <code>border-width</code></p><p>一般使用精确的像素值来设置</p></li><li><p>样式 <code>border-style</code></p><p>有多种设置的值</p><table><thead><tr><th>参数</th><th>类型</th></tr></thead><tbody><tr><td>none</td><td>无边框，此时指定border-width无效</td></tr><tr><td>hidden</td><td>隐藏边框</td></tr><tr><td>dotted</td><td>点线</td></tr><tr><td>dashed</td><td>虚线</td></tr><tr><td>solid</td><td>实线</td></tr><tr><td>double</td><td>双线</td></tr><tr><td>groove</td><td>3D凹槽</td></tr><tr><td>ridge</td><td>菱形边框</td></tr><tr><td>inset</td><td>3D凹边</td></tr><tr><td>outset</td><td>3D凸边</td></tr></tbody></table></li><li><p>颜色 <code>border-color</code></p></li></ul><h3 id="1-3-设置边框合并"><a href="#1-3-设置边框合并" class="headerlink" title="1.3 设置边框合并"></a>1.3 设置边框合并</h3><p>如果是两个边框靠在一起，那么他们的边框将不会重叠显示，而是分别显示，因此相邻位置的边框宽度会变成原来的2倍。所以需要通过一个属性来设置边框相关的信息。其中的collapse表示合并的意思。</p><pre><code class="css">div {    border-collapse: collapse;}</code></pre><h3 id="1-4-边框大小不包含在盒子内"><a href="#1-4-边框大小不包含在盒子内" class="headerlink" title="1.4 边框大小不包含在盒子内"></a>1.4 边框大小不包含在盒子内</h3><p>默认情况下：</p><p>设置了盒子大小为 <code>200*200</code> ，此时在设置边框大小为10px，最终展示出来包含边框的盒子的宽高为 <code>220*220</code>。</p><h2 id="2-padding"><a href="#2-padding" class="headerlink" title="2. padding"></a>2. padding</h2><p>padding在设置的时候可以只设定1个数字，也可以指定两个数字。</p><ul><li>如果只设定一个数字，表示上下左右的距离都是这个值</li><li>如果设置两个数字，则其中第一个数字表示上下的padding高度，第二个数字表示左右的padding宽度。</li></ul><pre><code class="css">div {    padding: 0 20px;}</code></pre><p>此外，如果设定了padding，那么盒子的大小也是会受到影响的。</p><p>但是如果盒子本身没有指定宽高属性，则此时的padding不会影响盒子的大小。</p><p>即使是设置宽度为100%，加上padding之后也是会影响大小的。</p><h2 id="3-margin"><a href="#3-margin" class="headerlink" title="3. margin"></a>3. margin</h2><p>该属性用于设置外边距，控制盒子与盒子之间的距离。</p><p>关于margin可以设置上下左右四个位置的边距，因此在设置的时候需要注意给哪个盒子设置。</p><ul><li><code>margin-top</code></li><li><code>margin-bottom</code></li><li><code>margin-left</code></li><li><code>margin-right</code></li></ul><p>如果使用2个数值来设定，则为上下、左右边距</p><p>如果使用4个数值来设定，则4个值的顺序为：上右下左（从上面开始顺时针转）</p><h3 id="3-1-块级盒子水平居中"><a href="#3-1-块级盒子水平居中" class="headerlink" title="3.1 块级盒子水平居中"></a>3.1 块级盒子水平居中</h3><p>外边距可以让块级盒子水平居中，但是必须要满足两个条件</p><ol><li>盒子必须指定宽度（width）</li><li>盒子左右的外边距设置为auto</li></ol><p>例如下面这个图中，将div设置为绿色，并且让其居中显示。</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/image-20210109145027990.png" alt="块级盒子水平居中显示"></p><pre><code class="css">div {    background-color: green;    width: 300px;    margin: 0 auto;}</code></pre><p>对于行内元素、行内块水平居中，需要对其父元素添加 <code>text-align: center</code> 属性。</p><h3 id="3-2-外边距合并"><a href="#3-2-外边距合并" class="headerlink" title="3.2 外边距合并"></a>3.2 外边距合并</h3><p>外边距合并有下面的两种情况：</p><ul><li><p><strong>相邻块元素垂直外边距的合并</strong></p><p>对于两个垂直放置的块元素，其上下边界会发生合并，只保留值较大的一个。比如设置下面的CSS样式：</p><pre><code class="css">div {    background-color: blue;    height: 100px;}.shang {    margin-bottom: 100px;}.xia {    margin-top: 200px;}</code></pre><p>在HTML页面中设置</p><pre><code class="html">&lt;div class=&quot;shang&quot;&gt;&lt;/div&gt;&lt;div class=&quot;xia&quot;&gt;&lt;/div&gt;</code></pre><p>会得到：</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/image-20210109150916158.png" alt="外边距和并"></p><p>两个div之间的距离是200px，也就是只取了较大值。</p><p>解决方法：在相邻的情况下尽量只给一个盒子添加margin值</p></li><li><p><strong>嵌套块元素垂直外边距的塌陷</strong></p><p>对于两个有嵌套关系（父子元素）的块元素，父子元素都有<strong>上外边距</strong>，此时父元素会塌陷较大的外边距值。只要给子元素添加margin-top值，就一定会出现塌陷的现象。</p><p>示意图如下：</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/image-20210109155219349.png" alt="垂直外边距塌陷"></p><pre><code class="css">.father {    width: 400px;    height: 400px;    background-color: purple;    margin-top: 50px;    /* padding: 1px; */}.son {    width: 200px;    height: 200px;    background-color: pink;    margin-top: 100px;}</code></pre><pre><code class="html">    &lt;div class=&quot;father&quot;&gt;        &lt;div class=&quot;son&quot;&gt;&lt;/div&gt;    &lt;/div&gt;</code></pre><p>这里上边距变成了100</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/image-20210109154426978.png" alt="垂直外边距塌陷示意图"></p><p>解决方法：</p><ol><li>为父元素定义上边框</li><li>为父元素定义上内边距</li><li>为父元素添加：<code>overflow:hidden</code></li></ol><p>加上之后显示就恢复正常了，此时外盒子的上边距为50，恢复正常</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/image-20210109154500870.png" alt="垂直外边距塌陷恢复"></p></li></ul><h3 id="3-3-清除内外边距"><a href="#3-3-清除内外边距" class="headerlink" title="3.3 清除内外边距"></a>3.3 清除内外边距</h3><p>对于网页元素来说，大多都是具有外边距的，因此可以通过设置通配符选择器的方式将默认内外边距给清除掉。</p><pre><code class="css">* {    padding: 0;    margin: 0;}</code></pre><p>对于行内元素而言，为了照顾兼容性，尽量只设置左右内外边距，不要设置上下内外边距。但是转换为块级和行内块元素就可以了。</p><h2 id="4-margin与padding"><a href="#4-margin与padding" class="headerlink" title="4. margin与padding"></a>4. margin与padding</h2><p>一般而言，设置左右的边距使用padding，设置上面的边距使用margin-top。</p><p>因为padding是算在盒子内部的，margin不算在盒子内部，需要占据额外的空间。</p><h1 id="圆角边框"><a href="#圆角边框" class="headerlink" title="圆角边框"></a>圆角边框</h1><p>CSS3之后新增的3个样式：圆角边框、盒子阴影、文字阴影</p><p>使用方式：设置 <code>border-radius: length</code> 属性即可。其中的length可以是精确的px也可以是百分比。</p><p>通过这种方式可以设置圆角矩形，也可以设置圆形。</p><p>该参数可以设置为1个值，2个值，4个值，分别表示左上、右上、右下、左下四个角（从左上角开始顺时针转动）</p><h1 id="盒子阴影"><a href="#盒子阴影" class="headerlink" title="盒子阴影"></a>盒子阴影</h1><p>CSS3版本之后出现的新特性，作用是给盒子加上阴影。通过 <code>box-shadow</code> 属性进行设置。</p><p><strong>注意：盒子阴影不会占用空间，不会影响其他盒子的排列</strong></p><p>该属性需要设置的参数为：</p><ul><li><code>h-shadow</code>：（必须）水平偏移距离</li><li><code>v-shadow</code>：（必须）垂直偏移距离</li><li><code>blur</code>：（选）模糊的距离</li><li><code>spread</code>：（选）阴影的尺寸</li><li><code>color</code>：（选）阴影颜色</li><li><code>inset</code>：（选）阴影外置或者内置，默认情况下是外置的，但是不能写outset，否则会出错</li></ul><p>例如下面这样：</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/1610248530950.png" alt="盒子阴影"></p><pre><code class="css">div {    width: 50px;    height: 50px;    background-color: pink;    box-shadow: 10px 10px 10px 10px #C3C3C3;}</code></pre><p>如果想要做成从中间往外发散的形式，则应该将前两个属性改为0</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/1610248645928.png" alt="盒子阴影从中间发散"></p><pre><code class="css">div {    width: 50px;    height: 50px;    background-color: pink;    box-shadow: 0 0 10px 10px #C3C3C3;}</code></pre><h1 id="文字阴影"><a href="#文字阴影" class="headerlink" title="文字阴影"></a>文字阴影</h1><p>文字阴影通过 <code>text-shadow</code> 属性进行设置。</p><ul><li><code>h-shadow</code>：水平偏移量</li><li><code>v-shadow</code>：垂直偏移量</li><li><code>blur</code>：模糊距离</li><li><code>color</code>：颜色</li></ul><p>例如对下面的文字进行阴影设置</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/1610249132849.png" alt="文字阴影"></p><pre><code class="css">div {    text-shadow: 5px 5px 5px black;}</code></pre><h1 id="浮动"><a href="#浮动" class="headerlink" title="浮动"></a>浮动</h1><h2 id="1-传统网页布局的三种方式（PC网页）"><a href="#1-传统网页布局的三种方式（PC网页）" class="headerlink" title="1. 传统网页布局的三种方式（PC网页）"></a>1. 传统网页布局的三种方式（PC网页）</h2><p>网页布局的本质：使用CSS摆放盒子。网页布局方式有以下三种，实际开发的时候， 一个网页基本上都包含了这三种布局方式，移动端则会使用新的布局方式。</p><ol><li><p><strong>普通流（标准流/文档流）</strong></p><p>将标签按照默认规定好的方式排列，比如：</p><ul><li>块级元素独占一行，从上到下排列</li><li>行内元素按照顺序从左到右排列，碰到父元素的边缘后会自动换行</li></ul></li><li><p><strong>浮动</strong></p></li><li><p><strong>定位</strong></p></li></ol><p>通过标准流方式来实现某些效果是比较复杂的，比如：</p><ul><li>一行内显示多个块元素</li><li>两个盒子实现左右对齐</li></ul><p>浮动可以<strong>改变元素默认的排列方式</strong>。</p><p>网页排列第一准则：<strong>多个块级元素纵向排列使用标准流实现，多个块级元素横向排列使用浮动实现</strong>。</p><h2 id="2-浮动的相关概念"><a href="#2-浮动的相关概念" class="headerlink" title="2. 浮动的相关概念"></a>2. 浮动的相关概念</h2><p>浮动：float属性用于创建浮动框，将其移动到一遍，直到<strong>左边缘</strong>或者<strong>右边缘</strong>触及包含<strong>块或另一个浮动框的边缘</strong>。</p><p>float属性的取值有3个：</p><ul><li><code>none</code>：元素不浮动</li><li><code>left</code>：元素向左浮动</li><li><code>right</code>：元素向右浮动</li></ul><p>需要注意的是：浮动默认情况下是<strong>紧紧贴在一起的，中间没有间隙</strong>。</p><pre><code class="css">div {    float: 属性值;}</code></pre><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/../css/t.assets/1610251138035.png" alt="左右浮动" style="zoom:80%;"><pre><code class="css">.zuo {    float: left;}.you {    float: right;}</code></pre><p>设置完css之后，再定义两个相对应的盒子，即可将盒子左右放置。</p><pre><code class="html">&lt;div class=&quot;zuo&quot;&gt;文字&lt;/div&gt;&lt;div class=&quot;you&quot;&gt;文字&lt;/div&gt;</code></pre><h2 id="3-浮动的特点"><a href="#3-浮动的特点" class="headerlink" title="3. 浮动的特点"></a>3. 浮动的特点</h2><h3 id="3-1-浮动元素会脱离标准流"><a href="#3-1-浮动元素会脱离标准流" class="headerlink" title="3.1 浮动元素会脱离标准流"></a>3.1 浮动元素会脱离标准流</h3><p>也就是说：浮动的盒子不再保留原先的位置。这样，这个盒子原来的位置就会空出来，其他的元素就会占据它原来的位置。</p><p>举例说明，如果在同一个父亲下的两个盒子一个浮动一个未浮动，则<strong>浮动的盒子会压住未浮动的盒子</strong>。</p><p>比如下面这个效果图，浮动的红色div会压住下面标准的粉色div</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/1610252213394.png" alt="浮动脱标"></p><pre><code class="css">div {    width: 200px;    height: 250px;    background-color: pink;    font-size: 20px;    line-height: 50px;}.zuo {    float: left;    width: 100px;    height: 100px;    background-color: red;}</code></pre><h3 id="3-2-浮动的元素会在一行内显示并且元素顶部对齐"><a href="#3-2-浮动的元素会在一行内显示并且元素顶部对齐" class="headerlink" title="3.2 浮动的元素会在一行内显示并且元素顶部对齐"></a>3.2 浮动的元素会在一行内显示并且元素顶部对齐</h3><p>如果多个盒子都设置了浮动，那么他们会显示在一行内，并且其顶端与顶部对齐，如果一行内装不下这些盒子，则会<strong>另起一行进行对齐</strong>。</p><h3 id="3-3-浮动的元素会具有行内块元素的特性"><a href="#3-3-浮动的元素会具有行内块元素的特性" class="headerlink" title="3.3 浮动的元素会具有行内块元素的特性"></a>3.3 浮动的元素会具有行内块元素的特性</h3><p>对于一些行内元素而言，是不能设置宽高的，但是如果加了float属性之后，将其设置为浮动元素，此时宽高的设置就会生效，该元素就具有了行内块元素的特性。</p><p>即：<strong>如果行内元素有了浮动，就不需要将其转换为行级、行内块元素就可以直接设置宽度和高度</strong>。</p><p>同样，对于块级元素，设置了浮动之后也会具有行内块元素的特征。对于宽高的实际情况，需要经过行内块元素的实际情况决定。</p><h2 id="4-浮动元素位置约束"><a href="#4-浮动元素位置约束" class="headerlink" title="4. 浮动元素位置约束"></a>4. 浮动元素位置约束</h2><p>为了约束浮动元素的位置，经常采用的策略为：</p><p><strong>先用标准流的父元素排列上下位置，之后内部子元素采取浮动排列左右位置</strong>，符合网页布局第一准则。</p><p>也就是用一个父盒子框柱，子元素在父盒子内部浮动。</p><h2 id="5-注意事项"><a href="#5-注意事项" class="headerlink" title="5. 注意事项"></a>5. 注意事项</h2><ol><li><p>一般来说是将浮动和标准流的父盒子进行搭配使用</p></li><li><p>一个元素浮动，那么他的兄弟元素也应当浮动。（一浮全浮）</p><p>注意，浮动的盒子只会影响浮动盒子后面的标准流，不会影响其前面的标准流，也就是说：</p><ul><li>标准流写在前面，浮动盒子写在后面：此时浮动不会压住标准流</li><li>浮动盒子写在前面，标准流写在后面：此时浮动会压住标准流</li></ul></li></ol><h2 id="6-清除浮动"><a href="#6-清除浮动" class="headerlink" title="6. 清除浮动"></a>6. 清除浮动</h2><h3 id="6-1-问题引入"><a href="#6-1-问题引入" class="headerlink" title="6.1 问题引入"></a>6.1 问题引入</h3><p>先看一个应用场景，由于在父元素盒子里面的内容不确定有多少，因此无法准确指定盒子大小。</p><p>比如对于长度不确定的新闻，无法准确指定装新闻的盒子的大小。</p><p>如果不指定父盒子的高度，并且将浮动的元素加入到父盒子之中，此时的<strong>父盒子高度</strong>会出现问题。比如下面：</p><p><img src="/2021/01/11/html/4_%E7%9B%92%E5%AD%90%E6%A8%A1%E5%9E%8B/1610256435165.png" alt="父盒子高度问题"></p><pre><code class="css">.father{    width: 500px;    border: 1px solid black;}.son1 {    background-color: red;    float: left;    height: 50px;    width: 100px;}.son2 {    background-color: blue;    float: left;    height: 60px;    width: 150px;}</code></pre><p>总结一下，清除浮动的原因：</p><ol><li>父级没有高度</li><li>子盒子浮动</li><li>影响下面的布局</li></ol><h3 id="6-2-清除浮动本质"><a href="#6-2-清除浮动本质" class="headerlink" title="6.2 清除浮动本质"></a>6.2 清除浮动本质</h3><p>清除浮动的本质就是清除浮动元素造成的影响。</p><p>如果父盒子本身有高度，则不需要清除浮动。</p><p><strong>清除完浮动之后，父亲就会根据浮动的子盒子自动检测高度</strong>，此时由于父亲有了高度，下面的标准流就不会出现显示位置异常的问题了。</p><p>清除浮动使用 <code>clear</code> 属性设置</p><ul><li>left：清除左侧浮动的影响</li><li>right：清除右侧浮动的影响</li><li>both：同时清除两侧浮动的影响（开发中常用）</li></ul><p>清除浮动的策略：闭合浮动</p><h3 id="6-3-方法1：额外标签法"><a href="#6-3-方法1：额外标签法" class="headerlink" title="6.3 方法1：额外标签法"></a>6.3 方法1：额外标签法</h3><p>额外标签法也称为隔墙法，做法是在<strong>浮动元素末尾加一个空标签</strong>，比如：</p><pre><code class="html">&lt;div style=&quot; clear: both &quot;&gt;&lt;/div&gt;</code></pre><p>也可以加一个其他标签，比如：</p><pre><code class="html">&lt;br/&gt;</code></pre><p>也就相当于是在浮动元素的底下再加一个<strong>标准的块级元素</strong>，此时这个标签会被放在浮动元素下面。</p><p>优点：通俗易懂，书写方便</p><p>缺点：会添加很多无意义的标签，结构化较差</p><h3 id="6-4-方法2：父元素overflow"><a href="#6-4-方法2：父元素overflow" class="headerlink" title="6.4 方法2：父元素overflow"></a>6.4 方法2：父元素overflow</h3><p>给父元素添加一个overflow属性，将其属性值设置为以下三种均可：</p><ul><li>hidden（常用）</li><li>auto</li><li>scroll</li></ul><pre><code class="css">.father {    overflow: hidden;}</code></pre><p>优点：代码简洁</p><p>缺点：无法显示溢出的部分</p><h3 id="6-5-方法3：after伪元素"><a href="#6-5-方法3：after伪元素" class="headerlink" title="6.5 方法3：after伪元素"></a>6.5 方法3：after伪元素</h3><p>给父元素添加相关的属性：</p><pre><code class="css">.clearfix:after { /* :after 是伪元素 */    content: &quot;&quot;;    display: block; /* 转成块元素 */    height: 0;    clear: both;    visibility: hidden;}/* IE6 7专有 */.clearfix {    *zoom: 1;}</code></pre><h3 id="6-6-方法4：双伪元素"><a href="#6-6-方法4：双伪元素" class="headerlink" title="6.6 方法4：双伪元素"></a>6.6 方法4：双伪元素</h3><p>也是给父元素添加相关属性。只不过这里用了两个伪元素</p><pre><code class="css">.clearfix:before, .clearfix:after {    content: &quot;&quot;;    display: table;}.clearfix:after {    clear: both;}.clearfix {    *zoom: 1;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
          <category> CSS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【前端 3】CSS进阶</title>
      <link href="/2021/01/09/html/3_CSS%E8%BF%9B%E9%98%B6/"/>
      <url>/2021/01/09/html/3_CSS%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="Emmet语法"><a href="#Emmet语法" class="headerlink" title="Emmet语法"></a>Emmet语法</h1><p>Emmet语法使用缩写来提高HTML和CSS的编写速度。</p><h2 id="1-快速生成HTML结构语法"><a href="#1-快速生成HTML结构语法" class="headerlink" title="1. 快速生成HTML结构语法"></a>1. 快速生成HTML结构语法</h2><ul><li>生成标签时直接输入标签名，然后按tab即可补全标签</li><li>需要生成多个标签时，加上 <code>*</code> 即可</li><li>如果有父子关系时，使用 <code>&gt;</code>，比如 <code>ul &gt; li</code></li><li>如果有兄弟关系时，使用 <code>+</code>，比如 <code>div + p</code></li><li>生成带有类名或者id名字的，直接写 <code>.demo</code> 或者 <code>#demo</code> 即可</li><li>如果生成的div类名有顺序，可以用自增符号 <code>$</code>，比如 <code>.demo$*5</code></li><li>如果想要在生成的标签内部写内容，则使用 <code>{}</code>，并且把内容写进去</li></ul><h2 id="2-快速生成CSS样式语法"><a href="#2-快速生成CSS样式语法" class="headerlink" title="2. 快速生成CSS样式语法"></a>2. 快速生成CSS样式语法</h2><p>CSS也可以简写，就是在写每个属性的时候，只写单词首字母即可</p><ul><li>比如 <code>line-height: 26px;</code> 可以直接用 <code>lh26</code> 进行补全</li><li>比如 <code>text-decoration: none;</code> 可以直接使用 <code>tdn</code> 进行补全</li></ul><h1 id="元素显示模式"><a href="#元素显示模式" class="headerlink" title="元素显示模式"></a>元素显示模式</h1><p>元素的显示模式指的是元素（标签）以什么方式进行显示，比如 <code>&lt;div&gt;</code> 自己占一行，多个 <code>&lt;span&gt;</code> 可以放在同一行。</p><p>HTML的元素主要分为两种：</p><h2 id="1-块元素"><a href="#1-块元素" class="headerlink" title="1. 块元素"></a>1. 块元素</h2><p><strong>块元素</strong>：一行只能放一个块元素</p><p>常见的块元素有：</p><ul><li><code>&lt;h1&gt; ~ &lt;h6&gt;</code>：文字类块元素</li><li><code>&lt;p&gt;</code>：文字类块元素</li><li><code>&lt;div&gt;</code>：</li><li><code>&lt;ul&gt;</code>：</li><li><code>&lt;ol&gt;</code>：</li><li><code>&lt;li&gt;</code>：</li></ul><p><strong>特点</strong>：</p><ol><li>自己独占一行</li><li>高度宽度、外边距内边距均可控制</li><li>宽度默认是其容器的100%</li><li>是一个容器及盒子，里面可以放行内或者块级元素。此外，<strong>文字类的块元素内</strong>不可以放其他的块级元素（如h与p），特别是不能放div。</li></ol><h2 id="2-行内元素"><a href="#2-行内元素" class="headerlink" title="2. 行内元素"></a>2. 行内元素</h2><p><strong>行内元素</strong>：一行可以放多个，有些地方行内元素也叫作内联元素。</p><p>常见的行内元素有：</p><ul><li><code>&lt;a&gt;</code>：链接，需要注意的是，链接里面不能再放链接了，但是<strong>可以放块级元素</strong>，不过将a转换成块级模式是最安全的。</li><li><code>&lt;strong&gt;</code>：</li><li><code>&lt;b&gt;</code>：</li><li><code>&lt;em&gt;</code>：</li><li><code>&lt;i&gt;</code>：</li><li><code>&lt;del&gt;</code>：</li><li><code>&lt;s&gt;</code>：</li><li><code>&lt;ins&gt;</code>：</li><li><code>&lt;u&gt;</code>：</li><li><code>&lt;span&gt;</code>：这个是最典型的行内元素。</li></ul><p><strong>特点</strong>：</p><ol><li>相邻的行内元素在同一行上，一行可以显示多个</li><li>高度、宽度的直接设置是无效的</li><li>默认的宽度就是它内容本身的宽度</li><li>行内元素只能容纳文本或者其他的行内元素。</li></ol><h2 id="3-行内块元素"><a href="#3-行内块元素" class="headerlink" title="3. 行内块元素"></a>3. 行内块元素</h2><p><strong>行内块元素</strong>：</p><p>在行内元素中，有几个特殊的标签，他们<strong>同时具有块元素与行内元素的特点</strong>，比如：</p><ul><li><code>&lt;img/&gt;</code>：图像</li><li><code>&lt;input/&gt;</code>：表单</li><li><code>&lt;td&gt;</code>：</li></ul><p>特点：</p><ol><li>与相邻的行内元素（行内块）在同一行，但是他们之间会有空白缝隙，一行可以显示多个</li><li>默认宽度就是它本身内容的宽度</li><li>高度、行高、外边距和内边距都可以控制（块级元素特点）</li></ol><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><table><thead><tr><th>元素模式</th><th>排列</th><th>设置样式</th><th>默认宽度</th><th>可包含内容</th></tr></thead><tbody><tr><td>块级元素</td><td>一行只能由一个块级元素</td><td>可以设置宽度和高度</td><td>其容器的100%</td><td>容器级可以包含任何标签</td></tr><tr><td>行内元素</td><td>一行可以放多个行内元素</td><td>不可以直接设置宽度和高度</td><td>其本身内容的宽度</td><td>容纳文本或者其他行内元素</td></tr><tr><td>行内块元素</td><td>一行可以放多个行内块元素</td><td>可以设置宽度和高度</td><td>其本身内容的宽度</td><td></td></tr></tbody></table><h2 id="5-显示模式转换"><a href="#5-显示模式转换" class="headerlink" title="5. 显示模式转换"></a>5. 显示模式转换</h2><p>特殊情况下，我们需要元素模式的转换，简单理解为：<strong>一个模式的元素需要另一种模式的特性</strong>。</p><p>比如想要增加链接 <code>&lt;a&gt;</code> 的触发范围。</p><p>例如：</p><ul><li><p><code>display:block</code>：转化为块级元素</p><p>例如下面，链接标签a本来是属于行内元素的，不能够定义宽度高度，如果想要这么设置，就需要将一个链接a转化成块级元素。</p><p>设置成块级元素之后，就可以设置宽度和高度，并且<strong>独占一行</strong>。</p><pre><code class="css">a {    width: 150px;    height: 50px;    blackground-color: red;    display: block;}</code></pre></li><li><p><code>display: inline</code>：转化为行内元素</p><p>例如下面，div本来是块级元素，可以定义宽高，并且独占一行，但是可以通过设置，将其转换为行内元素。</p><p>设置成行内元素之后，宽高设置就无效了，并且可以在一行内显示多个。</p><pre><code class="css">div {    /*设置之后下面的宽高设置其实已经失效了，不写也一样*/    width: 150px;    height: 50px;    blackground-color: red;    display: inline;}</code></pre></li><li><p><code>&lt;display: inline-block&gt;</code>：转换为行内块元素</p><p>例如下面，span是典型的行内元素，可以通过设置，将其转换为行内块元素。</p><p>设置之后，它就具有了行内块元素的特点，可以同时设置宽高，并且在一行内可以显示多个</p><pre><code class="css">span {    width: 150px;    height: 50px;    blackground-color: red;    display: inline-block;}</code></pre></li></ul><h1 id="CSS背景"><a href="#CSS背景" class="headerlink" title="CSS背景"></a>CSS背景</h1><h2 id="1-背景颜色"><a href="#1-背景颜色" class="headerlink" title="1. 背景颜色"></a>1. 背景颜色</h2><p><code>background-color</code> 属性定义了元素的背景颜色。</p><h2 id="2-背景图片"><a href="#2-背景图片" class="headerlink" title="2. 背景图片"></a>2. 背景图片</h2><p>背景图片的优点是很大，方便控制位置。</p><p>设置背景图片的时候，需要使用 <code>background-image</code> 属性来设置，其属性需要加上 <code>url()</code> 才能生效。</p><p>使用 <code>background-repeat</code> 属性对图片的平铺模式进行设置，有一下几种设置的方式：</p><ul><li><code>repeat</code>：（默认情况下是平铺的）</li><li><code>no-repeat</code>：</li><li><code>repeat-x</code>：沿着x轴平铺</li><li><code>repeat-y</code>：沿着y轴平铺</li></ul><p>注意：页面元素既可以添加背景颜色，也可以加入背景图片，但是背景色是在下面，背景图片在上面。</p><pre><code class="css">div {    background-image: url(图片路径);    background-repeat: no-repeat;}</code></pre><h2 id="3-背景图片位置"><a href="#3-背景图片位置" class="headerlink" title="3. 背景图片位置"></a>3. 背景图片位置</h2><p>使用 <code>background-position</code> 属性来设置背景图片的位置，设置的时候，可以使用方位名词，也可以使用精确单位。</p><ul><li><p>精确数值length：可以是百分数，也可以是由浮点数字和单位标识符组成的长度值</p><p>如果只制定了一个数字值，那么一定是x坐标，他的y坐标会居中。</p></li><li><p>方位名词position：top、center、bottom、left、center、right方位名词。使用方位名词时，两值的前后顺序不限</p><p>如果只指定了一个方位名词，另一个省略，则第二个默认是<strong>居中对齐</strong>的。</p></li><li><p>混合单位：混合使用精确数值和方位名词。</p></li></ul><pre><code class="css">div {    background-position: x y;    background-position: top left;    background-position: 100px 100px;    background-position: 100px center;    background-position: center 100px;}</code></pre><h2 id="4-背景图像固定（背景附着）"><a href="#4-背景图像固定（背景附着）" class="headerlink" title="4. 背景图像固定（背景附着）"></a>4. 背景图像固定（背景附着）</h2><p>使用 <code>background-attachment</code> 属性设置背景图像是<strong>固定</strong>还是<strong>随着页面的其余部分滚动</strong>。</p><p>可以设置两个属性来制定，后期可以使用该属性做一个视差滚动的效果</p><ul><li><code>scroll</code>：滚动</li><li><code>fixed</code>：固定</li></ul><pre><code class="css">div {    background-attachment: scroll;}</code></pre><h2 id="5-复合写法"><a href="#5-复合写法" class="headerlink" title="5. 复合写法"></a>5. 复合写法</h2><p>复合写法是一种简写，没有特定的顺序，一般约定的顺序为：</p><p><code>background: 背景颜色  背景图片地址  背景平铺  背景图片滚动  背景图片位置</code></p><h2 id="6-背景色半透明"><a href="#6-背景色半透明" class="headerlink" title="6. 背景色半透明"></a>6. 背景色半透明</h2><p>半透明写法使用rgba来设置，其中的第四个属性就是半透明度，从0取到1。</p><pre><code class="css">background: rgba(0,0,0,0.3)</code></pre><h1 id="CSS三大特性"><a href="#CSS三大特性" class="headerlink" title="CSS三大特性"></a>CSS三大特性</h1><h2 id="1-层叠性"><a href="#1-层叠性" class="headerlink" title="1. 层叠性"></a>1. 层叠性</h2><p>给相同的选择器设置相同的样式，此时一个样式就会覆盖另一个冲突的样式，主要用于解决样式冲突的问题。</p><p>原则：</p><ul><li>样式冲突，采取的原则是就近原则，<strong>哪个样式离结构近，就执行哪个样式</strong>。（就近原则）</li><li>样式不冲突，不会层叠。</li></ul><p>例如下面这段代码，两个div样式中的color属性冲突，但是font-size并不冲突，因此color会层叠，但是font-size不会层叠。</p><pre><code class="css">div {    color: red;    font-size: 12px;}div {    color: blue;}</code></pre><h2 id="2-继承性"><a href="#2-继承性" class="headerlink" title="2. 继承性"></a>2. 继承性</h2><p>子元素可以继承父元素的样式，用来简化代码，降低CSS格式复杂性。但是继承的内容也是有一定限制的，只有以下的这些会被继承：</p><ul><li><code>text-</code> 开头的</li><li><code>font-</code> 开头的</li><li><code>line-</code> 开头的</li><li><code>color</code></li></ul><h2 id="3-优先级"><a href="#3-优先级" class="headerlink" title="3. 优先级"></a>3. 优先级</h2><p>当一个元素指定多个选择器时，就会有优先级的概念</p><ul><li>选择器相同，则执行层叠性。</li><li>选择器不同，则根据选择器的权重执行。</li></ul><p>选择器的权重如下所示：</p><table><thead><tr><th>选择器</th><th>权重</th></tr></thead><tbody><tr><td>继承或<code>*</code></td><td>(0,0,0,0)</td></tr><tr><td>元素选择器</td><td>(0,0,0,1)</td></tr><tr><td>类选择器，伪类选择器</td><td>(0,0,1,0)</td></tr><tr><td>ID选择器</td><td>(0,1,0,0)</td></tr><tr><td>行内样式 <code>style=&quot;&quot;</code></td><td>(1,0,0,0)</td></tr><tr><td><code>!important</code> 重要的（在样式后面直接加<code>!important</code>）</td><td>无穷大</td></tr></tbody></table><p>注意：</p><ul><li><p>继承的优先级是0。虽然父元素的选择器权重可能很高，但是子元素继承过来的都是0</p></li><li><p>对于a链接，浏览器默认制定了一个样式，是蓝色有下划线，因此继承是无效的，比如把a链接放进body，并指定body的样式，此时a将不会从body中继承样式。</p><p>复合选择器中有权重叠加的问题。</p></li></ul><pre><code class="css">ul li {    color: green;}li {    color: green;}</code></pre><p>此时的 <code>ul li</code> 的权重为 <code>0,0,0,1 + 0,0,0,1 = 0,0,0,2</code> （注意，<strong>权重叠加不会进位</strong>），因此它的优先级是高于 <code>li</code> 的。</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
          <category> CSS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【前端 2】CSS</title>
      <link href="/2021/01/05/html/2_CSS/"/>
      <url>/2021/01/05/html/2_CSS/</url>
      
        <content type="html"><![CDATA[<h1 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h1><h2 id="1-作用"><a href="#1-作用" class="headerlink" title="1. 作用"></a>1. 作用</h2><p>CSS是层叠样式表的缩写，作用主要是设置HTML页面中的文本内容（字体、大小、对其方式等），图片的外形（宽高、边框样式、边距等），以及版面布局和外观显示样式。</p><h2 id="2-一个例子"><a href="#2-一个例子" class="headerlink" title="2. 一个例子"></a>2. 一个例子</h2><p><img src="/2021/01/05/html/2_CSS/image-20210104112456190.png" alt="image-20210104112456190"></p><pre><code class="html">&lt;style&gt;    h2 {        color: red;        font-size: 12px;    }&lt;/style&gt;&lt;h1&gt;一级标题&lt;/h1&gt;&lt;h2&gt;二级标题&lt;/h2&gt;&lt;h3&gt;三级标题&lt;/h3&gt;</code></pre><h2 id="3-语法规范"><a href="#3-语法规范" class="headerlink" title="3. 语法规范"></a>3. 语法规范</h2><p>CSS写在 <code>&lt;head&gt;</code> 标签中间，使用 <code>&lt;style&gt;</code> 标签来包裹，它的语法主要有两个部分构成：选择器、一条或多条的声明</p><p>比如前面那个例子中，h2就是一个选择器，后面的color和font-size就是声明。</p><ul><li>选择器：就是需要指定样式的HTML的标签</li><li>声明：具体的样式，每一条属性之间都需要加一个分号来分割</li></ul><h1 id="选择器"><a href="#选择器" class="headerlink" title="选择器"></a>选择器</h1><p>由于CSS是针对某个标签进行样式的修改，因此需要首先通过选择器将这些标签给选出来，但是有时候并不希望将某个标签的所有内容都改成同一个样式，这时候需要考虑不同的选择方式。</p><p>选择器又分为基础选择器和符合选择器两种</p><h2 id="1-基础选择器"><a href="#1-基础选择器" class="headerlink" title="1. 基础选择器"></a>1. 基础选择器</h2><p>基础选择器是由单个选择器组成的，其中包括四种类型，其中类选择器使用的最多</p><p>下面是黑马的总结</p><table><thead><tr><th>选择器名</th><th>作用</th><th>特点</th><th>使用场景</th><th>用法</th></tr></thead><tbody><tr><td>标签选择器</td><td>选出所有相同的标签，比如p</td><td>不能差异化选择</td><td>较多</td><td><code>p { color: red; }</code></td></tr><tr><td>类选择器</td><td>可以选出一个或多个标签</td><td>可以根据需求选择</td><td>最多</td><td><code>.nav { color: red; }</code></td></tr><tr><td>id选择器</td><td>一次只能选一个标签</td><td>只能选择一个</td><td>一般需要与js搭配</td><td><code>#nav { color: red; }</code></td></tr><tr><td>通配符选择器</td><td>选择页面中所有的标签</td><td>将所有标签全选</td><td>特殊情况使用</td><td><code>* { color: red; }</code></td></tr></tbody></table><h3 id="1-1-标签选择器"><a href="#1-1-标签选择器" class="headerlink" title="1.1 标签选择器"></a>1.1 标签选择器</h3><p>将<strong>HTML标签名</strong>作为选择器，为页面中所有的这一个标签指定统一的CSS样式。</p><p>缺点也是它会选择所有的标签。</p><pre><code class="html">标签名{    属性1: 值1;    属性2: 值2;}</code></pre><p>例如下面对p标签进行选择指定样式：</p><pre><code class="css">p {    color: red;}</code></pre><h3 id="1-2-类选择器（最常用）"><a href="#1-2-类选择器（最常用）" class="headerlink" title="1.2 类选择器（最常用）"></a>1.2 类选择器（最常用）</h3><p>可以<strong>单独地选择</strong>一个或几个标签来进行样式设计，需要注意的是类名不能是标签的名字。</p><pre><code class="html">.类名{    属性1: 值1;    属性2: 值2;}</code></pre><p>例如下面，将拥有red类的HTML元素都设置为红色</p><pre><code class="css">.bianse{    color: red;}</code></pre><p>这时候需要在html中的标签中，设置 <code>class</code> 属性即可</p><pre><code class="html">&lt;div class=&quot;bianse&quot;&gt; 红色 &lt;/div&gt;</code></pre><p>下面是一个例子：</p><p>在style中设置两个类，分别为red和green，此时在body中加入div，这些div的class就使用这两个类，即可得到下面的效果</p><p><img src="/2021/01/05/html/2_CSS/image-20210104133748102.png" alt="div"></p><pre><code class="html">&lt;head&gt;     &lt;!-- 此处省略前面内容 --&gt;       &lt;style&gt;        .red {            height: 20px;            width: 100px;            background-color: red;        }        .green {            height: 20px;            width: 100px;            background-color: green;        }    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=&quot;red&quot;&gt;&lt;/div&gt;    &lt;div class=&quot;green&quot;&gt;&lt;/div&gt;    &lt;div class=&quot;red&quot;&gt;&lt;/div&gt;&lt;/body&gt;</code></pre><p><strong>多类名</strong>：可以给一个标签指定多个类名，从而达到更多的选择目的，这些类名都可以选出这个标签。</p><p>这个多类名的意义也就是解耦合，比如有些类是专门用来控制颜色的，有些类是专门用来控制大小的，将功能不同的类写到不同的类中，这样就实现了解耦合的作用，否则全部写到一起，高度耦合会导致复用性很差。</p><p>下面就是个例子，还是上面的那个效果图，只不过是将大小与颜色的设置类给分开</p><pre><code class="html">&lt;head&gt;    &lt;style&gt;        .red {            background-color: red;        }        .green {            background-color: green;        }        .size20-100 {            height: 20px;            width: 100px;        }    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=&quot;red size20-100&quot;&gt;&lt;/div&gt;    &lt;div class=&quot;green size20-100&quot;&gt;&lt;/div&gt;    &lt;div class=&quot;red size20-100&quot;&gt;&lt;/div&gt;&lt;/body&gt;</code></pre><h3 id="1-3-id选择器"><a href="#1-3-id选择器" class="headerlink" title="1.3 id选择器"></a>1.3 id选择器</h3><p>这里是使用id来指定样式，在CSS中，id选择器使用 <code>#</code> 来定义。注意，与类选择器不同的是，id相当于标签的身份证号，<strong>每个标签只能有一个id</strong>，因此每个设置的id样式只能对于一个id的标签生效，对于其他标签是不可用的。</p><p>id选择器常用语页面上唯一性的元素上，经常与JS一起配合使用。</p><pre><code class="css">#id名{    属性1: 值1;    属性2: 值2;}</code></pre><p>例如下面</p><pre><code class="css">#nav {    color: red;}</code></pre><p>这时候，同样需要在HTML中需要指定样式的标签里加上id，并指定id的名字。</p><pre><code class="html">&lt;div id=&quot;nav&quot;&gt;test&lt;/div&gt;</code></pre><h3 id="1-4-通配符选择器"><a href="#1-4-通配符选择器" class="headerlink" title="1.4 通配符选择器"></a>1.4 通配符选择器</h3><p>通配符选择器使用 <code>*</code> 来定义，表示选取页面中的所有标签。也不用调用了，设置完直接就可以用了。</p><pre><code class="css">* {    属性1: 值1;    属性2: 值2;}</code></pre><p>由于威力太强大，一般是在特殊情况下才会使用的一种选择器，比如下面的这个，清除所有元素标签的内外边距</p><pre><code class="css">* {    margin: 0;    padding: 0;}</code></pre><h2 id="2-复合选择器"><a href="#2-复合选择器" class="headerlink" title="2. 复合选择器"></a>2. 复合选择器</h2><p>复合选择器就是由多个基本选择器组合而成的。</p><h3 id="2-1-后代选择器"><a href="#2-1-后代选择器" class="headerlink" title="2.1 后代选择器"></a>2.1 后代选择器</h3><p>假设在body中有<code>ol</code>和<code>ul</code>，在<code>ol</code>和<code>ul</code>中都包含了若干个<code>li</code>，此时如果只想要对<code>ol</code>中的<code>li</code>进行选择，此时可以使用后代选择器。</p><p>使用的方式就是用空格将父子关系的元素隔开即可。注意：</p><ul><li>父子关系可以叠加多代，也就是说在子代中还包含了其他标签，也会设置为相同的样式。</li><li>可以使用类选择器通过类名来写</li></ul><p><img src="/2021/01/05/html/2_CSS/image-20210105134153649.png" alt="后代选择器示意1"></p><pre><code class="html">&lt;ol class=&quot;nav&quot;&gt;    &lt;li&gt;ol的li&lt;/li&gt;    &lt;li&gt;ol的li&lt;/li&gt;    &lt;li&gt;ol的li&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;    &lt;li&gt;ul的li&lt;/li&gt;    &lt;li&gt;ul的li&lt;/li&gt;    &lt;li&gt;ul的li&lt;/li&gt;&lt;/ul&gt;</code></pre><p><img src="/2021/01/05/html/2_CSS/image-20210105134301613.png" alt="后代选择器示意2"></p><pre><code class="css">.nav li {    color: red;}</code></pre><h3 id="2-2-子选择器"><a href="#2-2-子选择器" class="headerlink" title="2.2 子选择器"></a>2.2 子选择器</h3><p>也叫作子元素选择器，只能选择作为某元素的<strong>最近一级</strong>子元素，与孙子没关系。</p><p>与后代选择器不同的是，两个元素之间是使用 <code>&gt;</code> 进行连接的。</p><pre><code class="html">&lt;div class=&quot;nav&quot;&gt;    &lt;a href=&quot;#&quot;&gt;儿子&lt;/a&gt;    &lt;p&gt;        &lt;a href=&quot;#&quot;&gt;孙子&lt;/a&gt;    &lt;/p&gt;&lt;/div&gt;</code></pre><p><img src="/2021/01/05/html/2_CSS/image-20210105135232116.png" alt="子选择器示意"></p><pre><code class="css">.nav&gt;a {    color: red;}</code></pre><h3 id="2-3-并集选择器"><a href="#2-3-并集选择器" class="headerlink" title="2.3 并集选择器"></a>2.3 并集选择器</h3><p>可以选择多组标签，同时为他们定义相同的样式。也就是用于<strong>集体声明</strong>。</p><p>并集选择器通过逗号连接而成，<strong>任何形式的选择器</strong>（包括后代选择器）都可以作为冰机选择器的一部分</p><p>下面这个<code>div p</code>就是后代选择器，一般来说是将不同的标签分行显示</p><pre><code class="css">ul, div p {    样式设置}</code></pre><h3 id="2-4-伪类选择器"><a href="#2-4-伪类选择器" class="headerlink" title="2.4 伪类选择器"></a>2.4 伪类选择器</h3><p>用于向某些选择器<strong>添加特殊的效果</strong>。</p><p>伪类选择器的语法是使用冒号表示，比如<code>:hover</code>、<code>:first-child</code>等。</p><p>伪类选择器有两种，一种是链接伪类选择器，一种是focus伪类选择器。</p><ol><li><p><strong>链接伪类选择器</strong></p><p>在网页中，对于某一个超链接，在不同的状态下需要有不同的展示效果。</p><ul><li><code>link</code>：选择所有未被访问的链接</li><li><code>visited</code>：选择所有已被访问的链接</li><li><code>hover</code>：选择鼠标指针位于其上的链接</li><li><code>active</code>：选择活动链接（鼠标按下未弹起）</li></ul><p>例如下面对链接标签a进行设置，对其各种不同状态的颜色都进行设置。（当然其他的也可以设置，比如下划线等）</p><pre><code class="css">a:link {    color: #666;}a:visited {    color: #FF0}a:hover {    color: #F0F}a:active {    color: #0F0}</code></pre><p>注意事项：</p><ol><li><p>为了保证能够生效，需要按照lvha的顺序进行声明（就是上面的顺序）。</p></li><li><p>因为a在浏览器中用于表示链接，它具有默认的样式，因此一般都需要给这个链接单独指定样式。</p></li><li><p>在项目中常用的写法是，先指定a，然后指定hover，这样的效果就是鼠标经过时为蓝色，其他情况下是黑色。</p><pre><code class="css">a {    color: gray;    text-decoration: none;}a:hover {    color: blue;}</code></pre></li></ol></li></ol><ol start="2"><li><p><strong>focus伪类选择器</strong></p><p>这个伪类选择器是用来获取焦点的表单元素，因此主要针对于表单使用该选择器。</p><p>例如下面这个例子，没有选中（获得焦点，得到光标）这个输入框的时候，颜色是白色，选中之后就变成黄色了。</p><p><img src="/2021/01/05/html/2_CSS/image-20210105162240060.png" alt="得到光标（获得焦点）之前"></p><p><img src="/2021/01/05/html/2_CSS/image-20210105162243581.png" alt="得到光标（获得焦点）之后"></p><pre><code class="css">input:focus {    background-color: yellow;}</code></pre></li></ol><h1 id="字体属性"><a href="#字体属性" class="headerlink" title="字体属性"></a>字体属性</h1><p>用于设置字体、大小、粗细、样式（比如倾斜等）</p><ol><li><p><strong>设置字体</strong></p><p>设置字体使用 <code>font-family</code>：</p><ul><li>对于字体的设置，可以设置多个字体，只需要在字体之间加上逗号即可，多个字体按照先后顺序查找，直到找到安装了的字体。</li><li>如果字体的名称中有空格，需要加上引号包起来。</li><li>通常对body标签进行设置，因为浏览器内的内容都是放在body里面的，可以起到全局设置的作用。</li></ul><pre><code class="css">body {    font-family: &quot;Times New Roman&quot;, &quot;Microsoft YaHei&quot;;}</code></pre></li></ol><ol start="2"><li><p><strong>设置字体大小</strong></p><p>使用 <code>font-size</code> 来设置字体大小，谷歌浏览器中默认的文字大小为16px。<strong>标题标签（<code>&lt;h&gt;</code>）是比较特殊的，需要单独进行设置大小</strong>。</p><pre><code class="css">p {    font-size: 20px;}</code></pre></li></ol><ol start="3"><li><p><strong>设置字体粗细</strong></p><p>使用 <code>font-weight</code> 设置字体粗细，其中包含了集中不同的属性，可以设置为：</p><ul><li><code>normal</code>：相当于数字值设置为400</li><li><code>bold</code>：相当于数字值设置为700</li><li><code>bolder</code></li><li><code>lighter</code></li><li>数字值：100-900之间的整百数值，并且这个数字后面不需要加单位。</li></ul><pre><code class="css">p {    font-weight: 400;}</code></pre></li></ol><ol start="4"><li><p><strong>设置字体样式</strong></p><p>使用 <code>font-style</code> 设置字体样式，主要是文字的风格，属性值包括：</p><ul><li><code>normal</code>：正常显示文字</li><li><code>italic</code>：显示斜体问题</li></ul><pre><code class="css">p {    font-style: italic;}</code></pre></li></ol><ol start="5"><li><p><strong>设置复合属性</strong></p><p>如果不想在设置的时候将其写成4行的形式，则可以通过复合的方式进行设置，需要注意的是，设置复合属性时，<strong>需要遵循固定的顺序，且用空格隔开</strong>。</p><p>如果不需要设置其中的某些属性，可以省略，但是 <code>font-size</code> 和 <code>font-family</code> 这两个属性<strong>必须要设置</strong>，否则不生效。</p><p>具体的顺序如下：</p><p><code>font: font-style  font-weight  font-size/line-height  font-family;</code></p><pre><code class="css">div {    font: italic 700 16px &#39;Microsoft YaHei&#39;;}</code></pre></li></ol><h1 id="文本属性"><a href="#文本属性" class="headerlink" title="文本属性"></a>文本属性</h1><h2 id="1-文本颜色"><a href="#1-文本颜色" class="headerlink" title="1. 文本颜色"></a>1. 文本颜色</h2><p>使用 <code>color</code> 属性进行颜色设置。颜色有三种方式可以设置：</p><ul><li>使用预设的颜色</li><li>使用16进制的形式</li><li>使用rgb颜色设置，其中前三个是RGB属性，第四个属性为颜色的透明度，最大为1.</li></ul><pre><code class="css">div {    color: red;    color: #FF0000;    color: rgb(255, 0, 0, 0.99);}</code></pre><h2 id="2-文本对齐"><a href="#2-文本对齐" class="headerlink" title="2. 文本对齐"></a>2. 文本对齐</h2><p>使用 <code>text-align</code> 属性来设置<strong>元素内</strong>文本的水平对齐方式，可以设置为以下这些值：</p><ul><li><code>center</code>：居中</li><li><code>left</code>：左对齐（默认）</li><li><code>right</code>：右对齐</li></ul><pre><code class="css">div {    text-align: center;}</code></pre><h2 id="3-文本装饰"><a href="#3-文本装饰" class="headerlink" title="3. 文本装饰"></a>3. 文本装饰</h2><p>使用 <code>text-decoration</code> 属性设置文本的修饰，比如给文本添加下划线、删除线、上划线等，可以设置为：</p><ul><li><code>none</code>：默认</li><li><code>underline</code>：下划线</li><li><code>overline</code>：上划线</li><li><code>line-through</code>：删除线</li></ul><pre><code class="css">p {    text-decoration: underline;}</code></pre><h2 id="4-文本缩进"><a href="#4-文本缩进" class="headerlink" title="4. 文本缩进"></a>4. 文本缩进</h2><p>使用 <code>text-indent</code> 属性来制定文本第一行的缩进，通常就是段落首行的缩进</p><p>可以设置两种不同的值，一种是像素大小，一种是相对大小（根据当前文字的大小）</p><pre><code class="css">p {    text-indent: 10px;    text-indent: 2em;}</code></pre><h2 id="5-行间距"><a href="#5-行间距" class="headerlink" title="5. 行间距"></a>5. 行间距</h2><p>使用 <code>line-height</code> 属性来设置行间距。行间距包含了文字高度、上下间距，行间距则是这三部分的和，如果改变行间距，不会改变文字的高度，智慧通过改变上下间距的方式进行修改。</p><pre><code class="css">p {    line-height: 26px;}</code></pre><h1 id="引入方式"><a href="#引入方式" class="headerlink" title="引入方式"></a>引入方式</h1><p>按照引入方式的不同，可以将CSS的代码分为三种：</p><p>内部样式表、外部样式表、行内样式表。</p><ol><li><p><strong>内部样式表（嵌入式引入）</strong></p><p>就是写在HTML页面内部，将所有点的CSS代码抽取出来，一般来说都是单独放在 <code>&lt;style&gt;</code> 标签之中的。</p></li><li><p><strong>外部样式表</strong></p><p>将样式单独写在css文件中，然后将css文件引入到html页面中来使用。</p><p>在css文件中不需要style标签，直接写样式就行了。</p><p>引入的方式是在html中使用 <code>&lt;link&gt;</code> 标签引入，其中的rel表示样式表。</p><pre><code class="html">&lt;link rel=&quot;stylesheet&quot; href=&quot;css文件路径&quot;&gt;</code></pre></li><li><p><strong>行内样式表</strong></p><p>在标签内部通过类似于 <code>style=&quot;color=&#39;red&#39;;&quot;</code> 这种形式来引入，可以控制当前标签的样式。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
          <category> CSS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【前端 1】HTML</title>
      <link href="/2021/01/04/html/1_html/"/>
      <url>/2021/01/04/html/1_html/</url>
      
        <content type="html"><![CDATA[<h1 id="基本标签"><a href="#基本标签" class="headerlink" title="基本标签"></a>基本标签</h1><ol><li><p>在vscode中，一个html格式的空白文件，写上一个 <code>!</code> 即可自动补全前面的一批标签内容</p><p><img src="/2021/01/04/html/1_html/image-20201231160837970.png" alt="VSCode自动补全内容"></p><p>其中的lang表示语言，charset表示字符编码</p></li></ol><h2 id="1-标题标签"><a href="#1-标题标签" class="headerlink" title="1. 标题标签"></a>1. 标题标签</h2><p>标题一共有6个级别，每个标题占一行，且大小不同。</p><p><img src="/2021/01/04/html/1_html/image-20201231161430385.png" alt="标题标签示意"></p><h2 id="2-段落标签与换行标签"><a href="#2-段落标签与换行标签" class="headerlink" title="2. 段落标签与换行标签"></a>2. 段落标签与换行标签</h2><p>段落标签 <code>&lt;p&gt; &lt;/p&gt;</code> ，其内部为一个段落。在每个段落中会根据浏览器页面的宽度进行自动换行，并且每个段落之间有比较大的空隙。</p><p>换行标签 <code>&lt;br/&gt;</code></p><h2 id="3-文本格式化标签"><a href="#3-文本格式化标签" class="headerlink" title="3. 文本格式化标签"></a>3. 文本格式化标签</h2><h3 id="3-1-加粗"><a href="#3-1-加粗" class="headerlink" title="3.1 加粗"></a>3.1 加粗</h3><p><code>&lt;strong&gt; &lt;/strong&gt;</code> 或者使用 <code>&lt;b&gt; &lt;/b&gt;</code> 两标签之间的内容将会被加粗</p><h3 id="3-2-倾斜"><a href="#3-2-倾斜" class="headerlink" title="3.2 倾斜"></a>3.2 倾斜</h3><p><code>&lt;em&gt; &lt;/em&gt;</code> 或者 <code>&lt;i&gt; &lt;/i&gt;</code></p><h3 id="3-3-下划线"><a href="#3-3-下划线" class="headerlink" title="3.3 下划线"></a>3.3 下划线</h3><p><code>&lt;ins&gt; &lt;/ins&gt;</code> 或者 <code>&lt;u&gt; &lt;/u&gt;</code></p><h3 id="3-4-删除线"><a href="#3-4-删除线" class="headerlink" title="3.4 删除线"></a>3.4 删除线</h3><p><code>&lt;del&gt; &lt;/del&gt;</code> 或者 <code>&lt;s&gt; &lt;/s&gt;</code></p><h2 id="4-div与span"><a href="#4-div与span" class="headerlink" title="4. div与span"></a>4. div与span</h2><p>这两个没有语义，就是盒子，用来装内容。</p><p>不同的是，div是独占式的，一行只能显示一个div，而span可以在同一行中显示</p><h2 id="5-图像标签与路径"><a href="#5-图像标签与路径" class="headerlink" title="5. 图像标签与路径"></a>5. 图像标签与路径</h2><p><code>&lt;img src=&quot;图像URL&quot; /&gt;</code>，其中的src是必须写的，还有一些其他的标签</p><table><thead><tr><th>标签名</th><th>属性值</th><th>意义</th></tr></thead><tbody><tr><td>src</td><td>图片路径</td><td>必填属性</td></tr><tr><td>alt</td><td>文本</td><td>替换文字，当图片不能显示时会展示的文字</td></tr><tr><td>title</td><td>文本</td><td>提示文本，鼠标放在图像上显示的文字</td></tr><tr><td>width</td><td>像素</td><td>设置图像宽度（等比例缩放）</td></tr><tr><td>height</td><td>像素</td><td>设置图像高度（等比例缩放）</td></tr><tr><td>border</td><td>像素</td><td>设置图像的边框粗细</td></tr></tbody></table><h2 id="6-超链接"><a href="#6-超链接" class="headerlink" title="6. 超链接"></a>6. 超链接</h2><p>超链接标签为 <code>&lt;a&gt;</code> ，在标签中还可以加入其它元素：</p><pre><code class="html">&lt;a href=&quot;跳转目标&quot; target=&quot;目标窗口的弹出方式&quot;&gt;文本、图像或音视频&lt;/a&gt;</code></pre><p>其中的href为必须的属性，当标签具有该属性时才可以进行跳转。</p><p>target表示跳转的方式，其中：</p><ul><li><code>_self</code>（默认方式）：在当前页面中打开</li><li><code>_blank</code>：在新窗口中打开</li></ul><p>链接分类：</p><p>根据href中填写跳转目标的不同类型，分为以下三种类型</p><ol><li><p><strong>外部链接</strong>：就是写上HTTP，再加上其他的网站地址</p></li><li><p><strong>内部链接</strong>：使用相对路径</p></li><li><p><strong>空链接</strong>：使用 <code>#</code> 表示没有确定的链接目标，会回到首页。可以用来当做未开发网页的链接，因为不加href则不会显示超链接的样式。</p></li><li><p><strong>下载链接</strong>：如果href里面写的是个文件或者压缩包，则会下载这个文件</p></li><li><p><strong>网页元素链接</strong>：在网页中的各种元素比如说文本、图像、表格、音频、视频都可以添加超链接</p></li><li><p><strong>锚点链接</strong>：点击这种链接之后会快速前往页面中的某个位置</p><p>比如 <code>&lt;a href=&quot;#two&quot;&gt;&lt;/a&gt;</code> 这种形式，在标识的前面加一个井号。这样可以跳到目标位置的属性。</p><p>目标位置则是通过id来设定，比如说 <code>&lt;h3 id=&quot;two&quot;&gt;11111&lt;/h3&gt;</code>，就是将该标签的id设置为two，以供跳转。</p></li></ol><h2 id="7-注释"><a href="#7-注释" class="headerlink" title="7. 注释"></a>7. 注释</h2><p>注释通过 <code>&lt;!-- --&gt;</code> 来实现，也可以用快捷键 <code>Ctrl + /</code>。</p><h2 id="8-特殊字符"><a href="#8-特殊字符" class="headerlink" title="8. 特殊字符"></a>8. 特殊字符</h2><p>比如空格，需要使用特殊字符来实现，就比较多，需要通过字符代码来打出来，用到的时候可以查一下。</p><pre><code>´    &amp;acute;        ©    &amp;copy;    &gt;    &amp;gt;    µ    &amp;micro;    ®    &amp;reg;&amp;    &amp;amp;        °    &amp;deg;    ¡    &amp;iexcl;        &amp;nbsp;    »    &amp;raquo;¦    &amp;brvbar;    ÷    &amp;divide;    ¿    &amp;iquest;    ¬    &amp;not;    §    &amp;sect;•    &amp;bull;        ½    &amp;frac12;    «    &amp;laquo;    ¶    &amp;para;    ¨    &amp;uml;¸    &amp;cedil;     ¼    &amp;frac14;    &lt;    &amp;lt;    ±    &amp;plusmn;    ×    &amp;times;¢    &amp;cent;      ¾    &amp;frac34;    ¯    &amp;macr;    “    &amp;quot;    ™    &amp;trade;€    &amp;euro;      £    &amp;pound;    ¥    &amp;yen;                „    &amp;bdquo;        …    &amp;hellip;    ·    &amp;middot;    ›    &amp;rsaquo;    ª    &amp;ordf;ˆ    &amp;circ;        “    &amp;ldquo;    —    &amp;mdash;    ’    &amp;rsquo;    º    &amp;ordm;†    &amp;dagger;     ‹    &amp;lsaquo;    –    &amp;ndash;    ‚    &amp;sbquo;    ”    &amp;rdquo;‡    &amp;Dagger;    ‘    &amp;lsquo;    ‰    &amp;permil;        &amp;shy;    ˜    &amp;tilde;≈    &amp;asymp;     ⁄    &amp;frasl;    ←    &amp;larr;    ∂    &amp;part;    ♠    &amp;spades;∩    &amp;cap;       ≥    &amp;ge;    ≤    &amp;le;    ″    &amp;Prime;    ∑    &amp;sum;♣    &amp;clubs;     ↔    &amp;harr;    ◊    &amp;loz;    ′    &amp;prime;    ↑    &amp;uarr;↓    &amp;darr;      ♥    &amp;hearts;    −    &amp;minus;    ∏    &amp;prod;    ‍    &amp;zwj;♦    &amp;diams;     ∞    &amp;infin;    ≠    &amp;ne;    √    &amp;radic;    ‌    &amp;zwnj;≡    &amp;equiv;        ∫    &amp;int;    ‾    &amp;oline;    →    &amp;rarr;        α    &amp;alpha;     η    &amp;eta;    μ    &amp;mu;    π    &amp;pi;    θ    &amp;theta;β    &amp;beta;         γ    &amp;gamma;    ν    &amp;nu;    ψ    &amp;psi;    υ    &amp;upsilon;χ    &amp;chi;        ι    &amp;iota;    ω    &amp;omega;    ρ    &amp;rho;    ξ    &amp;xi;δ    &amp;delta;        κ    &amp;kappa;    ο    &amp;omicron;    σ    &amp;sigma;    ζ    &amp;zeta;ε    &amp;epsilon;    λ    &amp;lambda;    φ    &amp;phi;    τ    &amp;tau;        Α    &amp;Alpha;        Η    &amp;Eta;    Μ    &amp;Mu;    Π    &amp;Pi;    Θ    &amp;Theta;Β    &amp;Beta;        Γ    &amp;Gamma;    Ν    &amp;Nu;    Ψ    &amp;Psi;    Υ    &amp;Upsilon;Χ    &amp;Chi;        Ι    &amp;Iota;    Ω    &amp;Omega;    Ρ    &amp;Rho;    Ξ    &amp;Xi;Δ    &amp;Delta;        Κ    &amp;Kappa;    Ο    &amp;Omicron;    Σ    &amp;Sigma;    Ζ    &amp;Zeta;Ε    &amp;Epsilon;    Λ    &amp;Lambda;    Φ    &amp;Phi;    Τ    &amp;Tau;    ς    &amp;sigmaf;</code></pre><h1 id="表格标签"><a href="#表格标签" class="headerlink" title="表格标签"></a>表格标签</h1><h2 id="1-基本语法"><a href="#1-基本语法" class="headerlink" title="1. 基本语法"></a>1. 基本语法</h2><p>表格用于展示数据，其结构化的显示使得可读性很好。主要是通过三个标签来实现，具体可以看例子。</p><p>对于如下所示的表格：</p><p><img src="/2021/01/04/html/1_html/image-20210103204241996.png" alt="表格标签基本语法"></p><p>需要写成下面这样：</p><pre><code class="html">&lt;table&gt;    &lt;!-- tr表示新起一行 --&gt;    &lt;tr&gt;        &lt;!-- td表示在当前行中的一个单元格 --&gt;        &lt;td&gt;(1,1)&lt;/td&gt;        &lt;td&gt;(1,2)&lt;/td&gt;        &lt;td&gt;(1,3)&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;        &lt;td&gt;(1,1)&lt;/td&gt;        &lt;td&gt;(2,2)&lt;/td&gt;        &lt;td&gt;(2,3)&lt;/td&gt;    &lt;/tr&gt;    &lt;tr&gt;        &lt;td&gt;(3,1)&lt;/td&gt;        &lt;td&gt;(3,2)&lt;/td&gt;        &lt;td&gt;(3,3)&lt;/td&gt;    &lt;/tr&gt;&lt;/table&gt;</code></pre><h2 id="2-表头标签"><a href="#2-表头标签" class="headerlink" title="2. 表头标签"></a>2. 表头标签</h2><p>表头一般来说在表格中都是比较特殊的，会加粗并且居中显示。</p><p>在HTML中，表头使用 <code>&lt;th&gt;表头&lt;/th&gt;</code> 的形式来写，表示table head，例如下面的示意图与代码可匹配</p><p><img src="/2021/01/04/html/1_html/image-20210103204650098.png" alt="添加表头标签"></p><pre><code class="html">&lt;table&gt;    &lt;!-- tr表示新起一行 --&gt;    &lt;tr&gt;        &lt;th&gt;第一列&lt;/th&gt;        &lt;th&gt;第二列&lt;/th&gt;        &lt;th&gt;第三列&lt;/th&gt;    &lt;/tr&gt;    &lt;tr&gt;        &lt;!-- td表示在当前行中的一个单元格 --&gt;        &lt;td&gt;(1,1)&lt;/td&gt;        &lt;td&gt;(1,2)&lt;/td&gt;        &lt;td&gt;(1,3)&lt;/td&gt;    &lt;/tr&gt;&lt;/table&gt;</code></pre><h2 id="3-表格属性（原生）"><a href="#3-表格属性（原生）" class="headerlink" title="3. 表格属性（原生）"></a>3. 表格属性（原生）</h2><p>设置表格样式的属性一般都是要写在 table 标签内部的。</p><ol><li><p>对齐方式</p><p>通过align属性来设置，可取值为 <code>center  left  right</code> 三个。比如将其设置为center，该表格将会在页面居中显示。</p><pre><code class="html">&lt;table align=&quot;center&quot;&gt;</code></pre></li><li><p>边框（指最外侧的框）</p><p><img src="/2021/01/04/html/1_html/image-20210103205521674.png" alt="表格边框"></p><pre><code class="html">&lt;table border=10&gt;</code></pre></li><li><p>（内部空隙）单元格<strong>边缘与内容间</strong>的像素值</p><p>（这里为了更直观表现，就把边框的大小设置为10）</p><p><img src="/2021/01/04/html/1_html/image-20210103205753251.png" alt="内部空隙"></p><pre><code class="html">&lt;table border=10 cellpadding=10&gt;</code></pre></li><li><p>（外部空隙）<strong>单元格之间</strong>的空白</p><p>（这里为了更直观表现，就把边框的大小设置为10）</p><p><img src="/2021/01/04/html/1_html/image-20210103205710820.png" alt="单元格空白"></p><pre><code class="html">&lt;table border=10 cellspacing=10&gt;</code></pre></li><li><p>表格宽度、高度：就是设置每个单元格的固定宽度</p><p>（这里为了更直观表现，就把边框的大小设置为10）</p><p><img src="/2021/01/04/html/1_html/image-20210103205842770.png" alt="表格宽高设置"></p><pre><code class="html">&lt;table border=10 width=10 height=20&gt;</code></pre></li></ol><h2 id="4-表格结构标签"><a href="#4-表格结构标签" class="headerlink" title="4. 表格结构标签"></a>4. 表格结构标签</h2><p>在table标签内部，可以将表格给分成两个区域：头部区域和主体区域。主要就是让表格的结构变得更加清晰一些，最终的展示效果不变。</p><p>其中需要注意的是thead中必须要包含tr标签，并且都是位于第一行的，并且这两个标签都需要包含在table的大标签之中。</p><p><img src="/2021/01/04/html/1_html/image-20210103210626609.png" alt="表格标签内部结构"></p><pre><code class="html">&lt;table border=1&gt;    &lt;thead&gt;        &lt;tr&gt;            &lt;th&gt;第一列&lt;/th&gt; &lt;th&gt;第二列&lt;/th&gt; &lt;th&gt;第三列&lt;/th&gt;        &lt;/tr&gt;    &lt;/thead&gt;    &lt;tbody&gt;        &lt;tr&gt;            &lt;!-- td表示在当前行中的一个单元格 --&gt;            &lt;td&gt;(1,1)&lt;/td&gt; &lt;td&gt;(1,2)&lt;/td&gt; &lt;td&gt;(1,3)&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;(1,1)&lt;/td&gt; &lt;td&gt;(2,2)&lt;/td&gt; &lt;td&gt;(2,3)&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;(3,1)&lt;/td&gt; &lt;td&gt;(3,2)&lt;/td&gt; &lt;td&gt;(3,3)&lt;/td&gt;        &lt;/tr&gt;    &lt;/tbody&gt;&lt;/table&gt;</code></pre><h2 id="5-合并单元格"><a href="#5-合并单元格" class="headerlink" title="5. 合并单元格"></a>5. 合并单元格</h2><p>合并单元格有两种方式：</p><ul><li>跨行合并：<code>rowspan=&quot;合并单元格的个数&quot;</code></li><li>跨列合并：<code>colspan=&quot;合并单元格的个数&quot;</code></li></ul><p>合并代码要写在目标单元格之中，根据合并方式的不同，目标单元格为：</p><ul><li>跨行合并：最上方的单元格中写合并代码</li><li>跨列合并：最左侧的单元格中写合并代码</li></ul><p>其实也很简单，代码和效果如下图所示：</p><p><img src="/2021/01/04/html/1_html/image-20210103211216925.png" alt="合并单元格"></p><pre><code class="html">&lt;table border=1&gt;    &lt;thead&gt;        &lt;!-- tr表示新起一行 --&gt;        &lt;tr&gt;            &lt;th&gt;第一列&lt;/th&gt; &lt;th&gt;第二列&lt;/th&gt; &lt;th&gt;第三列&lt;/th&gt;        &lt;/tr&gt;    &lt;/thead&gt;    &lt;tbody&gt;        &lt;tr&gt;            &lt;!-- td表示在当前行中的一个单元格 --&gt;            &lt;td colspan=&quot;2&quot;&gt;(1,1)&lt;/td&gt; &lt;td&gt;(1,2)&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;(1,1)&lt;/td&gt; &lt;td&gt;(2,2)&lt;/td&gt; &lt;td rowspan=&quot;2&quot;&gt;(2,3)&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;(3,1)&lt;/td&gt; &lt;td&gt;(3,2)&lt;/td&gt;        &lt;/tr&gt;    &lt;/tbody&gt;&lt;/table&gt;</code></pre><h1 id="列表标签"><a href="#列表标签" class="headerlink" title="列表标签"></a>列表标签</h1><p>列表用于布局，其最大的特点就是整齐、整洁、有序，且使用起来会很方便。</p><h2 id="1-无序列表"><a href="#1-无序列表" class="headerlink" title="1. 无序列表"></a>1. 无序列表</h2><p>无序列表的特点就是各个项目之间整齐并且没有顺序。</p><p>无序列表使用 <code>&lt;ul&gt;</code> 标签定义，其中的列表项使用 <code>&lt;li&gt;</code> 标签定义。此外需要注意，<strong><code>&lt;ul&gt;</code> 标签中只能放 <code>&lt;li&gt;</code> 标签</strong>，不能放其他元素，但是 <code>&lt;li&gt;</code> 中可以放其他的内容。</p><p>此外，无序列表会带有自己的样式属性（比如前面黑色的小圆点），但是在实际使用的时候经常用CSS来设置。</p><p><img src="/2021/01/04/html/1_html/image-20210104092044537.png" alt="无序列表"></p><pre><code class="html">&lt;ul&gt;    &lt;li&gt;第一行&lt;/li&gt;    &lt;li&gt;第二行&lt;/li&gt;    &lt;li&gt;第三行&lt;/li&gt;    &lt;li&gt;第四行&lt;/li&gt;&lt;/ul&gt;</code></pre><h2 id="2-有序列表"><a href="#2-有序列表" class="headerlink" title="2. 有序列表"></a>2. 有序列表</h2><p>各个小选项之间有一定的顺序，此时选用有序列表来实现。</p><p>有序列表使用 <code>&lt;ol&gt;</code> 标签定义，在其内部也是使用 <code>&lt;li&gt;</code> 标签来定义。关于这个标签，使用方式与无序列表是一样的，有相同的要求需要满足。</p><p>通常来说，默认的有序列表前面使用数字来标注其顺序。</p><p><img src="/2021/01/04/html/1_html/image-20210104092457278.png" alt="有序列表"></p><pre><code class="html">&lt;ol&gt;    &lt;li&gt;第一行&lt;/li&gt;    &lt;li&gt;第二行&lt;/li&gt;    &lt;li&gt;第三行&lt;/li&gt;    &lt;li&gt;第四行&lt;/li&gt;&lt;/ol&gt;</code></pre><h2 id="3-自定义列表"><a href="#3-自定义列表" class="headerlink" title="3. 自定义列表"></a>3. 自定义列表</h2><p>比如某个对于某个标题，都有几个子选项会对其进行说明，此时使用自定义列表。</p><p>自定义列表使用的标签有三个，<code>&lt;dl&gt;</code>  <code>&lt;dt&gt;</code>   <code>&lt;dd&gt;</code>。对于这些标签也是一样的规矩，只有一个dl，并且dl中只能包含dt和dd，dt和dd中可以是各种内容。</p><ul><li><code>&lt;dl&gt;</code>：用来包裹住整个自定义列表</li><li><code>&lt;dt&gt;</code>：相当于标题</li><li><code>&lt;dd&gt;</code>：围绕dt进行解释的子选项</li></ul><p><img src="/2021/01/04/html/1_html/image-20210104093131113.png" alt="自定义列表"></p><pre><code class="html">&lt;dl&gt;    &lt;dt&gt;标题&lt;/dt&gt;    &lt;dd&gt;解释1&lt;/dd&gt;    &lt;dd&gt;解释2&lt;/dd&gt;    &lt;dd&gt;解释3&lt;/dd&gt;&lt;/dl&gt;</code></pre><h1 id="表单标签"><a href="#表单标签" class="headerlink" title="表单标签"></a>表单标签</h1><p>一个完整的表单需要有：<strong>表单域</strong>、<strong>表单控件</strong>、<strong>提示信息</strong>三大部分组成。</p><h2 id="1-表单域"><a href="#1-表单域" class="headerlink" title="1. 表单域"></a>1. 表单域</h2><p>表单域使用 <code>&lt;form&gt;</code> 标签来实现，相当于是用来声明一个空间，然后在里面填写表单控件和相对应的提示信息。</p><p>其中的属性有：</p><ul><li><code>&lt;action&gt;</code>：是一个URL地址，用于指定接收并处理表单数据的服务器URL地址</li><li><code>&lt;method&gt;</code>：get或post方法，用于设置表单的提交方式</li><li><code>&lt;name&gt;</code>：表单名称，用于区分同一个页面中的多个表单域</li></ul><pre><code class="html">&lt;form action=&quot;url&quot; method=&quot;POST&quot; name=&quot;name1&quot;&gt;    &lt;!-- ... --&gt;&lt;/form&gt;</code></pre><h2 id="2-表单控件"><a href="#2-表单控件" class="headerlink" title="2. 表单控件"></a>2. 表单控件</h2><p>表单元素是在表单域中定义的各种表单元素，就是用户可以输入或者选择内容的控件</p><h3 id="2-1-输入表单"><a href="#2-1-输入表单" class="headerlink" title="2.1 输入表单"></a>2.1 输入表单</h3><p>输入表单最核心的内容是input标签，同时还有一个label标签与其配合使用。</p><p><code>&lt;label&gt;</code>：该标签用于给input元素定义标注（说明），用来绑定表单元素，当点击label标签内的文本时，就会自动将鼠标选中到表单中，增加用户体验。</p><p>使用方式是通过for和id来使用，保证label的for是input的id即可。</p><pre><code class="html">&lt;label for=&quot;test&quot;&gt;aaa &lt;/label&gt;&lt;input type=&quot;text&quot; id=&quot;test&quot;/&gt;</code></pre><p><code>&lt;input&gt;</code>：输入表单元素，用于收集用户的信息。</p><pre><code class="html">&lt;input type=&quot;属性值&quot; name=&quot;&quot; value=&quot;&quot; checked=&quot;checked&quot; maxlength=&quot;正整数&quot;/&gt;</code></pre><ul><li><p><strong>name</strong></p><p>用来区分表单，比如当type为checkbox的时候，<strong>相同name的box才可以互斥选择</strong></p></li><li><p><strong>value</strong></p><p>直接在表单里面显示出来。同时，如果在checkbox或者radio中写上value，则会在提交的时候得到这个value。主要是针对给后台人员使用的。</p><p>如果只是想用来作为一个占位符，则用placeholder比较好。</p><p><img src="/2021/01/04/html/1_html/image-20210104101228930.png" alt="value"></p></li><li><p><strong>checked</strong></p><p>就是页面一打开就默认被选中的选项，如果不需要默认被选中，则不写这一项</p></li><li><p><strong>maxlength</strong></p><p>表示最大长度，输入框内最多输入的内容长度，当超过这个长度就输入不进去了</p></li><li><p><strong>type</strong></p><ol><li><p>button</p><p><img src="/2021/01/04/html/1_html/image-20210104101704802.png" alt="button"></p></li><li><p>checkbox</p><p><img src="/2021/01/04/html/1_html/image-20210104094751517.png" alt="checkbox"></p></li><li><p>file</p><p><img src="/2021/01/04/html/1_html/image-20210104094820183.png" alt="file"></p></li><li><p>hidden</p><p>此时不会显示。</p></li><li><p>image</p><p><img src="/2021/01/04/html/1_html/image-20210104094852485.png" alt="image"></p></li><li><p>password（默认宽度是20个字符）</p><p><img src="/2021/01/04/html/1_html/image-20210104094908551.png" alt="password"></p></li><li><p>radio</p><p><img src="/2021/01/04/html/1_html/image-20210104094921151.png" alt="radio"></p></li><li><p>reset，点击会清空表单中的所有已输入数据</p><p><img src="/2021/01/04/html/1_html/image-20210104094931581.png" alt="reset"></p></li><li><p>submit，点击之后会进入action中指定的页面，并且将表单中的值送入页面</p><p><img src="/2021/01/04/html/1_html/image-20210104094944662.png" alt="submit"></p></li><li><p>text（默认宽度是20个字符）</p><p><img src="/2021/01/04/html/1_html/image-20210104094958998.png" alt="text"></p></li><li><p>placeholder：当输入内容时，placeholder的内容会自动消失，与value的使用场景不一样，value是默认值，而placeholder中的值是无效的。</p><p><img src="/2021/01/04/html/1_html/image-20210104101823261.png" alt="placeholder"></p></li></ol></li></ul><h3 id="2-2-下拉表单"><a href="#2-2-下拉表单" class="headerlink" title="2.2 下拉表单"></a>2.2 下拉表单</h3><p><code>&lt;select&gt;</code>：下拉表单元素</p><p>下拉标签就是有多种选项可以提供选择，但是又想要节约页面空间，此时可以用select标签来定义下拉标签。</p><p>在select中可以定义 <code>selected=&quot;selected&quot;</code> 表示当前项被默认选中。</p><p><img src="/2021/01/04/html/1_html/image-20210104104058269.png" alt="select"></p><pre><code class="html">&lt;select&gt;    &lt;option selected=&quot;selected&quot;&gt;选项一&lt;/option&gt;    &lt;option&gt;选项二&lt;/option&gt;    &lt;option&gt;选项三&lt;/option&gt;&lt;/select&gt;</code></pre><h3 id="2-3-文本框表单"><a href="#2-3-文本框表单" class="headerlink" title="2.3 文本框表单"></a>2.3 文本框表单</h3><p><code>&lt;textarea&gt;</code>：文本区域表单元素</p><p>就是一个文本框，其中可以设置每行和每列可输入的文字多少，但是实际使用的时候还是用CSS来设置宽高的，这两个属性用的并不多。</p><p>注意，在标签内部文字的状态就是展示的状态。</p><p><img src="/2021/01/04/html/1_html/image-20210104104636141.png" alt="textarea"></p><pre><code class="html">&lt;textarea cols=&quot;30&quot; rows=&quot;5&quot;&gt;            第一行            第二行            第三行第四行        第五行&lt;/textarea&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
          <category> HTML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>07_链码接口使用</title>
      <link href="/2020/12/12/fabric/08_%E9%93%BE%E7%A0%81/"/>
      <url>/2020/12/12/fabric/08_%E9%93%BE%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h1 id="链码实现例子"><a href="#链码实现例子" class="headerlink" title="链码实现例子"></a>链码实现例子</h1><p>这个链码就是fabric例程中给的sacc。</p><h2 id="1-shim"><a href="#1-shim" class="headerlink" title="1. shim"></a>1. shim</h2><p>每个链码都需要实现<strong><code>ChainCode</code>接口</strong>的 <code>Init</code> 和 <code>Invoke</code> 方法，因此需要使用import语句来导入链码必要的依赖。</p><ul><li>第一个是链码shim包</li><li>第二个是peer protobuf包</li></ul><pre><code class="go">package mainimport (    &quot;fmt&quot;    &quot;github.com/hyperledger/fabric-chaincode-go/shim&quot;    &quot;github.com/hyperledger/fabric-protos-go/peer&quot;)</code></pre><p>导包完成后需要加入一个结构体来作为shim方法的接收者</p><pre><code class="go">type SimpleAsset struct {}</code></pre><p>这里面目前还不需要加入什么东西</p><h2 id="2-初始化链码-Init"><a href="#2-初始化链码-Init" class="headerlink" title="2. 初始化链码 Init()"></a>2. 初始化链码 Init()</h2><p>链码的初始化使用 <code>Init</code> 方法完成</p><pre><code class="go">func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {}</code></pre><p>接着，在这一函数中，需要对传入进来的参数进行处理，首先要做的就是获取参数，并对其进行合法性验证</p><pre><code class="go">func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {    // 这里通过ChaincodeStubInterface中的GetStringArgs方法来获取参数    args := stub.GetStringArgs()    // 然后对参数的合法性进行验证，看传入的是否是2个参数    if len(args) != 2 {        return shim.Error(&quot;Incorrect arguments. Expecting a key and a value&quot;)    }}</code></pre><p>到此为止，已经确认传入的参数是合法的，此时将对账本写一个初始值，调用PutState方法</p><pre><code class="go">func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {    // 获取参数    args := stub.GetStringArgs()    // 合法性验证    if len(args) != 2 {        return shim.Error(&quot;Incorrect arguments. Expecting a key and a value&quot;)    }    // 这里调用PutState方法来将key-value键值对写入账本    err := stub.PutState(args[0], []byte(args[1]))    // 下面是对写入结果的处理，成功或者失败    if err != nil {        return shim.Error(fmt.Sprintf(&quot;Failed to create asset: %s&quot;, args[0]))    }    return shim.Success(nil)}</code></pre><h2 id="3-调用链码-Invoke"><a href="#3-调用链码-Invoke" class="headerlink" title="3. 调用链码 Invoke()"></a>3. 调用链码 Invoke()</h2><p>下面就是来实现 <code>Invoke</code> 方法</p><p>首先来定义这个函数，他与Init方法的参数传入、结果返回是一样的，唯一不一样的就是名字（- -!）</p><pre><code class="go">func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {}</code></pre><p>因为执行链码的时候，不管调用的是get还是set，都会首先进入到这个函数里面来，因此在这里面<strong>不仅需要对参数进行解析，还需要对操作的命令进行解析</strong>。</p><p>主要是通过使用 <code>GetFunctionAndParameters</code> 方法来实现的</p><pre><code class="go">func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // 获取操作以及参数    fn, args := stub.GetFunctionAndParameters()}</code></pre><p>在拿到参数之后，需要根据设置参数的不同来进行不同的操作</p><pre><code class="go">func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // 获取操作以及参数    fn, args := stub.GetFunctionAndParameters()    var result string    var err error    // 在这里判断操作的类型是什么，然后再根据具体的操作类型来调用对应的具体方法    if fn == &quot;set&quot; {            result, err = set(stub, args)    } else {            result, err = get(stub, args)    }    // 这里根据两种操作的具体返回结果来判断是否有错    if err != nil {            return shim.Error(err.Error())    }    return shim.Success([]byte(result))}</code></pre><h2 id="4-实现链码"><a href="#4-实现链码" class="headerlink" title="4. 实现链码"></a>4. 实现链码</h2><p>前面已经提到过，链码主要实现了两个功能：set和get，也在前面调用过这这两个函数，因此下面需要对这两个函数进行详细定义</p><ul><li><p><strong>set方法</strong></p><p>set方法需要验证参数的个数是否为2，如果是，则调用PutState方法将结果写入</p></li><li><p><strong>get方法</strong></p><p>get方法也需要验证参数个数是否为1，如果是的话，则调用GetState方法获取结果并写入</p></li></ul><pre><code class="go">func set(stub shim.ChaincodeStubInterface, args []string) (string, error) {    // 验证参数是否合法    if len(args) != 2 {        return &quot;&quot;, fmt.Errorf(&quot;Incorrect arguments. Expecting a key and a value&quot;)    }    // 执行写入操作    err := stub.PutState(args[0], []byte(args[1]))    // 返回操作结果    if err != nil {        return &quot;&quot;, fmt.Errorf(&quot;Failed to set asset: %s&quot;, args[0])    }    return args[1], nil}func get(stub shim.ChaincodeStubInterface, args []string) (string, error) {    // 验证参数是否合法    if len(args) != 1 {        return &quot;&quot;, fmt.Errorf(&quot;Incorrect arguments. Expecting a key&quot;)    }    // 执行读取操作    value, err := stub.GetState(args[0])    // 返回操作结果    if err != nil {        return &quot;&quot;, fmt.Errorf(&quot;Failed to get asset: %s with error: %s&quot;, args[0], err)    }    if value == nil {        return &quot;&quot;, fmt.Errorf(&quot;Asset not found: %s&quot;, args[0])    }    return string(value), nil}</code></pre><h1 id="链码API"><a href="#链码API" class="headerlink" title="链码API"></a>链码API</h1><p>链码调用最关键的就是 <code>shim.ChaincodeStubInterface</code> 这个接口，里面提供了很多相关的操作，这里对这些操作进行说明</p><h2 id="GetArgs"><a href="#GetArgs" class="headerlink" title="GetArgs"></a>GetArgs</h2><p>返回链码交易参数</p><pre><code class="go">// GetArgs 返回链码交易参数，返回类型是 [][]byteGetArgs() [][]byte</code></pre><h2 id="GetStringArgs"><a href="#GetStringArgs" class="headerlink" title="GetStringArgs"></a>GetStringArgs</h2><pre><code class="go">// GetStringArgs 获取链码交易的指定参数，返回类型是string数组// # {&quot;Args&quot;:[&quot;set&quot;,&quot;tom&quot;,&quot;100&quot;]}// args = stub.GetStringArgs()// fmt.Println(args)// # 输出结果// [&quot;set&quot;,&quot;tom&quot;,&quot;100&quot;]GetStringArgs() []string</code></pre><h2 id="GetFunctionAndParameters"><a href="#GetFunctionAndParameters" class="headerlink" title="GetFunctionAndParameters"></a>GetFunctionAndParameters</h2><pre><code class="go">// 获取调用链码交易中的参数，其中第一个参数作为被调用的函数名称，// 其余的参数作为函数的执行参数,是一个string数组// # {&quot;Args&quot;:[&quot;set&quot;,&quot;tom&quot;,&quot;100&quot;]}// fn, args := stub.GetFunctionAndParameters()// fmt.Println(fn, args)// # 输出结果// set [&quot;tom&quot;, &quot;100&quot;]GetFunctionAndParameters() (string, []string)</code></pre><h2 id="GetArgsSlice"><a href="#GetArgsSlice" class="headerlink" title="GetArgsSlice"></a>GetArgsSlice</h2><pre><code class="go">// GetArgsSlice 返回链码交易参数，返回类型是 byte数组GetArgsSlice() ([]byte, error)</code></pre><h2 id="GetTxID"><a href="#GetTxID" class="headerlink" title="GetTxID"></a>GetTxID</h2><pre><code class="go">// GetTxID 获取当前交易的tx_id，每一笔交易和每一个客户端是唯一的GetTxID() string</code></pre><h2 id="GetChannelID"><a href="#GetChannelID" class="headerlink" title="GetChannelID"></a>GetChannelID</h2><pre><code class="go">// GetChannelID 返回处理链码提议的通道channelGetChannelID() string</code></pre><h2 id="InvokeChaincode"><a href="#InvokeChaincode" class="headerlink" title="InvokeChaincode"></a>InvokeChaincode</h2><pre><code class="go">// 调用另一个链码中的 Invoke 方法,也就是不同链码之间进行通信的方式// InvokeChaincode 使用相同的交易上下文本地调用指定的链码Invoke。// 也就是说链码调用不创建一笔新的交易.// (1) 如果被调用的链码在相同的channel中，可以简化为 被调用链码的读集和写集 追加到 调用链码的交易中// (2) 如果是在不同的chanel中， 只有被调用链码的响应结果 追加到调用链码交易中。// 任何被调用链码的PutState不会写入到账本，也就是说不同通道的被调用链码不会产生交易读写集。// 只有调用链码的读写集才会写入到交易。// 实际上，不同channel的链码调用只是一个Query查询，不参加提交阶段的世界状态的验证。InvokeChaincode(chaincodeName string, args [][]byte, channel string) pb.Response</code></pre><h2 id="GetState"><a href="#GetState" class="headerlink" title="GetState"></a>GetState</h2><pre><code class="go">// GetState 负责查询账本，返回指定key的对应value值// 注意GetState不是从(writeset)写集 中读取数据，所以读取不到尚未提交的数据，// 也读取不到被PutState修改了但是尚未提交的数据// 如果key在账本中不存在，返回nil// strValue , err := stub.GetState(&quot;str&quot;)// if err != nil {//     fmt.Println(&quot;str GetState error: &quot;+err.Error()) }else {//     fmt.Printf(&quot;str value: %s \n&quot;,string(strValue))// }// # 输出结果// str value: helloGetState(key string) ([]byte, error)</code></pre><h2 id="PutState"><a href="#PutState" class="headerlink" title="PutState"></a>PutState</h2><pre><code class="go">// PutState设置一对指定的 `key` 和 `value` 到交易写集(writeset) 作为一个数据写提议。// 只有这笔交易被验证并且成功提交后才会写入到账本。//简单的key值不能是空字符串，并且不能以null字符开头，// 如果使用CouchDB，keys的值只能包含有效的UTF-8字符串，并且不能以&quot;_&quot;开头// 在账本中添加或更新一对键值。key是string类型，value是byte数组// err := stub.PutState(&quot;str&quot;,[]byte(&quot;hello&quot;))// if err != nil {//     fmt.Println(&quot;str PutState error: &quot;+err.Error()) }//  else{//     fmt.Println(&quot;str PutState success!&quot;)// }PutState(key string, value []byte) error</code></pre><h2 id="DelState"><a href="#DelState" class="headerlink" title="DelState"></a>DelState</h2><pre><code class="go">// DelState 交易提议的写集(writeset)中指定key的记录将会被删除。// key和key对应的value将会从账本中被删除，当交易被验证通过并成功提交后。DelState(key string) error</code></pre><h2 id="SetStateValidationParameter"><a href="#SetStateValidationParameter" class="headerlink" title="SetStateValidationParameter"></a>SetStateValidationParameter</h2><pre><code class="go">// 为`key`设置密钥级背书策略。SetStateValidationParameter(key string, ep []byte) error</code></pre><h2 id="GetStateValidationParameter"><a href="#GetStateValidationParameter" class="headerlink" title="GetStateValidationParameter"></a>GetStateValidationParameter</h2><pre><code class="go">//检索key-level背书策略用于GetStateValidationParameter(key string) ([]byte, error)</code></pre><h2 id="GetStateByRange"><a href="#GetStateByRange" class="headerlink" title="GetStateByRange"></a>GetStateByRange</h2><pre><code class="go">// GetStateByRange 查询指定范围内的键值，startKey 为起始 key，endKey为终止 keyGetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error)</code></pre><h2 id="GetStateByRangeWithPagination"><a href="#GetStateByRangeWithPagination" class="headerlink" title="GetStateByRangeWithPagination"></a>GetStateByRangeWithPagination</h2><pre><code class="go">// GetStateByRangeWithPagination返回账本中一组键的范围迭代器。迭代器可用于在startKey（包含）和endKey（包含）之间获取密钥。GetStateByRangeWithPagination(startKey, endKey string, pageSize int32,     bookmark string) (StateQueryIteratorInterface, *pb.QueryResponseMetadata, error)</code></pre><h2 id="GetStateByPartialCompositeKey"><a href="#GetStateByPartialCompositeKey" class="headerlink" title="GetStateByPartialCompositeKey"></a>GetStateByPartialCompositeKey</h2><pre><code class="go">// GetStateByPartialCompositeKey基于给定的部分组合键查询账本中的状态。 此函数返回一个迭代器，该迭代器可用于迭代其前缀与给定的部分组合键匹配的所有组合键。GetStateByPartialCompositeKey(objectType string, keys []string) (StateQueryIteratorInterface, error)</code></pre><h2 id="GetStateByPartialCompositeKeyWithPagination"><a href="#GetStateByPartialCompositeKeyWithPagination" class="headerlink" title="GetStateByPartialCompositeKeyWithPagination"></a>GetStateByPartialCompositeKeyWithPagination</h2><pre><code class="go">// GetStateByPartialCompositeKeyWithPagination根据给定的部分组合键查询账本中的状态。此函数返回一个迭代器，该迭代器可用于对前缀与给定的部分组合键匹配的组合键进行迭代。GetStateByPartialCompositeKeyWithPagination(objectType string, keys []string,     pageSize int32, bookmark string) (StateQueryIteratorInterface, *pb.QueryResponseMetadata, error)</code></pre><h2 id="CreateCompositeKey"><a href="#CreateCompositeKey" class="headerlink" title="CreateCompositeKey"></a>CreateCompositeKey</h2><pre><code class="go">// 给定一组属性attributes，将这些属性组合起来构造一个复合键//对象类型和熟悉值只能是有效的utf8字符串，并且不能包含 U+0000 (nil byte) and U+10FFFFCreateCompositeKey(objectType string, attributes []string) (string, error)</code></pre><h2 id="SplitCompositeKey"><a href="#SplitCompositeKey" class="headerlink" title="SplitCompositeKey"></a>SplitCompositeKey</h2><pre><code class="go">// 给定一个复合键，将其拆分为复合键所用的属性// 组合键常用于范围查询或者部分组合键查询SplitCompositeKey(compositeKey string) (string, []string, error)</code></pre><h2 id="GetQueryResult"><a href="#GetQueryResult" class="headerlink" title="GetQueryResult"></a>GetQueryResult</h2><pre><code class="go">// GetQueryResult 是对世界状态数据库进行富查询，仅有 couchDB 支持// 查询语句采用 底层状态数据库的语法。返回的StateQueryIterator可用于遍历查询 结果集。GetQueryResult(query string) (StateQueryIteratorInterface, error)</code></pre><h2 id="GetQueryResultWithPagination"><a href="#GetQueryResultWithPagination" class="headerlink" title="GetQueryResultWithPagination"></a>GetQueryResultWithPagination</h2><pre><code class="go">// GetQueryResultWithPagination对状态数据库执行“富”查询。//仅支持支持丰富查询的状态数据库（例如CouchDB）支持。 返回一个迭代器，该迭代器可用于迭代查询结果集中的键。GetQueryResultWithPagination(query string, pageSize int32,     bookmark string) (StateQueryIteratorInterface, *pb.QueryResponseMetadata, error)</code></pre><h2 id="GetHistoryForKey"><a href="#GetHistoryForKey" class="headerlink" title="GetHistoryForKey"></a>GetHistoryForKey</h2><pre><code class="go">// 返回某个key的历史记录// 对应key的每一次历史更新，相关的交易id和timestamp时间戳的历史记录value值都会返回// timestamp 是客户端proposal header中的timestamp// peer配置中 core.ledger.history.enableHistoryDatabase=true 才生效GetHistoryForKey(key string) (HistoryQueryIteratorInterface, error)</code></pre><h2 id="GetPrivateData"><a href="#GetPrivateData" class="headerlink" title="GetPrivateData"></a>GetPrivateData</h2><pre><code class="go">// 返回指定指定集合collection中的指定key的value值GetPrivateData(collection, key string) ([]byte, error)</code></pre><h2 id="GetPrivateDataHash"><a href="#GetPrivateDataHash" class="headerlink" title="GetPrivateDataHash"></a>GetPrivateDataHash</h2><pre><code class="go">// 返回指定指定集合collection中的指定key的hashGetPrivateDataHash(collection, key string) ([]byte, error)</code></pre><h2 id="PutPrivateData"><a href="#PutPrivateData" class="headerlink" title="PutPrivateData"></a>PutPrivateData</h2><pre><code class="go">// PutPrivateData 将指定的key和value对写入到交易私有写集（private writeset）// 注意只有 私有写集private writeset 的hash进入到交易提案的响应，// 事实上 私有写集private writeset临时存储了数据// PutPrivateData不会写入到 collection中，直到交易被验证和成功提交。PutPrivateData(collection string, key string, value []byte) error</code></pre><h2 id="DelPrivateData"><a href="#DelPrivateData" class="headerlink" title="DelPrivateData"></a>DelPrivateData</h2><pre><code class="go">// DelState 删除 交易私有写集private writeset 中指定key对应的记录DelPrivateData(collection, key string) error</code></pre><h2 id="SetPrivateDataValidationParameter"><a href="#SetPrivateDataValidationParameter" class="headerlink" title="SetPrivateDataValidationParameter"></a>SetPrivateDataValidationParameter</h2><pre><code class="go">// 设置由key指定的私有数据的密钥级背书策略。SetPrivateDataValidationParameter(collection, key string, ep []byte) error</code></pre><h2 id="GetPrivateDataValidationParameter"><a href="#GetPrivateDataValidationParameter" class="headerlink" title="GetPrivateDataValidationParameter"></a>GetPrivateDataValidationParameter</h2><pre><code class="go">// 获取由key指定的私有数据的密钥级背书策略。GetPrivateDataValidationParameter(collection, key string) ([]byte, error)</code></pre><h2 id="GetPrivateDataByRange"><a href="#GetPrivateDataByRange" class="headerlink" title="GetPrivateDataByRange"></a>GetPrivateDataByRange</h2><pre><code class="go">// 望文生义即可GetPrivateDataByRange(collection, startKey, endKey string) (StateQueryIteratorInterface, error)</code></pre><h2 id="GetPrivateDataByPartialCompositeKey"><a href="#GetPrivateDataByPartialCompositeKey" class="headerlink" title="GetPrivateDataByPartialCompositeKey"></a>GetPrivateDataByPartialCompositeKey</h2><pre><code class="go">GetPrivateDataByPartialCompositeKey(collection, objectType string, keys []string) (StateQueryIteratorInterface, error)</code></pre><h2 id="GetPrivateDataQueryResult"><a href="#GetPrivateDataQueryResult" class="headerlink" title="GetPrivateDataQueryResult"></a>GetPrivateDataQueryResult</h2><pre><code class="go">GetPrivateDataQueryResult(collection, query string) (StateQueryIteratorInterface, error)</code></pre><h2 id="GetCreator"><a href="#GetCreator" class="headerlink" title="GetCreator"></a>GetCreator</h2><pre><code class="go">// // 查询 `SignedProposal`的`SignatureHeader.Creator`GetCreator() ([]byte, error)</code></pre><h2 id="GetTransient"><a href="#GetTransient" class="headerlink" title="GetTransient"></a>GetTransient</h2><pre><code class="go">GetTransient() (map[string][]byte, error)</code></pre><h2 id="GetBinding"><a href="#GetBinding" class="headerlink" title="GetBinding"></a>GetBinding</h2><pre><code class="go">GetBinding() ([]byte, error)</code></pre><h2 id="GetDecorations"><a href="#GetDecorations" class="headerlink" title="GetDecorations"></a>GetDecorations</h2><pre><code class="go">GetDecorations() map[string][]byte</code></pre><h2 id="GetSignedProposal"><a href="#GetSignedProposal" class="headerlink" title="GetSignedProposal"></a>GetSignedProposal</h2><pre><code class="go">GetSignedProposal() (*pb.SignedProposal, error)</code></pre><h2 id="GetTxTimestamp"><a href="#GetTxTimestamp" class="headerlink" title="GetTxTimestamp"></a>GetTxTimestamp</h2><pre><code class="go">GetTxTimestamp() (*timestamp.Timestamp, error)</code></pre><h2 id="SetEvent"><a href="#SetEvent" class="headerlink" title="SetEvent"></a>SetEvent</h2><pre><code class="go">SetEvent(name string, payload []byte) error</code></pre><h1 id="常用API"><a href="#常用API" class="headerlink" title="常用API"></a>常用API</h1><ul><li><p><code>GetArgs() [][]byte</code></p><p>GetArgs 返回链码交易参数，返回类型是 [][]byte</p></li><li><p><code>GetStringArgs() []string</code></p><p>GetStringArgs 获取链码交易的指定参数，返回类型是string数组</p><pre><code class="go">//{&quot;Args&quot;:[&quot;set&quot;,&quot;tom&quot;,&quot;100&quot;]}args = stub.GetStringArgs()fmt.Println(args)// 输出结果[&quot;set&quot;,&quot;tom&quot;,&quot;100&quot;]12345</code></pre></li><li><p><code>GetFunctionAndParameters() (string, []string)</code></p><p> 获取调用链码交易中的参数，其中第一个参数作为被调用的函数名称,其余的参数作为函数的执行参数,是一个string数组</p><pre><code class="go">// {&quot;Args&quot;:[&quot;set&quot;,&quot;tom&quot;,&quot;100&quot;]}fn, args := stub.GetFunctionAndParameters()fmt.Println(fn, args)// 输出结果set [&quot;tom&quot;, &quot;100&quot;]//12345</code></pre></li><li><p><code>GetArgsSlice() ([]byte, error)</code></p><p>返回链码交易参数，返回类型是 byte数组</p></li><li><p><code>GetTxID() string</code></p><p>获取当前交易的tx_id，每一笔交易和每一个客户端是唯一的</p></li><li><p><code>GetChannelID() string</code></p><p>返回处理链码提议的通道channel</p></li><li><p><code>InvokeChaincode(chaincodeName string, args [][]byte, channel string) pb.Response</code></p><p>调用另一个链码中的 Invoke 方法,也就是不同链码之间进行通信的方式<br>InvokeChaincode 使用相同的交易上下文本地调用指定的链码Invoke。<br>也就是说链码调用不创建一笔新的交易.<br>(1) 如果被调用的链码在相同的channel中，可以简化为 被调用链码的读集和写集 追加到 调用链码的交易中<br>(2) 如果是在不同的chanel中， 只有被调用链码的响应结果 追加到调用链码交易中。<br>任何被调用链码的PutState不会写入到账本，也就是说不同通道的被调用链码不会产生交易读写集。<br>只有调用链码的读写集才会写入到交易。<br>实际上，不同channel的链码调用只是一个Query查询，不参加提交阶段的世界状态的验证。</p><pre><code class="go">trans:=[][]byte{[]byte(&quot;invoke&quot;),[]byte(&quot;a&quot;),[]byte(&quot;b&quot;),[]byte(&quot;11&quot;)}stub.InvokeChaincode(&quot;mycc&quot;,trans,&quot;mychannel&quot;)12</code></pre></li><li><p><code>GetState(key string) ([]byte, error)</code></p><p>GetState 负责查询账本，返回指定key的对应value值<br>注意GetState不是从(writeset)写集 中读取数据，所以读取不到尚未提交的数据，<br>也读取不到被PutState修改了但是尚未提交的数据<br>如果key在账本中不存在，返回nil</p><pre><code class="go">strValue , err := stub.GetState(&quot;str&quot;)if err != nil {    fmt.Println(&quot;str GetState error: &quot;+err.Error()) }else {     fmt.Printf(&quot;str value: %s \n&quot;,string(strValue))}// # 输出结果 str value: hello1234567</code></pre></li><li><p><code>PutState(key string, value []byte) error</code></p><p>PutState设置一对指定的 <code>key</code> 和 <code>value</code> 到交易写集(writeset) 作为一个数据写提议。<br>只有这笔交易被验证并且成功提交后才会写入到账本。<br>简单的key值不能是空字符串，并且不能以null字符开头，<br>如果使用CouchDB，keys的值只能包含有效的UTF-8字符串，并且不能以”_”开头<br>在账本中添加或更新一对键值。key是string类型，value是byte数组</p><pre><code class="go"> err := stub.PutState(&quot;str&quot;,[]byte(&quot;hello&quot;)) if err != nil {     fmt.Println(&quot;str PutState error: &quot;+err.Error()) } else{     fmt.Println(&quot;str PutState success!&quot;) }123456</code></pre></li><li><p><code>DelState(key string) error</code></p><p>DelState 交易提议的写集(writeset)中指定key的记录将会被删除。</p><p>key和key对应的value将会从账本中被删除，当交易被验证通过并成功提交后。</p><pre><code class="go">err = stub.DelState(&quot;str&quot;)1</code></pre></li><li><p><code>GetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error)</code></p><p>GetStateByRange 查询指定范围内的键值，startKey 为起始 key，endKey为终止 key</p><p>遍历 startKey (包含) and endKey (不包含)之间的所有key；</p><p>但是，如果startKey 和endKey之间keys的数量大于<code>totalQueryLimit</code> (defined in core.yaml),那么遍历器不能获取到所有的keys。</p><p>keys的集合按照字典顺序返回；</p><p>startKey and endKey可以是空字符串，就是不限定范围的查询。</p><p>遍历结束后要调用StateQueryIteratorInterface 的Close() 方法</p><pre><code class="go">err := stub.PutState(&quot;str&quot;,[]byte(&quot;hello&quot;))err = stub.PutState(&quot;str1&quot;,[]byte(&quot;hello1&quot;))err = stub.PutState(&quot;str2&quot;,[]byte(&quot;hello2&quot;))//startKey=str  endKey=str2resultIterator , err := stub.GetStateByRange(&quot;str&quot; , &quot;str2&quot;)defer resultIterator.Close()fmt.Println(&quot;-----start resultIterator-----&quot;)for resultIterator.HasNext() {item, _ := resultIterator.Next()fmt.Println(string(item.Value)) }fmt.Println(&quot;-----end resultIterator-----&quot;)# 运行结果-----start resultIterator-----hellohello1-----end resultIterator-----12345678910111213141516</code></pre></li><li><p><code>GetHistoryForKey(key string) (HistoryQueryIteratorInterface, error)</code></p><p>返回某个key的历史记录<br>对应key的每一次历史更新，相关的交易id和timestamp时间戳的历史记录value值都会返回<br>timestamp 是客户端proposal header中的timestamp<br>peer配置中 core.ledger.history.enableHistoryDatabase=true 才生效</p><pre><code class="go">historyIterator,err := stub.GetHistoryForKey(&quot;str&quot;)defer historyIterator.Close()fmt.Println(&quot;-----start historyIterator-----&quot;)for resultIterator.HasNext() {item, _ := historyIterator.Next()fmt.Println(string(item.TxId))fmt.Println(string(item.Value))}fmt.Println(&quot;-----end historyIterator-----&quot;)123456789</code></pre></li><li><p><code>CreateCompositeKey(objectType string, attributes []string) (string, error)</code></p><p>给定一组属性attributes，将这些属性组合起来构造一个复合键<br>对象类型和熟悉值只能是有效的utf8字符串，并且不能包含 U+0000 (nil byte) and U+10FFFF</p><pre><code class="go">indexName := &quot;sex~name&quot;indexKey , err :=stub.CreateCompositeKey(indexName,[]string{&quot;boy&quot;,&quot;xiaowang&quot;})value := []byte{0x00}stub.PutState(indexKey,value)fmt.Println(indexKey)indexKey , err =stub.CreateCompositeKey(indexName,[]string{&quot;boy&quot;,&quot;xiaoli&quot;})stub.PutState(indexKey,value)fmt.Println(indexKey) indexKey , err =stub.CreateCompositeKey(indexName,[]string{&quot;girl&quot;,&quot;xiaofang&quot;})fmt.Println(indexKey)stub.PutState(indexKey,value)# 运行结果sex~nameboyxiaowangsex~nameboyxiaolisex~namegirlxiaofang1234567891011121314151617</code></pre></li><li><p><code>GetQueryResult(query string) (StateQueryIteratorInterface, error)</code></p><p>GetQueryResult 是对世界状态数据库进行富查询，仅有 couchDB 支持<br>查询语句采用 底层状态数据库的语法。返回的StateQueryIterator可用于遍历查询 结果集。</p><pre><code class="go">resultIterator , err = stub.GetQueryResult(&quot;{\&quot;selector\&quot;: {\&quot;sex\&quot;:\&quot;boy\&quot;}}&quot; )defer resultIterator.Close()fmt.Println(&quot;-----start resultIterator-----&quot;)for resultIterator.HasNext() {item, _ := resultIterator.Next()fmt.Println(string(item.Value))}fmt.Println(&quot;-----end resultIterator-----&quot;)123456789</code></pre></li><li><p><code>GetPrivateData(collection, key string) ([]byte, error)</code></p><p>返回指定指定集合collection中的指定key的value值, 注意该方法 不会从 私有写集合private writeset 中读取数据，换句话说，GetPrivateData 方法不考虑 PutPrivateData方法修改过但还没有提交的数据。</p></li><li><p><code>GetPrivateDataHash(collection, key string) ([]byte, error)</code></p><p>返回指定指定集合collection中的指定key的hash</p></li><li><p><code>PutPrivateData(collection string, key string, value []byte) error</code></p><p>PutPrivateData 将指定的key和value对写入到交易私有写集（private writeset）<br>注意只有 私有写集private writeset 的hash进入到交易提案的响应，<br>事实上 私有写集private writeset临时存储了数据<br>PutPrivateData不会写入到 collection中，直到交易被验证和成功提交。</p></li><li><p><code>DelPrivateData(collection, key string) error</code><br>DelState 删除 交易私有写集private writeset 中指定key对应的记录</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02_部署调用链码</title>
      <link href="/2020/12/12/fabric/02_%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8%E9%93%BE%E7%A0%81/"/>
      <url>/2020/12/12/fabric/02_%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8%E9%93%BE%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h1 id="部署链码"><a href="#部署链码" class="headerlink" title="部署链码"></a>部署链码</h1><p>这一步用到的链码是example中的链码，存放的位置是：</p><pre><code>fabric-samples/chaincode/sacc</code></pre><p>直接将这个文件夹拷贝到<strong>两个peer节点</strong>，目录为</p><pre><code>peer/chaincode/sacc</code></pre><h2 id="1-安装链码"><a href="#1-安装链码" class="headerlink" title="1. 安装链码"></a>1. 安装链码</h2><p>因为实现Go链码的时候需要Go的标准库之外的一些依赖包（比如说shim），当链码安装到peer的时候，需要将这些包都包含在链码包中，构造称为一个模块，因此需要使用几个命令来处理依赖</p><pre><code class="bash">go mod tidygo mod vendor</code></pre><p>此后就将链码的依赖放进了本地的vendor目录中</p><p>当连同依赖都引入之后，可以调用以下命令将这些依赖包一起放入链码包</p><pre><code class="bash">peer chaincode packagepeer chaincode install </code></pre><h3 id="1-1-打包链码"><a href="#1-1-打包链码" class="headerlink" title="1.1 打包链码"></a>1.1 打包链码</h3><p>在Org1和Org2的peer中，<strong>分别执行</strong>以下步骤，将链码安装到各自的peer上。</p><pre><code class="bash">cd chaincode/sacc/go env -w GO111MODULE=ongo mod init saccgo mod tidygo mod vendor</code></pre><p>打包链码</p><pre><code class="bash">cd peerpeer lifecycle chaincode package chaincode/sacc.tar.gz --path chaincode/sacc --lang golang --label sacc_1</code></pre><h3 id="1-2-org1上安装链码"><a href="#1-2-org1上安装链码" class="headerlink" title="1.2 org1上安装链码"></a>1.2 org1上安装链码</h3><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer lifecycle chaincode install chaincode/sacc.tar.gzpeer lifecycle chaincode queryinstalled # 查询确认一下</code></pre><h3 id="1-3-org2上安装链码"><a href="#1-3-org2上安装链码" class="headerlink" title="1.3 org2上安装链码"></a>1.3 org2上安装链码</h3><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer lifecycle chaincode install chaincode/sacc.tar.gzpeer lifecycle chaincode queryinstalled # 查询确认一下</code></pre><h2 id="2-签名（审议）链码定义"><a href="#2-签名（审议）链码定义" class="headerlink" title="2. 签名（审议）链码定义"></a>2. 签名（审议）链码定义</h2><p>Org1和Org2的peer分别执行以下操作:</p><p>获取Package ID</p><pre><code class="bash">peer lifecycle chaincode queryinstalled</code></pre><p>将Package ID放入环境变量（相同的链码，在不同的peer上，PackageID的值是一样的。但只要链码中有一点变化比如多个空格多个注释，PackageID就会不同，但不同的peer上有不同的PackageID值并不影响链码提交上线）</p><pre><code class="bash">export CC_PACKAGE_ID=sacc_1:b33357c4012471d8bd96ba48fd2a12ada5fedfbfd6d623590295778500a0368d</code></pre><p>签名链码定义。签名链码定义是组织级别的，所以只需要一个peer节点操作，审议结果会通过gossip协议通知到组织内。</p><pre><code class="bash">peer lifecycle chaincode approveformyorg -o orderer.example.com:7050  --channelID channel1 --init-required --name sacc --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $ORDERER_TLSCA</code></pre><ul><li>–package-id标识链码；</li><li>–sequence是整数序列，第一次部署值为1，当链码升级时值为2；</li><li>–init-required 表示链码需要初始化，第一次invoke时，使用–isInit来初始化链码，执行init函数。</li><li>注意：在链码版本升级时，如果旧版本审议时有参数–init-required，则新版本的链码审议时–init-required也必须要有，否则审议通不过。</li></ul><p>查询确认结果</p><pre><code class="bash">peer lifecycle chaincode checkcommitreadiness --channelID channel1 --init-required --name sacc --version 1.0 --sequence 1 --tls --cafile $ORDERER_TLSCA --output json</code></pre><h2 id="3-向channel提交链码定义"><a href="#3-向channel提交链码定义" class="headerlink" title="3. 向channel提交链码定义"></a>3. 向channel提交链码定义</h2><p>当通道内大多数成员都已审议了链码定义后，可以提交链码到通道。提交需要用–peerAddresses来指定Org1和Org2中的两个节点，即需要有满足部署链码策略的足够的成员。组织已经同意了链码定义，因此选择组织中任意一个peer即可。</p><p>首先现将Org2的peer0.org2.example.com的tls证书复制过来，在org1中：</p><pre><code class="bash">mkdir -p peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/</code></pre><p>并且将Org2中该文件夹下的文件拷贝到Org1的该文件夹中</p><p>提交链码</p><pre><code class="bash">cd peerpeer lifecycle chaincode commit -o orderer.example.com:7050 --channelID channel1 --init-required --name sacc --version 1.0 --sequence 1 --tls --cafile $ORDERER_TLSCA --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt</code></pre><p>查询链码是否已经被提交到通道上</p><pre><code class="bash">peer lifecycle chaincode querycommitted --channelID channel1 --name sacc --cafile $ORDERER_TLSCA</code></pre><h1 id="调用链码"><a href="#调用链码" class="headerlink" title="调用链码"></a>调用链码</h1><p>链码调用需要有足够的满足背书策略的节点</p><h2 id="1-初始化链码"><a href="#1-初始化链码" class="headerlink" title="1. 初始化链码"></a>1. 初始化链码</h2><p>因链码定义中有–init-required，所以需要首先调用初始化函数Init。通过–isInit来指定运行Init函数</p><pre><code class="bash">peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt --isInit -c &#39;{&quot;Args&quot;:[&quot;a&quot;,&quot;bb&quot;]}&#39;</code></pre><p>此处因链码Init函数中使用stub.GetStringArgs()来获取参数，所以只需要传递具体值即可，不用传函数名。’{“Args”:[“a”,”bb”]}’</p><h2 id="2-调用链码"><a href="#2-调用链码" class="headerlink" title="2. 调用链码"></a>2. 调用链码</h2><p>此时链码中的Invoke函数，使用stub.GetFunctionAndParameters()来获取参数。第一个参数是函数名，第二个是函数参数的数组。注意需要使用–peerAddresses来收集足够多的背书节点，否则链码虽然会执行，但不会改变账本的数据。</p><pre><code class="bash">peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt  -c &#39;{&quot;Args&quot;:[&quot;set&quot;,&quot;a&quot;,&quot;cc&quot;]}&#39;</code></pre><h2 id="3-查询"><a href="#3-查询" class="headerlink" title="3. 查询"></a>3. 查询</h2><pre><code class="bash">peer chaincode query -C channel1 -n sacc  -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;</code></pre><h1 id="使用SDK-go调用链码"><a href="#使用SDK-go调用链码" class="headerlink" title="使用SDK-go调用链码"></a>使用SDK-go调用链码</h1><h2 id="1-安装SDK"><a href="#1-安装SDK" class="headerlink" title="1. 安装SDK"></a>1. 安装SDK</h2><pre><code class="bash">go get github.com/hyperledger/fabric-sdk-go</code></pre><h2 id="2-配置证书"><a href="#2-配置证书" class="headerlink" title="2. 配置证书"></a>2. 配置证书</h2><p>在peer1中复制org2的TLS证书</p><pre><code class="bash">将 organizations/peerOrganizations/org2.example.com/tlsca/tlsca.org2.example.com-cert.pem放入 peerOrganizations/org2.example.com/tlsca 文件夹中</code></pre><h2 id="3-创建配置文件"><a href="#3-创建配置文件" class="headerlink" title="3. 创建配置文件"></a>3. 创建配置文件</h2><p>创建一个SDK目录（与peer同级），并且编辑 <code>connection-profile.yaml</code> 文件</p><pre><code class="yaml">## Schema version of the content. Used by the SDK to apply the corresponding parsing rules.#version: 1.0.0## The client section used by GO SDK.#client:  # Which organization does this application instance belong to? The value must be the name of an org  # defined under &quot;organizations&quot;  organization: Org1MSP  logging:    level: info  # Global configuration for peer, event service and orderer timeouts  # if this this section is omitted, then default values will be used (same values as below)#  peer:#    timeout:#      connection: 10s#      response: 180s#      discovery:#        # Expiry period for discovery service greylist filter#        # The channel client will greylist peers that are found to be offline#        # to prevent re-selecting them in subsequent retries.#        # This interval will define how long a peer is greylisted#        greylistExpiry: 10s#  eventService:    # the below timeouts are commented out to use the default values that are found in    # &quot;pkg/fab/endpointconfig.go&quot;    # the client is free to override the default values by uncommenting and resetting    # the values as they see fit in their config file#    timeout:#      registrationResponse: 15s#  orderer:#    timeout:#      connection: 15s#      response: 15s#  global:#    timeout:#      query: 180s#      execute: 180s#      resmgmt: 180s#    cache:#      connectionIdle: 30s#      eventServiceIdle: 2m#      channelConfig: 30m#      channelMembership: 30s#      discovery: 10s#      selection: 10m  # Root of the MSP directories with keys and certs.  cryptoconfig:    # path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}    path: ../organizations  # Some SDKs support pluggable KV stores, the properties under &quot;credentialStore&quot;  # are implementation specific  credentialStore:    # [Optional]. Used by user store. Not needed if all credentials are embedded in configuration    # and enrollments are performed elswhere.    path: &quot;./tmp/state-store&quot;    # [Optional]. Specific to the CryptoSuite implementation used by GO SDK. Software-based implementations    # requiring a key store. PKCS#11 based implementations does not.    cryptoStore:      # Specific to the underlying KeyValueStore that backs the crypto key store.      path: ../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/  # [Optional] BCCSP config for the client. Used by GO SDK.  BCCSP:    security:     enabled: true     default:      provider: &quot;SW&quot;     hashAlgorithm: &quot;SHA2&quot;     softVerify: true     level: 256  tlsCerts:    # [Optional]. Use system certificate pool when connecting to peers, orderers (for negotiating TLS) Default: false    systemCertPool: true    # [Optional]. Client key and cert for TLS handshake with peers and orderers    client:      key:        # path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.key        path: ../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/client.key      cert:        # path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.crt        path: ../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/client.crt## [Optional]. But most apps would have this section so that channel objects can be constructed# based on the content below. If an app is creating channels, then it likely will not need this# section.#channels:  # Default channel is used if channel configuration is missing or if defined channel configuration is missing info  # If channel doesn&#39;t define peers then peers from default channel will be used  # If channel doesn&#39;t define orderes then orderes from default channel will be used  # If channel doesn&#39;t define policies then policies from default channel will be used.  # Also, if channel defines policies and some policy info is missing than that missing info will be filled from default channel.  _default:    # Optional. list of peers from participating orgs    peers:      peer0.org1.example.com:        # [Optional]. will this peer be sent transaction proposals for endorsement? The peer must        # have the chaincode installed. The app can also use this property to decide which peers        # to send the chaincode install request. Default: true        endorsingPeer: true        # [Optional]. will this peer be sent query proposals? The peer must have the chaincode        # installed. The app can also use this property to decide which peers to send the        # chaincode install request. Default: true        chaincodeQuery: true        # [Optional]. will this peer be sent query proposals that do not require chaincodes, like        # queryBlock(), queryTransaction(), etc. Default: true        ledgerQuery: true        # [Optional]. will this peer be the target of the SDK&#39;s listener registration? All peers can        # produce events but the app typically only needs to connect to one to listen to events.        # Default: true        eventSource: true    # [Optional]. The application can use these options to perform channel operations like retrieving channel    # config etc.    policies:      #[Optional] options for retrieving channel configuration blocks      queryChannelConfig:        #[Optional] min number of success responses (from targets/peers)        minResponses: 1        #[Optional] channel config will be retrieved for these number of random targets        maxTargets: 1        #[Optional] retry options for query config block        retryOpts:          #[Optional] number of retry attempts          attempts: 5          #[Optional] the back off interval for the first retry attempt          initialBackoff: 500ms          #[Optional] the maximum back off interval for any retry attempt          maxBackoff: 5s          #[Optional] he factor by which the initial back off period is exponentially incremented          backoffFactor: 2.0      #[Optional] options for retrieving discovery info      discovery:        #[Optional] discovery info will be retrieved for these number of random targets        maxTargets: 2        #[Optional] retry options for retrieving discovery info        retryOpts:          #[Optional] number of retry attempts          attempts: 4          #[Optional] the back off interval for the first retry attempt          initialBackoff: 500ms          #[Optional] the maximum back off interval for any retry attempt          maxBackoff: 5s          #[Optional] he factor by which the initial back off period is exponentially incremented          backoffFactor: 2.0      #[Optional] options for the event service      eventService:        # [Optional] resolverStrategy specifies the peer resolver strategy to use when connecting to a peer        # Possible values: [PreferOrg (default), MinBlockHeight, Balanced]        #        # PreferOrg:        #   Determines which peers are suitable based on block height lag threshold, although will prefer the peers in the        #   current org (as long as their block height is above a configured threshold). If none of the peers from the current org        #   are suitable then a peer from another org is chosen.        # MinBlockHeight:        #   Chooses the best peer according to a block height lag threshold. The maximum block height of all peers is        #   determined and the peers whose block heights are under the maximum height but above a provided &quot;lag&quot; threshold are load        #   balanced. The other peers are not considered.        # Balanced:        #   Chooses peers using the configured balancer.        resolverStrategy: PreferOrg        # [Optional] balancer is the balancer to use when choosing a peer to connect to        # Possible values: [Random (default), RoundRobin]        balancer: Random        # [Optional] blockHeightLagThreshold sets the block height lag threshold. This value is used for choosing a peer        # to connect to. If a peer is lagging behind the most up-to-date peer by more than the given number of        # blocks then it will be excluded from selection.        # Note that this parameter is applicable only when minBlockHeightResolverMode is set to ResolveByThreshold.        # Default: 5        blockHeightLagThreshold: 5        # [Optional] reconnectBlockHeightLagThreshold - the event client will disconnect from the peer if the peer&#39;s        # block height falls behind the specified number of blocks and will reconnect to a better performing peer.        # Note that this parameter is only applicable if peerMonitor is set to Enabled (default).        # Default: 10        # NOTES:        #   - Setting this value too low may cause the event client to disconnect/reconnect too frequently, thereby        #     affecting performance.        reconnectBlockHeightLagThreshold: 8        # [Optional] peerMonitorPeriod is the period in which the connected peer is monitored to see if        # the event client should disconnect from it and reconnect to another peer.        # Default: 0 (disabled) for Balanced resolverStrategy; 5s for PreferOrg and MinBlockHeight strategy        peerMonitorPeriod: 6s  #[Required if _default not defined; Optional if _default defined].  # name of the channel  # mychannel:  channel1:    # list of orderers designated by the application to use for transactions on this    # channel. This list can be a result of access control (&quot;org1&quot; can only access &quot;ordererA&quot;), or    # operational decisions to share loads from applications among the orderers.  The values must    # be &quot;names&quot; of orgs defined under &quot;organizations/peers&quot;    # deprecated: not recommended, to override any orderer configuration items, entity matchers should be used.   # orderers:   #   - orderer.example.com    #[Required if _default peers not defined; Optional if _default peers defined].    # list of peers from participating orgs    peers:      peer0.org1.example.com:        # [Optional]. will this peer be sent transaction proposals for endorsement? The peer must        # have the chaincode installed. The app can also use this property to decide which peers        # to send the chaincode install request. Default: true        endorsingPeer: true        # [Optional]. will this peer be sent query proposals? The peer must have the chaincode        # installed. The app can also use this property to decide which peers to send the        # chaincode install request. Default: true        chaincodeQuery: true        # [Optional]. will this peer be sent query proposals that do not require chaincodes, like        # queryBlock(), queryTransaction(), etc. Default: true        ledgerQuery: true        # [Optional]. will this peer be the target of the SDK&#39;s listener registration? All peers can        # produce events but the app typically only needs to connect to one to listen to events.        # Default: true        eventSource: true## list of participating organizations in this network#organizations:  # Org1:  Org1MSP:    mspid: Org1MSP    # This org&#39;s MSP store (absolute path or relative to client.cryptoconfig)    # cryptoPath:  peerOrganizations/org1.example.com/users/User1@org1.example.com/msp    cryptoPath:  ../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp    peers:      - peer0.org1.example.com    # [Optional]. Certificate Authorities issue certificates for identification purposes in a Fabric based    # network. Typically certificates provisioning is done in a separate process outside of the    # runtime network. Fabric-CA is a special certificate authority that provides a REST APIs for    # dynamic certificate management (enroll, revoke, re-enroll). The following section is only for    # Fabric-CA servers.    # certificateAuthorities:      # - ca.org1.example.com  # the profile will contain public information about organizations other than the one it belongs to.  # These are necessary information to make transaction lifecycles work, including MSP IDs and  # peers with a public URL to send transaction proposals. The file will not contain private  # information reserved for members of the organization, such as admin key and certificate,  # fabric-ca registrar enroll ID and secret, etc.  # Org2:  #   mspid: Org2MSP  #   # This org&#39;s MSP store (absolute path or relative to client.cryptoconfig)  #   cryptoPath:  peerOrganizations/org2.example.com/users/{username}@org2.example.com/msp  #   peers:  #     - peer0.org2.example.com  #   certificateAuthorities:  #     - ca.org2.example.com  # Orderer Org name  # ordererorg:#   OrdererOrg:#       # Membership Service Provider ID for this organization#       mspID: OrdererMSP#       # Needed to load users crypto keys and certs for this org (absolute path or relative to global crypto path, DEV mode)#       cryptoPath: ordererOrganizations/example.com/users/{username}@example.com/msp# ## List of orderers to send transaction and channel create/update requests to. For the time# being only one orderer is needed. If more than one is defined, which one get used by the# SDK is implementation specific. Consult each SDK&#39;s documentation for its handling of orderers.#orderers: #这部分内容没有起作用，原因未知  orderer.example.com:    # [Optional] Default: Infer from hostname    url: orderer.example.com:7050    # these are standard properties defined by the gRPC library    # they will be passed in as-is to gRPC client constructor    grpcOptions:      ssl-target-name-override: orderer.example.com      # These parameters should be set in coordination with the keepalive policy on the server,      # as incompatible settings can result in closing of connection.      # When duration of the &#39;keep-alive-time&#39; is set to 0 or less the keep alive client parameters are disabled      keep-alive-time: 0s      keep-alive-timeout: 20s      keep-alive-permit: false      fail-fast: false      # allow-insecure will be taken into consideration if address has no protocol defined, if true then grpc or else grpcs      allow-insecure: false    tlsCACerts:      # Certificate location absolute path      # path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem      path: ../organizations/orderer.example.com/tlscacerts/tlsca.example.com-cert.pem## List of peers to send various requests to, including endorsement, query# and event listener registration.#peers:  peer0.org1.example.com:    # this URL is used to send endorsement and query requests    # [Optional] Default: Infer from hostname    url: peer0.org1.example.com:7051    grpcOptions:      ssl-target-name-override: peer0.org1.example.com      # These parameters should be set in coordination with the keepalive policy on the server,      # as incompatible settings can result in closing of connection.      # When duration of the &#39;keep-alive-time&#39; is set to 0 or less the keep alive client parameters are disabled      keep-alive-time: 0s      keep-alive-timeout: 20s      keep-alive-permit: false      fail-fast: false      # allow-insecure will be taken into consideration if address has no protocol defined, if true then grpc or else grpcs      allow-insecure: false    tlsCACerts:      # Certificate location absolute path      # path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem      path: ../organizations/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem  # peer1.org1.example.com:  #   # this URL is used to send endorsement and query requests  #   url: peer1.org1.example.com:7151  #   grpcOptions:  #     ssl-target-name-override: peer1.org1.example.com  #     # These parameters should be set in coordination with the keepalive policy on the server,  #     # as incompatible settings can result in closing of connection.  #     # When duration of the &#39;keep-alive-time&#39; is set to 0 or less the keep alive client parameters are disabled  #     keep-alive-time: 0s  #     keep-alive-timeout: 20s  #     keep-alive-permit: false  #     fail-fast: false  #     # allow-insecure will be taken into consideration if address has no protocol defined, if true then grpc or else grpcs  #     allow-insecure: false  #   tlsCACerts:  #     # Certificate location absolute path  #     path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem  peer0.org2.example.com:    url: peer0.org2.example.com:7051    grpcOptions:      ssl-target-name-override: peer0.org2.example.com      # These parameters should be set in coordination with the keepalive policy on the server,      # as incompatible settings can result in closing of connection.      # When duration of the &#39;keep-alive-time&#39; is set to 0 or less the keep alive client parameters are disabled      keep-alive-time: 0s      keep-alive-timeout: 20s      keep-alive-permit: false      fail-fast: false      # allow-insecure will be taken into consideration if address has no protocol defined, if true then grpc or else grpcs      allow-insecure: falseca    tlsCACerts:      # path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org2.example.com/tlsca/tlsca.org2.example.com-cert.pem      path: ../organizations/peerOrganizations/org2.example.com/tlsca/tlsca.org2.example.com-cert.pem## Fabric-CA is a special kind of Certificate Authority provided by Hyperledger Fabric which allows# certificate management to be done via REST APIs. Application may choose to use a standard# Certificate Authority instead of Fabric-CA, in which case this section would not be specified.## certificateAuthorities:#   ca.org1.example.com:#     # [Optional] Default: Infer from hostname#     url: https://ca.org1.example.com:7054#     tlsCACerts:#       # Comma-Separated list of paths#       path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem#       # Client key and cert for SSL handshake with Fabric CA#       client:#         key:#           path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.key#         cert:#           path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.crt#     # Fabric-CA supports dynamic user enrollment via REST APIs. A &quot;root&quot; user, a.k.a registrar, is#     # needed to enroll and invoke new users.#     registrar:#       enrollId: admin#       enrollSecret: adminpw#     # [Optional] The optional name of the CA.#     caName: ca.org1.example.com#   ca.org2.example.com:#     url: https://ca.org2.example.com:8054#     tlsCACerts:#       # Comma-Separated list of paths#       path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org2.example.com/tlsca/tlsca.org2.example.com-cert.pem#       # Client key and cert for SSL handshake with Fabric CA#       client:#         key:#           path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.key#         cert:#           path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.crt#      # Fabric-CA supports dynamic user enrollment via REST APIs. A &quot;root&quot; user, a.k.a registrar, is#      # needed to enroll and invoke new users.#     registrar:#       enrollId: admin#       enrollSecret: adminpw#     # [Optional] The optional name of the CA.#     caName: ca.org2.example.com# EntityMatchers enable substitution of network hostnames with static configurations # so that properties can be mapped. Regex can be used for this purpose# UrlSubstitutionExp can be empty which means the same network hostname will be used# UrlSubstitutionExp can be given same as mapped peer url, so that mapped peer url can be used# UrlSubstitutionExp can have golang regex matchers like ${1}.local.example.${2}:${3} for pattern # like peer0.org1.example.com:1234 which converts peer0.org1.example.com to peer0.org1.local.example.com:1234# sslTargetOverrideUrlSubstitutionExp follow in the same lines as # SubstitutionExp for the fields gprcOptions.ssl-target-name-override respectively# In any case mappedHost&#39;s config will be used, so mapped host cannot be empty, if entityMatchers are used#entityMatchers:entityMatchers:  peer:    - pattern: (\w+).org1.example.com:(\d+)      urlSubstitutionExp: ${1}.org1.example.com:${2}      sslTargetOverrideUrlSubstitutionExp: ${1}.org1.example.com      mappedHost: peer0.org1.example.com    - pattern: (\w+).org2.example.com:(\d+)      urlSubstitutionExp: ${1}.org2.example.com:${2}      sslTargetOverrideUrlSubstitutionExp: ${1}.org2.example.com      mappedHost: peer0.org2.example.com  orderer:    - pattern: (\w+) #理论上该写(\w+).example.(\w+)，但总是访问127.0.0.1:7050,暂时未找到原因，先模糊匹配      urlSubstitutionExp: orderer.example.com:7050      sslTargetOverrideUrlSubstitutionExp: orderer.example.com      mappedHost: orderer.example.com##    - pattern: (\w+).example2.(\w+)#      urlSubstitutionExp: localhost:7050#      sslTargetOverrideUrlSubstitutionExp: localhost#      mappedHost: orderer.example.com##    - pattern: (\w+).example3.(\w+)#      urlSubstitutionExp:#      sslTargetOverrideUrlSubstitutionExp:#      mappedHost: orderer.example.com##    - pattern: (\w+).example4.(\w+):(\d+)#      urlSubstitutionExp: ${1}.example.${2}:${3}#      sslTargetOverrideUrlSubstitutionExp: ${1}.example.${2}#      mappedHost: orderer.example.com##  certificateAuthority:#    - pattern: (\w+).org1.example.(\w+)#      urlSubstitutionExp:#      mappedHost: ca.org1.example.com##    - pattern: (\w+).org2.example.(\w+)#      urlSubstitutionExp:#      mappedHost: ca.org2.example.com</code></pre><h2 id="4-调用"><a href="#4-调用" class="headerlink" title="4. 调用"></a>4. 调用</h2><pre><code class="bash">vim main.go</code></pre><p>编写SDK调用的代码</p><pre><code class="go">package mainimport (        &quot;fmt&quot;        &quot;os&quot;        &quot;github.com/hyperledger/fabric-sdk-go/pkg/core/config&quot;        &quot;github.com/hyperledger/fabric-sdk-go/pkg/fabsdk&quot;        &quot;github.com/hyperledger/fabric-sdk-go/pkg/common/logging&quot;        &quot;github.com/hyperledger/fabric-sdk-go/pkg/client/channel&quot;)var (        cc          = &quot;sacc&quot;        user        = &quot;Admin&quot; //此处Admin，但实际中应使用User1        secret      = &quot;&quot;        channelName = &quot;channel1&quot;        lvl         = logging.INFO        orgName     = &quot;Org1MSP&quot;)func main(){        c := config.FromFile(&quot;./connection-profile.yaml&quot;)        sdk, err := fabsdk.New(c)        if err != nil {                fmt.Printf(&quot;Failed to create new SDK: %s\n&quot;, err)                os.Exit(1)        }        defer sdk.Close()        clientChannelContext := sdk.ChannelContext(channelName, fabsdk.WithUser(user), fabsdk.WithOrg(orgName))        if err != nil {                fmt.Printf(&quot;Failed to create channel [%s] client: %#v&quot;, channelName, err)                os.Exit(1)        }        client, err := channel.New(clientChannelContext)        if err != nil {                fmt.Printf(&quot;Failed to create channel [%s]:&quot;, channelName, err)        }        queryCC(client, []byte(&quot;a&quot;))        invokeCC(client, &quot;ff55&quot;)        queryCC(client, []byte(&quot;a&quot;))}func invokeCC(client *channel.Client, newValue string) {        invokeArgs := [][]byte{[]byte(&quot;a&quot;), []byte(newValue)}        _, err := client.Execute(channel.Request{                ChaincodeID: cc,                Fcn:         &quot;set&quot;,                Args:        invokeArgs,        })        if err != nil {                fmt.Printf(&quot;Failed to invoke: %+v\n&quot;, err)        }}func queryCC(client *channel.Client, name []byte) string {        var queryArgs = [][]byte{name}        response, err := client.Query(channel.Request{                ChaincodeID: cc,                Fcn:         &quot;query&quot;,                Args:        queryArgs,        })        if err != nil {                fmt.Println(&quot;Failed to query: &quot;, err)        }        ret := string(response.Payload)        fmt.Println(&quot;Chaincode status: &quot;, response.ChaincodeStatus)        fmt.Println(&quot;Payload: &quot;, ret)        return ret}</code></pre><p>运行这段代码</p><pre><code class="bash">go mod init testsdkgo mod tidygo mod vendorgo run main.go</code></pre>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>06_docker compose启动节点</title>
      <link href="/2020/12/09/fabric/07_dockerCompose%E5%90%AF%E5%8A%A8fabric/"/>
      <url>/2020/12/09/fabric/07_dockerCompose%E5%90%AF%E5%8A%A8fabric/</url>
      
        <content type="html"><![CDATA[<h1 id="docker-compose启动节点"><a href="#docker-compose启动节点" class="headerlink" title="docker compose启动节点"></a>docker compose启动节点</h1><h2 id="1-生成密钥素材（order节点）"><a href="#1-生成密钥素材（order节点）" class="headerlink" title="1. 生成密钥素材（order节点）"></a>1. 生成密钥素材（order节点）</h2><p>在一个新的文件夹中</p><pre><code class="bash">mkdir order  orderer-production  organizations  peer0-org1-production chaincode</code></pre><p>生成秘钥素材，参考前面的内容</p><p>编写 <code>docker-compose.yaml</code></p><p>注意在这个compose文件中指定了一些环境变量，这些环境变量在每次打开命令行的时候都需要重新输入，如果想要避免这个麻烦，可以将这两个环境变量先写到bashrc文件中，每次启动命令行的时候都可以自动执行这两条环境变量的设置</p><p>下面两个主要是根据fabric版本以及docker项目名称来决定的，根据实际情况可以进行修改。</p><pre><code class="bash">export IMAGE_TAG=2.2.1export COMPOSE_PROJECT_NAME=test1</code></pre><pre><code class="yaml"># Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#version: &#39;3.5&#39;volumes:  orderer.example.com:  peer0.org1.example.com:  peer0.org2.example.com:networks:  test:services:  orderer.example.com:    container_name: orderer.example.com    image: hyperledger/fabric-orderer:$IMAGE_TAG    environment:      - FABRIC_LOGGING_SPEC=INFO      - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0      - ORDERER_GENERAL_LISTENPORT=7050      - ORDERER_GENERAL_GENESISMETHOD=file      - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/genesis.block      - ORDERER_GENERAL_LOCALMSPID=OrdererMSP      - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp      # enabled TLS      - ORDERER_GENERAL_TLS_ENABLED=true      - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key      - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt      - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]      # - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1      # - ORDERER_KAFKA_VERBOSE=true      - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt      - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key      - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]    working_dir: /home/fabric/go/src/github.com/hyperledger/fabric    command: orderer    volumes:        - ./order/system-genesis-block:/var/hyperledger/orderer        - ./organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp        - ./organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls:/var/hyperledger/orderer/tls        - ./orderer-production:/var/hyperledger/production/orderer    ports:      - 7050:7050    networks:      - test    extra_hosts: #虚拟机host地址      - &quot;orderer.example.com:192.168.108.139&quot;      - &quot;peer0.org1.example.com:192.168.108.140&quot;      - &quot;peer0.org2.example.com:192.168.108.141&quot;  peer0.org1.example.com:    container_name: peer0.org1.example.com    image: hyperledger/fabric-peer:$IMAGE_TAG    environment:      #Generic peer variables      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      # the following setting starts chaincode containers on the same      # bridge network as the peers      # https://docs.docker.com/compose/networking/      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=${COMPOSE_PROJECT_NAME}_test      - FABRIC_LOGGING_SPEC=INFO      #- FABRIC_LOGGING_SPEC=DEBUG      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_PROFILE_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt      - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key      - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt      # Peer specific variabes      - CORE_PEER_ID=peer0.org1.example.com      - CORE_PEER_ADDRESS=peer0.org1.example.com:7051      - CORE_PEER_LISTENADDRESS=0.0.0.0:7051      - CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052      - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052      - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP    volumes:        - /var/run/:/host/var/run/        - ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp        - ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls        - ./peer0-org1-production:/var/hyperledger/production    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer    command: peer node start    ports:      - 7051:7051    networks:      - test    extra_hosts:  #虚拟机host地址      - &quot;orderer.example.com:192.168.108.139&quot;      - &quot;peer0.org1.example.com:192.168.108.140&quot;      - &quot;peer0.org2.example.com:192.168.108.141&quot;  peer0.org2.example.com:    container_name: peer0.org2.example.com    image: hyperledger/fabric-peer:$IMAGE_TAG    environment:      #Generic peer variables      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      # the following setting starts chaincode containers on the same      # bridge network as the peers      # https://docs.docker.com/compose/networking/      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=${COMPOSE_PROJECT_NAME}_test      - FABRIC_LOGGING_SPEC=INFO      #- FABRIC_LOGGING_SPEC=DEBUG      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_PROFILE_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt      - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key      - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt      # Peer specific variabes      - CORE_PEER_ID=peer0.org2.example.com      - CORE_PEER_ADDRESS=peer0.org2.example.com:9051      - CORE_PEER_LISTENADDRESS=0.0.0.0:9051      - CORE_PEER_CHAINCODEADDRESS=peer0.org2.example.com:9052      - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:9052      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org2.example.com:9051      - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org2.example.com:9051      - CORE_PEER_LOCALMSPID=Org2MSP    volumes:        - /var/run/:/host/var/run/        - ./organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp:/etc/hyperledger/fabric/msp        - ./organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls:/etc/hyperledger/fabric/tls        - ./peer0-org2-production:/var/hyperledger/production    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer    command: peer node start    ports:      - 9051:9051    networks:      - test    extra_hosts: #虚拟机host地址      - &quot;orderer.example.com:192.168.108.139&quot;      - &quot;peer0.org1.example.com:192.168.108.140&quot;      - &quot;peer0.org2.example.com:192.168.108.141&quot;  cli-org1:      container_name: cli-org1      image: hyperledger/fabric-tools:$IMAGE_TAG      tty: true      stdin_open: true      environment:        # - GOPATH=/opt/gopathdocker-compose.yaml        - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock        - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=${COMPOSE_PROJECT_NAME}_test        - FABRIC_LOGGING_SPEC=INFO        - CORE_PEER_ID=peer0.org1.example.com        - CORE_PEER_ADDRESS=peer0.org1.example.com:7051        - CORE_PEER_LOCALMSPID=Org1MSP        - CORE_PEER_TLS_ENABLED=true        - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt        - CORE_PEER_MSPCONFIGPATH=/etc/hyperledger/fabric/users/Admin@org1.example.com/msp        - ORDERER_TLSCA=/var/hyperledger/orderer/tlscacerts/tlsca.example.com-cert.pem      working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1      command: sh      volumes:        # - /tmp/hyperledger/org1/peer1:/tmp/hyperledger/org1/peer1        # - /tmp/hyperledger/org1/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode        # - /tmp/hyperledger/org1/admin:/tmp/hyperledger/org1/admin        - /var/run/:/host/var/run/        - ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp        - ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls        - ./organizations/peerOrganizations/org1.example.com/users:/etc/hyperledger/fabric/users        - ./organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts:/var/hyperledger/orderer/tlscacerts        - ./order/channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/org1/channel-artifacts        - ./chaincode:/opt/gopath/src/github.com/hyperledger/fabric/org1/chaincode        - ./organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt:/etc/hyperledger/fabric/org2-peer0-tls/ca.crt #org2的peer0节点身份证书      networks:        - test      extra_hosts: #虚拟机host地址        - &quot;orderer.example.com:192.168.108.139&quot;        - &quot;peer0.org1.example.com:192.168.108.140&quot;        - &quot;peer0.org2.example.com:192.168.108.141&quot;  cli-org2:      container_name: cli-org2      image: hyperledger/fabric-tools:$IMAGE_TAG      tty: true      stdin_open: true      environment:        # - GOPATH=/opt/gopathdocker-compose.yaml        - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock        - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=${COMPOSE_PROJECT_NAME}_test        - FABRIC_LOGGING_SPEC=INFO        - CORE_PEER_ID=peer0.org2.example.com        - CORE_PEER_ADDRESS=peer0.org2.example.com:9051        - CORE_PEER_LOCALMSPID=Org2MSP        - CORE_PEER_TLS_ENABLED=true        - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt        - CORE_PEER_MSPCONFIGPATH=/etc/hyperledger/fabric/users/Admin@org2.example.com/msp        - ORDERER_TLSCA=/var/hyperledger/orderer/tlscacerts/tlsca.example.com-cert.pem      working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2      command: sh      volumes:        # - /tmp/hyperledger/org1/peer1:/tmp/hyperledger/org1/peer1        # - /tmp/hyperledger/org1/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode        # - /tmp/hyperledger/org1/admin:/tmp/hyperledger/org1/admin        - /var/run/:/host/var/run/        - ./organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp:/etc/hyperledger/fabric/msp        - ./organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls:/etc/hyperledger/fabric/tls        - ./organizations/peerOrganizations/org2.example.com/users:/etc/hyperledger/fabric/users        - ./organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts:/var/hyperledger/orderer/tlscacerts        - ./order/channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/org2/channel-artifacts        - ./chaincode:/opt/gopath/src/github.com/hyperledger/fabric/org2/chaincode        - ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt:/etc/hyperledger/fabric/org1-peer0-tls/ca.crt #org1的peer0节点身份证书      networks:        - test      extra_hosts: #虚拟机host地址        - &quot;orderer.example.com:192.168.108.139&quot;        - &quot;peer0.org1.example.com:192.168.108.140&quot;        - &quot;peer0.org2.example.com:192.168.108.141&quot;</code></pre><h2 id="2-创建创始节点和应用通道创建事务（order节点）"><a href="#2-创建创始节点和应用通道创建事务（order节点）" class="headerlink" title="2. 创建创始节点和应用通道创建事务（order节点）"></a>2. 创建创始节点和应用通道创建事务（order节点）</h2><h3 id="2-1-生成创世区块"><a href="#2-1-生成创世区块" class="headerlink" title="2.1 生成创世区块"></a>2.1 生成创世区块</h3><p>在目录下创建order目录，并且创建 <code>configtx.yaml</code>，内容如下</p><p>编写完成之后执行一条命令</p><pre><code class="bash">configtxgen -profile TwoOrgsOrdererGenesis -channelID system-channel -outputBlock ./system-genesis-block/genesis.block</code></pre><p>这时候会在order目录下生成 <code>system-gensis-block</code> 目录，在这里面的区块文件用于存储创世区块。</p><pre><code class="yaml"># Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#---##################################################################################   Section: Organizations##   - This section defines the different organizational identities which will#   be referenced later in the configuration.#################################################################################Organizations:    # SampleOrg defines an MSP using the sampleconfig.  It should never be used    # in production but may be used as a template for other definitions    - &amp;OrdererOrg        # DefaultOrg defines the organization which is used in the sampleconfig        # of the fabric.git development environment        Name: OrdererOrg        # ID to load the MSP definition as        ID: OrdererMSP        # MSPDir is the filesystem path which contains the MSP configuration        MSPDir: ../organizations/ordererOrganizations/example.com/msp        # Policies defines the set of policies at this level of the config tree        # For organization policies, their canonical path is usually        #   /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt;        Policies:            Readers:                Type: Signature                Rule: &quot;OR(&#39;OrdererMSP.member&#39;)&quot;            Writers:                Type: Signature                Rule: &quot;OR(&#39;OrdererMSP.member&#39;)&quot;            Admins:                Type: Signature                Rule: &quot;OR(&#39;OrdererMSP.admin&#39;)&quot;        OrdererEndpoints:            - &quot;orderer.example.com:7050&quot;    - &amp;Org1        # DefaultOrg defines the organization which is used in the sampleconfig        # of the fabric.git development environment        Name: Org1MSP        # ID to load the MSP definition as        ID: Org1MSP        MSPDir: ../organizations/peerOrganizations/org1.example.com/msp        # Policies defines the set of policies at this level of the config tree        # For organization policies, their canonical path is usually        #   /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt;        Policies:            Readers:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.admin&#39;, &#39;Org1MSP.peer&#39;, &#39;Org1MSP.client&#39;)&quot;            Writers:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.admin&#39;, &#39;Org1MSP.client&#39;)&quot;            Admins:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.admin&#39;)&quot;            Endorsement:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.peer&#39;)&quot;        # leave this flag set to true.        AnchorPeers:            # AnchorPeers defines the location of peers which can be used            # for cross org gossip communication.  Note, this value is only            # encoded in the genesis block in the Application section context            - Host: peer0.org1.example.com              Port: 7051    - &amp;Org2        # DefaultOrg defines the organization which is used in the sampleconfig        # of the fabric.git development environment        Name: Org2MSP        # ID to load the MSP definition as        ID: Org2MSP        MSPDir: ../organizations/peerOrganizations/org2.example.com/msp        # Policies defines the set of policies at this level of the config tree        # For organization policies, their canonical path is usually        #   /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt;        Policies:            Readers:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.admin&#39;, &#39;Org2MSP.peer&#39;, &#39;Org2MSP.client&#39;)&quot;            Writers:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.admin&#39;, &#39;Org2MSP.client&#39;)&quot;            Admins:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.admin&#39;)&quot;            Endorsement:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.peer&#39;)&quot;        AnchorPeers:            # AnchorPeers defines the location of peers which can be used            # for cross org gossip communication.  Note, this value is only            # encoded in the genesis block in the Application section context            - Host: peer0.org2.example.com              Port: 7051##################################################################################   SECTION: Capabilities##   - This section defines the capabilities of fabric network. This is a new#   concept as of v1.1.0 and should not be utilized in mixed networks with#   v1.0.x peers and orderers.  Capabilities define features which must be#   present in a fabric binary for that binary to safely participate in the#   fabric network.  For instance, if a new MSP type is added, newer binaries#   might recognize and validate the signatures from this type, while older#   binaries without this support would be unable to validate those#   transactions.  This could lead to different versions of the fabric binaries#   having different world states.  Instead, defining a capability for a channel#   informs those binaries without this capability that they must cease#   processing transactions until they have been upgraded.  For v1.0.x if any#   capabilities are defined (including a map with all capabilities turned off)#   then the v1.0.x peer will deliberately crash.#################################################################################Capabilities:    # Channel capabilities apply to both the orderers and the peers and must be    # supported by both.    # Set the value of the capability to true to require it.    Channel: &amp;ChannelCapabilities        # V2_0 capability ensures that orderers and peers behave according        # to v2.0 channel capabilities. Orderers and peers from        # prior releases would behave in an incompatible way, and are therefore        # not able to participate in channels at v2.0 capability.        # Prior to enabling V2.0 channel capabilities, ensure that all        # orderers and peers on a channel are at v2.0.0 or later.        V2_0: true    # Orderer capabilities apply only to the orderers, and may be safely    # used with prior release peers.    # Set the value of the capability to true to require it.    Orderer: &amp;OrdererCapabilities        # V2_0 orderer capability ensures that orderers behave according        # to v2.0 orderer capabilities. Orderers from        # prior releases would behave in an incompatible way, and are therefore        # not able to participate in channels at v2.0 orderer capability.        # Prior to enabling V2.0 orderer capabilities, ensure that all        # orderers on channel are at v2.0.0 or later.        V2_0: true    # Application capabilities apply only to the peer network, and may be safely    # used with prior release orderers.    # Set the value of the capability to true to require it.    Application: &amp;ApplicationCapabilities        # V2_0 application capability ensures that peers behave according        # to v2.0 application capabilities. Peers from        # prior releases would behave in an incompatible way, and are therefore        # not able to participate in channels at v2.0 application capability.        # Prior to enabling V2.0 application capabilities, ensure that all        # peers on channel are at v2.0.0 or later.        V2_0: true##################################################################################   SECTION: Application##   - This section defines the values to encode into a config transaction or#   genesis block for application related parameters#################################################################################Application: &amp;ApplicationDefaults    # Organizations is the list of orgs which are defined as participants on    # the application side of the network    Organizations:    # Policies defines the set of policies at this level of the config tree    # For Application policies, their canonical path is    #   /Channel/Application/&lt;PolicyName&gt;    Policies:        Readers:            Type: ImplicitMeta            Rule: &quot;ANY Readers&quot;        Writers:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;        Admins:            Type: ImplicitMeta            Rule: &quot;MAJORITY Admins&quot;        LifecycleEndorsement:            Type: ImplicitMeta            Rule: &quot;MAJORITY Endorsement&quot;        Endorsement:            Type: ImplicitMeta            Rule: &quot;MAJORITY Endorsement&quot;    Capabilities:        &lt;&lt;: *ApplicationCapabilities##################################################################################   SECTION: Orderer##   - This section defines the values to encode into a config transaction or#   genesis block for orderer related parameters#################################################################################Orderer: &amp;OrdererDefaults    # Orderer Type: The orderer implementation to start    OrdererType: etcdraft    EtcdRaft:        Consenters:            - Host: orderer.example.com              Port: 7050              ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt              ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt    # Batch Timeout: The amount of time to wait before creating a batch    BatchTimeout: 2s    # Batch Size: Controls the number of messages batched into a block    BatchSize:        # Max Message Count: The maximum number of messages to permit in a batch        MaxMessageCount: 10        # Absolute Max Bytes: The absolute maximum number of bytes allowed for        # the serialized messages in a batch.        AbsoluteMaxBytes: 99 MB        # Preferred Max Bytes: The preferred maximum number of bytes allowed for        # the serialized messages in a batch. A message larger than the preferred        # max bytes will result in a batch larger than preferred max bytes.        PreferredMaxBytes: 512 KB    # Organizations is the list of orgs which are defined as participants on    # the orderer side of the network    Organizations:    # Policies defines the set of policies at this level of the config tree    # For Orderer policies, their canonical path is    #   /Channel/Orderer/&lt;PolicyName&gt;    Policies:        Readers:            Type: ImplicitMeta            Rule: &quot;ANY Readers&quot;        Writers:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;        Admins:            Type: ImplicitMeta            Rule: &quot;MAJORITY Admins&quot;        # BlockValidation specifies what signatures must be included in the block        # from the orderer for the peer to validate it.        BlockValidation:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;##################################################################################   CHANNEL##   This section defines the values to encode into a config transaction or#   genesis block for channel related parameters.#################################################################################Channel: &amp;ChannelDefaults    # Policies defines the set of policies at this level of the config tree    # For Channel policies, their canonical path is    #   /Channel/&lt;PolicyName&gt;    Policies:        # Who may invoke the &#39;Deliver&#39; API        Readers:            Type: ImplicitMeta            Rule: &quot;ANY Readers&quot;        # Who may invoke the &#39;Broadcast&#39; API        Writers:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;        # By default, who may modify elements at this config level        Admins:            Type: ImplicitMeta            Rule: &quot;MAJORITY Admins&quot;    # Capabilities describes the channel level capabilities, see the    # dedicated Capabilities section elsewhere in this file for a full    # description    Capabilities:        &lt;&lt;: *ChannelCapabilities##################################################################################   Profile##   - Different configuration profiles may be encoded here to be specified#   as parameters to the configtxgen tool#################################################################################Profiles:    TwoOrgsOrdererGenesis:        &lt;&lt;: *ChannelDefaults        Orderer:            &lt;&lt;: *OrdererDefaults            Organizations:                - *OrdererOrg            Capabilities:                &lt;&lt;: *OrdererCapabilities        Consortiums:            SampleConsortium:                Organizations:                    - *Org1                    - *Org2    TwoOrgsChannel:        Consortium: SampleConsortium        &lt;&lt;: *ChannelDefaults        Application:            &lt;&lt;: *ApplicationDefaults            Organizations:                - *Org1                - *Org2            Capabilities:                &lt;&lt;: *ApplicationCapabilities</code></pre><h3 id="2-2-创建应用通道创建事务"><a href="#2-2-创建应用通道创建事务" class="headerlink" title="2.2 创建应用通道创建事务"></a>2.2 创建应用通道创建事务</h3><p>还在order目录下，执行下面的命令</p><pre><code class="bash">configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel1.tx -channelID channel1</code></pre><p>这时候会在目录下生成一个 <code>channel-artifacts</code> 目录，用于存放通道相关的内容。</p><p>要注意，这里因为生成的创世区块和通道配置信息的文件都放在这个order文件夹的目录下，因此需要<strong>将这个order目录复制到其他的peer节点</strong>之中。可以往前面翻看一下docker-compose中两个组织的cli配置，是以这个order目录为基准进行映射的，因此需要在每个peer上都有这个order目录才可以。</p><h2 id="3-启动节点"><a href="#3-启动节点" class="headerlink" title="3. 启动节点"></a>3. 启动节点</h2><h3 id="3-1-order节点"><a href="#3-1-order节点" class="headerlink" title="3.1 order节点"></a>3.1 order节点</h3><p>在order节点的大目录之中启动order节点：</p><pre><code class="bash">docker-compose up orderer.example.com</code></pre><h3 id="3-2-org1的peer0启动、加入通道"><a href="#3-2-org1的peer0启动、加入通道" class="headerlink" title="3.2 org1的peer0启动、加入通道"></a>3.2 org1的peer0启动、加入通道</h3><p>前面已经将很多内容给复制到org1的peer0中了，总结一下，就是需要前面已经生成创世区块和通道文件的order目录，以及身份认证文件organizations目录，后面再部署链码的时候还需要一个chaincode目录，这里也先将他放进来了。</p><p><img src="/2020/12/09/fabric/07_dockerCompose%E5%90%AF%E5%8A%A8fabric/image-20201209110508465.png" alt="org1 peer0目录下应有的项目"></p><pre><code class="bash">docker-compose up peer0.org1.example.com</code></pre><p>启动org1的cli工具</p><pre><code class="bash">docker-compose up cli-org1</code></pre><p>进入cli工具（由于前面启动cli工具的时候，命令行可能会卡死，所以需要再重新启动一个命令行，来进入工具）</p><pre><code class="bash">docker exec -it cli-org1 sh</code></pre><p>在<strong>cli容器的命令行中</strong>执行下面的代码，创建应用通道并将peer加入到通道中。注意：因docker容器中本身变量已经包含所需的一切环境变量，因此只需执行</p><pre><code class="bash">peer channel create -o orderer.example.com:7050  -c channel1 -f ./channel-artifacts/channel1.tx --outputBlock ./channel-artifacts/channel1.block --tls --cafile $ORDERER_TLSCApeer channel join -b ./channel-artifacts/channel1.block</code></pre><h3 id="3-3-org2的peer0启动、加入通道"><a href="#3-3-org2的peer0启动、加入通道" class="headerlink" title="3.3 org2的peer0启动、加入通道"></a>3.3 org2的peer0启动、加入通道</h3><p>同理，这里也展示一下org2的peer0目录中包含的内容，其实与org1的目录是类似的，同样需要order目录、organizations目录以及以后要用到的chaincode目录</p><p><img src="/2020/12/09/fabric/07_dockerCompose%E5%90%AF%E5%8A%A8fabric/image-20201209110709773.png" alt="org2的peer0目录"></p><p>启动org2的peer0</p><pre><code class="bash">mkdir peer0-org2-productiondocker-compose up peer0.org2.example.com</code></pre><p>启动org2的cli</p><pre><code class="bash">docker-compose up cli-org2</code></pre><p>将org2的peer加入通道</p><pre><code class="bash">docker exec -it cli-org2 sh# 然后在这个cli的sh工具中执行以下两条内容，主要是用来将org2的peer加入到通道中peer channel fetch 0 ./channel-artifacts/channel_org2.block -o orderer.example.com:7050  -c channel1 --tls --cafile $ORDERER_TLSCApeer channel join -b ./channel-artifacts/channel_org2.block</code></pre><h2 id="4-安装链码"><a href="#4-安装链码" class="headerlink" title="4. 安装链码"></a>4. 安装链码</h2><p>还是拿例程中的sacc链码作为例子，在目录中创建chaincode文件夹，并且将例程中的sacc全部都复制进来，并且进行下面的操作：</p><pre><code class="bash">cd chaincode/sacc/go env -w GO111MODULE=ongo mod init saccgo mod tidygo mod vendor</code></pre><p>然后在于chaincode目录同级的目录下执行下面的操作来打包链码</p><pre><code class="bash">peer lifecycle chaincode package chaincode/sacc.tar.gz --path chaincode/sacc --lang golang --label sacc_1</code></pre><p>打包完成之后，需要在两个org的peer上面都来安装链码，因此<strong>需要将这个chaincode文件夹下的链码文件分发到两个org的peer0上面</strong>。</p><h3 id="4-1-在org1和org2的peer0上安装、审议链码"><a href="#4-1-在org1和org2的peer0上安装、审议链码" class="headerlink" title="4.1 在org1和org2的peer0上安装、审议链码"></a>4.1 在org1和org2的peer0上安装、审议链码</h3><pre><code class="bash">peer lifecycle chaincode install chaincode/sacc.tar.gzpeer lifecycle chaincode queryinstalled # 查询确认一下</code></pre><p>安装完成之后，需要对链码进行审议，先执行下面的操作来<strong>获取package ID</strong></p><pre><code class="bash">peer lifecycle chaincode queryinstalled</code></pre><p>然后将这个查询得到的package ID加入到环境变量中</p><pre><code class="bash">export CC_PACKAGE_ID=sacc_1:b33357c4012471d8bd96ba48fd2a12ada5fedfbfd6d623590295778500a0368d</code></pre><p>对链码定义进行签名</p><pre><code class="bash">peer lifecycle chaincode approveformyorg -o orderer.example.com:7050  --channelID channel1 --init-required --name sacc --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $ORDERER_TLSCA</code></pre><p>其中的参数为：</p><ul><li><p><code>--package-id</code> 标识链码；</p></li><li><p><code>--sequence</code> 是整数序列，第一次部署值为1，当链码升级时值为2；</p></li><li><p><code>--init-required</code> 表示链码需要初始化，第一次invoke时，使用–isInit来初始化链码，执行init函数。</p><p><strong>注意：</strong>在链码版本升级时，如果旧版本审议时有参数–init-required，则新版本的链码审议时–init-required也必须要有，否则审议通不过。</p></li></ul><h3 id="4-2-查询审议结果"><a href="#4-2-查询审议结果" class="headerlink" title="4.2 查询审议结果"></a>4.2 查询审议结果</h3><pre><code class="bash">peer lifecycle chaincode checkcommitreadiness --channelID channel1 --init-required --name sacc --version 1.0 --sequence 1 --tls --cafile $ORDERER_TLSCA --output json</code></pre><p>如果审议都通过，则可以查询到下面的结果：</p><p><img src="/2020/12/09/fabric/07_dockerCompose%E5%90%AF%E5%8A%A8fabric/image-20201209112243106.png" alt="审议成功结果"></p><h3 id="4-3-提交链码（org1）"><a href="#4-3-提交链码（org1）" class="headerlink" title="4.3 提交链码（org1）"></a>4.3 提交链码（org1）</h3><p>提交链码的操作其实是在org1和org2上面都可以，下面是<strong>使用org1操作</strong>的例子，如果想要使用org2操作，则需要修改相应的内容</p><pre><code class="bash">peer lifecycle chaincode commit -o orderer.example.com:7050 --channelID channel1 --init-required --name sacc --version 1.0 --sequence 1 --tls --cafile $ORDERER_TLSCA --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles /etc/hyperledger/fabric/org2-peer0-tls/ca.crt</code></pre><h2 id="5-调用链码"><a href="#5-调用链码" class="headerlink" title="5. 调用链码"></a>5. 调用链码</h2><p>调用链码还是需要在cli的命令行里面调用</p><pre><code class="bash"># org2的peer0初始化调用链码peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /etc/hyperledger/fabric/org1-peer0-tls/ca.crt --isInit -c &#39;{&quot;Args&quot;:[&quot;a&quot;,&quot;bb&quot;]}&#39;# org1的peer0调用链码peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles /etc/hyperledger/fabric/org2-peer0-tls/ca.crt  -c &#39;{&quot;Args&quot;:[&quot;set&quot;,&quot;a&quot;,&quot;cc&quot;]}&#39;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>03_用户结构变动</title>
      <link href="/2020/12/09/fabric/03_%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%98%E5%8A%A8/"/>
      <url>/2020/12/09/fabric/03_%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%8F%98%E5%8A%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="增加peer"><a href="#增加peer" class="headerlink" title="增加peer"></a>增加peer</h1><h2 id="1-安装fabric-ca"><a href="#1-安装fabric-ca" class="headerlink" title="1. 安装fabric-ca"></a>1. 安装fabric-ca</h2><pre><code class="bash">mkdir -p $GOPATH/src/github.com/hyperledgercd $GOPATH/src/github.com/hyperledger# 1.下载源码git clone https://github.com/hyperledger/fabric-ca.git# 2.编译go env -w GO111MODULE= make fabric-ca-servermake fabric-ca-client# 3.安装编译好的文件cp $GOPATH/src/github.com/hyperledger/fabric-ca/bin/* /usr/local/binsudo chmod -R 775 /usr/local/bin/fabric-ca-serversudo chmod -R 775 /usr/local/bin/fabric-ca-client# 4.检查fabric-ca-server versionfabric-ca-server version</code></pre><h2 id="2-启动CA-server并获取证书"><a href="#2-启动CA-server并获取证书" class="headerlink" title="2. 启动CA-server并获取证书"></a>2. 启动CA-server并获取证书</h2><p><strong>创建peer1.org1.example.com的msp</strong></p><pre><code class="bash"># 1.初始化mkdir ~/work/example/ca_servercd ~/work/example/ca_serverfabric-ca-server init -b admin:adminpw --port 7054# 2.修改配置文件ca:  # Name of this CA  name: ca-org1  # Key file (is only used to import a private key into BCCSP)  keyfile: ../organizations/peerOrganizations/org1.example.com/ca/priv_sk  # Certificate file (default: ca-cert.pem)  certfile: ../organizations/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem  # Chain file  chainfile:# 因9443端口在peer中占用，所以暂时将本配置文件中operations部分注释掉# 3.开启serverfabric-ca-server start  -b admin:adminpw --port 7054# 4.使用client注册账号mkdir ~/work/example/ca_clientcd ~/work/example/ca_clientexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client enroll -u http://admin:adminpw@localhost:7054fabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u http://0.0.0.0:7054# 5.登陆peer1.org1.example.com账号来获取peer的mspmkdir ~/work/example/organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.comcd ~/work/example/organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.comexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client enroll -u http://peer1.org1.example.com:peer1PW@0.0.0.0:7054 -M $FABRIC_CA_CLIENT_HOME/msp# 6.声明管理员用户mkdir msp/admincertscp ~/work/example/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem msp/admincerts/</code></pre><p><strong>创建peer1.org1.example.com的tls</strong></p><pre><code class="bash"># 1.启动TLS servermkdir ~/work/example/tlsca_servercd ~/work/example/tlsca_serverfabric-ca-server init -b tlsadmin:tlsadminpw# 2.修改配置文件ca:  # Name of this CA  name: tlsca-org1  # Key file (is only used to import a private key into BCCSP)  keyfile: ../organizations/peerOrganizations/org1.example.com/tlsca/priv_sk  # Certificate file (default: ca-cert.pem)  certfile: ../organizations/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem  # Chain file  chainfile:# 因9443端口在peer中占用，所以暂时将本配置文件中operations部分注释掉# 3.开启serverfabric-ca-server start  -b tlsadmin:tlsadminpw --port 7055# 4.使用client注册账号mkdir ~/work/example/tlsca_clientcd ~/work/example/tlsca_clientexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client enroll -u http://tlsadmin:tlsadminpw@localhost:7055fabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u http://0.0.0.0:7055# 5.登陆peer1.org1.example.com账号来获取peer的mspmkdir ~/work/example/organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tlscd ~/work/example/organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.comexport FABRIC_CA_CLIENT_HOME=$PWD#注意下方--csr.hosts必须加，否则在将peer加入通道时会报错fabric-ca-client enroll -u http://peer1.org1.example.com:peer1PW@0.0.0.0:7055 -M $FABRIC_CA_CLIENT_HOME/tls --csr.hosts peer1.org1.example.commv tls/keystore/* tls/keystore/server.key</code></pre><h2 id="3-启动新增节点"><a href="#3-启动新增节点" class="headerlink" title="3. 启动新增节点"></a>3. 启动新增节点</h2><p>在全网的hosts文件中将新增节点的IP地址加进来</p><pre><code>192.168.1.108 orderer.example.com192.168.1.112 peer0.org1.example.com192.168.1.138 peer1.org1.example.com192.168.1.111 peer0.org2.example.com</code></pre><p>然后创建工作目录及获取需要的素材</p><pre><code class="bash">mkdir -p work/example/peercd work/examplescp -r dev2@192.168.1.112:~/work/example/organizations organizations</code></pre><p>创建core.yaml,对比peer0的core.yaml做如下修改</p><pre><code>15 peer.id: peer1.org1.example.com162 peer.gossip.externalEndpoint: peer1.org1.example.com:7051254 peer.tls.cert.file: ../organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/signcerts/cert.pem258 peer.tls.key.file: ../organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/keystore/server.key261 peer.tls.rootcert.file: ../organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/cacerts/0-0-0-0-7055.pem265 peer.tls.clientRootCAs.files: - ../organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/cacerts/0-0-0-0-7055.pem314 peer.mspConfigPath: ../organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp323 peer.localMspId: Org1MSP</code></pre><p>启动peer</p><pre><code class="bash">export FABRIC_CFG_PATH=$PWDpeer node start &gt;&gt; log_peer.log 2&gt;&amp;1 &amp;# peer在加入通道前，log会出现错误提示，暂时先忽略，如bad certificate server</code></pre><h2 id="4-将peer加入通道"><a href="#4-将peer加入通道" class="headerlink" title="4. 将peer加入通道"></a>4. 将peer加入通道</h2><p>系统已经有了通道channel1，peer1从Orderer获取通道的创始区块，命令中0来指定要获取的是创始区块。</p><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer1.org1.example.com:7051# 自定义orderer的tls ca证书变量export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pemmkdir channel-artifactspeer channel fetch 0 ./channel-artifacts/channel_org1.block -o orderer.example.com:7050  -c channel1 --tls --cafile $ORDERER_TLSCApeer channel join -b ./channel-artifacts/channel_org1.block# 此处如报错Error: error getting endorser client for channel: endorser client failed to connect to peer1.org1.example.com:7051: failed to create new connection: context deadline exceeded# 是因为怀疑是TLS CA在登陆时，没有指定--csr.hosts参数</code></pre><h2 id="5-安装并调用链码"><a href="#5-安装并调用链码" class="headerlink" title="5. 安装并调用链码"></a>5. 安装并调用链码</h2><p>首先将链代码复制到peer1的主机上</p><pre><code class="bash">cd ~/work/example/peermkdir chaincodescp -r dev2@192.168.1.112:~/work/example/peer/chaincode/sacc chaincode/sacc</code></pre><p>安装依赖包</p><pre><code class="bash">rm -rf chaincode/sacc/vendor/cd chaincode/saccgo env -w GO111MODULE=ongo mod init saccgo mod tidygo mod vendor</code></pre><p>安装链码</p><pre><code class="bash">cd ~/work/example/peer# export FABRIC_CFG_PATH=$PWD 此环境变量不设置export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer1.org1.example.com:7051peer lifecycle chaincode package chaincode/sacc.tar.gz --path chaincode/sacc --lang golang --label sacc_1peer lifecycle chaincode install chaincode/sacc.tar.gzpeer lifecycle chaincode queryinstalled #查询确认一下# 安装完毕，不必再审议链码，可以直接调用（只有新增组织时需要审议）# 如果报错，等待几分钟，即可</code></pre><p>调用链码</p><pre><code class="bash"># 自定义orderer的tls ca证书变量export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer chaincode query -C channel1 -n sacc  -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc   -c &#39;{&quot;Args&quot;:[&quot;get&quot;,&quot;a&quot;]}&#39;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer1.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt  -c &#39;{&quot;Args&quot;:[&quot;set&quot;,&quot;a&quot;,&quot;cc&quot;]}&#39;# 调用链码，背书节点必须满足策略，当前默认为大多数组织同意，即必须有属于两个组织的peer才能更新数据成功，否则随提交成功，但并没有更新数据</code></pre><h1 id="增加组织"><a href="#增加组织" class="headerlink" title="增加组织"></a>增加组织</h1><p>在192.168.1.138的主机上增加组织Org3的一个peer，首先需要在hosts文件中将该节点加进去</p><h2 id="1-获取身份证书"><a href="#1-获取身份证书" class="headerlink" title="1. 获取身份证书"></a>1. 获取身份证书</h2><p>因此处直接创建组织，所以直接使用cryptogen工具来创建即可，不必使用Fabric CA</p><pre><code class="bash">mkdir -p ~/work/example_org3/cd ~/work/example_org3/</code></pre><p>编辑配置文件vim org3-crypto.yaml</p><pre><code class="yaml">PeerOrgs:  # ---------------------------------------------------------------------------  # Org3  # ---------------------------------------------------------------------------  - Name: Org3MSP    Domain: org3.example.com    EnableNodeOUs: true    Template:      Count: 1    Users:      Count: 1</code></pre><p>生成文件</p><pre><code class="bash">cryptogen generate --config=org3-crypto.yaml --output=&quot;./organizations&quot;</code></pre><h2 id="2-启动新增组织节点"><a href="#2-启动新增组织节点" class="headerlink" title="2. 启动新增组织节点"></a>2. 启动新增组织节点</h2><pre><code class="bash">mkdir ~/work/example_org3/peercd ~/work/example_org3/peervim core.yaml</code></pre><p>对照org1的peer中core.yaml修改以下内容</p><pre><code class="yaml">15 peer.id: peer0.org3.example.com23 peer.listenAddress: 0.0.0.0:905128 peer.chaincodeListenAddress: 0.0.0.0:905240 peer.address: 0.0.0.0:905186 peer.gossip.bootstrap: 127.0.0.1:9051162 peer.gossip.externalEndpoint: peer0.org3.example.com:9051254 peer.tls.cert.file: ../organizations/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/server.crt258 peer.tls.key.file: ../organizations/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/server.key261 peer.tls.rootcert.file: ../organizations/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/ca.crt265 peer.tls.clientRootCAs.files: - ../organizations/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/ca.crt314 peer.mspConfigPath: ../organizations/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/msp323 peer.localMspId: Org3MSP681 operations.listenAddress: 127.0.0.1:9445 #因本机上还有个peer使用了9443</code></pre><p>启动</p><pre><code class="bash">export FABRIC_CFG_PATH=$PWDpeer node start</code></pre><h2 id="3-获取配置区块"><a href="#3-获取配置区块" class="headerlink" title="3. 获取配置区块"></a>3. 获取配置区块</h2><p>Org3还不是通道成员，我们需要以其它组织的admin来拉取通道配置。Org1组织。因Org1的peer1.org1.example.com也在Org3的主机上，因此直接用本地路径。生产环境要传输获取的区块。</p><pre><code class="bash">cd ~/work/example_org3/peerexport CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../../example/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../../example/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer1.org1.example.com:7051#自定义变量export ORDERER_TLSCA=${PWD}/../../example/organizations/orderer.example.com/tlscacerts/tlsca.example.com-cert.pem#拉取配置区块mkdir channel-artifactspeer channel fetch config ./channel-artifacts/config_block.pb -o orderer.example.com:7050 -c channel1 --tls --cafile $ORDERER_TLSCA</code></pre><h2 id="4-创建新组织的configtx-yaml"><a href="#4-创建新组织的configtx-yaml" class="headerlink" title="4. 创建新组织的configtx.yaml"></a>4. 创建新组织的configtx.yaml</h2><p>打开新的终端，屏蔽之前的环境变量影响</p><pre><code class="bash">cd ~/work/example_org3</code></pre><p>创建configtx.yaml</p><pre><code class="yaml"># Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#---##################################################################################   Section: Organizations##   - This section defines the different organizational identities which will#   be referenced later in the configuration.#################################################################################Organizations:    - &amp;Org3        # DefaultOrg defines the organization which is used in the sampleconfig        # of the fabric.git development environment        Name: Org3MSP        # ID to load the MSP definition as        ID: Org3MSP        MSPDir: ./organizations/peerOrganizations/org3.example.com/msp        Policies:            Readers:                Type: Signature                Rule: &quot;OR(&#39;Org3MSP.admin&#39;, &#39;Org3MSP.peer&#39;, &#39;Org3MSP.client&#39;)&quot;            Writers:                Type: Signature                Rule: &quot;OR(&#39;Org3MSP.admin&#39;, &#39;Org3MSP.client&#39;)&quot;            Admins:                Type: Signature                Rule: &quot;OR(&#39;Org3MSP.admin&#39;)&quot;            Endorsement:                Type: Signature                Rule: &quot;OR(&#39;Org3MSP.peer&#39;)&quot;        AnchorPeers:            # AnchorPeers defines the location of peers which can be used            # for cross org gossip communication.  Note, this value is only            # encoded in the genesis block in the Application section context            - Host: peer0.org3.example.com              Port: 9051</code></pre><p>执行如下命令创建org3.json</p><pre><code class="bash">export FABRIC_CFG_PATH=$PWDconfigtxgen -printOrg Org3MSP &gt; ./organizations/peerOrganizations/org3.example.com/org3.json</code></pre><h2 id="5-修改配置"><a href="#5-修改配置" class="headerlink" title="5. 修改配置"></a>5. 修改配置</h2><pre><code class="bash">cd channel-artifactsexport CHANNEL_NAME=channel1configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.jsonjq -s &#39;.[0] * {&quot;channel_group&quot;:{&quot;groups&quot;:{&quot;Application&quot;:{&quot;groups&quot;: {&quot;Org3MSP&quot;:.[1]}}}}}&#39; config.json ../../organizations/peerOrganizations/org3.example.com/org3.json &gt; modified_config.jsonconfigtxlator proto_encode --input config.json --type common.Config --output config.pbconfigtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pbconfigtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated modified_config.pb --output org3_update.pbconfigtxlator proto_decode --input org3_update.pb --type common.ConfigUpdate | jq . &gt; org3_update.jsonecho &#39;{&quot;payload&quot;:{&quot;header&quot;:{&quot;channel_header&quot;:{&quot;channel_id&quot;:&quot;&#39;$CHANNEL_NAME&#39;&quot;, &quot;type&quot;:2}},&quot;data&quot;:{&quot;config_update&quot;:&#39;$(cat org3_update.json)&#39;}}}&#39; | jq . &gt; org3_update_in_envelope.jsonconfigtxlator proto_encode --input org3_update_in_envelope.json --type common.Envelope --output org3_update_in_envelope.pb</code></pre><h2 id="6-提交修改"><a href="#6-提交修改" class="headerlink" title="6. 提交修改"></a>6. 提交修改</h2><p>在通道写入配置之前，当前默认策略是需要大多数组织同意，所以需要大多数组织管理员签名。</p><p>先以Org1的组织管理员来签名</p><pre><code class="bash">cd ~/work/example_org3/peer/export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../../example/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../../example/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer1.org1.example.com:7051#自定义变量export ORDERER_TLSCA=${PWD}/../../example/organizations/orderer.example.com/tlscacerts/tlsca.example.com-cert.pempeer channel signconfigtx -f ./channel-artifacts/org3_update_in_envelope.pb</code></pre><p>然后Org2的管理员来签名，首先将org3_update_in_envelope.pb传输给Org2的某个peer主机</p><p>在peer0.org2.example.com上</p><pre><code class="bash">cd ~/work/example/peerscp dev4@192.168.1.138:~/work/example_org3/peer/channel-artifacts/org3_update_in_envelope.pb ./channel-artifacts/export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer channel update -f ./channel-artifacts/org3_update_in_envelope.pb -c channel1 -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA</code></pre><p>此时配置区块会升级到block 3</p><h2 id="7-将新组织的peer加入通道"><a href="#7-将新组织的peer加入通道" class="headerlink" title="7. 将新组织的peer加入通道"></a>7. 将新组织的peer加入通道</h2><p>回到Org3的peer所在主机上</p><pre><code class="bash">cd ~/work/example_org3/peerexport CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org3MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org3.example.com/users/Admin@org3.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org3.example.com/users/Admin@org3.example.com/mspexport CORE_PEER_ADDRESS=peer0.org3.example.com:9051export ORDERER_TLSCA=${PWD}/../../example/organizations/orderer.example.com/tlscacerts/tlsca.example.com-cert.pem# 获取区块peer channel fetch 0 ./channel-artifacts/channel1.block -o orderer.example.com:7050 -c channel1 --tls --cafile $ORDERER_TLSCA#注意，我们传递了0来标识想要通道上的第一个区块：创始区块。如果我们直接使用peer channel fetch config，我们会接收block 3(升级Org3定义的区块)。然而我们不能从后续的区块开始，我们必须从区块0开始。peer channel join -b ./channel-artifacts/channel1.block</code></pre><h2 id="8-安装调用链码"><a href="#8-安装调用链码" class="headerlink" title="8. 安装调用链码"></a>8. 安装调用链码</h2><p>打开新的终端，复制链码</p><pre><code class="bash">cp -r ../../example/peer/chaincode/ .rm chaincode/sacc.tar.gz</code></pre><p>安装链码</p><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org3MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org3.example.com/users/Admin@org3.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org3.example.com/users/Admin@org3.example.com/mspexport CORE_PEER_ADDRESS=peer0.org3.example.com:9051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer lifecycle chaincode package chaincode/sacc.tar.gz --path chaincode/sacc --lang golang --label sacc_1peer lifecycle chaincode install chaincode/sacc.tar.gzpeer lifecycle chaincode queryinstalledexport CC_PACKAGE_ID=sacc_1:b33357c4012471d8bd96ba48fd2a12ada5fedfbfd6d623590295778500a0368d#注意与增加节点不同，新增组织必须要审议以下链码，才能调用链码peer lifecycle chaincode approveformyorg -o orderer.example.com:7050  --channelID channel1 --init-required --name sacc --version 1.0 --package-id $CC_PACKAGE_ID --sequence 1 --tls --cafile $ORDERER_TLSCA#审议结果可以通过peer lifecycle chaincode querycommitted --channelID channel1 --name sacc --cafile $ORDERER_TLSCA查询</code></pre><p>调用链码</p><pre><code class="bash">peer chaincode query -C channel1 -n sacc  -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org3.example.com:9051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../../example/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt  -c &#39;{&quot;Args&quot;:[&quot;set&quot;,&quot;a&quot;,&quot;2255&quot;]}&#39;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org3.example.com:9051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer1.org1.example.com:7051 --tlsRootCertFiles ${PWD}/../../example/organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/signcerts/cert.pem  -c &#39;{&quot;Args&quot;:[&quot;set&quot;,&quot;a&quot;,&quot;3355&quot;]}&#39;</code></pre><h1 id="新增order节点"><a href="#新增order节点" class="headerlink" title="新增order节点"></a>新增order节点</h1><p>在192.168.1.112的服务器上新增一个排序节点orderer1.example.com</p><p><strong>在增加orderer节点时，必须保证系统通道内的大多数已加入orderer在正常工作，如果正常工作的不能达到大多数，则系统通道将彻底无法修改。</strong></p><p>在这里遇到很多坑，尤其需要注意版本orderer（2.2版）的可执行文件必须是go1.14.6以上版本。</p><p>编辑各个主机的/etc/hosts</p><pre><code>192.168.1.108 orderer.example.com192.168.1.112 orderer1.example.com192.168.1.112 peer0.org1.example.com192.168.1.138 peer1.org1.example.com192.168.1.111 peer0.org2.example.com192.168.1.138 peer0.org3.example.com</code></pre><h2 id="1-获取order1的MSP"><a href="#1-获取order1的MSP" class="headerlink" title="1. 获取order1的MSP"></a>1. 获取order1的MSP</h2><pre><code class="bash">mkdir ~/work/example/ca_order_servercd ~/work/example/ca_order_server# 1.初始化fabric-ca-server init -b admin:adminpw --port 7055# 2.修改fabric-ca-server-config.yamlca:  # Name of this CA  name: OrdererOrg  # Key file (is only used to import a private key into BCCSP)  keyfile: ../organizations/ordererOrganizations/example.com/ca/priv_sk  # Certificate file (default: ca-cert.pem)  certfile: ../organizations/ordererOrganizations/example.com/ca/ca.example.com-cert.pem  # Chain file  chainfile:# 因9443端口在peer中占用，所以暂时将本配置文件中operations部分注释掉# 3.启动serverfabric-ca-server start  -b admin:adminpw --port 7055# 4.client登陆mkdir ~/work/example/ca_order_clientcd ~/work/example/ca_order_clientexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client enroll -u http://admin:adminpw@localhost:7055fabric-ca-client register -d --id.name orderer1.example.com --id.secret orderPW --id.type orderer -u http://0.0.0.0:7055# 5.登陆orderer1.example.com获取mspcd ~/work/example/organizations/ordererOrganizations/example.com/orderersmkdir orderer1.example.comcd orderer1.example.comexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client enroll -u http://orderer1.example.com:orderPW@0.0.0.0:7055 -M $FABRIC_CA_CLIENT_HOME/msp# 6.声明管理员用户mkdir msp/admincertscp ../../users/Admin@example.com/msp/signcerts/Admin@example.com-cert.pem msp/admincerts/</code></pre><h2 id="2-获取order1的TLS"><a href="#2-获取order1的TLS" class="headerlink" title="2. 获取order1的TLS"></a>2. 获取order1的TLS</h2><pre><code class="bash"># 1.启动TLS servermkdir ~/work/example/tlsca_order_servercd ~/work/example/tlsca_order_serverfabric-ca-server init -b tlsadmin:tlsadminpw# 2.修改配置文件ca:  # Name of this CA  name: tlsca-OrdererOrg  # Key file (is only used to import a private key into BCCSP)  keyfile: ../organizations/ordererOrganizations/example.com/tlsca/priv_sk  # Certificate file (default: ca-cert.pem)  certfile: ../organizations/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem  # Chain file  chainfile:# 因9443端口在peer中占用，所以暂时将本配置文件中operations部分注释掉# 3.开启serverfabric-ca-server start  -b tlsadmin:tlsadminpw --port 7056# 4.使用client注册账号mkdir ~/work/example/tlsca_order_clientcd ~/work/example/tlsca_order_clientexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client enroll -u http://tlsadmin:tlsadminpw@localhost:7056fabric-ca-client register -d --id.name orderer1.example.com --id.secret orderPW --id.type orderer -u http://0.0.0.0:7056# 5.登录orderer1.example.com获取tlscd ~/work/example/organizations/ordererOrganizations/example.com/orderers/orderer1.example.comexport FABRIC_CA_CLIENT_HOME=$PWD#注意下方--csr.hosts必须加，否则在将peer加入通道时会报错fabric-ca-client enroll -u http://orderer1.example.com:orderPW@0.0.0.0:7056 -M $FABRIC_CA_CLIENT_HOME/tls --csr.hosts orderer1.example.commv tls/keystore/* tls/keystore/server.key</code></pre><h2 id="3-编辑系统区块"><a href="#3-编辑系统区块" class="headerlink" title="3. 编辑系统区块"></a>3. 编辑系统区块</h2><pre><code class="bash"># 首先从peer0.org1.example.com拉取系统配置区块（在core.yaml所在目录执行）cd ~/work/example/peermkdir -p conf-orderer1/sysexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/msp/ #order组织的管理员export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/tls/ca.crtexport CORE_PEER_LOCALMSPID=&quot;OrdererMSP&quot; #order组织mspidexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pemexport CH_NAME=system-channelpeer channel fetch config conf-orderer1/sys/config_block.pb -o orderer.example.com:7050 -c $CH_NAME --tls --cafile $ORDERER_TLSCAcd conf-orderer1/sys/configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.jsoncp config.json modified_config.json</code></pre><p>在modified_config.json中修改内容</p><p><strong>位置一</strong></p><p>找到如下位置</p><pre><code class="json">{  &quot;client_tls_cert&quot;: &quot;ORDER TLS SERVER CERT&quot;,  &quot;host&quot;: &quot;orderer.example.com&quot;,  &quot;port&quot;: 7050,  &quot;server_tls_cert&quot;: &quot;ORDER TLS SERVER CERT&quot;}</code></pre><p>其中client_tls_cert和server_tls_cert的内容是以下</p><pre><code class="bash">cat ~/work/example/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt |base64</code></pre><p>对于Fabric CA server产生的tls msp路径如下：</p><pre><code class="bash"># 方式一：cat ~/work/example/organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/signcerts/cert.pem |base64  &gt; cert.txt# 进入python终端获取去掉回车的证书&#39;&#39;.join(file(&#39;cert.txt&#39;,&#39;r&#39;).read().split(&#39;\n&#39;))# 方式二：进入python终端f = &#39;/home/dev2/work/example/organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/signcerts/cert.pem&#39;import base64base64.b64encode(file(f, &#39;r&#39;).read())</code></pre><p>在此位置修改成如下代码（在base64转义后去掉证书中的回车）</p><pre><code class="json">{  &quot;client_tls_cert&quot;: &quot;ORDER TLS SERVER CERT&quot;,  &quot;host&quot;: &quot;orderer.example.com&quot;,  &quot;port&quot;: 7050,  &quot;server_tls_cert&quot;: &quot;ORDER TLS SERVER CERT&quot;},{  &quot;client_tls_cert&quot;: &quot;ORDER1 TLS SERVER CERT&quot;,  &quot;host&quot;: &quot;orderer1.example.com&quot;,  &quot;port&quot;: 7050,  &quot;server_tls_cert&quot;: &quot;ORDER1 TLS SERVER CERT&quot;}</code></pre><p><strong>位置二</strong></p><p>修改如下内容</p><pre><code class="json">&quot;Endpoints&quot;: {&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;: {  &quot;addresses&quot;: [    &quot;orderer.example.com:7050&quot;,    &quot;orderer1.example.com:7050&quot;  ]},// 注意如果是以下内容，则后续无法成功添加orderer，请检查orderer版本和go版本&quot;OrdererAddresses&quot;: {    &quot;mod_policy&quot;: &quot;/Channel/Orderer/Admins&quot;,    &quot;value&quot;: {      &quot;addresses&quot;: [        &quot;orderer.example.com:7050&quot;      ]}</code></pre><h2 id="4-提交修改的配置区块"><a href="#4-提交修改的配置区块" class="headerlink" title="4. 提交修改的配置区块"></a>4. 提交修改的配置区块</h2><pre><code class="bash">configtxlator proto_encode --input config.json --type common.Config &gt; config.pbconfigtxlator proto_encode --input modified_config.json --type common.Config &gt; modified_config.pbconfigtxlator compute_update --channel_id $CH_NAME --original config.pb --updated modified_config.pb --output config_update.pbconfigtxlator proto_decode --input config_update.pb --type common.ConfigUpdate --output config_update.jsonecho &#39;{&quot;payload&quot;:{&quot;header&quot;:{&quot;channel_header&quot;:{&quot;channel_id&quot;:&quot;&#39;$CH_NAME&#39;&quot;, &quot;type&quot;:2}},&quot;data&quot;:{&quot;config_update&quot;:&#39;$(cat config_update.json)&#39;}}}&#39; | jq . &gt; config_update_in_envelope.jsonconfigtxlator proto_encode --input config_update_in_envelope.json --type common.Envelope --output config_update_in_envelope.pbcd ../../#以OrdererMSP组织管理员的身份签名export CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/msp/ #order组织的管理员export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/tls/ca.crtexport CORE_PEER_LOCALMSPID=&quot;OrdererMSP&quot; #order组织mspidexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer channel signconfigtx -f ./conf-orderer1/sys/config_update_in_envelope.pb#提交（不需要其它管理员签名，属于OrdererOrg组织内部增加节点），peer channel update -f ./conf-orderer1/sys/config_update_in_envelope.pb -c $CH_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA</code></pre><h2 id="5-启动新的order节点"><a href="#5-启动新的order节点" class="headerlink" title="5. 启动新的order节点"></a>5. 启动新的order节点</h2><pre><code class="bash">#获取最新的系统通道配置区块，仍在peer0服务器上cd ~/work/example/peermkdir system-genesis-blockexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/msp/ #order组织的管理员export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/tls/ca.crtexport CORE_PEER_LOCALMSPID=&quot;OrdererMSP&quot; #order组织mspidexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pemexport CH_NAME=system-channelpeer channel fetch config system-genesis-block/genesis.block -o orderer.example.com:7050 -c $CH_NAME --tls --cafile $ORDERER_TLSCA</code></pre><p>到orderer1的服务器上，</p><pre><code class="bash">cd ~/work/example/order</code></pre><p>现将系统配置的最新区块复制过来</p><pre><code class="bash">scp -r user@ip:~/work/example/peer/system-genesis-block .</code></pre><p>对照原节点的orderer.yaml做如下修改</p><pre><code class="yaml">16 General.ListenAddress: orderer1.example.com19 General.ListenPort: 705025 General.TLS.PrivateKey: ../organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/keystore/server.key27 General.TLS.Certificate: ../organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/signcerts/cert.pem29 General.TLS.RootCAs: ../organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/cacerts/0-0-0-0-7056.pem52 Cluster.ClientCertificate: ../organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/signcerts/cert.pem54 Cluster.ClientPrivateKey:../organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/tls/keystore/server.key89 LocalMSPDir: ../organizations/ordererOrganizations/example.com/orderers/orderer1.example.com/msp</code></pre><p>运行orderer1</p><pre><code class="bash">orderer start</code></pre><h2 id="6-将新的order节点加入应用通道"><a href="#6-将新的order节点加入应用通道" class="headerlink" title="6. 将新的order节点加入应用通道"></a>6. 将新的order节点加入应用通道</h2><p>当前orderer1仅仅加入了系统通道，并没有加入应用通用channel1，下面将orderer1加入channel1</p><p>仍然在peer0的服务器上</p><pre><code class="bash">cd ~/work/example/peermkdir -p conf-orderer1/channel1export CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/msp/ #order组织的管理员export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/tls/ca.crtexport CORE_PEER_LOCALMSPID=&quot;OrdererMSP&quot; #order组织mspidexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pemexport CH_NAME=channel1#获取最新的应用通道配置区块peer channel fetch config conf-orderer1/channel1/config_block.pb -o orderer.example.com:7050 -c $CH_NAME --tls --cafile $ORDERER_TLSCAcd conf-orderer1/channel1configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.jsoncp config.json modified_config.json</code></pre><p>然后按照步骤5的内容修改modified_config.json的两处内容之后</p><pre><code class="bash">configtxlator proto_encode --input config.json --type common.Config &gt; config.pbconfigtxlator proto_encode --input modified_config.json --type common.Config &gt; modified_config.pbconfigtxlator compute_update --channel_id $CH_NAME --original config.pb --updated modified_config.pb --output config_update.pbconfigtxlator proto_decode --input config_update.pb --type common.ConfigUpdate --output config_update.jsonecho &#39;{&quot;payload&quot;:{&quot;header&quot;:{&quot;channel_header&quot;:{&quot;channel_id&quot;:&quot;&#39;$CH_NAME&#39;&quot;, &quot;type&quot;:2}},&quot;data&quot;:{&quot;config_update&quot;:&#39;$(cat config_update.json)&#39;}}}&#39; | jq . &gt; config_update_in_envelope.jsonconfigtxlator proto_encode --input config_update_in_envelope.json --type common.Envelope --output config_update_in_envelope.pb</code></pre><pre><code class="bash">cd ../../#以OrdererMSP组织管理员的身份签名export CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/msp/ #order组织的管理员export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/ordererOrganizations/example.com/users/Admin@example.com/tls/ca.crtexport CORE_PEER_LOCALMSPID=&quot;OrdererMSP&quot; #order组织mspidexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer channel signconfigtx -f ./conf-orderer1/channel1/config_update_in_envelope.pb#提交（此时不需要其它管理员签名，属于排序组织OrdererOrg内部增加节点），peer channel update -f ./conf-orderer1/channel1/config_update_in_envelope.pb -c $CH_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA</code></pre><p>提交之后一段时间内会在orderer的log中看到报错，忽略即可。</p><pre><code class="bash"># orderer端[orderer.consensus.etcdraft] logSendFailure -&gt; ERRO 122 Failed to send StepRequest to 2, because: aborted channel=channel1 node=1# peer如果此时调用链码会看到错误got unexpected status: SERVICE_UNAVAILABLE -- no Raft leader</code></pre><p>等待5分钟，错误消失，即可使用orderer1来接收链码调用</p><h1 id="删除order节点"><a href="#删除order节点" class="headerlink" title="删除order节点"></a>删除order节点</h1><p>和新增步骤类似，只是从modified_config.json中两处修改该位置中，找到对应orderer信息删除即可。</p><p>删除应用通道orderer节点和删除系统通道orderer节点两步要分开执行。</p><p>提交时，作者的环境是两个orderer同属一个排序组织。只需要一个orderer对事物变更进行签名，再提交即可。</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01_搭建基础网络</title>
      <link href="/2020/12/02/fabric/01_%E6%90%AD%E5%BB%BA%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/12/02/fabric/01_%E6%90%AD%E5%BB%BA%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="搭建基础网络"><a href="#搭建基础网络" class="headerlink" title="搭建基础网络"></a>搭建基础网络</h1><p>下面将会搭建一个有3个节点（其中1个order，2个peer）的网络。因此首先需要配置服务器的host文件，将域名映射到对应的IP地址。这一步需要根据集群中服务器的不同状态来确定不同的值。</p><pre><code>192.168.108.128 orderer.example.com192.168.108.133 peer0.org1.example.com192.168.108.132 peer0.org2.example.com</code></pre><p>在搭建网络时，需要将文件夹配置成如下的结构：</p><pre><code>─── fabricStu    ├── order    ├── peer    └── organizations</code></pre><p>其中：</p><ul><li><strong>order文件夹</strong>：用于存放排序节点相关的配置文件以及内容</li><li><strong>peer文件夹</strong>：用于存放普通peer节点相关的配置文件及内容</li><li><strong>organizations文件夹</strong>：用于存放节点证书相关文件</li></ul><p>此外还需要注意，如果是在order节点，只需要配置order文件夹，如果是在peer节点，只需要配置peer文件夹。这里为了说明方便，就把所有的文件夹都放在这里。</p><h2 id="1-生成证书素材"><a href="#1-生成证书素材" class="headerlink" title="1. 生成证书素材"></a>1. 生成证书素材</h2><p>首先在organizations文件夹中编辑 <code>crypto-config.yaml</code> 文件</p><pre><code class="yaml">OrdererOrgs:  - Name: OrdererOrg    Domain: example.com #此处是根域名不是orderer.example.com    EnableNodeOUs: true #身份分类启用，此项很关键，若不设置peer可能无法连接到orderer    Specs:      - Hostname: ordererPeerOrgs:  - Name: Org1MSP    Domain: org1.example.com    EnableNodeOUs: true  #身份分类启用，此项很关键，若不设置peer可能无法连接到orderer    Template:      Count: 1    Users:      Count: 1  - Name: Org2MSP    Domain: org2.example.com    EnableNodeOUs: true  #身份分类启用，此项很关键，若不设置peer可能无法连接到orderer    Template:      Count: 1    Users:      Count: 1</code></pre><p>使用cryptogen工具来生成证书</p><pre><code class="bash">cryptogen generate --config=crypto-config.yaml --output ./</code></pre><p>生成完成之后，整个目录的结构为：</p><pre><code>├── crypto-config.yaml├── ordererOrganizations│   └── example.com│       ├── ca│       │   ├── ca.example.com-cert.pem│       │   └── priv_sk│       ├── msp│       │   ├── admincerts│       │   ├── cacerts│       │   │   └── ca.example.com-cert.pem│       │   ├── config.yaml│       │   └── tlscacerts│       │       └── tlsca.example.com-cert.pem│       ├── orderers│       │   └── orderer.example.com│       │       ├── msp│       │       │   ├── admincerts│       │       │   ├── cacerts│       │       │   │   └── ca.example.com-cert.pem│       │       │   ├── config.yaml│       │       │   ├── keystore│       │       │   │   └── priv_sk│       │       │   ├── signcerts│       │       │   │   └── orderer.example.com-cert.pem│       │       │   └── tlscacerts│       │       │       └── tlsca.example.com-cert.pem│       │       └── tls│       │           ├── ca.crt│       │           ├── server.crt│       │           └── server.key│       ├── tlsca│       │   ├── priv_sk│       │   └── tlsca.example.com-cert.pem│       └── users│           └── Admin@example.com│               ├── msp│               │   ├── admincerts│               │   ├── cacerts│               │   │   └── ca.example.com-cert.pem│               │   ├── config.yaml│               │   ├── keystore│               │   │   └── priv_sk│               │   ├── signcerts│               │   │   └── Admin@example.com-cert.pem│               │   └── tlscacerts│               │       └── tlsca.example.com-cert.pem│               └── tls│                   ├── ca.crt│                   ├── client.crt│                   └── client.key└── peerOrganizations    ├── org1.example.com    │   ├── ca    │   │   ├── ca.org1.example.com-cert.pem    │   │   └── priv_sk    │   ├── msp    │   │   ├── admincerts    │   │   ├── cacerts    │   │   │   └── ca.org1.example.com-cert.pem    │   │   ├── config.yaml    │   │   └── tlscacerts    │   │       └── tlsca.org1.example.com-cert.pem    │   ├── peers    │   │   └── peer0.org1.example.com    │   │       ├── msp    │   │       │   ├── admincerts    │   │       │   ├── cacerts    │   │       │   │   └── ca.org1.example.com-cert.pem    │   │       │   ├── config.yaml    │   │       │   ├── keystore    │   │       │   │   └── priv_sk    │   │       │   ├── signcerts    │   │       │   │   └── peer0.org1.example.com-cert.pem    │   │       │   └── tlscacerts    │   │       │       └── tlsca.org1.example.com-cert.pem    │   │       └── tls    │   │           ├── ca.crt    │   │           ├── server.crt    │   │           └── server.key    │   ├── tlsca    │   │   ├── priv_sk    │   │   └── tlsca.org1.example.com-cert.pem    │   └── users    │       ├── Admin@org1.example.com    │       │   ├── msp    │       │   │   ├── admincerts    │       │   │   ├── cacerts    │       │   │   │   └── ca.org1.example.com-cert.pem    │       │   │   ├── config.yaml    │       │   │   ├── keystore    │       │   │   │   └── priv_sk    │       │   │   ├── signcerts    │       │   │   │   └── Admin@org1.example.com-cert.pem    │       │   │   └── tlscacerts    │       │   │       └── tlsca.org1.example.com-cert.pem    │       │   └── tls    │       │       ├── ca.crt    │       │       ├── client.crt    │       │       └── client.key    │       └── User1@org1.example.com    │           ├── msp    │           │   ├── admincerts    │           │   ├── cacerts    │           │   │   └── ca.org1.example.com-cert.pem    │           │   ├── config.yaml    │           │   ├── keystore    │           │   │   └── priv_sk    │           │   ├── signcerts    │           │   │   └── User1@org1.example.com-cert.pem    │           │   └── tlscacerts    │           │       └── tlsca.org1.example.com-cert.pem    │           └── tls    │               ├── ca.crt    │               ├── client.crt    │               └── client.key    └── org2.example.com        ├── ca        │   ├── ca.org2.example.com-cert.pem        │   └── priv_sk        ├── msp        │   ├── admincerts        │   ├── cacerts        │   │   └── ca.org2.example.com-cert.pem        │   ├── config.yaml        │   └── tlscacerts        │       └── tlsca.org2.example.com-cert.pem        ├── peers        │   └── peer0.org2.example.com        │       ├── msp        │       │   ├── admincerts        │       │   ├── cacerts        │       │   │   └── ca.org2.example.com-cert.pem        │       │   ├── config.yaml        │       │   ├── keystore        │       │   │   └── priv_sk        │       │   ├── signcerts        │       │   │   └── peer0.org2.example.com-cert.pem        │       │   └── tlscacerts        │       │       └── tlsca.org2.example.com-cert.pem        │       └── tls        │           ├── ca.crt        │           ├── server.crt        │           └── server.key        ├── tlsca        │   ├── priv_sk        │   └── tlsca.org2.example.com-cert.pem        └── users            ├── Admin@org2.example.com            │   ├── msp            │   │   ├── admincerts            │   │   ├── cacerts            │   │   │   └── ca.org2.example.com-cert.pem            │   │   ├── config.yaml            │   │   ├── keystore            │   │   │   └── priv_sk            │   │   ├── signcerts            │   │   │   └── Admin@org2.example.com-cert.pem            │   │   └── tlscacerts            │   │       └── tlsca.org2.example.com-cert.pem            │   └── tls            │       ├── ca.crt            │       ├── client.crt            │       └── client.key            └── User1@org2.example.com                ├── msp                │   ├── admincerts                │   ├── cacerts                │   │   └── ca.org2.example.com-cert.pem                │   ├── config.yaml                │   ├── keystore                │   │   └── priv_sk                │   ├── signcerts                │   │   └── User1@org2.example.com-cert.pem                │   └── tlscacerts                │       └── tlsca.org2.example.com-cert.pem                └── tls                    ├── ca.crt                    ├── client.crt                    └── client.key</code></pre><h2 id="2-生成系统的创世块"><a href="#2-生成系统的创世块" class="headerlink" title="2. 生成系统的创世块"></a>2. 生成系统的创世块</h2><p>需要在order文件夹下，编辑 <code>configtx.yaml</code> 文件，编辑完成之后执行下面这个命令：</p><pre><code class="bash">configtxgen -profile TwoOrgsOrdererGenesis -channelID system-channel -outputBlock ./system-genesis-block/genesis.block</code></pre><p>这个文件分成了两个部分：</p><ol><li><p>Organizations：定义了不同的组织，稍后将在配置中引用这些组织身份。</p></li><li><p>Capabilities：定义功能，其中通道的功能既适用于order，也适用于peer，并且二者必须同时支持</p></li><li><p>Application：定义了要编码为应用程序相关参数的配置tx或创世块的值</p></li><li><p>Orderer：定义了要编码为与orderer相关的参数的配置tx或创世块的值</p><ul><li>MaxMessageCount</li><li>AbsoluteMaxBytes</li><li>PreferredMaxBytes</li></ul></li><li><p>Channel：定义了要编码为通道相关参数的配置tx或创世块的值。</p></li><li><p>Profile：对不同的配置文件进行编码以将其指定为configtxgen工具的参数</p><p>这个参数就比较有意思了，在这一步生成创世区块以及第三步创建应用通道创建事务这两部都需要用到，并且分别用了这里面定义的两个参数</p></li></ol><pre><code class="yaml">Organizations:    - &amp;OrdererOrg        # DefaultOrg defines the organization which is used in the sampleconfig        # of the fabric.git development environment        Name: OrdererOrg        # ID to load the MSP definition as        ID: OrdererMSP        # MSPDir is the filesystem path which contains the MSP configuration        MSPDir: ../organizations/ordererOrganizations/example.com/msp        # Policies defines the set of policies at this level of the config tree        # For organization policies, their canonical path is usually        #   /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt;        Policies:            Readers:                Type: Signature                Rule: &quot;OR(&#39;OrdererMSP.member&#39;)&quot;            Writers:                Type: Signature                Rule: &quot;OR(&#39;OrdererMSP.member&#39;)&quot;            Admins:                Type: Signature                Rule: &quot;OR(&#39;OrdererMSP.admin&#39;)&quot;        OrdererEndpoints:            - &quot;orderer.example.com:7050&quot;    - &amp;Org1        # DefaultOrg defines the organization which is used in the sampleconfig        # of the fabric.git development environment        Name: Org1MSP        # ID to load the MSP definition as        ID: Org1MSP        MSPDir: ../organizations/peerOrganizations/org1.example.com/msp        # Policies defines the set of policies at this level of the config tree        # For organization policies, their canonical path is usually        #   /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt;        Policies:            Readers:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.admin&#39;, &#39;Org1MSP.peer&#39;, &#39;Org1MSP.client&#39;)&quot;            Writers:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.admin&#39;, &#39;Org1MSP.client&#39;)&quot;            Admins:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.admin&#39;)&quot;            Endorsement:                Type: Signature                Rule: &quot;OR(&#39;Org1MSP.peer&#39;)&quot;        # leave this flag set to true.        AnchorPeers:            # AnchorPeers defines the location of peers which can be used            # for cross org gossip communication.  Note, this value is only            # encoded in the genesis block in the Application section context            - Host: peer0.org1.example.com              Port: 7051    - &amp;Org2        # DefaultOrg defines the organization which is used in the sampleconfig        # of the fabric.git development environment        Name: Org2MSP        # ID to load the MSP definition as        ID: Org2MSP        MSPDir: ../organizations/peerOrganizations/org2.example.com/msp        # Policies defines the set of policies at this level of the config tree        # For organization policies, their canonical path is usually        #   /Channel/&lt;Application|Orderer&gt;/&lt;OrgName&gt;/&lt;PolicyName&gt;        Policies:            Readers:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.admin&#39;, &#39;Org2MSP.peer&#39;, &#39;Org2MSP.client&#39;)&quot;            Writers:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.admin&#39;, &#39;Org2MSP.client&#39;)&quot;            Admins:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.admin&#39;)&quot;            Endorsement:                Type: Signature                Rule: &quot;OR(&#39;Org2MSP.peer&#39;)&quot;        AnchorPeers:            # AnchorPeers defines the location of peers which can be used            # for cross org gossip communication.  Note, this value is only            # encoded in the genesis block in the Application section context            - Host: peer0.org2.example.com              Port: 7051Capabilities:    Channel: &amp;ChannelCapabilities        V2_0: true    Orderer: &amp;OrdererCapabilities        V2_0: true    Application: &amp;ApplicationCapabilities        V2_0: trueApplication: &amp;ApplicationDefaults    # Organizations is the list of orgs which are defined as participants on    # the application side of the network    Organizations:    # Policies defines the set of policies at this level of the config tree    # For Application policies, their canonical path is    #   /Channel/Application/&lt;PolicyName&gt;    Policies:        Readers:            Type: ImplicitMeta            Rule: &quot;ANY Readers&quot;        Writers:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;        Admins:            Type: ImplicitMeta            Rule: &quot;MAJORITY Admins&quot;        LifecycleEndorsement:            Type: ImplicitMeta            Rule: &quot;MAJORITY Endorsement&quot;        Endorsement:            Type: ImplicitMeta            Rule: &quot;MAJORITY Endorsement&quot;    Capabilities:        &lt;&lt;: *ApplicationCapabilitiesOrderer: &amp;OrdererDefaults    # Orderer Type: The orderer implementation to start    OrdererType: etcdraft    EtcdRaft:        Consenters:            - Host: orderer.example.com              Port: 7050              ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt              ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt    # Batch Timeout: The amount of time to wait before creating a batch    BatchTimeout: 2s    # Batch Size: Controls the number of messages batched into a block    BatchSize:        # Max Message Count: The maximum number of messages to permit in a batch        MaxMessageCount: 10        # Absolute Max Bytes: The absolute maximum number of bytes allowed for        # the serialized messages in a batch.        AbsoluteMaxBytes: 99 MB        # Preferred Max Bytes: The preferred maximum number of bytes allowed for        # the serialized messages in a batch. A message larger than the preferred        # max bytes will result in a batch larger than preferred max bytes.        PreferredMaxBytes: 512 KB    # Organizations is the list of orgs which are defined as participants on    # the orderer side of the network    Organizations:    # Policies defines the set of policies at this level of the config tree    # For Orderer policies, their canonical path is    #   /Channel/Orderer/&lt;PolicyName&gt;    Policies:        Readers:            Type: ImplicitMeta            Rule: &quot;ANY Readers&quot;        Writers:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;        Admins:            Type: ImplicitMeta            Rule: &quot;MAJORITY Admins&quot;        # BlockValidation specifies what signatures must be included in the block        # from the orderer for the peer to validate it.        BlockValidation:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;Channel: &amp;ChannelDefaults    # Policies defines the set of policies at this level of the config tree    # For Channel policies, their canonical path is    #   /Channel/&lt;PolicyName&gt;    Policies:        # Who may invoke the &#39;Deliver&#39; API        Readers:            Type: ImplicitMeta            Rule: &quot;ANY Readers&quot;        # Who may invoke the &#39;Broadcast&#39; API        Writers:            Type: ImplicitMeta            Rule: &quot;ANY Writers&quot;        # By default, who may modify elements at this config level        Admins:            Type: ImplicitMeta            Rule: &quot;MAJORITY Admins&quot;    # Capabilities describes the channel level capabilities, see the    # dedicated Capabilities section elsewhere in this file for a full    # description    Capabilities:        &lt;&lt;: *ChannelCapabilitiesProfiles:    TwoOrgsOrdererGenesis:        &lt;&lt;: *ChannelDefaults        Orderer:            &lt;&lt;: *OrdererDefaults            Organizations:                - *OrdererOrg            Capabilities:                &lt;&lt;: *OrdererCapabilities        Consortiums:            SampleConsortium:                Organizations:                    - *Org1                    - *Org2    TwoOrgsChannel:        Consortium: SampleConsortium        &lt;&lt;: *ChannelDefaults        Application:            &lt;&lt;: *ApplicationDefaults            Organizations:                - *Org1                - *Org2            Capabilities:                &lt;&lt;: *ApplicationCapabilities</code></pre><h2 id="3-创建应用通道创建事务"><a href="#3-创建应用通道创建事务" class="headerlink" title="3. 创建应用通道创建事务"></a>3. 创建应用通道创建事务</h2><pre><code class="bash">configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel1.tx -channelID channel1</code></pre><h2 id="4-配置启动orderer节点"><a href="#4-配置启动orderer节点" class="headerlink" title="4. 配置启动orderer节点"></a>4. 配置启动orderer节点</h2><p>在order目录中放入 <code>orderer.yaml</code>，之后使用下面的命令启动之</p><pre><code class="bash">orderer start</code></pre><pre><code class="yaml"># Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0#---##################################################################################   Orderer Configuration##   - This controls the type and configuration of the orderer.#################################################################################General:    # Listen address: The IP on which to bind to listen.    ListenAddress: orderer.example.com    # Listen port: The port on which to bind to listen.    ListenPort: 7050    # TLS: TLS settings for the GRPC server.    TLS:        Enabled: true        # PrivateKey governs the file location of the private key of the TLS certificate.        PrivateKey: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.key        # Certificate governs the file location of the server TLS certificate.        Certificate: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt        RootCAs:          - ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/ca.crt        ClientAuthRequired: false #此处暂时为false，正式环境是否需要设置为true，而且下面的值也不确定填写什么（如只写一个组织的那其它组织怎么办）        ClientRootCAs:    # Keepalive settings for the GRPC server.    Keepalive:        # ServerMinInterval is the minimum permitted time between client pings.        # If clients send pings more frequently, the server will        # disconnect them.        ServerMinInterval: 60s        # ServerInterval is the time between pings to clients.        ServerInterval: 7200s        # ServerTimeout is the duration the server waits for a response from        # a client before closing the connection.        ServerTimeout: 20s    # Cluster settings for ordering service nodes that communicate with other ordering service nodes    # such as Raft based ordering service.    Cluster:        # SendBufferSize is the maximum number of messages in the egress buffer.        # Consensus messages are dropped if the buffer is full, and transaction        # messages are waiting for space to be freed.        SendBufferSize: 10        # ClientCertificate governs the file location of the client TLS certificate        # used to establish mutual TLS connections with other ordering service nodes.        ClientCertificate: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt        # ClientPrivateKey governs the file location of the private key of the client TLS certificate.        ClientPrivateKey: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.key        # The below 4 properties should be either set together, or be unset together.        # If they are set, then the orderer node uses a separate listener for intra-cluster        # communication. If they are unset, then the general orderer listener is used.        # This is useful if you want to use a different TLS server certificates on the        # client-facing and the intra-cluster listeners.        # ListenPort defines the port on which the cluster listens to connections.        ListenPort:        # ListenAddress defines the IP on which to listen to intra-cluster communication.        ListenAddress:        # ServerCertificate defines the file location of the server TLS certificate used for intra-cluster        # communication.        ServerCertificate:        # ServerPrivateKey defines the file location of the private key of the TLS certificate.        ServerPrivateKey:    # Bootstrap method: The method by which to obtain the bootstrap block    # system channel is specified. The option can be one of:    #   &quot;file&quot; - path to a file containing the genesis block or config block of system channel    #   &quot;none&quot; - allows an orderer to start without a system channel configuration    BootstrapMethod: file    # Bootstrap file: The file containing the bootstrap block to use when    # initializing the orderer system channel and BootstrapMethod is set to    # &quot;file&quot;.  The bootstrap file can be the genesis block, and it can also be    # a config block for late bootstrap of some consensus methods like Raft.    # Generate a genesis block by updating $FABRIC_CFG_PATH/configtx.yaml and    # using configtxgen command with &quot;-outputBlock&quot; option.    # Defaults to file &quot;genesisblock&quot; (in $FABRIC_CFG_PATH directory) if not specified.    BootstrapFile: ./system-genesis-block/genesis.block    # LocalMSPDir is where to find the private crypto material needed by the    # orderer. It is set relative here as a default for dev environments but    # should be changed to the real location in production.    LocalMSPDir: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/    # LocalMSPID is the identity to register the local MSP material with the MSP    # manager. IMPORTANT: The local MSP ID of an orderer needs to match the MSP    # ID of one of the organizations defined in the orderer system channel&#39;s    # /Channel/Orderer configuration. The sample organization defined in the    # sample configuration provided has an MSP ID of &quot;SampleOrg&quot;.    LocalMSPID: OrdererMSP #注意这里写ID不要写NAME很容易错    # Enable an HTTP service for Go &quot;pprof&quot; profiling as documented at:    # https://golang.org/pkg/net/http/pprof    Profile:        Enabled: false        Address: 0.0.0.0:6060    # BCCSP configures the blockchain crypto service providers.    BCCSP:        # Default specifies the preferred blockchain crypto service provider        # to use. If the preferred provider is not available, the software        # based provider (&quot;SW&quot;) will be used.        # Valid providers are:        #  - SW: a software based crypto provider        #  - PKCS11: a CA hardware security module crypto provider.        Default: SW        # SW configures the software based blockchain crypto provider.        SW:            # TODO: The default Hash and Security level needs refactoring to be            # fully configurable. Changing these defaults requires coordination            # SHA2 is hardcoded in several places, not only BCCSP            Hash: SHA2            Security: 256            # Location of key store. If this is unset, a location will be            # chosen using: &#39;LocalMSPDir&#39;/keystore            FileKeyStore:                KeyStore:        # Settings for the PKCS#11 crypto provider (i.e. when DEFAULT: PKCS11)        PKCS11:            # Location of the PKCS11 module library            Library:            # Token Label            Label:            # User PIN            Pin:            Hash:            Security:            FileKeyStore:                KeyStore:    # Authentication contains configuration parameters related to authenticating    # client messages    Authentication:        # the acceptable difference between the current server time and the        # client&#39;s time as specified in a client request message        TimeWindow: 15m##################################################################################   SECTION: File Ledger##   - This section applies to the configuration of the file or json ledgers.#################################################################################FileLedger:    # Location: The directory to store the blocks in.    # NOTE: If this is unset, a new temporary location will be chosen every time    # the orderer is restarted, using the prefix specified by Prefix.    Location: production/orderer/    # The prefix to use when generating a ledger directory in temporary space.    # Otherwise, this value is ignored.    Prefix: hyperledger-fabric-ordererledger##################################################################################   SECTION: Kafka##   - This section applies to the configuration of the Kafka-based orderer, and#     its interaction with the Kafka cluster.#################################################################################Kafka:    # Retry: What do if a connection to the Kafka cluster cannot be established,    # or if a metadata request to the Kafka cluster needs to be repeated.    Retry:        # When a new channel is created, or when an existing channel is reloaded        # (in case of a just-restarted orderer), the orderer interacts with the        # Kafka cluster in the following ways:        # 1. It creates a Kafka producer (writer) for the Kafka partition that        # corresponds to the channel.        # 2. It uses that producer to post a no-op CONNECT message to that        # partition        # 3. It creates a Kafka consumer (reader) for that partition.        # If any of these steps fail, they will be re-attempted every        # &lt;ShortInterval&gt; for a total of &lt;ShortTotal&gt;, and then every        # &lt;LongInterval&gt; for a total of &lt;LongTotal&gt; until they succeed.        # Note that the orderer will be unable to write to or read from a        # channel until all of the steps above have been completed successfully.        ShortInterval: 5s        ShortTotal: 10m        LongInterval: 5m        LongTotal: 12h        # Affects the socket timeouts when waiting for an initial connection, a        # response, or a transmission. See Config.Net for more info:        # https://godoc.org/github.com/Shopify/sarama#Config        NetworkTimeouts:            DialTimeout: 10s            ReadTimeout: 10s            WriteTimeout: 10s        # Affects the metadata requests when the Kafka cluster is in the middle        # of a leader election.See Config.Metadata for more info:        # https://godoc.org/github.com/Shopify/sarama#Config        Metadata:            RetryBackoff: 250ms            RetryMax: 3        # What to do if posting a message to the Kafka cluster fails. See        # Config.Producer for more info:        # https://godoc.org/github.com/Shopify/sarama#Config        Producer:            RetryBackoff: 100ms            RetryMax: 3        # What to do if reading from the Kafka cluster fails. See        # Config.Consumer for more info:        # https://godoc.org/github.com/Shopify/sarama#Config        Consumer:            RetryBackoff: 2s    # Settings to use when creating Kafka topics.  Only applies when    # Kafka.Version is v0.10.1.0 or higher    Topic:        # The number of Kafka brokers across which to replicate the topic        ReplicationFactor: 3    # Verbose: Enable logging for interactions with the Kafka cluster.    Verbose: false    # TLS: TLS settings for the orderer&#39;s connection to the Kafka cluster.    TLS:      # Enabled: Use TLS when connecting to the Kafka cluster.      Enabled: false      # PrivateKey: PEM-encoded private key the orderer will use for      # authentication.      PrivateKey:        # As an alternative to specifying the PrivateKey here, uncomment the        # following &quot;File&quot; key and specify the file name from which to load the        # value of PrivateKey.        #File: path/to/PrivateKey      # Certificate: PEM-encoded signed public key certificate the orderer will      # use for authentication.      Certificate:        # As an alternative to specifying the Certificate here, uncomment the        # following &quot;File&quot; key and specify the file name from which to load the        # value of Certificate.        #File: path/to/Certificate      # RootCAs: PEM-encoded trusted root certificates used to validate      # certificates from the Kafka cluster.      RootCAs:        # As an alternative to specifying the RootCAs here, uncomment the        # following &quot;File&quot; key and specify the file name from which to load the        # value of RootCAs.        #File: path/to/RootCAs    # SASLPlain: Settings for using SASL/PLAIN authentication with Kafka brokers    SASLPlain:      # Enabled: Use SASL/PLAIN to authenticate with Kafka brokers      Enabled: false      # User: Required when Enabled is set to true      User:      # Password: Required when Enabled is set to true      Password:    # Kafka protocol version used to communicate with the Kafka cluster brokers    # (defaults to 0.10.2.0 if not specified)    Version:##################################################################################   Debug Configuration##   - This controls the debugging options for the orderer#################################################################################Debug:    # BroadcastTraceDir when set will cause each request to the Broadcast service    # for this orderer to be written to a file in this directory    BroadcastTraceDir:    # DeliverTraceDir when set will cause each request to the Deliver service    # for this orderer to be written to a file in this directory    DeliverTraceDir:##################################################################################   Operations Configuration##   - This configures the operations server endpoint for the orderer#################################################################################Operations: #生产环境此处该如何设置    # host and port for the operations server    ListenAddress: 127.0.0.1:8443    # TLS configuration for the operations endpoint    TLS:        # TLS enabled        Enabled: false        # Certificate is the location of the PEM encoded TLS certificate        Certificate:        # PrivateKey points to the location of the PEM-encoded key        PrivateKey:        # Most operations service endpoints require client authentication when TLS        # is enabled. ClientAuthRequired requires client certificate authentication        # at the TLS layer to access all resources.        ClientAuthRequired: false        # Paths to PEM encoded ca certificates to trust for client authentication        ClientRootCAs: []##################################################################################   Metrics  Configuration##   - This configures metrics collection for the orderer#################################################################################Metrics:    # The metrics provider is one of statsd, prometheus, or disabled    Provider: disabled    # The statsd configuration    Statsd:      # network type: tcp or udp      Network: udp      # the statsd server address      Address: 127.0.0.1:8125      # The interval at which locally cached counters and gauges are pushed      # to statsd; timings are pushed immediately      WriteInterval: 30s      # The prefix is prepended to all emitted statsd metrics      Prefix:##################################################################################   Consensus Configuration##   - This section contains config options for a consensus plugin. It is opaque#     to orderer, and completely up to consensus implementation to make use of.#################################################################################Consensus:    # The allowed key-value pairs here depend on consensus plugin. For etcd/raft,    # we use following options:    # WALDir specifies the location at which Write Ahead Logs for etcd/raft are    # stored. Each channel will have its own subdir named after channel ID.    WALDir: etcdraft/wal    # SnapDir specifies the location at which snapshots for etcd/raft are    # stored. Each channel will have its own subdir named after channel ID.    SnapDir: etcdraft/snapshot</code></pre><h2 id="5-配置并启动peer节点"><a href="#5-配置并启动peer节点" class="headerlink" title="5. 配置并启动peer节点"></a>5. 配置并启动peer节点</h2><h3 id="5-1-peer1配置"><a href="#5-1-peer1配置" class="headerlink" title="5.1 peer1配置"></a>5.1 peer1配置</h3><p>将前面crypto-gen生成的peer组织相关信息（也就是下面这个文件夹）放到peer1虚拟机对应的相同位置中</p><pre><code>organizations/peerOrganizations/org1.example.com</code></pre><p>然后在organizations同级的目录下创建一个peer文件夹，进入其中，编辑 <code>core.yaml</code> 文件</p><pre><code class="yaml"># Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0##################################################################################    Peer section################################################################################peer:    # The peer id provides a name for this peer instance and is used when    # naming docker resources.    id: peer0.org1.example.com    # The networkId allows for logical separation of networks and is used when    # naming docker resources.    networkId: dev1    # The Address at local network interface this Peer will listen on.    # By default, it will listen on all network interfaces    listenAddress: 0.0.0.0:7051    # The endpoint this peer uses to listen for inbound chaincode connections.    # If this is commented-out, the listen address is selected to be    # the peer&#39;s address (see below) with port 7052    # chaincodeListenAddress: 0.0.0.0:7052    # The endpoint the chaincode for this peer uses to connect to the peer.    # If this is not specified, the chaincodeListenAddress address is selected.    # And if chaincodeListenAddress is not specified, address is selected from    # peer listenAddress.    # chaincodeAddress: 0.0.0.0:7052    # When used as peer config, this represents the endpoint to other peers    # in the same organization. For peers in other organization, see    # gossip.externalEndpoint for more info.    # When used as CLI config, this means the peer&#39;s endpoint to interact with    address: 0.0.0.0:7051    # Whether the Peer should programmatically determine its address    # This case is useful for docker containers.    addressAutoDetect: false    # Keepalive settings for peer server and clients    keepalive:        # Interval is the duration after which if the server does not see        # any activity from the client it pings the client to see if it&#39;s alive        interval: 7200s        # Timeout is the duration the server waits for a response        # from the client after sending a ping before closing the connection        timeout: 20s        # MinInterval is the minimum permitted time between client pings.        # If clients send pings more frequently, the peer server will        # disconnect them        minInterval: 60s        # Client keepalive settings for communicating with other peer nodes        client:            # Interval is the time between pings to peer nodes.  This must            # greater than or equal to the minInterval specified by peer            # nodes            interval: 60s            # Timeout is the duration the client waits for a response from            # peer nodes before closing the connection            timeout: 20s        # DeliveryClient keepalive settings for communication with ordering        # nodes.        deliveryClient:            # Interval is the time between pings to ordering nodes.  This must            # greater than or equal to the minInterval specified by ordering            # nodes.            interval: 60s            # Timeout is the duration the client waits for a response from            # ordering nodes before closing the connection            timeout: 20s    # Gossip related configuration    gossip:        # Bootstrap set to initialize gossip with.        # This is a list of other peers that this peer reaches out to at startup.        # Important: The endpoints here have to be endpoints of peers in the same        # organization, because the peer would refuse connecting to these endpoints        # unless they are in the same organization as the peer.        bootstrap: 127.0.0.1:7051        # NOTE: orgLeader and useLeaderElection parameters are mutual exclusive.        # Setting both to true would result in the termination of the peer        # since this is undefined state. If the peers are configured with        # useLeaderElection=false, make sure there is at least 1 peer in the        # organization that its orgLeader is set to true.        # Defines whenever peer will initialize dynamic algorithm for        # &quot;leader&quot; selection, where leader is the peer to establish        # connection with ordering service and use delivery protocol        # to pull ledger blocks from ordering service. It is recommended to        # use leader election for large networks of peers.        useLeaderElection: true        # Statically defines peer to be an organization &quot;leader&quot;,        # where this means that current peer will maintain connection        # with ordering service and disseminate block across peers in        # its own organization        orgLeader: false        # Interval for membershipTracker polling        membershipTrackerInterval: 5s        # Overrides the endpoint that the peer publishes to peers        # in its organization. For peers in foreign organizations        # see &#39;externalEndpoint&#39;        endpoint:        # Maximum count of blocks stored in memory        maxBlockCountToStore: 100        # Max time between consecutive message pushes(unit: millisecond)        maxPropagationBurstLatency: 10ms        # Max number of messages stored until a push is triggered to remote peers        maxPropagationBurstSize: 10        # Number of times a message is pushed to remote peers        propagateIterations: 1        # Number of peers selected to push messages to        propagatePeerNum: 3        # Determines frequency of pull phases(unit: second)        # Must be greater than digestWaitTime + responseWaitTime        pullInterval: 4s        # Number of peers to pull from        pullPeerNum: 3        # Determines frequency of pulling state info messages from peers(unit: second)        requestStateInfoInterval: 4s        # Determines frequency of pushing state info messages to peers(unit: second)        publishStateInfoInterval: 4s        # Maximum time a stateInfo message is kept until expired        stateInfoRetentionInterval:        # Time from startup certificates are included in Alive messages(unit: second)        publishCertPeriod: 10s        # Should we skip verifying block messages or not (currently not in use)        skipBlockVerification: false        # Dial timeout(unit: second)        dialTimeout: 3s        # Connection timeout(unit: second)        connTimeout: 2s        # Buffer size of received messages        recvBuffSize: 20        # Buffer size of sending messages        sendBuffSize: 200        # Time to wait before pull engine processes incoming digests (unit: second)        # Should be slightly smaller than requestWaitTime        digestWaitTime: 1s        # Time to wait before pull engine removes incoming nonce (unit: milliseconds)        # Should be slightly bigger than digestWaitTime        requestWaitTime: 1500ms        # Time to wait before pull engine ends pull (unit: second)        responseWaitTime: 2s        # Alive check interval(unit: second)        aliveTimeInterval: 5s        # Alive expiration timeout(unit: second)        aliveExpirationTimeout: 25s        # Reconnect interval(unit: second)        reconnectInterval: 25s        # This is an endpoint that is published to peers outside of the organization.        # If this isn&#39;t set, the peer will not be known to other organizations.        externalEndpoint: peer0.org1.example.com:7051        # Leader election service configuration        election:            # Longest time peer waits for stable membership during leader election startup (unit: second)            startupGracePeriod: 15s            # Interval gossip membership samples to check its stability (unit: second)            membershipSampleInterval: 1s            # Time passes since last declaration message before peer decides to perform leader election (unit: second)            leaderAliveThreshold: 10s            # Time between peer sends propose message and declares itself as a leader (sends declaration message) (unit: second)            leaderElectionDuration: 5s        pvtData:            # pullRetryThreshold determines the maximum duration of time private data corresponding for a given block            # would be attempted to be pulled from peers until the block would be committed without the private data            pullRetryThreshold: 60s            # As private data enters the transient store, it is associated with the peer&#39;s ledger&#39;s height at that time.            # transientstoreMaxBlockRetention defines the maximum difference between the current ledger&#39;s height upon commit,            # and the private data residing inside the transient store that is guaranteed not to be purged.            # Private data is purged from the transient store when blocks with sequences that are multiples            # of transientstoreMaxBlockRetention are committed.            transientstoreMaxBlockRetention: 1000            # pushAckTimeout is the maximum time to wait for an acknowledgement from each peer            # at private data push at endorsement time.            pushAckTimeout: 3s            # Block to live pulling margin, used as a buffer            # to prevent peer from trying to pull private data            # from peers that is soon to be purged in next N blocks.            # This helps a newly joined peer catch up to current            # blockchain height quicker.            btlPullMargin: 10            # the process of reconciliation is done in an endless loop, while in each iteration reconciler tries to            # pull from the other peers the most recent missing blocks with a maximum batch size limitation.            # reconcileBatchSize determines the maximum batch size of missing private data that will be reconciled in a            # single iteration.            reconcileBatchSize: 10            # reconcileSleepInterval determines the time reconciler sleeps from end of an iteration until the beginning            # of the next reconciliation iteration.            reconcileSleepInterval: 1m            # reconciliationEnabled is a flag that indicates whether private data reconciliation is enable or not.            reconciliationEnabled: true            # skipPullingInvalidTransactionsDuringCommit is a flag that indicates whether pulling of invalid            # transaction&#39;s private data from other peers need to be skipped during the commit time and pulled            # only through reconciler.            skipPullingInvalidTransactionsDuringCommit: false            # implicitCollectionDisseminationPolicy specifies the dissemination  policy for the peer&#39;s own implicit collection.            # When a peer endorses a proposal that writes to its own implicit collection, below values override the default values            # for disseminating private data.            # Note that it is applicable to all channels the peer has joined. The implication is that requiredPeerCount has to            # be smaller than the number of peers in a channel that has the lowest numbers of peers from the organization.            implicitCollectionDisseminationPolicy:               # requiredPeerCount defines the minimum number of eligible peers to which the peer must successfully               # disseminate private data for its own implicit collection during endorsement. Default value is 0.               requiredPeerCount: 0               # maxPeerCount defines the maximum number of eligible peers to which the peer will attempt to               # disseminate private data for its own implicit collection during endorsement. Default value is 1.               maxPeerCount: 1        # Gossip state transfer related configuration        state:            # indicates whenever state transfer is enabled or not            # default value is true, i.e. state transfer is active            # and takes care to sync up missing blocks allowing            # lagging peer to catch up to speed with rest network            enabled: true            # checkInterval interval to check whether peer is lagging behind enough to            # request blocks via state transfer from another peer.            checkInterval: 10s            # responseTimeout amount of time to wait for state transfer response from            # other peers            responseTimeout: 3s            # batchSize the number of blocks to request via state transfer from another peer            batchSize: 10            # blockBufferSize reflects the size of the re-ordering buffer            # which captures blocks and takes care to deliver them in order            # down to the ledger layer. The actually buffer size is bounded between            # 0 and 2*blockBufferSize, each channel maintains its own buffer            blockBufferSize: 100            # maxRetries maximum number of re-tries to ask            # for single state transfer request            maxRetries: 3    # TLS Settings    tls:        # Require server-side TLS        enabled:  true        # Require client certificates / mutual TLS.        # Note that clients that are not configured to use a certificate will        # fail to connect to the peer.        clientAuthRequired: false #正式环境是否要设置为true，下方clientKey该如何设置。若为true，在peer channel list会报错        # X.509 certificate used for TLS server        cert:            file: ../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt        # Private key used for TLS server (and client if clientAuthEnabled        # is set to true        key:            file: ../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key        # Trusted root certificate chain for tls.cert        rootcert:            file: ../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt        # Set of root certificate authorities used to verify client certificates        clientRootCAs:            files:              - ../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt        # Private key used for TLS when making client connections.  If        # not set, peer.tls.key.file will be used instead        clientKey:            file:         # X.509 certificate used for TLS when making client connections.        # If not set, peer.tls.cert.file will be used instead        clientCert:            file:    # Authentication contains configuration parameters related to authenticating    # client messages    authentication:        # the acceptable difference between the current server time and the        # client&#39;s time as specified in a client request message        timewindow: 15m    # Path on the file system where peer will store data (eg ledger). This    # location must be access control protected to prevent unintended    # modification that might corrupt the peer operations.    fileSystemPath: ./production    # BCCSP (Blockchain crypto provider): Select which crypto implementation or    # library to use    BCCSP:        Default: SW        # Settings for the SW crypto provider (i.e. when DEFAULT: SW)        SW:            # TODO: The default Hash and Security level needs refactoring to be            # fully configurable. Changing these defaults requires coordination            # SHA2 is hardcoded in several places, not only BCCSP            Hash: SHA2            Security: 256            # Location of Key Store            FileKeyStore:                # If &quot;&quot;, defaults to &#39;mspConfigPath&#39;/keystore                KeyStore:        # Settings for the PKCS#11 crypto provider (i.e. when DEFAULT: PKCS11)        PKCS11:            # Location of the PKCS11 module library            Library:            # Token Label            Label:            # User PIN            Pin:            Hash:            Security:    # Path on the file system where peer will find MSP local configurations    mspConfigPath: ../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp    # Identifier of the local MSP    # ----!!!!IMPORTANT!!!-!!!IMPORTANT!!!-!!!IMPORTANT!!!!----    # Deployers need to change the value of the localMspId string.    # In particular, the name of the local MSP ID of a peer needs    # to match the name of one of the MSPs in each of the channel    # that this peer is a member of. Otherwise this peer&#39;s messages    # will not be identified as valid by other nodes.    localMspId: Org1MSP    # CLI common client config options    client:        # connection timeout        connTimeout: 3s    # Delivery service related config    deliveryclient:        # It sets the total time the delivery service may spend in reconnection        # attempts until its retry logic gives up and returns an error        reconnectTotalTimeThreshold: 3600s        # It sets the delivery service &lt;-&gt; ordering service node connection timeout        connTimeout: 3s        # It sets the delivery service maximal delay between consecutive retries        reConnectBackoffThreshold: 3600s        # A list of orderer endpoint addresses which should be overridden        # when found in channel configurations.        addressOverrides:        #  - from:        #    to:        #    caCertsFile:        #  - from:        #    to:        #    caCertsFile:    # Type for the local MSP - by default it&#39;s of type bccsp    localMspType: bccsp    # Used with Go profiling tools only in none production environment. In    # production, it should be disabled (eg enabled: false)    profile:        enabled:     false        listenAddress: 0.0.0.0:6060    # Handlers defines custom handlers that can filter and mutate    # objects passing within the peer, such as:    #   Auth filter - reject or forward proposals from clients    #   Decorators  - append or mutate the chaincode input passed to the chaincode    #   Endorsers   - Custom signing over proposal response payload and its mutation    # Valid handler definition contains:    #   - A name which is a factory method name defined in    #     core/handlers/library/library.go for statically compiled handlers    #   - library path to shared object binary for pluggable filters    # Auth filters and decorators are chained and executed in the order that    # they are defined. For example:    # authFilters:    #   -    #     name: FilterOne    #     library: /opt/lib/filter.so    #   -    #     name: FilterTwo    # decorators:    #   -    #     name: DecoratorOne    #   -    #     name: DecoratorTwo    #     library: /opt/lib/decorator.so    # Endorsers are configured as a map that its keys are the endorsement system chaincodes that are being overridden.    # Below is an example that overrides the default ESCC and uses an endorsement plugin that has the same functionality    # as the default ESCC.    # If the &#39;library&#39; property is missing, the name is used as the constructor method in the builtin library similar    # to auth filters and decorators.    # endorsers:    #   escc:    #     name: DefaultESCC    #     library: /etc/hyperledger/fabric/plugin/escc.so    handlers:        authFilters:          -            name: DefaultAuth          -            name: ExpirationCheck    # This filter checks identity x509 certificate expiration        decorators:          -            name: DefaultDecorator        endorsers:          escc:            name: DefaultEndorsement            library:        validators:          vscc:            name: DefaultValidation            library:    #    library: /etc/hyperledger/fabric/plugin/escc.so    # Number of goroutines that will execute transaction validation in parallel.    # By default, the peer chooses the number of CPUs on the machine. Set this    # variable to override that choice.    # NOTE: overriding this value might negatively influence the performance of    # the peer so please change this value only if you know what you&#39;re doing    validatorPoolSize:    # The discovery service is used by clients to query information about peers,    # such as - which peers have joined a certain channel, what is the latest    # channel config, and most importantly - given a chaincode and a channel,    # what possible sets of peers satisfy the endorsement policy.    discovery:        enabled: true        # Whether the authentication cache is enabled or not.        authCacheEnabled: true        # The maximum size of the cache, after which a purge takes place        authCacheMaxSize: 1000        # The proportion (0 to 1) of entries that remain in the cache after the cache is purged due to overpopulation        authCachePurgeRetentionRatio: 0.75        # Whether to allow non-admins to perform non channel scoped queries.        # When this is false, it means that only peer admins can perform non channel scoped queries.        orgMembersAllowedAccess: false    # Limits is used to configure some internal resource limits.    limits:        # Concurrency limits the number of concurrently running requests to a service on each peer.        # Currently this option is only applied to endorser service and deliver service.        # When the property is missing or the value is 0, the concurrency limit is disabled for the service.        concurrency:            # endorserService limits concurrent requests to endorser service that handles chaincode deployment, query and invocation,            # including both user chaincodes and system chaincodes.            endorserService: 2500            # deliverService limits concurrent event listeners registered to deliver service for blocks and transaction events.            deliverService: 2500#################################################################################    VM section################################################################################vm:    # Endpoint of the vm management system.  For docker can be one of the following in general    # unix:///var/run/docker.sock    # http://localhost:2375    # https://localhost:2376    endpoint: unix:///var/run/docker.sock    # settings for docker vms    docker:        tls:            enabled: false            ca:                file: docker/ca.crt            cert:                file: docker/tls.crt            key:                file: docker/tls.key        # Enables/disables the standard out/err from chaincode containers for        # debugging purposes        attachStdout: false        # Parameters on creating docker container.        # Container may be efficiently created using ipam &amp; dns-server for cluster        # NetworkMode - sets the networking mode for the container. Supported        # standard values are: `host`(default),`bridge`,`ipvlan`,`none`.        # Dns - a list of DNS servers for the container to use.        # Note:  `Privileged` `Binds` `Links` and `PortBindings` properties of        # Docker Host Config are not supported and will not be used if set.        # LogConfig - sets the logging driver (Type) and related options        # (Config) for Docker. For more info,        # https://docs.docker.com/engine/admin/logging/overview/        # Note: Set LogConfig using Environment Variables is not supported.        hostConfig:            NetworkMode: host            Dns:               # - 192.168.0.1            LogConfig:                Type: json-file                Config:                    max-size: &quot;50m&quot;                    max-file: &quot;5&quot;            Memory: 2147483648#################################################################################    Chaincode section################################################################################chaincode:    # The id is used by the Chaincode stub to register the executing Chaincode    # ID with the Peer and is generally supplied through ENV variables    # the `path` form of ID is provided when installing the chaincode.    # The `name` is used for all other requests and can be any string.    id:        path:        name:    # Generic builder environment, suitable for most chaincode types    builder: $(DOCKER_NS)/fabric-ccenv:$(TWO_DIGIT_VERSION)    # Enables/disables force pulling of the base docker images (listed below)    # during user chaincode instantiation.    # Useful when using moving image tags (such as :latest)    pull: false    golang:        # golang will never need more than baseos        runtime: $(DOCKER_NS)/fabric-baseos:$(TWO_DIGIT_VERSION)        # whether or not golang chaincode should be linked dynamically        dynamicLink: false    java:        # This is an image based on java:openjdk-8 with addition compiler        # tools added for java shim layer packaging.        # This image is packed with shim layer libraries that are necessary        # for Java chaincode runtime.        runtime: $(DOCKER_NS)/fabric-javaenv:$(TWO_DIGIT_VERSION)    node:        # This is an image based on node:$(NODE_VER)-alpine        runtime: $(DOCKER_NS)/fabric-nodeenv:$(TWO_DIGIT_VERSION)    # List of directories to treat as external builders and launchers for    # chaincode. The external builder detection processing will iterate over the    # builders in the order specified below.    externalBuilders: []        # - path: /path/to/directory        #   name: descriptive-builder-name        #   environmentWhitelist:        #      - ENVVAR_NAME_TO_PROPAGATE_FROM_PEER        #      - GOPROXY    # The maximum duration to wait for the chaincode build and install process    # to complete.    installTimeout: 300s    # Timeout duration for starting up a container and waiting for Register    # to come through.    startuptimeout: 300s    # Timeout duration for Invoke and Init calls to prevent runaway.    # This timeout is used by all chaincodes in all the channels, including    # system chaincodes.    # Note that during Invoke, if the image is not available (e.g. being    # cleaned up when in development environment), the peer will automatically    # build the image, which might take more time. In production environment,    # the chaincode image is unlikely to be deleted, so the timeout could be    # reduced accordingly.    executetimeout: 30s    # There are 2 modes: &quot;dev&quot; and &quot;net&quot;.    # In dev mode, user runs the chaincode after starting peer from    # command line on local machine.    # In net mode, peer will run chaincode in a docker container.    mode: net    # keepalive in seconds. In situations where the communication goes through a    # proxy that does not support keep-alive, this parameter will maintain connection    # between peer and chaincode.    # A value &lt;= 0 turns keepalive off    keepalive: 0    # system chaincodes whitelist. To add system chaincode &quot;myscc&quot; to the    # whitelist, add &quot;myscc: enable&quot; to the list below, and register in    # chaincode/importsysccs.go    system:        _lifecycle: enable        cscc: enable        lscc: enable        escc: enable        vscc: enable        qscc: enable    # Logging section for the chaincode container    logging:      # Default level for all loggers within the chaincode container      level:  info      # Override default level for the &#39;shim&#39; logger      shim:   warning      # Format for the chaincode container logs      format: &#39;%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -&gt; %{level:.4s} %{id:03x}%{color:reset} %{message}&#39;#################################################################################    Ledger section - ledger configuration encompasses both the blockchain#    and the state################################################################################ledger:  blockchain:  state:    # stateDatabase - options are &quot;goleveldb&quot;, &quot;CouchDB&quot;    # goleveldb - default state database stored in goleveldb.    # CouchDB - store state database in CouchDB    stateDatabase: goleveldb    # Limit on the number of records to return per query    totalQueryLimit: 100000    couchDBConfig:       # It is recommended to run CouchDB on the same server as the peer, and       # not map the CouchDB container port to a server port in docker-compose.       # Otherwise proper security must be provided on the connection between       # CouchDB client (on the peer) and server.       couchDBAddress: 127.0.0.1:5984       # This username must have read and write authority on CouchDB       username:       # The password is recommended to pass as an environment variable       # during start up (eg CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD).       # If it is stored here, the file must be access control protected       # to prevent unintended users from discovering the password.       password:       # Number of retries for CouchDB errors       maxRetries: 3       # Number of retries for CouchDB errors during peer startup       maxRetriesOnStartup: 12       # CouchDB request timeout (unit: duration, e.g. 20s)       requestTimeout: 35s       # Limit on the number of records per each CouchDB query       # Note that chaincode queries are only bound by totalQueryLimit.       # Internally the chaincode may execute multiple CouchDB queries,       # each of size internalQueryLimit.       internalQueryLimit: 1000       # Limit on the number of records per CouchDB bulk update batch       maxBatchUpdateSize: 1000       # Warm indexes after every N blocks.       # This option warms any indexes that have been       # deployed to CouchDB after every N blocks.       # A value of 1 will warm indexes after every block commit,       # to ensure fast selector queries.       # Increasing the value may improve write efficiency of peer and CouchDB,       # but may degrade query response time.       warmIndexesAfterNBlocks: 1       # Create the _global_changes system database       # This is optional.  Creating the global changes database will require       # additional system resources to track changes and maintain the database       createGlobalChangesDB: false       # CacheSize denotes the maximum mega bytes (MB) to be allocated for the in-memory state       # cache. Note that CacheSize needs to be a multiple of 32 MB. If it is not a multiple       # of 32 MB, the peer would round the size to the next multiple of 32 MB.       # To disable the cache, 0 MB needs to be assigned to the cacheSize.       cacheSize: 64  history:    # enableHistoryDatabase - options are true or false    # Indicates if the history of key updates should be stored.    # All history &#39;index&#39; will be stored in goleveldb, regardless if using    # CouchDB or alternate database for the state.    enableHistoryDatabase: true  pvtdataStore:    # the maximum db batch size for converting    # the ineligible missing data entries to eligible missing data entries    collElgProcMaxDbBatchSize: 5000    # the minimum duration (in milliseconds) between writing    # two consecutive db batches for converting the ineligible missing data entries to eligible missing data entries    collElgProcDbBatchesInterval: 1000#################################################################################    Operations section################################################################################operations:    # host and port for the operations server    listenAddress: 127.0.0.1:9443    # TLS configuration for the operations endpoint    tls:        # TLS enabled        enabled: false #生产环境是否要设置        # path to PEM encoded server certificate for the operations server        cert:            file:        # path to PEM encoded server key for the operations server        key:            file:        # most operations service endpoints require client authentication when TLS        # is enabled. clientAuthRequired requires client certificate authentication        # at the TLS layer to access all resources.        clientAuthRequired: false        # paths to PEM encoded ca certificates to trust for client authentication        clientRootCAs:            files: []#################################################################################    Metrics section################################################################################metrics:    # metrics provider is one of statsd, prometheus, or disabled    provider: disabled    # statsd configuration    statsd:        # network type: tcp or udp        network: udp        # statsd server address        address: 127.0.0.1:8125        # the interval at which locally cached counters and gauges are pushed        # to statsd; timings are pushed immediately        writeInterval: 10s        # prefix is prepended to all emitted statsd metrics        prefix:</code></pre><p>启动：</p><p>在peer目录中：</p><pre><code class="bash">export FABRIC_CFG_PATH=$PWDpeer node start &gt;&gt; log_peer.log 2&gt;&amp;1 &amp;</code></pre><h3 id="5-2-peer2配置"><a href="#5-2-peer2配置" class="headerlink" title="5.2 peer2配置"></a>5.2 peer2配置</h3><p>首先还是复制peer2的证书素材，将其放入下面这个文件夹中</p><pre><code>organizations/peerOrganizations/org2.example.com</code></pre><p>然后复制order的tls证书，注意这里复制的时候是将tlscacerts文件夹中的内容复制过来的，并不是将所有的信息全都拷过来，并且拷过来的时候需要注意放的文件夹位置，不是原来的文件夹位置，而是需要重新创建一个</p><pre><code># 原目录organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts# 复制到目录organizations/orderer.example.com/tlscacerts</code></pre><p>关于配置文件，主要是对照peer1的配置，将对应的org1改成org2，文件中需要修改的位置为：</p><pre><code>15 peer.id: peer0.org2.example.com162 peer.gossip.externalEndpoint: peer0.org2.example.com:7051254 peer.tls.cert.file: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/server.crt258 peer.tls.key.file: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/server.key261 peer.tls.rootcert.file: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt265 peer.tls.clientRootCAs.files: - ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt314 peer.mspConfigPath: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp323 peer.localMspId: Org2MSP</code></pre><p>修改完成之后的配置为：</p><pre><code class="yaml"># Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0##################################################################################    Peer section################################################################################peer:    # The peer id provides a name for this peer instance and is used when    # naming docker resources.    id: peer0.org2.example.com    # The networkId allows for logical separation of networks and is used when    # naming docker resources.    networkId: dev1    # The Address at local network interface this Peer will listen on.    # By default, it will listen on all network interfaces    listenAddress: 0.0.0.0:7051    # The endpoint this peer uses to listen for inbound chaincode connections.    # If this is commented-out, the listen address is selected to be    # the peer&#39;s address (see below) with port 7052    # chaincodeListenAddress: 0.0.0.0:7052    # The endpoint the chaincode for this peer uses to connect to the peer.    # If this is not specified, the chaincodeListenAddress address is selected.    # And if chaincodeListenAddress is not specified, address is selected from    # peer listenAddress.    # chaincodeAddress: 0.0.0.0:7052    # When used as peer config, this represents the endpoint to other peers    # in the same organization. For peers in other organization, see    # gossip.externalEndpoint for more info.    # When used as CLI config, this means the peer&#39;s endpoint to interact with    address: 0.0.0.0:7051    # Whether the Peer should programmatically determine its address    # This case is useful for docker containers.    addressAutoDetect: false    # Keepalive settings for peer server and clients    keepalive:        # Interval is the duration after which if the server does not see        # any activity from the client it pings the client to see if it&#39;s alive        interval: 7200s        # Timeout is the duration the server waits for a response        # from the client after sending a ping before closing the connection        timeout: 20s        # MinInterval is the minimum permitted time between client pings.        # If clients send pings more frequently, the peer server will        # disconnect them        minInterval: 60s        # Client keepalive settings for communicating with other peer nodes        client:            # Interval is the time between pings to peer nodes.  This must            # greater than or equal to the minInterval specified by peer            # nodes            interval: 60s            # Timeout is the duration the client waits for a response from            # peer nodes before closing the connection            timeout: 20s        # DeliveryClient keepalive settings for communication with ordering        # nodes.        deliveryClient:            # Interval is the time between pings to ordering nodes.  This must            # greater than or equal to the minInterval specified by ordering            # nodes.            interval: 60s            # Timeout is the duration the client waits for a response from            # ordering nodes before closing the connection            timeout: 20s    # Gossip related configuration    gossip:        # Bootstrap set to initialize gossip with.        # This is a list of other peers that this peer reaches out to at startup.        # Important: The endpoints here have to be endpoints of peers in the same        # organization, because the peer would refuse connecting to these endpoints        # unless they are in the same organization as the peer.        bootstrap: 127.0.0.1:7051        # NOTE: orgLeader and useLeaderElection parameters are mutual exclusive.        # Setting both to true would result in the termination of the peer        # since this is undefined state. If the peers are configured with        # useLeaderElection=false, make sure there is at least 1 peer in the        # organization that its orgLeader is set to true.        # Defines whenever peer will initialize dynamic algorithm for        # &quot;leader&quot; selection, where leader is the peer to establish        # connection with ordering service and use delivery protocol        # to pull ledger blocks from ordering service. It is recommended to        # use leader election for large networks of peers.        useLeaderElection: true        # Statically defines peer to be an organization &quot;leader&quot;,        # where this means that current peer will maintain connection        # with ordering service and disseminate block across peers in        # its own organization        orgLeader: false        # Interval for membershipTracker polling        membershipTrackerInterval: 5s        # Overrides the endpoint that the peer publishes to peers        # in its organization. For peers in foreign organizations        # see &#39;externalEndpoint&#39;        endpoint:        # Maximum count of blocks stored in memory        maxBlockCountToStore: 100        # Max time between consecutive message pushes(unit: millisecond)        maxPropagationBurstLatency: 10ms        # Max number of messages stored until a push is triggered to remote peers        maxPropagationBurstSize: 10        # Number of times a message is pushed to remote peers        propagateIterations: 1        # Number of peers selected to push messages to        propagatePeerNum: 3        # Determines frequency of pull phases(unit: second)        # Must be greater than digestWaitTime + responseWaitTime        pullInterval: 4s        # Number of peers to pull from        pullPeerNum: 3        # Determines frequency of pulling state info messages from peers(unit: second)        requestStateInfoInterval: 4s        # Determines frequency of pushing state info messages to peers(unit: second)        publishStateInfoInterval: 4s        # Maximum time a stateInfo message is kept until expired        stateInfoRetentionInterval:        # Time from startup certificates are included in Alive messages(unit: second)        publishCertPeriod: 10s        # Should we skip verifying block messages or not (currently not in use)        skipBlockVerification: false        # Dial timeout(unit: second)        dialTimeout: 3s        # Connection timeout(unit: second)        connTimeout: 2s        # Buffer size of received messages        recvBuffSize: 20        # Buffer size of sending messages        sendBuffSize: 200        # Time to wait before pull engine processes incoming digests (unit: second)        # Should be slightly smaller than requestWaitTime        digestWaitTime: 1s        # Time to wait before pull engine removes incoming nonce (unit: milliseconds)        # Should be slightly bigger than digestWaitTime        requestWaitTime: 1500ms        # Time to wait before pull engine ends pull (unit: second)        responseWaitTime: 2s        # Alive check interval(unit: second)        aliveTimeInterval: 5s        # Alive expiration timeout(unit: second)        aliveExpirationTimeout: 25s        # Reconnect interval(unit: second)        reconnectInterval: 25s        # This is an endpoint that is published to peers outside of the organization.        # If this isn&#39;t set, the peer will not be known to other organizations.        externalEndpoint: peer0.org2.example.com:7051        # Leader election service configuration        election:            # Longest time peer waits for stable membership during leader election startup (unit: second)            startupGracePeriod: 15s            # Interval gossip membership samples to check its stability (unit: second)            membershipSampleInterval: 1s            # Time passes since last declaration message before peer decides to perform leader election (unit: second)            leaderAliveThreshold: 10s            # Time between peer sends propose message and declares itself as a leader (sends declaration message) (unit: second)            leaderElectionDuration: 5s        pvtData:            # pullRetryThreshold determines the maximum duration of time private data corresponding for a given block            # would be attempted to be pulled from peers until the block would be committed without the private data            pullRetryThreshold: 60s            # As private data enters the transient store, it is associated with the peer&#39;s ledger&#39;s height at that time.            # transientstoreMaxBlockRetention defines the maximum difference between the current ledger&#39;s height upon commit,            # and the private data residing inside the transient store that is guaranteed not to be purged.            # Private data is purged from the transient store when blocks with sequences that are multiples            # of transientstoreMaxBlockRetention are committed.            transientstoreMaxBlockRetention: 1000            # pushAckTimeout is the maximum time to wait for an acknowledgement from each peer            # at private data push at endorsement time.            pushAckTimeout: 3s            # Block to live pulling margin, used as a buffer            # to prevent peer from trying to pull private data            # from peers that is soon to be purged in next N blocks.            # This helps a newly joined peer catch up to current            # blockchain height quicker.            btlPullMargin: 10            # the process of reconciliation is done in an endless loop, while in each iteration reconciler tries to            # pull from the other peers the most recent missing blocks with a maximum batch size limitation.            # reconcileBatchSize determines the maximum batch size of missing private data that will be reconciled in a            # single iteration.            reconcileBatchSize: 10            # reconcileSleepInterval determines the time reconciler sleeps from end of an iteration until the beginning            # of the next reconciliation iteration.            reconcileSleepInterval: 1m            # reconciliationEnabled is a flag that indicates whether private data reconciliation is enable or not.            reconciliationEnabled: true            # skipPullingInvalidTransactionsDuringCommit is a flag that indicates whether pulling of invalid            # transaction&#39;s private data from other peers need to be skipped during the commit time and pulled            # only through reconciler.            skipPullingInvalidTransactionsDuringCommit: false            # implicitCollectionDisseminationPolicy specifies the dissemination  policy for the peer&#39;s own implicit collection.            # When a peer endorses a proposal that writes to its own implicit collection, below values override the default values            # for disseminating private data.            # Note that it is applicable to all channels the peer has joined. The implication is that requiredPeerCount has to            # be smaller than the number of peers in a channel that has the lowest numbers of peers from the organization.            implicitCollectionDisseminationPolicy:               # requiredPeerCount defines the minimum number of eligible peers to which the peer must successfully               # disseminate private data for its own implicit collection during endorsement. Default value is 0.               requiredPeerCount: 0               # maxPeerCount defines the maximum number of eligible peers to which the peer will attempt to               # disseminate private data for its own implicit collection during endorsement. Default value is 1.               maxPeerCount: 1        # Gossip state transfer related configuration        state:            # indicates whenever state transfer is enabled or not            # default value is true, i.e. state transfer is active            # and takes care to sync up missing blocks allowing            # lagging peer to catch up to speed with rest network            enabled: true            # checkInterval interval to check whether peer is lagging behind enough to            # request blocks via state transfer from another peer.            checkInterval: 10s            # responseTimeout amount of time to wait for state transfer response from            # other peers            responseTimeout: 3s            # batchSize the number of blocks to request via state transfer from another peer            batchSize: 10            # blockBufferSize reflects the size of the re-ordering buffer            # which captures blocks and takes care to deliver them in order            # down to the ledger layer. The actually buffer size is bounded between            # 0 and 2*blockBufferSize, each channel maintains its own buffer            blockBufferSize: 100            # maxRetries maximum number of re-tries to ask            # for single state transfer request            maxRetries: 3    # TLS Settings    tls:        # Require server-side TLS        enabled:  true        # Require client certificates / mutual TLS.        # Note that clients that are not configured to use a certificate will        # fail to connect to the peer.        clientAuthRequired: false #正式环境是否要设置为true，下方clientKey该如何设置。若为true，在peer channel list会报错        # X.509 certificate used for TLS server        cert:            file: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/server.crt        # Private key used for TLS server (and client if clientAuthEnabled        # is set to true        key:            file: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/server.key        # Trusted root certificate chain for tls.cert        rootcert:            file: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt        # Set of root certificate authorities used to verify client certificates        clientRootCAs:            files:              - ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt        # Private key used for TLS when making client connections.  If        # not set, peer.tls.key.file will be used instead        clientKey:            file:         # X.509 certificate used for TLS when making client connections.        # If not set, peer.tls.cert.file will be used instead        clientCert:            file:    # Authentication contains configuration parameters related to authenticating    # client messages    authentication:        # the acceptable difference between the current server time and the        # client&#39;s time as specified in a client request message        timewindow: 15m    # Path on the file system where peer will store data (eg ledger). This    # location must be access control protected to prevent unintended    # modification that might corrupt the peer operations.    fileSystemPath: ./production    # BCCSP (Blockchain crypto provider): Select which crypto implementation or    # library to use    BCCSP:        Default: SW        # Settings for the SW crypto provider (i.e. when DEFAULT: SW)        SW:            # TODO: The default Hash and Security level needs refactoring to be            # fully configurable. Changing these defaults requires coordination            # SHA2 is hardcoded in several places, not only BCCSP            Hash: SHA2            Security: 256            # Location of Key Store            FileKeyStore:                # If &quot;&quot;, defaults to &#39;mspConfigPath&#39;/keystore                KeyStore:        # Settings for the PKCS#11 crypto provider (i.e. when DEFAULT: PKCS11)        PKCS11:            # Location of the PKCS11 module library            Library:            # Token Label            Label:            # User PIN            Pin:            Hash:            Security:    # Path on the file system where peer will find MSP local configurations    mspConfigPath: ../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp    # Identifier of the local MSP    # ----!!!!IMPORTANT!!!-!!!IMPORTANT!!!-!!!IMPORTANT!!!!----    # Deployers need to change the value of the localMspId string.    # In particular, the name of the local MSP ID of a peer needs    # to match the name of one of the MSPs in each of the channel    # that this peer is a member of. Otherwise this peer&#39;s messages    # will not be identified as valid by other nodes.    localMspId: Org2MSP    # CLI common client config options    client:        # connection timeout        connTimeout: 3s    # Delivery service related config    deliveryclient:        # It sets the total time the delivery service may spend in reconnection        # attempts until its retry logic gives up and returns an error        reconnectTotalTimeThreshold: 3600s        # It sets the delivery service &lt;-&gt; ordering service node connection timeout        connTimeout: 3s        # It sets the delivery service maximal delay between consecutive retries        reConnectBackoffThreshold: 3600s        # A list of orderer endpoint addresses which should be overridden        # when found in channel configurations.        addressOverrides:        #  - from:        #    to:        #    caCertsFile:        #  - from:        #    to:        #    caCertsFile:    # Type for the local MSP - by default it&#39;s of type bccsp    localMspType: bccsp    # Used with Go profiling tools only in none production environment. In    # production, it should be disabled (eg enabled: false)    profile:        enabled:     false        listenAddress: 0.0.0.0:6060    # Handlers defines custom handlers that can filter and mutate    # objects passing within the peer, such as:    #   Auth filter - reject or forward proposals from clients    #   Decorators  - append or mutate the chaincode input passed to the chaincode    #   Endorsers   - Custom signing over proposal response payload and its mutation    # Valid handler definition contains:    #   - A name which is a factory method name defined in    #     core/handlers/library/library.go for statically compiled handlers    #   - library path to shared object binary for pluggable filters    # Auth filters and decorators are chained and executed in the order that    # they are defined. For example:    # authFilters:    #   -    #     name: FilterOne    #     library: /opt/lib/filter.so    #   -    #     name: FilterTwo    # decorators:    #   -    #     name: DecoratorOne    #   -    #     name: DecoratorTwo    #     library: /opt/lib/decorator.so    # Endorsers are configured as a map that its keys are the endorsement system chaincodes that are being overridden.    # Below is an example that overrides the default ESCC and uses an endorsement plugin that has the same functionality    # as the default ESCC.    # If the &#39;library&#39; property is missing, the name is used as the constructor method in the builtin library similar    # to auth filters and decorators.    # endorsers:    #   escc:    #     name: DefaultESCC    #     library: /etc/hyperledger/fabric/plugin/escc.so    handlers:        authFilters:          -            name: DefaultAuth          -            name: ExpirationCheck    # This filter checks identity x509 certificate expiration        decorators:          -            name: DefaultDecorator        endorsers:          escc:            name: DefaultEndorsement            library:        validators:          vscc:            name: DefaultValidation            library:    #    library: /etc/hyperledger/fabric/plugin/escc.so    # Number of goroutines that will execute transaction validation in parallel.    # By default, the peer chooses the number of CPUs on the machine. Set this    # variable to override that choice.    # NOTE: overriding this value might negatively influence the performance of    # the peer so please change this value only if you know what you&#39;re doing    validatorPoolSize:    # The discovery service is used by clients to query information about peers,    # such as - which peers have joined a certain channel, what is the latest    # channel config, and most importantly - given a chaincode and a channel,    # what possible sets of peers satisfy the endorsement policy.    discovery:        enabled: true        # Whether the authentication cache is enabled or not.        authCacheEnabled: true        # The maximum size of the cache, after which a purge takes place        authCacheMaxSize: 1000        # The proportion (0 to 1) of entries that remain in the cache after the cache is purged due to overpopulation        authCachePurgeRetentionRatio: 0.75        # Whether to allow non-admins to perform non channel scoped queries.        # When this is false, it means that only peer admins can perform non channel scoped queries.        orgMembersAllowedAccess: false    # Limits is used to configure some internal resource limits.    limits:        # Concurrency limits the number of concurrently running requests to a service on each peer.        # Currently this option is only applied to endorser service and deliver service.        # When the property is missing or the value is 0, the concurrency limit is disabled for the service.        concurrency:            # endorserService limits concurrent requests to endorser service that handles chaincode deployment, query and invocation,            # including both user chaincodes and system chaincodes.            endorserService: 2500            # deliverService limits concurrent event listeners registered to deliver service for blocks and transaction events.            deliverService: 2500#################################################################################    VM section################################################################################vm:    # Endpoint of the vm management system.  For docker can be one of the following in general    # unix:///var/run/docker.sock    # http://localhost:2375    # https://localhost:2376    endpoint: unix:///var/run/docker.sock    # settings for docker vms    docker:        tls:            enabled: false            ca:                file: docker/ca.crt            cert:                file: docker/tls.crt            key:                file: docker/tls.key        # Enables/disables the standard out/err from chaincode containers for        # debugging purposes        attachStdout: false        # Parameters on creating docker container.        # Container may be efficiently created using ipam &amp; dns-server for cluster        # NetworkMode - sets the networking mode for the container. Supported        # standard values are: `host`(default),`bridge`,`ipvlan`,`none`.        # Dns - a list of DNS servers for the container to use.        # Note:  `Privileged` `Binds` `Links` and `PortBindings` properties of        # Docker Host Config are not supported and will not be used if set.        # LogConfig - sets the logging driver (Type) and related options        # (Config) for Docker. For more info,        # https://docs.docker.com/engine/admin/logging/overview/        # Note: Set LogConfig using Environment Variables is not supported.        hostConfig:            NetworkMode: host            Dns:               # - 192.168.0.1            LogConfig:                Type: json-file                Config:                    max-size: &quot;50m&quot;                    max-file: &quot;5&quot;            Memory: 2147483648#################################################################################    Chaincode section################################################################################chaincode:    # The id is used by the Chaincode stub to register the executing Chaincode    # ID with the Peer and is generally supplied through ENV variables    # the `path` form of ID is provided when installing the chaincode.    # The `name` is used for all other requests and can be any string.    id:        path:        name:    # Generic builder environment, suitable for most chaincode types    builder: $(DOCKER_NS)/fabric-ccenv:$(TWO_DIGIT_VERSION)    # Enables/disables force pulling of the base docker images (listed below)    # during user chaincode instantiation.    # Useful when using moving image tags (such as :latest)    pull: false    golang:        # golang will never need more than baseos        runtime: $(DOCKER_NS)/fabric-baseos:$(TWO_DIGIT_VERSION)        # whether or not golang chaincode should be linked dynamically        dynamicLink: false    java:        # This is an image based on java:openjdk-8 with addition compiler        # tools added for java shim layer packaging.        # This image is packed with shim layer libraries that are necessary        # for Java chaincode runtime.        runtime: $(DOCKER_NS)/fabric-javaenv:$(TWO_DIGIT_VERSION)    node:        # This is an image based on node:$(NODE_VER)-alpine        runtime: $(DOCKER_NS)/fabric-nodeenv:$(TWO_DIGIT_VERSION)    # List of directories to treat as external builders and launchers for    # chaincode. The external builder detection processing will iterate over the    # builders in the order specified below.    externalBuilders: []        # - path: /path/to/directory        #   name: descriptive-builder-name        #   environmentWhitelist:        #      - ENVVAR_NAME_TO_PROPAGATE_FROM_PEER        #      - GOPROXY    # The maximum duration to wait for the chaincode build and install process    # to complete.    installTimeout: 300s    # Timeout duration for starting up a container and waiting for Register    # to come through.    startuptimeout: 300s    # Timeout duration for Invoke and Init calls to prevent runaway.    # This timeout is used by all chaincodes in all the channels, including    # system chaincodes.    # Note that during Invoke, if the image is not available (e.g. being    # cleaned up when in development environment), the peer will automatically    # build the image, which might take more time. In production environment,    # the chaincode image is unlikely to be deleted, so the timeout could be    # reduced accordingly.    executetimeout: 30s    # There are 2 modes: &quot;dev&quot; and &quot;net&quot;.    # In dev mode, user runs the chaincode after starting peer from    # command line on local machine.    # In net mode, peer will run chaincode in a docker container.    mode: net    # keepalive in seconds. In situations where the communication goes through a    # proxy that does not support keep-alive, this parameter will maintain connection    # between peer and chaincode.    # A value &lt;= 0 turns keepalive off    keepalive: 0    # system chaincodes whitelist. To add system chaincode &quot;myscc&quot; to the    # whitelist, add &quot;myscc: enable&quot; to the list below, and register in    # chaincode/importsysccs.go    system:        _lifecycle: enable        cscc: enable        lscc: enable        escc: enable        vscc: enable        qscc: enable    # Logging section for the chaincode container    logging:      # Default level for all loggers within the chaincode container      level:  info      # Override default level for the &#39;shim&#39; logger      shim:   warning      # Format for the chaincode container logs      format: &#39;%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -&gt; %{level:.4s} %{id:03x}%{color:reset} %{message}&#39;#################################################################################    Ledger section - ledger configuration encompasses both the blockchain#    and the state################################################################################ledger:  blockchain:  state:    # stateDatabase - options are &quot;goleveldb&quot;, &quot;CouchDB&quot;    # goleveldb - default state database stored in goleveldb.    # CouchDB - store state database in CouchDB    stateDatabase: goleveldb    # Limit on the number of records to return per query    totalQueryLimit: 100000    couchDBConfig:       # It is recommended to run CouchDB on the same server as the peer, and       # not map the CouchDB container port to a server port in docker-compose.       # Otherwise proper security must be provided on the connection between       # CouchDB client (on the peer) and server.       couchDBAddress: 127.0.0.1:5984       # This username must have read and write authority on CouchDB       username:       # The password is recommended to pass as an environment variable       # during start up (eg CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD).       # If it is stored here, the file must be access control protected       # to prevent unintended users from discovering the password.       password:       # Number of retries for CouchDB errors       maxRetries: 3       # Number of retries for CouchDB errors during peer startup       maxRetriesOnStartup: 12       # CouchDB request timeout (unit: duration, e.g. 20s)       requestTimeout: 35s       # Limit on the number of records per each CouchDB query       # Note that chaincode queries are only bound by totalQueryLimit.       # Internally the chaincode may execute multiple CouchDB queries,       # each of size internalQueryLimit.       internalQueryLimit: 1000       # Limit on the number of records per CouchDB bulk update batch       maxBatchUpdateSize: 1000       # Warm indexes after every N blocks.       # This option warms any indexes that have been       # deployed to CouchDB after every N blocks.       # A value of 1 will warm indexes after every block commit,       # to ensure fast selector queries.       # Increasing the value may improve write efficiency of peer and CouchDB,       # but may degrade query response time.       warmIndexesAfterNBlocks: 1       # Create the _global_changes system database       # This is optional.  Creating the global changes database will require       # additional system resources to track changes and maintain the database       createGlobalChangesDB: false       # CacheSize denotes the maximum mega bytes (MB) to be allocated for the in-memory state       # cache. Note that CacheSize needs to be a multiple of 32 MB. If it is not a multiple       # of 32 MB, the peer would round the size to the next multiple of 32 MB.       # To disable the cache, 0 MB needs to be assigned to the cacheSize.       cacheSize: 64  history:    # enableHistoryDatabase - options are true or false    # Indicates if the history of key updates should be stored.    # All history &#39;index&#39; will be stored in goleveldb, regardless if using    # CouchDB or alternate database for the state.    enableHistoryDatabase: true  pvtdataStore:    # the maximum db batch size for converting    # the ineligible missing data entries to eligible missing data entries    collElgProcMaxDbBatchSize: 5000    # the minimum duration (in milliseconds) between writing    # two consecutive db batches for converting the ineligible missing data entries to eligible missing data entries    collElgProcDbBatchesInterval: 1000#################################################################################    Operations section################################################################################operations:    # host and port for the operations server    listenAddress: 127.0.0.1:9443    # TLS configuration for the operations endpoint    tls:        # TLS enabled        enabled: false #生产环境是否要设置        # path to PEM encoded server certificate for the operations server        cert:            file:        # path to PEM encoded server key for the operations server        key:            file:        # most operations service endpoints require client authentication when TLS        # is enabled. clientAuthRequired requires client certificate authentication        # at the TLS layer to access all resources.        clientAuthRequired: false        # paths to PEM encoded ca certificates to trust for client authentication        clientRootCAs:            files: []#################################################################################    Metrics section################################################################################metrics:    # metrics provider is one of statsd, prometheus, or disabled    provider: disabled    # statsd configuration    statsd:        # network type: tcp or udp        network: udp        # statsd server address        address: 127.0.0.1:8125        # the interval at which locally cached counters and gauges are pushed        # to statsd; timings are pushed immediately        writeInterval: 10s        # prefix is prepended to all emitted statsd metrics        prefix:</code></pre><p>设置完成后启动peer2</p><pre><code class="bash">export FABRIC_CFG_PATH=$PWDpeer node start &gt;&gt; log_peer.log 2&gt;&amp;1 &amp;</code></pre><h2 id="6-创建并加入应用通道"><a href="#6-创建并加入应用通道" class="headerlink" title="6. 创建并加入应用通道"></a>6. 创建并加入应用通道</h2><h3 id="6-1-创建通道"><a href="#6-1-创建通道" class="headerlink" title="6.1 创建通道"></a>6.1 创建通道</h3><p>在<strong>org1</strong>的peer目录中，将order节点中order目录下的 <code>channel-artifacts</code> 文件夹拷贝到该目录下，然后导入环境变量</p><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051# 自定义orderer的tls ca证书变量export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem</code></pre><p>创建通道</p><pre><code class="bash">peer channel create -o orderer.example.com:7050  -c channel1 -f ./channel-artifacts/channel1.tx --outputBlock ./channel-artifacts/channel1.block --tls --cafile $ORDERER_TLSCA</code></pre><h3 id="6-2-将peer1加入通道中"><a href="#6-2-将peer1加入通道中" class="headerlink" title="6.2 将peer1加入通道中"></a>6.2 将peer1加入通道中</h3><p>将peer加入到channel1中</p><pre><code class="bash">peer channel join -b ./channel-artifacts/channel1.block</code></pre><p>验证peer是否已经加入到通道中，该命令将会列出区块高度和最新的区块哈希值</p><pre><code class="bash">peer channel getinfo -c channel1</code></pre><h3 id="6-3-将peer2加入通道中"><a href="#6-3-将peer2加入通道中" class="headerlink" title="6.3 将peer2加入通道中"></a>6.3 将peer2加入通道中</h3><p>因为通道已经存在了，因此不需要再执行创建通道的操作，只需要先导入环境变量，并从orderer处获取通道的创世区块，再加入通道即可。</p><p>在<strong>org2</strong>的peer目录中，先创建 <code>channel-artifacts</code> 文件夹</p><pre><code class="bash">mkdir channel-artifactscd channel-artifacts</code></pre><p>导入环境变量</p><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:7051# 自定义orderer的tls ca证书变量export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem</code></pre><p>获取创世区块</p><pre><code class="bash">peer channel fetch 0 ./channel-artifacts/channel_org2.block -o orderer.example.com:7050  -c channel1 --tls --cafile $ORDERER_TLSCA</code></pre><p>将peer2加入到channel1中</p><pre><code class="bash">peer channel join -b ./channel-artifacts/channel_org2.block</code></pre><h2 id="7-设置锚节点"><a href="#7-设置锚节点" class="headerlink" title="7. 设置锚节点"></a>7. 设置锚节点</h2><p>一个组织至少需要一个peer成为锚节点，最好设置多个锚节点以备冗余。组织的锚节点的信息在通道的配置中，组织通过升级通道来指定自己的锚节点。流程和通道更新的步骤相似。</p><h3 id="7-1-设置org1的锚节点"><a href="#7-1-设置org1的锚节点" class="headerlink" title="7.1 设置org1的锚节点"></a>7.1 设置org1的锚节点</h3><p>首先设置环境变量，在org1的peer目录下执行</p><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051# 自定义orderer的tls ca证书变量export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem</code></pre><p>拉取最新的通道配置区块</p><pre><code class="bash">peer channel fetch config channel-artifacts/config_block.pb -o orderer.example.com:7050  -c channel1 --tls --cafile $ORDERER_TLSCA</code></pre><p>进入channel-artifacts文件夹中</p><pre><code class="bash">cd channel-artifacts</code></pre><p>使用configtxlator工具来操作通道配置</p><pre><code class="bash">configtxlator proto_decode --input config_block.pb --type common.Block --output config_block.jsonjq .data.data[0].payload.data.config config_block.json &gt; config.json</code></pre><p>编辑配置文件，先将原来的配置文件复制一份，然后再修改。修改的时候主要是用jq工具来将Org1锚节点加入到通道配置文件。</p><blockquote><p>注意下方 <code>.channel_group.groups.Application.groups.Org1MSP.values</code> 中 <code>Org1MSP</code> 是组织的Name不是组织的ID</p></blockquote><pre><code class="bash">cp config.json config_copy.json# 注意此处修改的内容host和port，要改为实际的jq &#39;.channel_group.groups.Application.groups.Org1MSP.values += {&quot;AnchorPeers&quot;:{&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:{&quot;anchor_peers&quot;: [{&quot;host&quot;: &quot;peer0.org1.example.com&quot;,&quot;port&quot;: 7051}]},&quot;version&quot;: &quot;0&quot;}}&#39; config_copy.json &gt; modified_config.json</code></pre><p>将原来的配置文件和修改过的配置文件转到protobuf格式，并核算它们之间的不同。</p><pre><code class="bash">configtxlator proto_encode --input config.json --type common.Config --output config.pbconfigtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pbconfigtxlator compute_update --channel_id channel1 --original config.pb --updated modified_config.pb --output config_update.pb</code></pre><p>将修改的protobuf格式的配置channel_update.pb封装在事务中，并创建通道升级事务。</p><pre><code class="bash">configtxlator proto_decode --input config_update.pb --type common.ConfigUpdate --output config_update.jsonecho &#39;{&quot;payload&quot;:{&quot;header&quot;:{&quot;channel_header&quot;:{&quot;channel_id&quot;:&quot;channel1&quot;, &quot;type&quot;:2}},&quot;data&quot;:{&quot;config_update&quot;:&#39;$(cat config_update.json)&#39;}}}&#39; | jq . &gt; config_update_in_envelope.jsonconfigtxlator proto_encode --input config_update_in_envelope.json --type common.Envelope --output config_update_in_envelope.pb</code></pre><p>更新通道配置，因为修改部分只影响Org1，另一个通道不需要签名本次升级。</p><pre><code class="bash">cd ..peer channel update -f channel-artifacts/config_update_in_envelope.pb -c channel1 -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA</code></pre><h3 id="7-2-设置org2的锚节点"><a href="#7-2-设置org2的锚节点" class="headerlink" title="7.2 设置org2的锚节点"></a>7.2 设置org2的锚节点</h3><p>首先设置环境变量，在org1的peer目录下执行</p><pre><code class="bash">export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:7051# 自定义orderer的tls ca证书变量export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem</code></pre><p>拉取最新的通道配置区块</p><pre><code class="bash">peer channel fetch config channel-artifacts/config_block.pb -o orderer.example.com:7050  -c channel1 --tls --cafile $ORDERER_TLSCA</code></pre><p>进入channel-artifacts文件夹中</p><pre><code class="bash">cd channel-artifacts</code></pre><p>使用configtxlator工具来操作通道配置</p><pre><code class="bash">configtxlator proto_decode --input config_block.pb --type common.Block --output config_block.jsonjq .data.data[0].payload.data.config config_block.json &gt; config.json</code></pre><p>编辑配置文件，先将原来的配置文件复制一份，然后再修改。修改的时候主要是用jq工具来将Org2锚节点加入到通道配置文件。</p><blockquote><p>注意下方 <code>.channel_group.groups.Application.groups.Org2MSP.values</code> 中 <code>Org2MSP</code> 是组织的Name不是组织的ID</p></blockquote><pre><code class="bash">cp config.json config_copy.json# 注意此处修改的内容host和port，要改为实际的jq &#39;.channel_group.groups.Application.groups.Org2MSP.values += {&quot;AnchorPeers&quot;:{&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:{&quot;anchor_peers&quot;: [{&quot;host&quot;: &quot;peer0.org2.example.com&quot;,&quot;port&quot;: 7051}]},&quot;version&quot;: &quot;0&quot;}}&#39; config_copy.json &gt; modified_config.json</code></pre><p>将原来的配置文件和修改过的配置文件转到protobuf格式，并核算它们之间的不同。</p><pre><code class="bash">configtxlator proto_encode --input config.json --type common.Config --output config.pbconfigtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pbconfigtxlator compute_update --channel_id channel1 --original config.pb --updated modified_config.pb --output config_update.pb</code></pre><p>将修改的protobuf格式的配置channel_update.pb封装在事务中，并创建通道升级事务。</p><pre><code class="bash">configtxlator proto_decode --input config_update.pb --type common.ConfigUpdate --output config_update.jsonecho &#39;{&quot;payload&quot;:{&quot;header&quot;:{&quot;channel_header&quot;:{&quot;channel_id&quot;:&quot;channel1&quot;, &quot;type&quot;:2}},&quot;data&quot;:{&quot;config_update&quot;:&#39;$(cat config_update.json)&#39;}}}&#39; | jq . &gt; config_update_in_envelope.jsonconfigtxlator proto_encode --input config_update_in_envelope.json --type common.Envelope --output config_update_in_envelope.pb</code></pre><p>更新通道配置，因为修改部分只影响Org2，另一个通道不需要签名本次升级。</p><pre><code class="bash">cd ..peer channel update -f channel-artifacts/config_update_in_envelope.pb -c channel1 -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA</code></pre><h3 id="7-3-确认结果"><a href="#7-3-确认结果" class="headerlink" title="7.3 确认结果"></a>7.3 确认结果</h3><pre><code class="bash">peer channel getinfo -c channel1</code></pre><p>7</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>05_javaSDK使用</title>
      <link href="/2020/12/01/fabric/05_java%20SDK%E4%BD%BF%E7%94%A8/"/>
      <url>/2020/12/01/fabric/05_java%20SDK%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="java-SDK使用"><a href="#java-SDK使用" class="headerlink" title="java SDK使用"></a>java SDK使用</h1><p>工程一般会使用SDK去调用网络完成交易</p><p>为了完成SDK调用需要使用Fabric-Gateway与Fabric网络建立联系，需要使用connectionProfile这一配置文件。文件中包含的内容为</p><table><thead><tr><th>参数名</th><th>描述</th></tr></thead><tbody><tr><td>name</td><td>自定义网络名称</td></tr><tr><td>version</td><td>自定义网络版本</td></tr><tr><td>client</td><td>客户端相关信息</td></tr><tr><td>channels</td><td>网络所包含的通道信息</td></tr><tr><td>organizations</td><td>网络中组织信息</td></tr><tr><td>orderers</td><td>排序节点信息</td></tr><tr><td>peer</td><td>pee节点信息</td></tr><tr><td>certificateAuthorities</td><td>ca节点信息</td></tr></tbody></table><h2 id="1-client"><a href="#1-client" class="headerlink" title="1. client"></a>1. client</h2><pre><code class="json">&quot;client&quot;: {    &quot;organization&quot;: &quot;Org1&quot;,    &quot;connection&quot;: {        &quot;timeout&quot;: {            &quot;peer&quot;: {                &quot;endorser&quot;: &quot;300&quot;            },            &quot;orderer&quot;: &quot;300&quot;        }    }},</code></pre><h2 id="2-channels"><a href="#2-channels" class="headerlink" title="2. channels"></a>2. channels</h2><p>这下面是本文件描述的所有通道信息，最好是不同的通道用不同的配置文件来描述</p><pre><code class="json">&quot;channels&quot;: {    &quot;mychannel&quot;: {        &quot;orderers&quot;: [            &quot;orderer.example.com&quot;        ],        &quot;peers&quot;: {            &quot;peer0.org1.example.com&quot;: {                &quot;endorsingPeer&quot;: true,                &quot;chaincodeQuery&quot;: true,                &quot;ledgerQuery&quot;: true,                &quot;eventSource&quot;: true            },            &quot;peer0.org2.example.com&quot;: {                &quot;endorsingPeer&quot;: true,                &quot;chaincodeQuery&quot;: true,                &quot;ledgerQuery&quot;: true,                &quot;eventSource&quot;: true            }        }    }},</code></pre><p>对于每个peer的四个属性含义分别为：</p><ul><li><strong>endorsingPeer</strong>：具有背书权限节点</li><li><strong>chaincodeQuery</strong>：具有合约查询权限节点</li><li><strong>ledgerQuery</strong>：具有账本查询权限节点</li><li><strong>eventSource</strong>：event hub节点</li></ul><h2 id="3-organizations"><a href="#3-organizations" class="headerlink" title="3. organizations"></a>3. organizations</h2><p>其中admin私钥与admin签名证书支持路径与文件内容，路径使用参数<code>path</code>，对应值填写路径，文件内容使用参数<code>pem</code>，对应值填写私钥或者证书内容。</p><pre><code class="json">&quot;organizations&quot;: {    &quot;Org1&quot;: {        &quot;mspid&quot;: &quot;Org1MSP&quot;,        &quot;peers&quot;: [            &quot;peer0.org1.example.com&quot;        ],        &quot;certificateAuthorities&quot;: [            &quot;ca-org1&quot;        ],        &quot;adminPrivateKeyPEM&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore/priv_sk&quot;        },        &quot;signedCertPEM&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem&quot;        }    },    &quot;Org2&quot;: {        &quot;mspid&quot;: &quot;Org2MSP&quot;,        &quot;peers&quot;: [            &quot;peer0.org2.example.com&quot;        ],        &quot;certificateAuthorities&quot;: [            &quot;ca-org2&quot;        ],        &quot;adminPrivateKeyPEM&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp/keystore/priv_sk&quot;        },        &quot;signedCertPEM&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp/signcerts/Admin@org2.example.com-cert.pem&quot;        }    }},</code></pre><h2 id="4-orderers"><a href="#4-orderers" class="headerlink" title="4. orderers"></a>4. orderers</h2><pre><code class="json">&quot;orderers&quot;: {    &quot;orderer.example.com&quot;: {        &quot;url&quot;: &quot;grpcs://192.168.2.104:7050&quot;,        &quot;mspid&quot;: &quot;OrdererMSP&quot;,        &quot;grpcOptions&quot;: {            &quot;ssl-target-name-override&quot;: &quot;orderer.example.com&quot;,            &quot;hostnameOverride&quot;: &quot;orderer.example.com&quot;        },        &quot;tlsCACerts&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/ca.crt&quot;        },        &quot;adminPrivateKeyPEM&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/ordererOrganizations/example.com/users/Admin@example.com/msp/keystore/priv_sk&quot;        },        &quot;signedCertPEM&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/ordererOrganizations/example.com/users/Admin@example.com/msp/signcerts/Admin@example.com-cert.pem&quot;        }    }},</code></pre><h2 id="5-peers"><a href="#5-peers" class="headerlink" title="5. peers"></a>5. peers</h2><pre><code class="json">&quot;peers&quot;: {    &quot;peer0.org1.example.com&quot;: {        &quot;url&quot;: &quot;grpcs://192.168.2.104:7051&quot;,        &quot;grpcOptions&quot;: {            &quot;ssl-target-name-override&quot;: &quot;peer0.org1.example.com&quot;,            &quot;hostnameOverride&quot;: &quot;peer0.org1.example.com&quot;,            &quot;request-timeout&quot;: 120001        },        &quot;tlsCACerts&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt&quot;        }    },    &quot;peer0.org2.example.com&quot;: {        &quot;url&quot;: &quot;grpcs://192.168.2.104:9051&quot;,        &quot;grpcOptions&quot;: {            &quot;ssl-target-name-override&quot;: &quot;peer0.org2.example.com&quot;,            &quot;hostnameOverride&quot;: &quot;peer0.org2.example.com&quot;,            &quot;request-timeout&quot;: 120001        },        &quot;tlsCACerts&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt&quot;        }    }},</code></pre><h2 id="6-certificateAuthorities"><a href="#6-certificateAuthorities" class="headerlink" title="6. certificateAuthorities"></a>6. certificateAuthorities</h2><pre><code class="json">&quot;certificateAuthorities&quot;: {    &quot;ca-org1&quot;: {        &quot;url&quot;: &quot;https://192.168.2.104:7054&quot;,        &quot;grpcOptions&quot;: {            &quot;verify&quot;: true        },        &quot;tlsCACerts&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem&quot;        },        &quot;registrar&quot;: [            {                &quot;enrollId&quot;: &quot;admin&quot;,                &quot;enrollSecret&quot;: &quot;adminpw&quot;            }        ]    },    &quot;ca-org2&quot;: {        &quot;url&quot;: &quot;https://192.168.2.104:8054&quot;,        &quot;grpcOptions&quot;: {            &quot;verify&quot;: true        },        &quot;tlsCACerts&quot;: {            &quot;path&quot;: &quot;src/main/resources/crypto-config/peerOrganizations/org2.example.com/ca/ca.org2.example.com-cert.pem&quot;        },        &quot;registrar&quot;: [            {                &quot;enrollId&quot;: &quot;admin&quot;,                &quot;enrollSecret&quot;: &quot;adminpw&quot;            }        ]    }}</code></pre><h1 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h1><pre><code>src/main/java ： 存放demo主程序类src/main/resources/connection.json ： 上面新建好的connectionProfilesrc/main/resources/crypto-config: 存放fabric网络证书内容(选择用到的就行)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>04_用户使用链码</title>
      <link href="/2020/12/01/fabric/04_%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E9%93%BE%E7%A0%81/"/>
      <url>/2020/12/01/fabric/04_%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E9%93%BE%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h1 id="链码中用户权限"><a href="#链码中用户权限" class="headerlink" title="链码中用户权限"></a>链码中用户权限</h1><p>链码中用户权限有三种方式：参见<a href="https://github.com/hyperledger/fabric-chaincode-go/blob/master/pkg/cid/README.md" target="_blank" rel="noopener">https://github.com/hyperledger/fabric-chaincode-go/blob/master/pkg/cid/README.md</a></p><ul><li>用户的属性</li><li>用户的id及MspId</li><li>用户身份的OU（组织单元organizational unit）</li></ul><h2 id="1-使用用户属性来控制权限"><a href="#1-使用用户属性来控制权限" class="headerlink" title="1. 使用用户属性来控制权限"></a>1. 使用用户属性来控制权限</h2><p>属性的两种使用方式</p><pre><code class="go">// 方式一，获取属性值val, ok, err := cid.GetAttributeValue(stub, &quot;attr1&quot;)if err != nil {   // 获取属性时有错误}if !ok {   // 没有此属性}// 变量val为属性的值// 方式二，判断属性值是否为某个值err := cid.AssertAttributeValue(stub, &quot;attr2&quot;, &quot;true&quot;)if err != nil {   // 如果attr2的值不是&quot;true&quot;,则会有err} else {   //是&quot;true&quot;,执行这里 }</code></pre><p>编辑链码fabric-samples中的示例代码sacc.go。</p><p>假设需求是，拥有属性addPrefix的用户设置值时加个前缀prefix_。没有此属性的用户设置时不加前缀。更改Invoke函数。</p><pre><code class="go">func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // Extract the function and args from the transaction proposal    fn, args := stub.GetFunctionAndParameters()    var result string    var err error    if fn == &quot;set&quot; {        err := cid.AssertAttributeValue(stub, &quot;addPrefix&quot;, &quot;true&quot;)        if err == nil {            args = [] string {args[0], &quot;prefix_&quot;+args[1]}        }         result, err = set(stub, args)    } else { // assume &#39;get&#39; even if fn is nil        result, err = get(stub, args)    }    if err != nil {        return shim.Error(err.Error())    }    // Return the result as success payload    return shim.Success([]byte(result))}</code></pre><p>在Org1的peer0和Org2的peer0上升级链码，Org3暂时不升级（不升级链码的组织用户调用链码时会报错，无法调用）。（因各种问题，作者的链码版本此时已升级到第4版，按第4版贴出部分安装调用代码）</p><p>在Org1和Org2的peer上执行以下代码，环境变量按前文设置，此时不再贴出。</p><pre><code class="bash">peer lifecycle chaincode package chaincode/sacc4.tar.gz --path chaincode/sacc4 --lang golang --label sacc_4peer lifecycle chaincode install chaincode/sacc4.tar.gz export CC_PACKAGE_ID=sacc_4:46d5aed45040c0d190081a8cb3fd550b6e6af4cafadc742e707d2af44bd35650peer lifecycle chaincode approveformyorg -o orderer.example.com:7050  --channelID channel1 --init-required --name sacc --version 4.0 --package-id $CC_PACKAGE_ID --sequence 4 --tls --cafile $ORDERER_TLSCApeer lifecycle chaincode checkcommitreadiness --channelID channel1 --init-required --name sacc --version 4.0 --sequence 4 --tls --cafile $ORDERER_TLSCA --output json</code></pre><p>提交并初始化链码</p><pre><code class="bash">peer lifecycle chaincode commit -o orderer.example.com:7050 --channelID channel1 --init-required --name sacc --version 4.0 --sequence 4 --tls --cafile $ORDERER_TLSCA --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtpeer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt --isInit -c &#39;{&quot;Args&quot;:[&quot;a&quot;,&quot;bb&quot;]}&#39;</code></pre><p><strong>创建Org1的用户user2</strong></p><p>首先，启动peer0.org1.example.com上之前的Fabric CA server</p><pre><code class="bash">cd ~/work/example/ca_serverfabric-ca-server start  -b admin:adminpw --port 7054</code></pre><p>注册包含属性addPrefix的用户</p><pre><code class="bash">cd ~/work/example/ca_clientexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client register --id.name user2 --id.secret user2pw --id.type user  --id.attrs &#39;addPrefix=true:ecert&#39;</code></pre><p>获取msp</p><pre><code class="bash">cd ~/work/example/organizations/peerOrganizations/org1.example.com/users/mkdir User2@org1.example.comcd User2@org1.example.comexport FABRIC_CA_CLIENT_HOME=$PWDfabric-ca-client enroll -u http://user2:user2pw@0.0.0.0:7054 -M $FABRIC_CA_CLIENT_HOME/msp#生成管理员证书cd mspmkdir admincertscp signcerts/cert.pem admincerts/</code></pre><p>使用user2调用链码</p><pre><code class="bash">cd ~/work/example/peer/export CORE_PEER_TLS_ENABLED=trueexport CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;#此处不单独获取tls证书，直接使用peer的tls证书，效果一样。生产环境中需要单独获取tls证书，流程参见5.2部分export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/../organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=${PWD}/../organizations/peerOrganizations/org1.example.com/users/User2@org1.example.com/mspexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export ORDERER_TLSCA=${PWD}/../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#查询当前值peer chaincode query -C channel1 -n sacc  -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;#设置值为22，结果应为prefix_22peer chaincode invoke -o orderer.example.com:7050 --tls --cafile $ORDERER_TLSCA -C channel1 -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles $CORE_PEER_TLS_ROOTCERT_FILE --peerAddresses peer0.org2.example.com:7051 --tlsRootCertFiles ${PWD}/../organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt  -c &#39;{&quot;Args&quot;:[&quot;set&quot;,&quot;a&quot;,&quot;22&quot;]}&#39;</code></pre><p>此时切换其它账号设置，即可看到只有user2设置值时会加前缀prefix_</p><h2 id="2-用户（客户端）的ID与MSP-ID"><a href="#2-用户（客户端）的ID与MSP-ID" class="headerlink" title="2. 用户（客户端）的ID与MSP ID"></a>2. 用户（客户端）的ID与MSP ID</h2><p>用户ID的获取方式</p><pre><code class="go">import &quot;github.com/hyperledger/fabric-chaincode-go/pkg/cid&quot;//方式一：id, err := cid.GetID(stub) //此id为字符串,看源代码知其实是调用方式二//方式二：c, err := cid.New(stub)id, err := c.GetID()//拓展阅读id的源代码如下//_id := fmt.Sprintf(&quot;x509::%s::%s&quot;, getDN(&amp;c.cert.Subject), getDN(&amp;c.cert.Issuer))//id = base64.StdEncoding.EncodeToString([]byte(_id))</code></pre><p>获取 MSP ID（即组织ID）</p><pre><code class="go">import &quot;github.com/hyperledger/fabric-chaincode-go/pkg/cid&quot;//方式一mspid, err := cid.GetMSPID(stub) //看源代码知，其实是调用方式二//方式二c, err := cid.New(stub) //c为ClientID结构体的实例化mspid, err := c.GetMSPID() //实为c.mspID//拓展阅读结构体ClientIDtype ClientID struct {    stub  ChaincodeStubInterface    mspID string    cert  *x509.Certificate    attrs *attrmgr.Attributes}</code></pre><p>升级链码，加上功能，打印用户的id及MSPID，修改Invoke部分</p><pre><code class="go">func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // Extract the function and args from the transaction proposal    fn, args := stub.GetFunctionAndParameters()    var result string    var err error    if fn == &quot;set&quot; {        err := cid.AssertAttributeValue(stub, &quot;addPrefix&quot;, &quot;true&quot;)        if err == nil {            args = [] string {args[0], &quot;prefix_&quot;+args[1]}        }         c, err := cid.New(stub)        id, err := c.GetID()        mspid, err := c.GetMSPID()        fmt.Println(&quot;*************************************************************************************\n&quot;)        fmt.Printf(&quot;id=%s,  mspid=%s&quot;, id, mspid)        fmt.Println(&quot;*************************************************************************************\n&quot;)        result, err = set(stub, args)    } else { // assume &#39;get&#39; even if fn is nil        result, err = get(stub, args)    }    if err != nil {        return shim.Error(err.Error())    }    // Return the result as success payload    return shim.Success([]byte(result))}</code></pre><p>在Org1和Org2的peer上安装，审议，提交链码。注意此处为链码升级，因此在审议链码时，参数–name值不变（此处为sacc），如果–name 变化就是安装其它链码与已安装的链码无关。</p><p>启动后调用链码，查看链码日志输出</p><pre><code class="bash">1. docker ps 找到对应链码版本的容器ID2. docker logs -f 容器ID# 输出内容为（修饰过展示，便于理解）id = eDUwOTo6Q049QWRtaW5Ab3JnMS5leGFtcGxlLmNvbSxMPVNhbiBGcmFuY2lzY28sU1Q9Q2FsaWZvcm5pYSxDPVVTOjpDTj1jYS5vcmcxLmV4YW1wbGUuY29tLE89b3JnMS5leGFtcGxlLmNvbSxMPVNhbiBGcmFuY2lzY28sU1Q9Q2FsaWZvcm5pYSxDPVVTmspid = Org1MSP</code></pre><h2 id="3-从属关系OU"><a href="#3-从属关系OU" class="headerlink" title="3. 从属关系OU"></a>3. 从属关系OU</h2><p>请注意，ECert的“OU”或组织单位总是根据identities type和affiliance的值设置的。对于注册，OU计算为<code>OU=&lt;type&gt;，OU=&lt;affiliationRoot&gt;，…，OU=&lt;affiliationLeaf&gt;</code>。例如，一个隶属关系为“org1.dept2.team3”的“client”类型的标识将具有以下组织单位：<code>OU=client，OU=org1，OU=dept2，OU=team3</code></p><pre><code class="go">found, err := cid.HasOUValue(stub, &quot;org1&quot;) //也可以c, err := cid.New(stub) found, err := c.HasOUValue(&quot;org1&quot;)if err != nil {   // Return an error}if !found {   // The client identity is not part of the Organizational Unit   // Return an error}//拓展阅读，贴出源码func (c *ClientID) HasOUValue(OUValue string) (bool, error) {    x509Cert := c.cert    if x509Cert == nil {        // Here it will return false and an error, as there is no x509 type cert to check for OU values.        return false, fmt.Errorf(&quot;cannot obtain an X509 certificate for the identity&quot;)    }    for _, OU := range x509Cert.Subject.OrganizationalUnit {        if OU == OUValue {            return true, nil        }    }    return false, nil}//因此使用时比如某个用户注册时是fabric-ca-client register --id.name user2o --id.secret userpw --id.type client --id.affiliation org2.department1//假如链码如下所示：x509Cert, err := c.GetX509Certificate()if err != nil {    fmt.Println(&quot;no cert!!!&quot;)} else {    for _, OU := range x509Cert.Subject.OrganizationalUnit {        fmt.Printf(&quot;OU=%s\n&quot;, OU)    }}found, err := c.HasOUValue(&quot;org2&quot;)if found {    fmt.Println(&quot;has org2&quot;)} else {    fmt.Println(&quot;no org2!!!&quot;)}found, err = c.HasOUValue(&quot;department1&quot;)if found {    fmt.Println(&quot;has department1&quot;)}  else {    fmt.Println(&quot;no department1 !!!&quot;)}found, err = c.HasOUValue(&quot;org2.department1&quot;)if found {    fmt.Println(&quot;has org2.department1&quot;)}  else {    fmt.Println(&quot;no org2.department1 !!!&quot;)}        //链码截止//那么输出为// OU=client// OU=org2// OU=department1// has org2// has department1// no org2.department1 !!!// 因此HasOUValue函数不能判断org2.department1，只能判断org2和department1。</code></pre><p>查看user的OU，修改invoke部分</p><pre><code class="go">func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // Extract the function and args from the transaction proposal    fn, args := stub.GetFunctionAndParameters()    var result string    var err error    if fn == &quot;set&quot; {        err := cid.AssertAttributeValue(stub, &quot;addPrefix&quot;, &quot;true&quot;)        if err == nil {            args = [] string {args[0], &quot;prefix_&quot;+args[1]}        }         c, err := cid.New(stub)        id, err := c.GetID()        mspid, err := c.GetMSPID()        fmt.Println(&quot;*************************************************************************************\n&quot;)        fmt.Printf(&quot;id=%s\n&quot;, id)        fmt.Printf(&quot;mspid=%s\n&quot;, mspid)        //输出所属的OU        x509Cert, err := c.GetX509Certificate()        if err != nil {            fmt.Println(&quot;no cert!!!&quot;)        } else {            for _, OU := range x509Cert.Subject.OrganizationalUnit {                fmt.Printf(&quot;OU=%s\n&quot;, OU)            }        }        fmt.Println(&quot;*************************************************************************************\n&quot;)        result, err = set(stub, args)    } else { // assume &#39;get&#39; even if fn is nil        result, err = get(stub, args)    }    if err != nil {        return shim.Error(err.Error())    }    // Return the result as success payload    return shim.Success([]byte(result))}</code></pre><p>输出结果</p><pre><code class="bash">当用户为Admin或User1：(cryptogen工具生成的用户没有OU)OU部分输出为空，开始时crypto-config.yaml 中没有设置EnableNodeOUs: true，设置后猜测应该此处有输出。待验证当用户为User2 （Fabric CA注册的用户时只有--id.type user）OU=user</code></pre><p>注册新账号</p><pre><code class="bash">fabric-ca-client register --id.name user2o --id.secret userpw --id.type client --id.affiliation org2.department1注意：1.此处的affiliation中org2并不是联盟链中Org2MSP，仍然数以Org1MSP。此字段可以理解为一个属性，本身并不代表在原生链中的权限。注意在正式开发中要区分org1和org22.--id.affiliation的值只能从Fabric CA Server配置文件中选择（可以修改配置文件），当前文件内容为： affiliations:   org1:      - department1      - department2   org2:      - department1--id.affiliation值可以是：org1org1.department1</code></pre><p>以user2o调用连码，查看输出结果</p><pre><code class="bash">OU=clientOU=org2OU=department1</code></pre><h2 id="4-混合使用"><a href="#4-混合使用" class="headerlink" title="4. 混合使用"></a>4. 混合使用</h2><pre><code class="bash">id, err := cid.New(stub)if err != nil {   // Handle error}mspid, err := id.GetMSPID()if err != nil {   // Handle error}switch mspid {   case &quot;org1MSP&quot;:      err = id.AssertAttributeValue(&quot;attr1&quot;, &quot;true&quot;)   case &quot;org2MSP&quot;:      err = id.AssertAttributeValue(&quot;attr2&quot;, &quot;true&quot;)   default:      err = errors.New(&quot;Wrong MSP&quot;)}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【hadoop 3】hadoop分布式安装总结</title>
      <link href="/2020/11/26/hadoop/%E5%AE%89%E8%A3%85/"/>
      <url>/2020/11/26/hadoop/%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h1 id="安装文件"><a href="#安装文件" class="headerlink" title="安装文件"></a>安装文件</h1><ol><li><p>安装java和hadoop，解压到一个目录里面就可以了，然后在profile文件中配置javahome和hadoophome</p><pre><code class="bash">export HADOOP_HOME=/opt/hadoop-3.2.1export JAVA_HOME=/opt/jdk1.8.0_271    export JRE_HOME=${JAVA_HOME}/jre    export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib    export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH </code></pre></li></ol><ol start="2"><li><p>复制虚拟机，并且修改/etc/hosts，将集群的几个机器的名称和IP地址记录下来</p><pre><code>192.168.108.129 hadoop001192.168.108.130 hadoop002192.168.108.131 hadoop003</code></pre></li></ol><ol start="3"><li><p>配置免密登录：</p><p>在<code>master</code>上生成公钥和密钥对，一路回车即可</p><pre><code class="bash">ssh-keygen -t rsa</code></pre><p>将密钥加入公钥中</p><pre><code class="bash">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></pre><p>将公钥复制到其他从节点</p><pre><code class="bash">ssh-copy-id hadoop002ssh-copy-id hadoop003</code></pre><p>测试方式是在hadoop001上面使用<code>ssh hadoop002</code> 来测试，可以输入exit退出</p></li></ol><h1 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h1><p>以下四个配置文件的位置都是在 <code>hadoop-3.2.1/etc/hadoop</code> 目录下</p><h2 id="1-hadoop-env-sh"><a href="#1-hadoop-env-sh" class="headerlink" title="1. hadoop-env.sh"></a>1. hadoop-env.sh</h2><p>修改配置文件 <code>hadoop-env.sh</code></p><pre><code class="bash">export JAVA_HOME=/opt/jdk1.8.0_271export HADOOP_PID_DIR=/opt/hadoop-3.2.1/pidsexport HADOOP_LOG_DIR=/opt/hadoop-3.2.1/logs</code></pre><blockquote><p><strong>说明：</strong><br><code>JAVA_HOME</code>：hadoop所用的jdk路径<br><code>HADOOP_PID_DIR</code>：进程标识文件目录<br><code>HADOOP_LOG_DIR</code>：日志文件目录</p></blockquote><h2 id="2-四个xml配置文件"><a href="#2-四个xml配置文件" class="headerlink" title="2. 四个xml配置文件"></a>2. 四个xml配置文件</h2><h3 id="2-1-core-site-xml"><a href="#2-1-core-site-xml" class="headerlink" title="2.1 core-site.xml"></a>2.1 core-site.xml</h3><pre><code class="xml">&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://hadoop001:9000&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;        &lt;value&gt;/opt/hadoop-3.2.1/tmp&lt;/value&gt;    &lt;/property&gt;    &lt;!-- 以下可选 --&gt;    &lt;property&gt;        &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;        &lt;value&gt;*&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;        &lt;value&gt;*&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre><blockquote><p><strong>说明：</strong><br><code>fs.defaultFS</code>：NameNode的URI，HDFS端口<br><code>hadoop.tmp.dir</code>：存放hadoop文件系统的基本配置文件<br><code>hadoop.proxyuser</code>参考：<a href="https://blog.csdn.net/u012948976/article/details/49904675`（可选，我需要用到这个）`" target="_blank" rel="noopener">https://blog.csdn.net/u012948976/article/details/49904675`（可选，我需要用到这个）`</a></p></blockquote><h3 id="2-2-hdfs-site-xml"><a href="#2-2-hdfs-site-xml" class="headerlink" title="2.2 hdfs-site.xml"></a>2.2 hdfs-site.xml</h3><pre><code class="xml">&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;3&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;    &lt;value&gt;file:/opt/hadoop-3.2.1/dfs/name&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;    &lt;value&gt;file:/opt/hadoop-3.2.1/dfs/data&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;hadoop003:50090&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;      &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;      &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;dfs.permissions&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><blockquote><p><strong>说明：</strong><br><code>dfs.replication</code>：备份系数<br><code>dfs.namenode.name.dir</code>：fsimage存放路径<br><code>dfs.datanode.data.dir</code>：数据块文件的本地路径<br><code>dfs.namenode.secondary.http-address</code>：配置SecondaryNameNode的地址<code>（我将其规划在虚拟机node2上，此时还没创建这个虚拟机，先配置了再说）</code><br><code>dfs.webhdfs.enabled</code>：开启webhdfs</p></blockquote><h3 id="2-3-mapred-site-xml"><a href="#2-3-mapred-site-xml" class="headerlink" title="2.3 mapred-site.xml"></a>2.3 mapred-site.xml</h3><pre><code class="xml">&lt;configuration&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;       &lt;value&gt;yarn&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;       &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.map.env&lt;/name&gt;       &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;       &lt;value&gt;HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;       &lt;value&gt;hadoop001:10020&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;       &lt;value&gt;hadoop001:19888&lt;/value&gt;   &lt;/property&gt;&lt;/configuration&gt;</code></pre><blockquote><p><strong>简要说明：</strong><br>配置Hadoop jobhistory历史服务器以及MAPRED_HOME</p></blockquote><h3 id="2-4-yarn-site-xml"><a href="#2-4-yarn-site-xml" class="headerlink" title="2.4 yarn-site.xml"></a>2.4 yarn-site.xml</h3><pre><code class="xml">&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;        &lt;value&gt;hadoop001&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;     &lt;/property&gt;    &lt;property&gt;       &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;       &lt;value&gt;1024&lt;/value&gt;       &lt;description&gt;default value is 1024&lt;/description&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre><h2 id="3-workers"><a href="#3-workers" class="headerlink" title="3. workers"></a>3. workers</h2><p>workers</p><pre><code>hadoop001hadoop002hadoop003</code></pre><h2 id="4-四个sh文件"><a href="#4-四个sh文件" class="headerlink" title="4. 四个sh文件"></a>4. 四个sh文件</h2><p>主要是在这四个文件中添加一些权限配置</p><h3 id="4-1-start-dfs-sh"><a href="#4-1-start-dfs-sh" class="headerlink" title="4.1 start-dfs.sh"></a>4.1 start-dfs.sh</h3><pre><code class="sh">HDFS_DATANODE_USER=rootHDFS_DATANODE_SECURE_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=root</code></pre><h3 id="4-2-start-yarn-sh"><a href="#4-2-start-yarn-sh" class="headerlink" title="4.2 start-yarn.sh"></a>4.2 start-yarn.sh</h3><pre><code class="sh">YARN_RESOURCEMANAGER_USER=rootHDFS_DATANODE_SECURE_USER=yarnYARN_NODEMANAGER_USER=root</code></pre><h3 id="4-3-stop-dfs-sh"><a href="#4-3-stop-dfs-sh" class="headerlink" title="4.3 stop-dfs.sh"></a>4.3 stop-dfs.sh</h3><pre><code class="sh">HDFS_DATANODE_USER=rootHDFS_DATANODE_SECURE_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=root</code></pre><h3 id="4-4-stop-yarn-sh"><a href="#4-4-stop-yarn-sh" class="headerlink" title="4.4 stop-yarn.sh"></a>4.4 stop-yarn.sh</h3><pre><code class="sh">YARN_RESOURCEMANAGER_USER=rootHDFS_DATANODE_SECURE_USER=yarnYARN_NODEMANAGER_USER=root</code></pre><h1 id="分发虚拟机"><a href="#分发虚拟机" class="headerlink" title="分发虚拟机"></a>分发虚拟机</h1><p>分发到其他两个虚拟机中</p><pre><code class="bash">scp -r /opt/hadoop-3.2.1 hadoop@hadoop002:/optscp -r /opt/hadoop-3.2.1 hadoop@hadoop002:/opt</code></pre><p>这个过程会比较慢，可以先将它打包之后再进行分发</p><h1 id="开启并测试"><a href="#开启并测试" class="headerlink" title="开启并测试"></a>开启并测试</h1><h2 id="1-格式化namenode"><a href="#1-格式化namenode" class="headerlink" title="1. 格式化namenode"></a>1. 格式化namenode</h2><p>首先需要格式化namenode</p><pre><code class="bash">hadoop namenode -format</code></pre><p>如果是反复格式化，则可能会出现datanode无法启动的问题，此时需要删除几个文件夹：</p><ul><li>tmp</li><li>logs</li><li>dfs</li></ul><h2 id="2-开启关闭集群"><a href="#2-开启关闭集群" class="headerlink" title="2. 开启关闭集群"></a>2. 开启关闭集群</h2><p>以上全部完成之后，可以开启整个集群</p><pre><code class="sh">start-all.sh</code></pre><p>如果要关闭，则使用</p><pre><code class="sh">stop-all.sh</code></pre><p>开启成功之后，可以使用jps查看线程情况</p><h2 id="3-存取文件测试"><a href="#3-存取文件测试" class="headerlink" title="3. 存取文件测试"></a>3. 存取文件测试</h2><p>存取文件可以使用hdfs来进行</p><p>新建文件夹</p><pre><code class="sh">hdfs dfs -mkdir -p /user/hadoop</code></pre><p>上传文件</p><pre><code class="sh">hdfs dfs -put 文件完整路径 hdfs的完整路径</code></pre><p>获取文件</p><pre><code class="sh">hdfs dfs -get 文件完整路径</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【QT 3】模型-视图结构</title>
      <link href="/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/"/>
      <url>/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="模型-视图结构"><a href="#模型-视图结构" class="headerlink" title="模型 / 视图结构"></a>模型 / 视图结构</h1><p>QT中的模型/视图结构类似于MVC的设计模式，完成数据与界面的分离，被叫做InterView框架，Qt的这个框架引入了代理，通过使用代理，能够自定义数据条目（item）的显示和编辑方式。</p><ul><li>模型：与数据源通信，并为其他部件提供接口</li><li>视图：从模型中获得用来引用数据item的模型索引</li><li>代理：负责绘制数据item，当编辑item时，代理和模型直接进行通信。</li></ul><p>模型、视图、代理之间通过信号与槽进行通信，他们的关系为：</p><img src="/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/image-20201029104746440.png" alt="模型/视图结构" style="zoom:80%;"><ol><li>数据发生改变时，模型发出信号通知视图</li><li>用户对界面进行操作，视图发出信号</li><li>代理发出信号告知模型和视图编辑器目前的状态</li></ol><h2 id="1-模型-Model"><a href="#1-模型-Model" class="headerlink" title="1. 模型 Model"></a>1. 模型 Model</h2><p>所有基于item数据的数据模型Model，都是基于QAbstractItemModel类，这个类定义了视图组件和代理存取数据的接口。</p><p>数据无需存储在数据模型中，这个数据可以是其他类、文件、数据库或者任何的数据源。QT中与数据模型相关的几个类的层次结构如下：</p><p>（注意，抽象类是无法直接使用的，因此需要子类去继承，来实现一些纯虚函数）</p><img src="/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/image-20201029145014621.png" alt="Model相关的类" style="zoom:80%;"><ol><li>QStringListModel：处理字符串列表数据类型的model类</li><li>QStandardItemModel：标准的基于item数据的model类，其中每个item可以是任意数据类型</li><li>QFileSystemModel：文件系统的model类</li><li>QSortFilterProxyModel：与其他数据模型结合，提供排序和过滤功能的model类</li><li>QSqlQueryModel：用于数据库SQL查询结果的model类</li><li>QSqlTableModel：用于数据库的一个数据表的model类</li><li>QSqlRelationalTableModel：关系型数据表的model类</li></ol><h2 id="2-视图-View"><a href="#2-视图-View" class="headerlink" title="2. 视图 View"></a>2. 视图 View</h2><img src="/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/image-20201029145441116.png" alt="View相关的类" style="zoom:80%;"><ol><li>QListView：用于显示单列的列表数据，适用于一维数据的操作</li><li>QTreeView：用于显示树状结构数据，适用于树状结构数据的操作</li><li>QTableView：用于显示表格状数据，适用于二维表格型数据的操作</li><li>QColumnView：用多个QListView显示树状层次结构，每一层用一个QListView显示</li><li>QHeaderView：提供行或列表头的视图组件，如QTableView的行表头和列表头</li></ol><img src="/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/image-20201029150229256.png" alt="数据表现形式" style="zoom:80%;"><h2 id="3-代理-Delegate"><a href="#3-代理-Delegate" class="headerlink" title="3. 代理 Delegate"></a>3. 代理 Delegate</h2><p>代理的概念就是在View组件上为编辑数据提供编辑器，比如在表格组件中编辑一个单元格数据时，这个单元格可以设置为QLineEdit、QSpinBox、QComboBox等形式。</p><h2 id="4-其他概念"><a href="#4-其他概念" class="headerlink" title="4. 其他概念"></a>4. 其他概念</h2><h3 id="4-1-模型索引"><a href="#4-1-模型索引" class="headerlink" title="4.1 模型索引"></a>4.1 模型索引</h3><p>为了整数据的表示和存取隔离，在数据模型中引入了模型索引的概念，通过数据模型存取的每个数据都有一个模型索引，视图组件和代理都通过模型索引来获取数据。</p><p>QModelIndex为表示模型索引的类。提供数据存取的一个临时指针，用于通过数据模型提取或修改数据。由于模型内部组织数据的结构随时可能变化，因此<strong>模型索引是临时的</strong>。如果需要使用持久性的模型索引，则需要使用QPersistentModelIndex类。</p><pre><code class="c++">QModelIndex index1 = model-&gt;index(0, 0, QModelIndex()); // 顶层节点用QModelIndex()来表示QModelIndex index2 = model-&gt;index(1, 1, index1);</code></pre><h1 id="QFileSystemModel"><a href="#QFileSystemModel" class="headerlink" title="QFileSystemModel"></a>QFileSystemModel</h1><p>这是一个用来访问本机文件系统的数据模型，可以用来创建目录、删除目录、重命名目录，获取文件和文件夹的相关详细信息。</p><p>在UI界面中添加三种view，然后通过QFileSystemModel来实现：</p><pre><code class="c++">model = new QFileSystemModel(this);model-&gt;setRootPath(QDir::currentPath());ui-&gt;treeView-&gt;setModel(model);ui-&gt;listView-&gt;setModel(model);ui-&gt;tableView-&gt;setModel(model);connect(ui-&gt;treeView, SIGNAL(clicked(QModelIndex)), ui-&gt;listView, SLOT(setRootIndex(QModelIndex)));connect(ui-&gt;treeView, SIGNAL(clicked(QModelIndex)), ui-&gt;tableView, SLOT(setRootIndex(QModelIndex)));</code></pre><img src="/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/image-20201029154033995.png" alt="QFileSystemModel" style="zoom:80%;"><h1 id="QStringListModel"><a href="#QStringListModel" class="headerlink" title="QStringListModel"></a>QStringListModel</h1><h2 id="1-初始化设置"><a href="#1-初始化设置" class="headerlink" title="1. 初始化设置"></a>1. 初始化设置</h2><p>用于处理字符串列表的数据模型，在界面上显示和编辑字符串列表。</p><pre><code class="c++">strList &lt;&lt; &quot;北京&quot; &lt;&lt; &quot;上海&quot; &lt;&lt; &quot;天津&quot; &lt;&lt; &quot;广州&quot; &lt;&lt; &quot;山东&quot; &lt;&lt; &quot;河南&quot; &lt;&lt; &quot;重庆&quot;;strModel = new QStringListModel(this);strModel-&gt;setStringList(strList);ui-&gt;listView-&gt;setModel(strModel);// 设置是否可以编辑以及编辑的条件ui-&gt;listView-&gt;setEditTriggers(QAbstractItemView::DoubleClicked | QAbstractItemView::SelectedClicked);ui-&gt;listView-&gt;setEditTriggers(QAbstractItemView::NoEditTriggers);</code></pre><img src="/2020/10/29/QT/4_%E6%A8%A1%E5%9E%8B%20%E8%A7%86%E5%9B%BE%E7%BB%93%E6%9E%84/image-20201029161644707.png" alt="QStringListModel测试" style="zoom:80%;"><h2 id="2-添加项"><a href="#2-添加项" class="headerlink" title="2. 添加项"></a>2. 添加项</h2><p>例如点击某个按钮会触发槽函数使得增加一项，则应当在model中先insert一行，并且设置data，总之是比较复杂的。</p><pre><code class="c++">void Widget::on_pushButton_clicked(){    strModel-&gt;insertRow(strModel-&gt;rowCount());    QModelIndex index = strModel-&gt;index(strModel-&gt;rowCount() - 1, 0);    strModel-&gt;setData(index, &quot;newItem&quot;, Qt::DisplayRole);    ui-&gt;listView-&gt;setCurrentIndex(index);}</code></pre><h2 id="3-删除项"><a href="#3-删除项" class="headerlink" title="3. 删除项"></a>3. 删除项</h2><p>删除项是通过index来删除的</p><pre><code class="c++">void Widget::on_pushButton_2_clicked(){    QModelIndex index = ui-&gt;listView-&gt;currentIndex();    strModel-&gt;removeRow(index.row()); // 这个函数的参数是一个数字}</code></pre><h1 id="QStandardItemModel"><a href="#QStandardItemModel" class="headerlink" title="QStandardItemModel"></a>QStandardItemModel</h1>]]></content>
      
      
      <categories>
          
          <category> 客户端 </category>
          
          <category> QT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【QT 2】控件</title>
      <link href="/2020/10/28/QT/3_%E6%8E%A7%E4%BB%B6/"/>
      <url>/2020/10/28/QT/3_%E6%8E%A7%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="控件"><a href="#控件" class="headerlink" title="控件"></a>控件</h1><h2 id="1-按钮"><a href="#1-按钮" class="headerlink" title="1. 按钮"></a>1. 按钮</h2><img src="/2020/10/28/QT/3_%E6%8E%A7%E4%BB%B6/image-20201028144401536.png" alt="按钮控件" style="zoom:80%;"><h3 id="1-1-Push-Button"><a href="#1-1-Push-Button" class="headerlink" title="1.1 Push Button"></a>1.1 Push Button</h3><p><strong>按钮</strong></p><h3 id="1-2-Tool-Button"><a href="#1-2-Tool-Button" class="headerlink" title="1.2 Tool Button"></a>1.2 Tool Button</h3><p><strong>工具按钮</strong></p><p>QToolButton类提供了用于命令或选项可以快速访问的按钮，通常可以用在QToolBar里面。</p><p>工具按钮和普通的命令按钮不同，通常不显示文本，而显示图标。</p><h3 id="1-3-Radio-Button"><a href="#1-3-Radio-Button" class="headerlink" title="1.3 Radio Button"></a>1.3 Radio Button</h3><p>单选按钮，默认所有的radio button互斥，如果想要让这些button按照组进行互斥，则需要通过buttonGroup操作</p><pre><code class="c++">QButtonGroup *bg = new QButtonGroup;bg-&gt;addButton(ui-&gt;radioButton);bg-&gt;addButton(ui-&gt;radioButton_2);QButtonGroup *bg1 = new QButtonGroup;bg1-&gt;addButton(ui-&gt;radioButton_3);bg1-&gt;addButton(ui-&gt;radioButton_4);</code></pre><img src="/2020/10/28/QT/3_%E6%8E%A7%E4%BB%B6/image-20201028155748534.png" alt="按钮效果" style="zoom:80%;"><h3 id="1-4-Check-Box"><a href="#1-4-Check-Box" class="headerlink" title="1.4 Check Box"></a>1.4 Check Box</h3><p>复选框</p><h3 id="1-5-Command-Link-Button"><a href="#1-5-Command-Link-Button" class="headerlink" title="1.5 Command Link Button"></a>1.5 Command Link Button</h3><p>命令链接按钮，这应该是一种特殊的push button，效果如图所示：</p><img src="/2020/10/28/QT/3_%E6%8E%A7%E4%BB%B6/image-20201028154759501.png" alt="command link button效果图" style="zoom:80%;"><h3 id="1-6-Dialog-Button-Box"><a href="#1-6-Dialog-Button-Box" class="headerlink" title="1.6 Dialog Button Box"></a>1.6 Dialog Button Box</h3><p>对话框按钮box，如果只是普通的OK和Cancel，则可以这样写：</p><pre><code class="c++">buttonBox1 = new QDialogButtonBox(QDialogButtonBox::Ok | QDialogButtonBox::Cancel, this);connect(buttonBox1, SIGNAL(accepted()), this, SLOT(button1()));connect(buttonBox1, SIGNAL(rejected()), this, SLOT(button2()));</code></pre><p>由于Dialog Button中还有很多其他的按钮形式，如果想要使用这些，则应该这样写：</p><p>（下面的例子是用Help按钮）</p><pre><code class="c++">buttonBox1 = new QDialogButtonBox(QDialogButtonBox::Ok | QDialogButtonBox::Help, this);connect(buttonBox1, SIGNAL(accepted()), this, SLOT(button1()));connect(buttonBox1-&gt;button(QDialogButtonBox::Help), SIGNAL(clicked()), this, SLOT(button2()));</code></pre><h2 id="2-输入部件"><a href="#2-输入部件" class="headerlink" title="2. 输入部件"></a>2. 输入部件</h2><h3 id="2-1-Combo-Box"><a href="#2-1-Combo-Box" class="headerlink" title="2.1 Combo Box"></a>2.1 Combo Box</h3><p>下拉菜单</p><h3 id="2-2-Font-Combo-Box"><a href="#2-2-Font-Combo-Box" class="headerlink" title="2.2 Font Combo Box"></a>2.2 Font Combo Box</h3><p>用来选字体的下拉菜单</p><h3 id="2-3-Line-Edit-Text-Edit-Plain-Text-Edit"><a href="#2-3-Line-Edit-Text-Edit-Plain-Text-Edit" class="headerlink" title="2.3 Line Edit / Text Edit / Plain Text Edit"></a>2.3 Line Edit / Text Edit / Plain Text Edit</h3><p>用于文本编辑，区别是一个是只有一行，一个是带样式的文本编辑，一个是单纯的文本编辑</p><h3 id="2-4-Spin-Box-Double-Spin-Box"><a href="#2-4-Spin-Box-Double-Spin-Box" class="headerlink" title="2.4 Spin Box / Double Spin Box"></a>2.4 Spin Box / Double Spin Box</h3><p>可增减的数字选择器，只不过一个是整数的，一个是浮点数的</p><h3 id="2-5-Time-Edit-Date-Edit"><a href="#2-5-Time-Edit-Date-Edit" class="headerlink" title="2.5 Time Edit / Date Edit"></a>2.5 Time Edit / Date Edit</h3><p>时间编辑器、日期编辑器、时间+日期编辑器</p><h3 id="2-6-Dial"><a href="#2-6-Dial" class="headerlink" title="2.6 Dial"></a>2.6 Dial</h3><p>拨盘</p><h3 id="2-7-Hotizontal-Vertival-Scroll-Bar"><a href="#2-7-Hotizontal-Vertival-Scroll-Bar" class="headerlink" title="2.7 Hotizontal / Vertival Scroll Bar"></a>2.7 Hotizontal / Vertival Scroll Bar</h3><p>垂直或水平的滚动条</p><h3 id="2-8-Horizontal-Vertival-Slider"><a href="#2-8-Horizontal-Vertival-Slider" class="headerlink" title="2.8 Horizontal / Vertival Slider"></a>2.8 Horizontal / Vertival Slider</h3><p>垂直或水平的调整条</p><h3 id="2-9-Key-Sequence-Edit"><a href="#2-9-Key-Sequence-Edit" class="headerlink" title="2.9 Key Sequence Edit"></a>2.9 Key Sequence Edit</h3><p>就是用来接收按键的，比如将输入焦点放到这个框内之后，再按键盘上的按键，就会将按键记录下来。</p><h2 id="3-显示控件"><a href="#3-显示控件" class="headerlink" title="3. 显示控件"></a>3. 显示控件</h2><h3 id="3-1-Label"><a href="#3-1-Label" class="headerlink" title="3.1 Label"></a>3.1 Label</h3><p>标签</p><h3 id="3-2-Text-Browser"><a href="#3-2-Text-Browser" class="headerlink" title="3.2 Text Browser"></a>3.2 Text Browser</h3><p>文本浏览器</p><h3 id="3-3-Graphics-View"><a href="#3-3-Graphics-View" class="headerlink" title="3.3 Graphics View"></a>3.3 Graphics View</h3><p>图形视图</p><h3 id="3-4-Calendar-Widget"><a href="#3-4-Calendar-Widget" class="headerlink" title="3.4 Calendar Widget"></a>3.4 Calendar Widget</h3><p>日历</p><h3 id="3-5-LCD-Number"><a href="#3-5-LCD-Number" class="headerlink" title="3.5 LCD Number"></a>3.5 LCD Number</h3><p>液晶数字</p><h3 id="3-6-Progress-Bar"><a href="#3-6-Progress-Bar" class="headerlink" title="3.6 Progress Bar"></a>3.6 Progress Bar</h3><p>进度条</p><h3 id="3-7-Horizontal-Vertical-Line"><a href="#3-7-Horizontal-Vertical-Line" class="headerlink" title="3.7 Horizontal / Vertical Line"></a>3.7 Horizontal / Vertical Line</h3><p>水平 / 垂直线</p><h3 id="3-8-OpenGL-Widget"><a href="#3-8-OpenGL-Widget" class="headerlink" title="3.8 OpenGL Widget"></a>3.8 OpenGL Widget</h3><p>OpenGL图形库工具</p><h3 id="3-9-QQuick-Widget"><a href="#3-9-QQuick-Widget" class="headerlink" title="3.9 QQuick Widget"></a>3.9 QQuick Widget</h3><p>嵌入式QML工具</p><h2 id="4-空间间隔组"><a href="#4-空间间隔组" class="headerlink" title="4. 空间间隔组"></a>4. 空间间隔组</h2><p>就是Spacers，有水平间隔组件和垂直间隔组件两种</p><h2 id="5-容器组"><a href="#5-容器组" class="headerlink" title="5. 容器组"></a>5. 容器组</h2><h3 id="5-1-Group-Box"><a href="#5-1-Group-Box" class="headerlink" title="5.1 Group Box"></a>5.1 Group Box</h3><p>组框</p><h3 id="5-2-Scroll-Area"><a href="#5-2-Scroll-Area" class="headerlink" title="5.2 Scroll Area"></a>5.2 Scroll Area</h3><p>滚动区域</p><h3 id="5-3-Tool-Box"><a href="#5-3-Tool-Box" class="headerlink" title="5.3 Tool Box"></a>5.3 Tool Box</h3><p>工具箱</p><h3 id="5-4-Tab-Widget"><a href="#5-4-Tab-Widget" class="headerlink" title="5.4 Tab Widget"></a>5.4 Tab Widget</h3><p>标签小部件</p><h3 id="5-5-Stacked-Widget"><a href="#5-5-Stacked-Widget" class="headerlink" title="5.5 Stacked Widget"></a>5.5 Stacked Widget</h3><p>堆叠部件</p><h3 id="5-6-Frame"><a href="#5-6-Frame" class="headerlink" title="5.6 Frame"></a>5.6 Frame</h3><p>帧</p><h3 id="5-7-Widget"><a href="#5-7-Widget" class="headerlink" title="5.7 Widget"></a>5.7 Widget</h3><p>小部件</p><h3 id="5-8-MDI-Area"><a href="#5-8-MDI-Area" class="headerlink" title="5.8 MDI Area"></a>5.8 MDI Area</h3><p>MDI区域</p><h3 id="5-9-Dock-Widget"><a href="#5-9-Dock-Widget" class="headerlink" title="5.9 Dock Widget"></a>5.9 Dock Widget</h3><p>停靠窗体部件</p><h3 id="5-10-QAxWidget"><a href="#5-10-QAxWidget" class="headerlink" title="5.10 QAxWidget"></a>5.10 QAxWidget</h3><p>封装flash的ActiveX控件</p><h2 id="6-项目视图组"><a href="#6-项目视图组" class="headerlink" title="6. 项目视图组"></a>6. 项目视图组</h2><h3 id="6-1-List-View"><a href="#6-1-List-View" class="headerlink" title="6.1 List View"></a>6.1 List View</h3><h3 id="6-2-Tree-View"><a href="#6-2-Tree-View" class="headerlink" title="6.2 Tree View"></a>6.2 Tree View</h3><h3 id="6-3-Table-View"><a href="#6-3-Table-View" class="headerlink" title="6.3 Table View"></a>6.3 Table View</h3><h3 id="6-4-Column-View"><a href="#6-4-Column-View" class="headerlink" title="6.4 Column View"></a>6.4 Column View</h3><h2 id="7-项目控件组"><a href="#7-项目控件组" class="headerlink" title="7. 项目控件组"></a>7. 项目控件组</h2><h3 id="7-1-List-Widget"><a href="#7-1-List-Widget" class="headerlink" title="7.1 List Widget"></a>7.1 List Widget</h3><p>清单控件</p><h3 id="7-2-Tree-Widget"><a href="#7-2-Tree-Widget" class="headerlink" title="7.2 Tree Widget"></a>7.2 Tree Widget</h3><p>树形控件</p><h3 id="7-3-Table-Widget"><a href="#7-3-Table-Widget" class="headerlink" title="7.3 Table Widget"></a>7.3 Table Widget</h3><p>表控件</p>]]></content>
      
      
      <categories>
          
          <category> 客户端 </category>
          
          <category> QT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【QT 1】布局管理</title>
      <link href="/2020/10/28/QT/2_%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/"/>
      <url>/2020/10/28/QT/2_%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="布局管理"><a href="#布局管理" class="headerlink" title="布局管理"></a>布局管理</h1><h2 id="0-布局管理器"><a href="#0-布局管理器" class="headerlink" title="0. 布局管理器"></a>0. 布局管理器</h2><p>在设计较为复杂的用户界面的时候，需要使用QT提供的布局管理器</p><pre><code class="c++">// 创建一个Grid网格布局管理对象，this指的是父窗口QGridLayout *mainLayout = new QGridLayout(this);mainLayout-&gt;addWidget(label1, 0, 0);mainLayout-&gt;addWidget(label1, 0, 1);mainLayout-&gt;addWidget(label1, 1, 0);mainLayout-&gt;addWidget(label1, 2, 0);// 将布局管理器添加到对应的窗口部件对象中setLayout(mainLayout);</code></pre><h2 id="1-分割窗口-QSplitter类"><a href="#1-分割窗口-QSplitter类" class="headerlink" title="1. 分割窗口 QSplitter类"></a>1. 分割窗口 QSplitter类</h2><p>该类可以用于灵活地分割窗口布局。</p><p>下面就是一个使用QSplitter进行窗口分割布局的一个例子，该例子的目的是生成一个左边1个输入框，右边2个输入框的结构。</p><img src="/2020/10/28/QT/2_%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/image-20201020165409481.png" alt="Splitter结构示意图" style="zoom:80%;"><ol><li>首先需要一个主分割窗口，即splitterMain</li><li>往splitterMain中放入左侧的输入框</li><li>由于右侧有两个widget，因此需要再分一下，这里就在里面加一个<strong>垂直的splitter</strong>，并且将该splitter的父窗口指定为splitterMain，这样，添加之后就可以直接将它作为新成分添加到splitterMain中了</li></ol><p>将这个设计思路转换成代码，即为：</p><pre><code class="c++">QSplitter *splitterMain = new QSplitter(Qt::Horizontal, nullptr);QTextEdit * textLeft = new QTextEdit(QObject::tr(&quot;Left Widget&quot;), splitterMain);textLeft-&gt;setAlignment(Qt::AlignCenter);    // 设置字体居中显示QSplitter *splitterRight = new QSplitter(Qt::Vertical, splitterMain);splitterRight-&gt;setOpaqueResize(false);      // 设定分隔条在拖拽时是否实时显示更新QTextEdit * textUp = new QTextEdit(QObject::tr(&quot;Top Widget&quot;), splitterRight);textUp-&gt;setAlignment(Qt::AlignCenter);      // 设置字体居中显示QTextEdit * textBottom = new QTextEdit(QObject::tr(&quot;Bottom Widget&quot;), splitterRight);textBottom-&gt;setAlignment(Qt::AlignCenter);  // 设置字体居中显示splitterMain-&gt;setStretchFactor(1,1);        // 设定可伸缩控件splitterMain-&gt;setWindowTitle(QObject::tr(&quot;Splitter&quot;));splitterMain-&gt;show();</code></pre><h3 id="1-1-setStretchFactor设置伸缩因子"><a href="#1-1-setStretchFactor设置伸缩因子" class="headerlink" title="1.1 setStretchFactor设置伸缩因子"></a>1.1 setStretchFactor设置伸缩因子</h3><p>这个函数有2个参数：</p><ol><li><p>第一个参数：子控件的索引值ID，这个ID号是根据加入的先后来算的，比如第一个加入的控件的ID为0，第二个加入的为1，等等。</p><p>这个函数可以理解为<strong>用来设置第i个控件的伸缩比</strong></p></li><li><p>第二个参数：伸缩系数</p><p>可以理解为伸缩比例，如果为0，则表示在放大窗口的时候不进行拉伸。为了验证这个参数的功能，这里在右侧控件中加入了一个mid控件，并且进行如下设置：</p><pre><code class="c++">splitterRight-&gt;setStretchFactor(0,1);splitterRight-&gt;setStretchFactor(1,2);splitterRight-&gt;setStretchFactor(2,3);</code></pre><p>这个设置的意思就是对于右侧的Splitter，第0个的伸缩比例为1，第1个的伸缩比例为2，第2个的伸缩比例为3，这样就会出现下面的效果，也就是进行拉伸的话，会使得拉伸的比例为设置的值。</p><img src="/2020/10/28/QT/2_%E5%B8%83%E5%B1%80%E7%AE%A1%E7%90%86/image-20201020172446854.png" alt="伸缩系数的作用" style="zoom:80%;"></li></ol><h2 id="2-停靠窗口-QDockWidget类"><a href="#2-停靠窗口-QDockWidget类" class="headerlink" title="2. 停靠窗口 QDockWidget类"></a>2. 停靠窗口 QDockWidget类</h2><h2 id="3-堆栈窗口-QStackedWidget类"><a href="#3-堆栈窗口-QStackedWidget类" class="headerlink" title="3. 堆栈窗口 QStackedWidget类"></a>3. 堆栈窗口 QStackedWidget类</h2><h2 id="4-基本布局-Layouts系列"><a href="#4-基本布局-Layouts系列" class="headerlink" title="4. 基本布局 Layouts系列"></a>4. 基本布局 Layouts系列</h2><h3 id="4-1-QGridLayout"><a href="#4-1-QGridLayout" class="headerlink" title="4.1 QGridLayout"></a>4.1 QGridLayout</h3><h3 id="4-2-QVBoxLayout"><a href="#4-2-QVBoxLayout" class="headerlink" title="4.2 QVBoxLayout"></a>4.2 QVBoxLayout</h3><h3 id="4-3-QHBoxLayout"><a href="#4-3-QHBoxLayout" class="headerlink" title="4.3 QHBoxLayout"></a>4.3 QHBoxLayout</h3><h3 id><a href="#" class="headerlink" title></a></h3>]]></content>
      
      
      <categories>
          
          <category> 客户端 </category>
          
          <category> QT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【QT 4】QT界面编辑器</title>
      <link href="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/"/>
      <url>/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="QT界面编辑器"><a href="#QT界面编辑器" class="headerlink" title="QT界面编辑器"></a>QT界面编辑器</h1><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h2 id="操作内容"><a href="#操作内容" class="headerlink" title="操作内容"></a>操作内容</h2><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020153201068.png" alt="可操作的内容" style="zoom:80%;"><p>在上图中红框圈着的部分包含了以下几个部分：</p><ol><li>Edit Widgets：默认就是选的这个，表示对界面进行组件的添加或删除</li><li>Edit Signals / Slots：编辑信号与槽，这个是一种可视化的编辑机制，并不适合传递的双方不在同一个类中的情况</li><li>Edit Buddies：指的是一个Label与一个组件相关联</li><li>Edit Tab Order：编辑按下tab键之后，<strong>输入焦点</strong>的变化顺序，比如输入完用户名之后按tab自动到输入密码的输入框中。像Label这种不能输入的就不需要编辑tab顺序</li><li>布局管理</li></ol><p>在ui文件中，界面上的文字设置内容将会被独立称为一个函数如下：</p><pre><code class="c++">void retranslateUi(QWidget *Widget){    Widget-&gt;setWindowTitle(QCoreApplication::translate(&quot;Widget&quot;, &quot;Widget&quot;, nullptr));    pushButton-&gt;setText(QCoreApplication::translate(&quot;Widget&quot;, &quot;PushButton&quot;, nullptr));} // retranslateUi</code></pre><h3 id="1-编辑组件"><a href="#1-编辑组件" class="headerlink" title="1. 编辑组件"></a>1. 编辑组件</h3><h3 id="2-编辑信号-槽"><a href="#2-编辑信号-槽" class="headerlink" title="2. 编辑信号/槽"></a>2. 编辑信号/槽</h3><p>是用一种可视化的方式进行信号与槽的编辑，例如下面这个例子，点击button12，触发treewidget的expandAll操作。</p><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020154735874.png" alt="可视化配置信号与槽" style="zoom:80%;"><p>可以看生成的ui文件中对信号与槽的定义如下：</p><pre><code class="c++">QObject::connect(pushButton_12, SIGNAL(clicked()), treeWidget, SLOT(expandAll()));QMetaObject::connectSlotsByName(Widget);</code></pre><h3 id="3-伙伴关系"><a href="#3-伙伴关系" class="headerlink" title="3. 伙伴关系"></a>3. 伙伴关系</h3><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020153849925.png" alt="伙伴模式" style="zoom:80%;"><p>伙伴模式指的是<strong>将Label与一个组件相关联</strong>。比如，上面这张图中，将label与输入框建立伙伴关系，并且设置lable为 <code>&amp;name</code> 此时显示出来的仍然是name，但是可以进行快捷键操作，在这里就是使用键盘的 Alt + n 可以<strong>快速将焦点切换到输入框内</strong>。</p><h3 id="4-编辑tab顺序"><a href="#4-编辑tab顺序" class="headerlink" title="4. 编辑tab顺序"></a>4. 编辑tab顺序</h3><p>编辑tab顺序可直接在界面编辑器上面进行编辑，例如，将下面的界面进行编辑tab顺序之后，界面上显示的状态如下：</p><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020154526040.png" alt="tab切换焦点顺序" style="zoom:80%;"><p>可以去ui_widgets.h中看一下具体实现，可以发现用代码来实现的话，如下所示：</p><pre><code class="c++">QWidget::setTabOrder(lineEdit, pushButton_3);QWidget::setTabOrder(pushButton_3, pushButton_2);QWidget::setTabOrder(pushButton_2, pushButton_14);QWidget::setTabOrder(pushButton_14, pushButton_13);QWidget::setTabOrder(pushButton_13, pushButton_10);QWidget::setTabOrder(pushButton_10, pushButton_11);QWidget::setTabOrder(pushButton_11, pushButton_12);QWidget::setTabOrder(pushButton_12, pushButton_9);QWidget::setTabOrder(pushButton_9, pushButton_8);QWidget::setTabOrder(pushButton_8, treeWidget);QWidget::setTabOrder(treeWidget, pushButton);QWidget::setTabOrder(pushButton, pushButton_5);QWidget::setTabOrder(pushButton_5, pushButton_4);QWidget::setTabOrder(pushButton_4, pushButton_6);QWidget::setTabOrder(pushButton_6, pushButton_7);</code></pre><h3 id="5-布局管理"><a href="#5-布局管理" class="headerlink" title="5. 布局管理"></a>5. 布局管理</h3><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020151202099.png" alt="布局管理方式" style="zoom:80%;"><p>有 Layouts 和 Spacers 两种组件布局管理方式。使用的时候，先将Layouts组件拖到窗口中，然后再将小的组件拖动到Layouts中。</p><ol><li><p><strong>Layouts</strong></p><ul><li><p><strong>Vertical Layout</strong>：垂直方向布局，组件自动在垂直方向上分布</p><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020152202944.png" alt="Vertical Layout显示样式" style="zoom:80%;"></li><li><p><strong>Horizontal Layout</strong>：水平方向布局，组件自动在水平方向上分布</p><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020152121500.png" alt="Horizontal Layout显示样式" style="zoom:80%;"></li><li><p><strong>Grid Layout</strong>：网格状布局，网格布局的大小改变时，每个小网格的大小都改变</p><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020151957432.png" alt="Grid Layout显示样式" style="zoom:80%;"></li><li><p><strong>Form Layout</strong>：窗体模具，与网格状布局类似，<strong>只有最右侧的一列网格会变化大小</strong>，并且<strong>只可以显示出2列</strong></p><img src="/2020/10/20/QT/QT%E7%95%8C%E9%9D%A2%E7%BC%96%E8%BE%91%E5%99%A8/image-20201020151909063.png" alt="Form Layout显示样式" style="zoom:80%;"></li></ul></li><li><p><strong>Spacers</strong></p><ul><li><strong>Horizontal Spacer</strong>：一个用于水平分隔的空格</li><li><strong>Vertical Spacer</strong>：一个用于垂直分隔的空格</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 客户端 </category>
          
          <category> QT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> QT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【笔记】Spring总结</title>
      <link href="/2020/06/01/%E7%AC%94%E8%AE%B0/spring/"/>
      <url>/2020/06/01/%E7%AC%94%E8%AE%B0/spring/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="简述Spring"><a href="#简述Spring" class="headerlink" title="简述Spring"></a>简述Spring</h1><p>spring框架里面，最关键的两个机制，就是ioc（控制反转）和aop（面向切面编程），Spring使用IOC来降低程序代码之间的耦合度，并且通过AOP来简化大量的重复开发工作。</p><blockquote><p>耦合指的是，在代码中通过new的方式直接创建某个类的对象。这个系统里，有几十个地方，都用到了这个类，此后一旦要把这个类换成其他的类，则需要把这几十个地方全部都修改，因此改动代码成本很大，改动完以后的测试的成本很大，并且过程可能很复杂，出现一些bug，此时就会很痛苦。</p><p>归根结底，代码里各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，重新测试，可能还会有bug。</p></blockquote><p>使用了 Spring IOC 框架，控制反转，依赖注入，可以将系统的类与类之间彻底的解耦合，将对象的创建权交给Spring容器去做。</p><p>主要的组成模块：</p><ul><li>Spring Core：核心类库，提供IOC服务</li><li>Spring Context：提供框架式的Bean访问方式，以及企业级功能</li><li>Spring AOP</li><li>Spring DAO</li><li>Spring MVC</li></ul><p>Spring的优点</p><ol><li>轻量级：基础版的Spring框架只有2MB</li><li>控制反转：Spring通过控制反转实现了松耦合，依赖被注入到对象，而不是使用new的方式创建对象</li><li>面向切面编程：把应用的业务逻辑与系统的服务分离开来</li><li>通过容器管理应用程序对象的配置和声明周期</li></ol><h1 id="Spring-Bean的原理"><a href="#Spring-Bean的原理" class="headerlink" title="Spring Bean的原理"></a>Spring Bean的原理</h1><p>SpringBean是构成Spring应用的核心，其中的对象由SpringIOC容器实例化、组装、管理</p><h2 id="1-Bean的五种作用域"><a href="#1-Bean的五种作用域" class="headerlink" title="1. Bean的五种作用域"></a>1. Bean的五种作用域</h2><ol><li>singleton：默认，每个容器中只有一个bean的实例。单例实现的原理：采用单例注册表的方式进行实现，而这个注册表的缓存是HashMap对象，如果配置文件中的配置信息不要求使用单例，Spring会采用新建实例的方式返回对象实例</li><li>prototype：一个Bean可以定义多个实例，每次要用bean的时候都会创建一个新的出来</li><li>request：为每一个网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收</li><li>session：与request范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效</li><li>globalSession：同一个全局HTTPSession定义一个Bean，仅适用于WebApplicationContext环境</li></ol><h2 id="2-Bean的生命周期"><a href="#2-Bean的生命周期" class="headerlink" title="2. Bean的生命周期"></a>2. Bean的生命周期</h2><p>如果要使用一个Bean对象，首先就要将它实例化出来，实例化bean之后需要看一下这个对象依赖了谁，去把它依赖的对象也创建出来，并且为其进行依赖注入，依赖注入的方法有构造方法注入，setter方法注入等。这一步完成之后去处理aware接口，这个aware接口的作用也就如同它的意思：感知，就是让Bean感知到自己在Spring容器中的属性，比如了实现BeanNameAware接口，可以让该Bean感知到自身的BeanName，另外还有BeanFactoryAware接口，BeanApplicationContextAware接口，他们都是把Spring容器自己传递给Bean。处理完aware接口之后，就是要进行初始化。spring预留了一些初始化之前和之后所做的操作，具体就是在BeanPostProcessor接口中实现的postProcessBeforeInitialization和postProcessAfterInitialization方法。在初始化之前先调用postProcessBeforeInitialization，然后调用配置文件中init-method设置的初始化方法，然后再去调用postProcessAfterInitialization方法，这样就算是彻底完成了一个bean的初始化。完成初始化之后，这个bean就可以在它的生命周期内一直被使用了，当销毁bean的时候，就是去回调Disposable接口的destroy方法，然后执行配置文件中destroy-method指定的方法，此后，bean就完成了整个生命周期。</p><h2 id="3-Spring框架中的单例Beans是线程安全的么"><a href="#3-Spring框架中的单例Beans是线程安全的么" class="headerlink" title="3. Spring框架中的单例Beans是线程安全的么"></a>3. Spring框架中的单例Beans是线程安全的么</h2><p>这个是需要看情况的：</p><p>要先引出作用域，spring bean默认singleton，多个线程并发访问这个实例，肯定是线程不安全的，如果是在这个单例的bean中放的是一些线程安全的bean，比如ConcurrentHashMap，其实多个线程访问也是并发安全的。或者这个bean中就没有放什么实例变量，只是一堆方法在调用，最后变成多个线程并发执行同一串单例对象的方法，最终去并发访问数据库去了，这样也是线程安全的。</p><h1 id="Spring处理并发问题（ThreadLocal）"><a href="#Spring处理并发问题（ThreadLocal）" class="headerlink" title="Spring处理并发问题（ThreadLocal）"></a>Spring处理并发问题（ThreadLocal）</h1><p>在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域，因为Spring对一些Bean中非线程安全状态采用ThreadLocal进行处理，解决线程安全问题。</p><p>ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。</p><ul><li>同步机制采用了“时间换空间”的方式，仅提供一份变量，不同的线程在访问前需要获取锁，没获得锁的线程则需要排队。</li><li>而ThreadLocal采用了“空间换时间”的方式。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。</li></ul><h1 id="IOC原理"><a href="#IOC原理" class="headerlink" title="IOC原理"></a>IOC原理</h1><p>底层的核心技术是反射，他会<strong>通过反射技术</strong>，根据指定类的全限定类名去自己构建对应的对象出来</p><h2 id="1-依赖注入的4种方式"><a href="#1-依赖注入的4种方式" class="headerlink" title="1. 依赖注入的4种方式"></a>1. 依赖注入的4种方式</h2><ol><li>基于注解注入</li><li>set注入</li><li>构造器注入</li><li>静态工厂注入：配置文件中，通过bean标签来注入，class写工厂的类，factory-method写工厂类中用于创建bean的方法</li></ol><h2 id="2-IOC容器的两种类型"><a href="#2-IOC容器的两种类型" class="headerlink" title="2. IOC容器的两种类型"></a>2. IOC容器的两种类型</h2><p><strong>IoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map（key，value）,Map 中存放的是各种对象。</strong></p><p>对于IOC来说，最重要的是容器，容器管理Bean的生命周期，容器分为：</p><ol><li>BeanFactory：就是一个HashMap，key是BeanName，value是Bean实例，通常只提供注册和获取两个功能</li><li>ApplicationContext：是BeanFactory的子类，它实现了多个接口，具备更多的功能</li></ol><p><strong>对比BeanFactory和ApplicationContext</strong></p><ol><li>BeanFactory采用延迟加载的形式来注入Bean，只有在用到某个Bean的时候，才会对该Bean进行加载实例化。这样的一个坏处是如果有一个Bean有问题，要在使用它的时候才能发现这个问题</li><li>ApplicationContext是在容器启动时，一次性创建所有的Bean，这样就可以直接发现哪些Bean的配置有问题，同时，在使用Bean的时候不需要等待，因为他们已经被创建好了，因此对比BeanFactory，ApplicationContext的不足在于占用内存空间，当配置的Bean较多时，启动较慢</li></ol><h2 id="3-Spring循环依赖"><a href="#3-Spring循环依赖" class="headerlink" title="3. Spring循环依赖"></a>3. Spring循环依赖</h2><p>Spring中有三种循环依赖的场景：</p><ol><li>构造器注入循环依赖：在A的构造方法中需要用到B的对象，在B的构造方法中又用到A的对象</li><li>setter方法单例的循环依赖：就是在A和B的setter方法中分别注入对方的对象</li><li>setter方法prototype的循环依赖：就是bean的作用域为prototype的对象，产生的循环依赖</li></ol><p>不能解决的情况： </p><ol><li>构造器注入循环依赖 </li><li><code>prototype</code> 注入循环依赖</li></ol><p>能解决的情况： </p><ol><li>setter方法注入单例的循环依赖</li></ol><p><strong>原理</strong></p><p>当获得对象的引用时，<strong>对象的属性是可以延后设置的</strong>。在循环依赖问题的解决过程中使用了“三级缓存”</p><ol><li>一级缓存：用于存放完全初始化好的 bean，<strong>从该缓存中取出的 bean 可以直接使用</strong></li><li>二级缓存：存放尚未填充属性的原始的 bean 对象</li><li>三级缓存：单例对象工厂的cache，存放 bean 工厂对象</li></ol><p><strong>步骤</strong></p><ol><li>先从一级缓存中获取</li><li>如果获取不到或者对象正在创建中，那就再从二级缓存中获取</li><li>如果还是获取不到，且允许从singletonFactory中通过getObject()获取。就从三级缓存singletonFactory.getObject()获取。<strong>（如果获取到了就从三级缓存中移除，并且放进二级缓存。其实也就是从三级缓存到了二级缓存）</strong></li></ol><p>创建bean实例之后，这个对象虽然还不完整，但是已经可以被认出来了，这样就可以直接把这个还没初始化完成的对象先拿去用</p><p>因为对象创建的时候，执行构造方法，会把自己曝光到singletonFactory中去，然而<strong>加入<code>singletonFactories</code>三级缓存的前提是执行了构造器，所以构造器的循环依赖没法解决</strong></p><h2 id="4-如果注入的属性为null，你会从哪几个方向去排查"><a href="#4-如果注入的属性为null，你会从哪几个方向去排查" class="headerlink" title="4. 如果注入的属性为null，你会从哪几个方向去排查"></a>4. 如果注入的属性为null，你会从哪几个方向去排查</h2><p>首先要看一下这个类是不是被Spring托管的类，如果这一点没有问题的话，就去查看配置文件是否有错误，比如说：springMVC 和 spring 是两个容器，如果加载配置文件在spring容器中，要给 springMVC 注入属性  会找不到配置文件</p><h1 id="AOP原理"><a href="#AOP原理" class="headerlink" title="AOP原理"></a>AOP原理</h1><p>在业务代码中，有一样的代码必须在很多个地方都出现，也就是必须重复很多次相同的东西，如果全部写在代码里面就比较麻烦并且不易维护，使用 AOP 可以做一个切面，给某些类<strong>生成代理</strong>，在不改变原有业务逻辑的情况下，增强横切逻辑代码，从根本上解耦合，避免横切逻辑代码重复。</p><h2 id="1-AOP中的几个名词"><a href="#1-AOP中的几个名词" class="headerlink" title="1. AOP中的几个名词"></a>1. AOP中的几个名词</h2><ul><li><p><strong>Joinpoint（连接点）</strong></p><p>连接业务和增强方法的点，比如在业务层接口中的所有接口，都是连接点。</p></li><li><p><strong>Pointcut（切入点）</strong></p><p><strong>被增强的方法叫做切入点</strong>，没有被增强的方法就不是切入点。</p></li><li><p><strong>Advice（通知/增强）</strong></p><p>拦截到Joinpoint之后要做的事情就是通知，也就是一些<strong>公共代码</strong>。通知的类型有5种：</p><p>调用切入点方法之前的叫做<strong>前置通知</strong>，之后的叫<strong>后置通知</strong>，catch里面的叫<strong>异常通知</strong>，finally里面的叫<strong>最终通知</strong>。整个invoke方法在执行就是<strong>环绕通知</strong>。在环绕通知中，有明确地切入点方法调用。</p></li><li><p><strong>Introduction（引介）</strong></p><p>是一种特殊的通知，在不修改代码的前提下，Introduction可以在运行期为类动态地添加一些方法或者字段</p></li><li><p><strong>Aspect（切面）</strong></p><p>是切入点和通知（引介）的结合就叫做切面</p></li><li><p><strong>Target（目标对象）</strong></p><p>代理的目标对象，即被代理对象。例如例子中的accountService</p></li><li><p><strong>Weaving（织入）</strong></p><p>把通知应用到目标对象来创建新的代理对象的过程。也就是加入事务的过程叫做织入。</p><p>spring采用动态代理织入，AspectJ采用编译器织入和类装载期织入</p></li><li><p><strong>Proxy（代理）</strong></p><p>一个类被AOP织入增强后，就产生一个结果代理类。target是被代理对象，proxy是代理对象</p></li></ul><h2 id="2-五种通知方式"><a href="#2-五种通知方式" class="headerlink" title="2. 五种通知方式"></a>2. 五种通知方式</h2><ol><li><strong>前置通知</strong>：在某连接点（join point）之前执行的通知，但这个通知不能阻止连接点前的执行（除非它抛出一个异常）。</li><li><strong>后置通知</strong>：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。 </li><li><strong>异常通知</strong>：在方法抛出异常退出时执行的通知。 </li><li><strong>最终通知</strong>：在某连接点（join point）正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回。 </li><li><strong>环绕通知</strong>：包围一个连接点（join point）的通知，如方法调用。这是最强大的一种通知类型。 环绕通知可以在方法调用前后完成自定义的行为。它也会选择是否继续执行连接点或直接返回它们自己的返回值或抛出异常来结束执行。 环绕通知是最常用的一种通知类型。大部分基于拦截的AOP框架，例如Nanning和JBoss4，都只提供环绕通知。 </li></ol><h2 id="3-AOP原理"><a href="#3-AOP原理" class="headerlink" title="3. AOP原理"></a>3. AOP原理</h2><p>AOP实现的关键在于<strong>代理设计模式</strong>，AOP代理主要分为静态代理和动态代理，静态代理的代表是AspectJ，动态代理的代表是SpringAOP</p><ol><li><p><strong>静态代理</strong>：在编译阶段生成代理类，因此也称为编译时增强，他会<strong>在编译阶段将切面织入到java字节码中</strong>，运行时就是运行这个增强后的AOP对象</p></li><li><p><strong>动态代理</strong>：其实就是动态的创建一个代理类出来，并且创建这个代理类的实例对象。所有的方法调用，都是走代理类的对象，他负责做一些代码上的增强，并且调用自己写的那个类。</p><p>SpringAOP的动态代理主要有两种方式：JDK动态代理和CGLIB动态代理</p><ul><li><p><strong>JDK动态代理</strong>：如果你的类是实现了InvocationHandler接口的，那么SpringAOP会使用jdk动态代理。</p><p>需要实现invoke方法，通过invoke方法来反射调用自己类中的代码，将增强代码和业务逻辑编制在一起，接着Proxy利用InvocationHandler动态创建一个目标类的实例</p></li><li><p><strong>CGLIB动态代理</strong>：如果代理类没有实现InvocationHandler接口，那么SpringAOP会选择使用CGLIB来动态代理目标类。</p><p>他会生成你的类的一个子类，动态生成字节码，覆盖你的一些方法，并且在方法里加入增强的代码，这样调用方法实际上就是通过这个生成的子类对象来调用的。</p><p>CGLIB<strong>是通过继承的方式做的动态代理</strong>，因此如果某个类被标记为final，则它无法使用CGLIB进行动态代理</p></li></ul></li></ol><p>静态代理与动态代理的区别在于生成AOP代理对象的时机不同，相对来说静态代理方法具有更好的性能，但是AspectJ需要特定的编译器进行处理，而SpringAOP则无需特定的编译器处理</p><h1 id="Spring事务"><a href="#Spring事务" class="headerlink" title="Spring事务"></a>Spring事务</h1><p>事务就是：如果开启了一个事务，在这个事务里执行多条增删改的SQL语句，在这个过程中，如果任何一个SQL语句失败了，就会导致事务的回滚，把其他SQL做的数据更改都恢复回去</p><p>在一个事务里的SQL要么一起成功，要么一起失败，事务功能可以保证我们的数据一致，在业务逻辑组件中加入这个事务。</p><p><strong>Spring事务本质就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务的</strong>。真正的数据库层的事务提交和回滚时通过binlog 或者redo log来实现的</p><h2 id="1-Spring事务种类"><a href="#1-Spring事务种类" class="headerlink" title="1. Spring事务种类"></a>1. Spring事务种类</h2><p>要在Spring中开启事务，就是在需要开启事务的方法上面加一个 <code>@Transactional(propagation)</code> 注解，此时就spring会使用AOP思想，对你的这个方法在执行之前，织入开启事务的代码，执行完毕之后，织入回滚、提交事务的代码，然后根据你方法是否报错，来决定回滚还是提交事务</p><p>分为编程式事务管理和声明式事务管理两种方式</p><ol><li>编程式事务管理使用TransactionTemplate，需要在代码逻辑中掺杂事务管理的内容</li><li>声明式事务管理建立在AOP之上，其本质是通过AOP功能，对方法前后进行拦截，将事务处理的功能编织到拦截的方法中，也就是在目标方法开始之前加入一个事务，在执行完目标方法之后根据执行情况提交或回滚事务</li></ol><p>二者的区别：</p><ol><li>声明式事务的最大优点就是不需要在业务逻辑中掺杂事务管理的代码，只需要在配置文件中做相关的事务规则声明或者通过 <code>@Transactional</code> 注解的方式，便可以将事务规则应用到业务逻辑中</li><li>声明式事务管理要优先于编程式事务管理，这正是spring提倡的非侵入式开发方式，使业务代码不受污染，只需要加上注解就能获得完全的事务支持。唯一不足的地方，就是最细的粒度只能到达方法级别，无法做到像编程式事务那样作用到代码块级别</li></ol><h2 id="2-Spring事务传播行为"><a href="#2-Spring事务传播行为" class="headerlink" title="2. Spring事务传播行为"></a>2. Spring事务传播行为</h2><p>事务传播行为说的是，当多个事务同时存在时，spring如何处理这些事务的行为</p><p>REQUIRED就是大家都加入到一个事务里，REQUIRES_NEW 就是每人都创建一个事务，NESTED就是嵌套事务</p><ol><li><p><strong>PROPAGATION_REQUIRED</strong></p><p>（默认）如果当前没有事务就创建一个事务，如果当前存在事务，就加入该事务，是最常用的设置</p><p>也就是说只会创建一个事务。例如在下面的例子中，methodA调用了methodB，因为这两个方法都需要事务支持，B会加入到A的事务中</p><pre><code class="java">@Transactional(propagation=Propagation.REQUIRED)public void methodA() {    methodB();}@Transactional(propagation=Propagation.REQUIRED)public void methodB() {}</code></pre></li><li><p><strong>Propagation.SUPPORTS</strong></p><p>支持当前事务，如果当前存在事务，就加入，如果不存在事务，就以非事务的方式运行</p></li><li><p><strong>Propagation.MANDATORY</strong></p><p>支持当前事务，如果当前存在事务，就加入，如果不存在事务，就抛出异常</p></li><li><p><strong>Propagation.REQUIRES_NEW</strong></p><p>无论当前是否存在事务，都创建新事务</p></li><li><p><strong>Propagation.NOT_SUPPORTED</strong></p><p>以非事务的方式执行操作，如果当前存在事务，就把当前事务挂起</p></li><li><p><strong>Propagation.NEVER</strong></p><p>以非事务的方式执行，如果当前存在事务，就抛出异常</p></li><li><p><strong>Propagation.NESTED</strong></p><p>如果当前存在事务，就在嵌套事务内执行，如果当前没有事务，则按REQUIRED属性执行</p><p><strong>流程</strong>：</p><ul><li>开启一个事务</li><li><strong>设置一个回滚点，savepoint</strong></li><li>执行方法B里的一些代码</li><li><strong>如果方法B里抛出了异常，此时进行回滚，回滚到之前的savepoint</strong></li><li>执行方法A里的一些代码，doSomethingPost()</li><li>提交或者回滚事务</li></ul><p><strong>嵌套事务</strong>：外层的事务如果回滚，会导致内层的事务也回滚；但是内层的事务如果回滚，仅仅是回滚自己的代码</p></li></ol><h2 id="3-Spring事务隔离级别"><a href="#3-Spring事务隔离级别" class="headerlink" title="3. Spring事务隔离级别"></a>3. Spring事务隔离级别</h2><p>① ISOLATION_DEFAULT：这是个 PlatfromTransactionManager 默认的隔离级别，使用数据库默认的事务隔离级别。</p><p>② ISOLATION_READ_UNCOMMITTED：读未提交，允许另外一个事务可以看到这个事务未提交的数据。</p><p>③ ISOLATION_READ_COMMITTED：读已提交，保证一个事务修改的数据提交后才能被另一事务读取，而且能看到该事务对已有记录的更新。</p><p>④ ISOLATION_REPEATABLE_READ：可重复读，保证一个事务修改的数据提交后才能被另一事务读取，但是不能看到该事务对已有记录的更新。</p><p>⑤ ISOLATION_SERIALIZABLE：一个事务在执行的过程中完全看不到其他事务对数据库所做的更新。</p><h1 id="Spring-框架中都用到了哪些设计模式"><a href="#Spring-框架中都用到了哪些设计模式" class="headerlink" title="Spring 框架中都用到了哪些设计模式"></a>Spring 框架中都用到了哪些设计模式</h1><p>（1）工厂模式：对于Spring ioc而言，他自己就是一个大工厂，把所有的bean实例都放进spring容器中，当需要使用对象的时候通过工厂将对象从工厂中给拿出来。</p><p>（2）单例模式：Bean默认为单例模式，确保在运行期间一个类只有一个实例对象。</p><p>（3）代理模式：Spring的AOP功能用到了动态代理的设计模式，如果说你要对一些类的方法切入一些增强的代码，会创建一些动态代理的对象，让你对那些目标对象的访问，先经过动态代理对象，动态代理对象先做一些增强的代码，调用你的目标对象。</p><p>（4）模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。</p><p>（5）观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现–ApplicationListener。</p><h1 id="SpringMVC流程"><a href="#SpringMVC流程" class="headerlink" title="SpringMVC流程"></a>SpringMVC流程</h1><p>它的核心是一个servlet，将servlet注册到tomcat里面，</p><ol><li>tomcat的工作线程将用户的请求转交给springmvc框架的DispatcherServlet</li><li>DispatcherServlet查找标注了 <code>@Controller</code> 和 <code>@RestController</code> 注解的controller类，我们一般会给controller类和其中的具体方法上面加 <code>@RequestMapping</code> 注解，用来标注哪些方法用来处理哪些请求，此时根据类上面加的 <code>@RequestMapping</code> 注解找到对应的Controller，然后再根据这个Controller中方法上面的 <code>@RequestaMapping</code> 注解 ，定位到Controller中具体的方法。</li><li>DispatcherServlet会调用controller中的这个方法对消息进行处理</li><li>请求处理完成之后，Controller方法有一个返回值，会有两种不同的后续处理路线：<ol><li>如果Controller标注的是 <code>@Controller</code> 注解，则它是走jsp、模板技术。把前端页面放在后端的工程里面，Controller处理完成后返回一个页面模板的名字，spring mvc的框架使用模板技术，通过<strong>视图解析器</strong>对页面做一个渲染，并交给浏览器去显示</li><li>如果Controller标注的是 <code>@RestController</code> 注解，则是走前后端的分离，Controller处理完成之后返回一个json串，也就是说只返回前端所需要的json数据</li></ol></li></ol><p>如下面代码所示，到 /home 的请求会由 get() 方法来处理，而到 /home/index 的请求会由 index() 来处理。 </p><pre><code class="java">@RestController  @RequestMapping(&quot;/home&quot;)  public class IndexController {      @RequestMapping(&quot;/&quot;)      String get() {          //mapped to hostname:port/home/          return &quot;Hello from get&quot;;      }      @RequestMapping(&quot;/index&quot;)      String index() {          //mapped to hostname:port/home/index/          return &quot;Hello from index&quot;;      }  }  </code></pre><h2 id="1-Controller和-RestController的区别"><a href="#1-Controller和-RestController的区别" class="headerlink" title="1. @Controller和@RestController的区别"></a>1. @Controller和@RestController的区别</h2><p>如果只是使用@RestController注解Controller，则Controller中的方法<strong>无法返回jsp页面，或者html</strong>，返回的内容就是Return 里的内容。</p><p>如果需要返回到指定页面，则需要用 @Controller配合视图解析器InternalResourceViewResolver才行。</p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【笔记】数据库与MySQL</title>
      <link href="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><h2 id="1-java如何访问数据库"><a href="#1-java如何访问数据库" class="headerlink" title="1. java如何访问数据库"></a>1. java如何访问数据库</h2><p>java系统通过MySQL驱动与数据库建立网络连接，通过这个连接来执行SQL语句</p><h2 id="2-数据库连接池"><a href="#2-数据库连接池" class="headerlink" title="2. 数据库连接池"></a>2. 数据库连接池</h2><p>数据库连接池就是创建多个数据库的连接，这样不同的请求发过来就可以通过不同的连接来访问数据库，防止反复建立连接销毁连接导致的效率低下问题</p><h2 id="3-SQL执行流程"><a href="#3-SQL执行流程" class="headerlink" title="3. SQL执行流程"></a>3. SQL执行流程</h2><h3 id="3-1-查询语句"><a href="#3-1-查询语句" class="headerlink" title="3.1 查询语句"></a>3.1 查询语句</h3><p><strong>查询语句在SQL如何执行</strong></p><p>客户端通过连接器进行查询，先到缓存中查找是否存在结果，如果存在则直接返回查询结果，如果不存在，则进行数据库的查询操作，对SQL语句进行分析和优化之后，到存储引擎中执行查询。</p><ol><li><p><strong>建立连接</strong></p><p>客户端会与数据库通过连接器建立连接，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。由于建立连接和断开连接的过程复杂，会耗费较多的时间，因此通常都使用长连接</p></li><li><p><strong>查询缓存</strong></p><p>建立连接完成之后，首先会去查询缓存，如果在缓存中命中了数据，则可以直接将数据返回，节省时间。但是这个查询缓存虽然可以在多次查询相同数据时能够加速查询，但是也是有弊端的，因为缓存的失效非常频繁，<strong>只要对数据表有修改，这个缓存就会失效</strong>，因此如果是对于经常更新的表，是不太适合使用缓存的。在mysql8.0之后“指定使用缓存”这个功能就被取消了，也就是不能指定去查询缓存。</p></li><li><p><strong>分析器分析</strong></p><p>主要就是进行词法分析和语法分析，先根据词法分析看有没有输入错误的内容，然后根据语法分析看是否满足SQL的语法规则</p></li><li><p><strong>优化器优化</strong></p><p>优化器是在表里面有多个索引的时候，决定使用哪个索引，再比如如果有执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。</p></li><li><p><strong>执行器执行</strong></p><p>要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。</p></li></ol><p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611105026003.png" alt="查询的执行流程"></p><h3 id="3-2-更新语句"><a href="#3-2-更新语句" class="headerlink" title="3.2 更新语句"></a>3.2 更新语句</h3><p><strong>更新语句的执行过程</strong></p><p>简而言之，当有一条记录需要更新的时候，InnoDB 引擎就<strong>会先把记录写到 redo log里面，并更新内存</strong>，这个时候更新就算完成了。同时，InnoDB 引擎会<strong>在适当的时候，将这个操作记录更新到磁盘里面</strong>，而这个更新往往是在系统比较空闲的时候做。</p><p>InnoDB 的 redo log 是固定大小的，对于日志都是从头开始写，写到末尾就又回到开头循环写。</p><p>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失。</p><p>详细的步骤：</p><ol><li><p><strong>连接、分析、优化、执行</strong></p><p>首先还是通过一个数据库连接发送到MySQL上，经过分析器、优化器等环节，生成执行计划，接着由执行器负责计划的执行。</p></li><li><p><strong>获取数据</strong></p><p>执行器先找数据，如果数据本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</p></li><li><p><strong>执行操作</strong></p><p>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</p></li><li><p><strong>更新redo log（第一阶段）</strong></p><p>这个redo log的更新是一个<strong>二阶段提交</strong>的过程，引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。</p></li><li><p><strong>生成bin log并存盘</strong></p><p>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</p></li><li><p><strong>更新redo log（第二阶段）</strong></p><p>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</p></li></ol><h4 id="a-为什么redo-log的更新需要两阶段提交？"><a href="#a-为什么redo-log的更新需要两阶段提交？" class="headerlink" title="a. 为什么redo log的更新需要两阶段提交？"></a>a. 为什么redo log的更新需要两阶段提交？</h4><p>如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。</p><p>比如说先写bin log再写redo log，或者先写redo log再写bin log，都会有问题，都会导致通过bin log恢复和通过redo log恢复出来的数据不一致。</p><p>当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。</p><h4 id="b-redo-log和bin-log的区别："><a href="#b-redo-log和bin-log的区别：" class="headerlink" title="b. redo log和bin log的区别："></a>b. redo log和bin log的区别：</h4><ol><li>从作用的角度来考虑，redo log主要是用于</li><li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li><li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。</li><li>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li></ol><p><strong>事务</strong></p><p>对于事务而言，如果还没提交事务，MySQL就宕机了，此时Buffer Pool中的数据会全部丢失，写入Redo Log Buffer 中的Redo Log也会丢失，但是因为没有提交就宕机表示事务是执行失败了，他还没有更新磁盘，所以是不会有问题的</p><p>当提交事务的时候，会根据一定的策略将redo log buffer中的redo log内容刷入磁盘文件中。</p><p>这个策略有以下几种：</p><ol><li>提交事务的时候不会将redo log buffer中的数据刷到磁盘中的，此时可能提交事务了，但是mysql宕机，导致内存中的数据和redo log全部丢失。</li><li>提交事务的时候必须把redo log 从内存中刷入磁盘文件，换句话说，一旦事务提交成功，redolog就一定在磁盘文件里。此时就算buffer pool中更新过的数据没有刷到磁盘中，mysql也可以根据redo log 去恢复之前做过的修改</li><li>提交事务的时候，把redo log写入到磁盘文件对应的OS cache缓存中，而不是直接写入磁盘文件，可能1秒之后才会把OS cache中的数据写到磁盘文件中。这种情况下，可能宕机的时候redo log还在OS cache中没有刷到磁盘中，那么数据就会丢失。</li></ol><p>在提交事务的时候，同时也会写入binlog</p><p>对于binlog日志，有不同的刷盘策略，</p><ol><li>通过OS cache进行缓存，binlog先写入OS cache中，和redo log的刷新机制一样，如果在OS cache中就宕机，则其中的binlog就会丢失。</li><li>直接写入磁盘，这种情况下，提交事务之后，直接刷盘，即使机器宕机，也不会丢失binlog</li></ol><p>当把binlog写入磁盘文件之后，就会完成最终的事务提交，此时会把本次更新的binlog文件名称和这次更新的binlog日志在文件中的位置都写到redo log中，同时在redo log日志文件中写入一个commit标记。</p><p>完成了这些才算是真正完成了事务的提交。</p><h2 id="4-MySQL中的结构"><a href="#4-MySQL中的结构" class="headerlink" title="4. MySQL中的结构"></a>4. MySQL中的结构</h2><p>在执行更新数据的SQL语句的时候会用到buffer pool和redo log，还有一些相关的概念：</p><h3 id="4-1-缓冲池（Buffer-Pool）"><a href="#4-1-缓冲池（Buffer-Pool）" class="headerlink" title="4.1 缓冲池（Buffer Pool）"></a>4.1 缓冲池（Buffer Pool）</h3><p>缓冲池是Innodb中比较重要的组件，放在内存中，里面会缓存很多的数据，方便以后查询的时候，不必再去磁盘中查询了</p><h3 id="4-2-undo-Log"><a href="#4-2-undo-Log" class="headerlink" title="4.2 undo Log"></a>4.2 undo Log</h3><p>就是将更新前的值放进undo log文件中，可以使得更新的数据能够回滚</p><h3 id="4-3-redo-Log"><a href="#4-3-redo-Log" class="headerlink" title="4.3 redo Log"></a>4.3 redo Log</h3><p>防止在发生故障的时间点，尚有脏页未写入磁盘。在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。</p><p>redo log是一种偏向物理性质的重做日志，它里面记录的东西类似于：对某个数据页中的什么记录做了个什么修改</p><p>它是属于innodb存储引擎特有的一个东西</p><h3 id="4-4-bin-log"><a href="#4-4-bin-log" class="headerlink" title="4.4 bin log"></a>4.4 bin log</h3><p>用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。同时也可以用于数据库的基于时间点的还原。</p><p>binlog叫做归档日志，它里面存的是偏向于逻辑性的日志，例如：对那个表的id=几的一行数据做了更新操作，更新后的值是多少，并且binlog并不是innodb特有的，而是属于mysql的范畴</p><h1 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h1><h2 id="1-几种join"><a href="#1-几种join" class="headerlink" title="1. 几种join"></a>1. 几种join</h2><ol><li><p>left join</p><p>以表A为主，关联上表B的数据，最终的结果是：A表中的全部数据和B表中与A表重合的数据</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611094609665.png" alt="left join" style="zoom: 50%;"><pre><code class="mysql">SELECT &lt;select_list&gt;FROM Table_A ALEFT JOIN Table_B BON A.Key = B.Key</code></pre></li></ol><ol start="2"><li><p>right join</p><p>以表B为主，关联上表A的数据，最终的结果是：B表中的全部数据和B表中与A表重合的数据</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611094841686.png" alt="right join" style="zoom:50%;"><pre><code class="mysql">SELECT &lt;select_list&gt;FROM Table_A ARIGHT JOIN Table_B BON A.Key = B.Key</code></pre></li></ol><ol start="3"><li><p>inner join（join）</p><p>展示交集，没有关联的部分就不展示</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611094543524.png" alt="inner join（join）" style="zoom: 50%;"><pre><code class="mysql">SELECT &lt;select_list&gt; FROM Table_A AINNER JOIN Table_B BON A.Key = B.Key</code></pre></li></ol><ol start="4"><li><p>full outer join</p><p>求并集</p></li></ol>   <img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611094857756.png" alt="full outer join" style="zoom:50%;"><pre><code class="mysql">   SELECT &lt;select_list&gt;   FROM Table_A A   FULL OUTER JOIN Table_B B   ON A.Key = B.Key</code></pre><ol start="5"><li><p>left excluding join</p><p>相当于在left join的语句后面加一个where判断，将B为null的排除掉</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611095036831.png" alt="left excluding join" style="zoom:50%;"><pre><code class="mysql">SELECT &lt;select_list&gt; FROM Table_A ALEFT JOIN Table_B BON A.Key = B.KeyWHERE B.Key IS NULL</code></pre></li></ol><ol start="6"><li><p>right excluding join</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611095044933.png" alt="right excluding join" style="zoom:50%;"><pre><code class="mysql">SELECT &lt;select_list&gt;FROM Table_A ARIGHT JOIN Table_B BON A.Key = B.KeyWHERE A.Key IS NULL</code></pre></li></ol><ol start="7"><li><p>outer excluding join</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611095056551.png" alt="outer excluding join" style="zoom:50%;"><pre><code class="mysql">SELECT &lt;select_list&gt;FROM Table_A AFULL OUTER JOIN Table_B BON A.Key = B.KeyWHERE A.Key IS NULL OR B.Key IS NULL</code></pre></li></ol><h1 id="数据库三范式"><a href="#数据库三范式" class="headerlink" title="数据库三范式"></a>数据库三范式</h1><ul><li><p>1NF：数据库表中的任何属性都是原子性的，不可再分（<strong>字段不可分</strong>）</p></li><li><p>2NF：非主属性要与数据表中的任意候选键有完全依赖关系（<strong>非主键字段完全依赖于主键</strong>）</p><blockquote><p>候选键指的是具有成为主键的资质，但是并不是主键的键</p></blockquote></li><li><p>3NF ：对于任何非主属性都要与主属性有直接关系，不存在传递依赖（非主键要和主键有直接关系，<strong>不能传递依赖</strong>）</p></li></ul><p><strong>反范式</strong>：通过增加冗余，重复数据来提高数据库的读性能</p><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p>数据库的事务是指一组sql语句，在这组的sql操作中，要么全部执行成功，要么全部执行失败。</p><h2 id="1-事务的ACID特性"><a href="#1-事务的ACID特性" class="headerlink" title="1. 事务的ACID特性"></a>1. 事务的ACID特性</h2><ol><li><p><strong>原子性（Atomicity）</strong></p><p>事务被视为不可分割的最小单元，事务的所有操作要么全部成功提交，要么全部失败回滚，回滚可以通过回滚日志来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可</p><p>原子性基于日志的 <code>Redo/Undo</code> 机制实现</p></li><li><p><strong>一致性（Consistency）</strong></p><p>数据库在事务执行前后保持一致性状态，所有事务对一个数据的读取结果都是相同的</p></li><li><p><strong>隔离性（Isolation）</strong></p><p>一个事务所做的修改在最终提交之前对其他事务不可见</p></li><li><p><strong>持久性（Durability）</strong></p><p>一旦事务提交，其所做的修改会被永远保存在数据库中，即使系统发生崩溃，事务执行的结果也不会丢失，通过重做日志（RedoLog）来保证持久性</p></li></ol><h2 id="2-事务隔离级别与三大问题"><a href="#2-事务隔离级别与三大问题" class="headerlink" title="2. 事务隔离级别与三大问题"></a>2. 事务隔离级别与三大问题</h2><h3 id="2-1-三大问题"><a href="#2-1-三大问题" class="headerlink" title="2.1 三大问题"></a>2.1 三大问题</h3><ol><li><strong>脏读</strong>：事务A读取到了事务B未提交的更改，如果B回滚，则A读到的数据都是不合法的</li><li><strong>不可重复读</strong>：事务A在事务B提交之前读取到的值与事务B提交之后读取到的值是不一样的</li><li><strong>幻读</strong>：事务A读取某个范围的数据之后，事务B在该范围之内增加了新数据，A再次读取该范围的数据会读取到之前没有的数据</li></ol><p>不可重复读和幻读的区别在于，不可重复读是读到的数据被修改，幻读是读到了之前没有的数据，因此需要在区间上也加锁，即只能使用Next-Key Locks 将区间锁上，解决幻读，而只锁记录是无法解决的。</p><h3 id="2-2-四大隔离级别"><a href="#2-2-四大隔离级别" class="headerlink" title="2.2 四大隔离级别"></a>2.2 四大隔离级别</h3><ol><li><p><strong>——读未提交——</strong></p><p>​            脏读</p></li><li><p><strong>——读已提交——</strong></p><p>​      不可重复读</p></li><li><p><strong>——可重复读——</strong></p><p>​           幻读</p></li><li><p><strong>——串行化——</strong>：就是不允许多个事务并发执行，同一个时间只能有一个事务正在执行</p></li></ol><p>在MySQL中，默认的隔离级别是RR（可重复读），但是MySQL的RR隔离级别和SQL语言规定的RR级别是不一样的，它<strong>可以避免幻读</strong>。</p><p>也就是说，<strong>在MySQL里面执行事务，默认情况下是不会发生脏读、不可重复读、幻读的问题的，并且事务的执行是并行的，大家不会互相影响。</strong></p><h2 id="3-隔离级别的实现"><a href="#3-隔离级别的实现" class="headerlink" title="3. 隔离级别的实现"></a>3. 隔离级别的实现</h2><ul><li>Read uncommitted的实现：每次读时都读最新的那个版本，并发问题最严重</li><li>Read committed的实现：避免脏写，在每次读取数据时都生成一个readview，readview其中存有创建当前结构的事务ID，活跃事务ID，然后从记录开始读每个undo log，如果某个undo log刚好是事务的创建ID或不在readview的活跃事务列表中就可以读，这样就避免了脏读。</li><li>Repeatable read的实现：在事务第一次读的时候生成readview，然后读记录，这样就能保证事务中两次读取的结果一样。</li><li>Serializable的实现：依赖mysql的锁</li></ul><h2 id="4-事务的启动方式"><a href="#4-事务的启动方式" class="headerlink" title="4. 事务的启动方式"></a>4. 事务的启动方式</h2><ol><li>显式启动事务语句，begin或者start transaction,提交commit，回滚rollback；</li><li>set autocommit=0，该命令会<strong>把这个线程的自动提交关掉</strong>。这样<strong>只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行commit或rollback或断开连接</strong>。</li></ol><h1 id="当前读与快照读"><a href="#当前读与快照读" class="headerlink" title="当前读与快照读"></a>当前读与快照读</h1><h2 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h2><p>InnoDB存储引擎，为了提高并发，使用MVCC机制。在并发事务时，通过读取数据行的历史数据版本，来提高并发的一种机制。当我们查询数据库某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，不能看到时间点之后事务提交更新的结果。</p><p><strong>快照读</strong>：读取的时快照数据，不加锁的简单SELECT就是快照读</p><p><strong>当前读</strong>：读取的时最新的数据，不是历史版本。加锁的SELECT，或者对数据进行增删改时，就需要进行当前读</p><h2 id="2-RR当前读、快照读的幻读解决"><a href="#2-RR当前读、快照读的幻读解决" class="headerlink" title="2. RR当前读、快照读的幻读解决"></a>2. RR当前读、快照读的幻读解决</h2><p>innodb的默认事务隔离级别是RR（可重复读）。</p><ul><li>对于<strong>RR隔离级别的快照读</strong>版本，它的实现技术是mvcc + undo log。基于版本的控制协议。该技术不仅可以保证innodb的可重复读，而且可以防止幻读。（这也就是是此前以rr隔离级别实践时，不仅可以防止可重复读，也防止了幻读）但是它防止的是快照读，也就是读取的数据虽然是一致的，但是数据是历史数据。</li><li>对于<strong>RR隔离级别的当前读</strong>版本，它是通过 MVCC + Next-key Lock来实现的，innodb提供了一个间隙锁的技术，<strong>即next－key，也就是结合grap锁与行锁，</strong>达到最终目的。</li></ul><h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><p>锁的粒度越小，并发度就越高，但是系统的开销就越大</p><h2 id="1-共享锁与排它锁"><a href="#1-共享锁与排它锁" class="headerlink" title="1. 共享锁与排它锁"></a>1. 共享锁与排它锁</h2><ul><li><strong>共享锁</strong>：称为S锁，对于锁定的资源，能够并行读，但是不能进行写操作；</li><li><strong>排它锁</strong>：称为X锁，假如当前写操作没有完成，那么它会阻断其它的写锁和读锁，即写加锁，其它读写都阻塞。</li></ul><h2 id="2-全局锁、表锁与行锁"><a href="#2-全局锁、表锁与行锁" class="headerlink" title="2. 全局锁、表锁与行锁"></a>2. 全局锁、表锁与行锁</h2><p>根据加锁的范围，分为三种不同的类型：</p><ul><li><p><strong>全局锁</strong></p><p>全局锁就是对整个数据库实例加锁</p><p>全局锁的典型使用场景是，做<strong>全库逻辑备份</strong>。也就是把整库每个表都 select 出来存成文本。</p></li><li><p><strong>行锁</strong></p><p>锁定当前数据行，事务A更新了一行，事务B也要更新这一行，则必须等待事务A进行commit或者rollback之后，事务B才可以执行。锁的粒度小，加锁慢，发生锁冲突的概率小，并发度高。</p><p>行锁也是MyISAM和InnoDB的区别之一，InnoDB支持行锁并且支持事务，myisam则不支持行锁</p></li><li><p><strong>表锁</strong></p><pre><code class="mysql">lock tables t1 read, t2 write;</code></pre><p>表锁则锁的粒度大，加锁快，开销小，但是锁冲突的概率大，并发度低。</p></li></ul><h2 id="3-意向锁"><a href="#3-意向锁" class="headerlink" title="3. 意向锁"></a>3. 意向锁</h2><p><strong>意向锁</strong>：给上一个级别的空间示意这里面是否加了锁</p><p>例如，给某一行的数据加上排它锁时，DB会给比行大一级的空间（如页 / 表）加上意向锁，告诉其他人这个页 / 表中已经有人上过排它锁了，不可以对整个表进行全局扫描。这样就避免了其他事务想给页 / 表加锁时去朱行扫描整个页 / 表。</p><h2 id="4-间隙锁-Gap-Lock、Next-Key-Lock"><a href="#4-间隙锁-Gap-Lock、Next-Key-Lock" class="headerlink" title="4. 间隙锁 (Gap Lock、Next-Key Lock)"></a>4. 间隙锁 (Gap Lock、Next-Key Lock)</h2><p>间隙锁则分为两种：<code>Gap Locks</code> 和 <code>Next-Key Locks</code>。</p><ul><li>Gap Locks会锁住两个索引之间的区间，比如 <code>select * from User where id&gt;3 and id&lt;5 for update</code>，就会在区间（3，5）之间加上Gap Locks。</li><li>Next-Key Locks是Gap Locks+Record Locks形成闭区间锁 <code>select * from User where id&gt;=3 and id=&lt;5 for update</code>，就会在区间[3,5]之间加上Next-Key Locks。</li></ul><h2 id="5-何时加锁"><a href="#5-何时加锁" class="headerlink" title="5. 何时加锁"></a>5. 何时加锁</h2><p>在数据库的增、删、改、查中，只有增、删、改才会加上排它锁，而只是查询并不会加锁，只能通过在select语句后显式加lock in share mode或者for update来加共享锁或者排它锁。</p><h2 id="6-死锁"><a href="#6-死锁" class="headerlink" title="6. 死锁"></a>6. 死锁</h2><p>死锁一般是事务相互持有对方的资源，并且等待对方资源，最后形成环路造成的。</p><p>比如下图中的A和B两个事务，A事务先修改id=1的数据，然后修改id=2的数据，B事务先修改id=2的数据，然后修改id=1的数据，这样A事务对id=1的数据加了锁，B事务对id=2的数据加了锁，这样A持有B需要的锁，B持有A需要的锁，就形成了死锁。</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200612225926121.png" alt="两个事务的执行流程" style="zoom:80%;"><h3 id="6-1-死锁的解决"><a href="#6-1-死锁的解决" class="headerlink" title="6.1 死锁的解决"></a>6.1 死锁的解决</h3><ol><li>直接等待，并且设置一个超时时间，但是如果设置的超时时间太短会导致误判，如果时间太长也不好。</li><li>进行死锁检测，如果发现死锁，就回滚其中一个事务，可以让另一个事务继续执行下去，但是这种方式会造成性能的额外开销。</li></ol><p>如果事务中需要锁多个行，要把<strong>最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放</strong>。</p><p>因此，就简要来说，减少死锁的主要方向，就是控制访问相同资源的并发事务量，尽量避免死锁，而不是去解决死锁。</p><h1 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h1><h2 id="0-乐观锁与悲观锁"><a href="#0-乐观锁与悲观锁" class="headerlink" title="0. 乐观锁与悲观锁"></a>0. 乐观锁与悲观锁</h2><ul><li><p><strong>悲观锁</strong>：指对数据被外界修改这一事件保持保守态度，认为总会有外界来修改数据。在整个数据处理过程中，将数据处于锁定状态，悲观锁的实现往往依靠数据库提供的锁机制</p></li><li><p><strong>乐观锁</strong>：认为数据一般情况下不会产生冲突，因此只会在数据进行提交更新的时候，才会对数据是否冲突进行检测，如果发现了冲突就返回错误信息，让用户决定如何去做</p></li></ul><p>最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。</p><p>MVCC是为了实现读-写冲突的不加锁，这里的读就是快照读，是一种乐观锁。</p><p>也就是说，如果在有人更新数据的时候，你要去读取这个数据，是没问题的，完全根据UndoLog，从版本链中找到一条可以读的数据，从而不需要加锁，避免频繁的加锁互斥。</p><h2 id="1-UndoLog回滚日志"><a href="#1-UndoLog回滚日志" class="headerlink" title="1. UndoLog回滚日志"></a>1. UndoLog回滚日志</h2><p>MVCC使用到的快照存储在UndoLog中，该日志通过回滚指针把一个数据行（Record）的所有快照都连接起来。</p><p>UndoLog存储在每个数据行尾部的隐藏列中，InnoDB在每行后面有隐藏列，其中<strong>和MVCC有关的两个列</strong>是：</p><ol start="2"><li><strong>trx_id（最近一次更新这条数据的事务ID）</strong>：就是最近一次更新这条数据的事务的ID</li><li><strong>rollback_ptr（回滚指针）</strong>：指向UndoLog信息，通过一个回滚指针把一个数据行的所有快照（历史版本）全部连接起来</li></ol><p>下面是关于undolog的更新方式</p><ul><li>插入：假设有一个事务A，它的ID是50，插入了一条数据，将这条数据的trx_id设置为当前的ID，并且由于是新插入的数据，因此rollback指针会指向一个空的undo log</li><li>更新：假设有另一个事务B，它的ID是51，来修改这个值，此时更新之前会生成一个undolog来记录之前的值，然后把数据更新，并且更改它的两个隐藏字段，让回滚指针指向历史版本的undolog</li></ul><p>也就是说，<strong>每一条数据都会通过它尾部隐藏的回滚指针字段将它的历史版本的undolog给串联起来</strong>。</p><h2 id="2-ReadView"><a href="#2-ReadView" class="headerlink" title="2. ReadView"></a>2. ReadView</h2><p>事务在<strong>第一次查询的时候，会创建一个ReadView</strong>，在这个ReadView中统计四个信息：创建这个ReadView的事务ID，活跃的事务ID，还有活跃事务中最大最小的事务ID</p><p>ReadView中维护了一批事务ID，包含四个部分：</p><ol><li>正在活跃的事务ID集合</li><li>活跃的事务中最大的事务ID</li><li>活跃的事务中最小的事务ID</li><li>创建这个ReadView的事务ID（也就是本事务ID）</li></ol><p>ReadView需要和undolog多版本链来配合使用，通过对比ReadView中的活跃事务ID与undolog中的trx_id的大小来确定记录是否可以被访问到。分为以下三种情况：</p><ol><li><p><strong>本行数据的trx_id(最后一次被修改的事务ID) &lt; 活跃的最小事务ID</strong></p><p>表示本行记录上一次被修改的时候当前活跃的这些事务还没开启呢，并且当前事务是比最小活跃事务的ID还要大的，也就是比，因此本行记录对于当前事务是可见的</p></li><li><p><strong>本行数据的trx_id(最后一次被修改的事务ID) &gt; 活跃的最大事务ID</strong></p><p>表示本行记录上一次被修改的时候，当前活跃的这些事务都已经开启了，因此为了保证RR，该行记录对本事务不可见，他需要去翻UndoLog，直到找到一个可见的版本</p></li><li><p><strong>本行数据的trx_id(最后一次被修改的事务ID) 介于最大与最小事务ID之间</strong></p><p>查找事务ID是否在活跃事务集合中，如果在，则表示本事务还在活跃，不可见，否则表示事务已经完成提交，可见</p></li></ol><h2 id="3-ReadView实现RC与RR"><a href="#3-ReadView实现RC与RR" class="headerlink" title="3. ReadView实现RC与RR"></a>3. ReadView实现RC与RR</h2><h3 id="3-1-RC"><a href="#3-1-RC" class="headerlink" title="3.1 RC"></a>3.1 RC</h3><p>RC隔离级别指的是，在事务的运行期间，只要别的事务修改数据并且提交了，就可以读取到人家修改的事务的。</p><p>实现RC就是通过ReadView来做的，在每次进行查询的时候都生成一个新的ReadView。</p><p>来分析一下流程吧，事务A在生成ReadView之后，去查询某个数据，这时候，如果这个数据恰好被另一个事务B修改过，并且这个事务B还没有结束，那么这个事务B就会存在于事务A的ReadView的活跃事务集合中，此时，即使事务A读取到了被事务B修改过的数据，也会因为这个数据的trx_id在ReadView中，从而会通过回滚指针查询历史版本的undolog。如果事务B执行完成，此时事务A又进行了一次查询，这时候重新生成了一个ReadView，只不过此时由于事务B已经完成，就不会出现在事务A的ReadView中了，这个数据对于事务A就是可见的，也就实现了读已提交</p><h3 id="3-2-RR"><a href="#3-2-RR" class="headerlink" title="3.2 RR"></a>3.2 RR</h3><p>RR隔离级别是，对于同一个事务，它去读取某个数据的时候，不会因为另一个事务的提交导致两次读取的结果不同。</p><p>RR也是通过ReadView来实现的，事务开启的时候创建一个ReadView，此后本事务的所有查询都会基于这个ReadView进行。</p><p>分析过程和上面其实差不太多，唯一一点不同的是，事务B在提交之后，虽然已经不活跃了，但是在事务A的ReadView中，依然是存在的，它始终被事务A当做是正在运行的状态，就不会去读取该事务修改的所有数据了。</p><p>还有一个需要关注的点是，MySQL的RR隔离级别是可以避免幻读的，它避免幻读分两种不同的场景，一种是当前读一种是快照读，对于快照读，可以使用MVCC来解决，而要避免当前读场景下的幻读，则需要通过Next-Key Lock，这个Lock是结合了行锁和间隙锁，可以把索引的间隙也锁起来，避免在区间内插入数据。这样就是用到了锁。</p><h2 id="4-MVCC的原理"><a href="#4-MVCC的原理" class="headerlink" title="4. MVCC的原理"></a>4. MVCC的原理</h2><p>在内部实现中，MVCC是通过 UndoLog + ReadView 进行数据读取的。</p><p><strong>具体的流程</strong>：</p><ol><li>先获取事务自己的ID（事务版本号）</li><li>获取ReadView</li><li>查询得到数据，然后与ReadView中的事务版本号进行对比</li><li>如果不符规则，则从UndoLog（回滚日志）中查询历史快照来找到符合规则的数据</li><li>返回符合规则的数据</li></ol><h1 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h1><h2 id="1-行锁的三种实现方式"><a href="#1-行锁的三种实现方式" class="headerlink" title="1. 行锁的三种实现方式"></a>1. 行锁的三种实现方式</h2><ol><li><p><strong>Record Locks（记录锁）</strong></p><p>锁定一个记录上的索引，而不是锁定记录本身，如果没有创建索引，就会自动在主键上创建聚集索引，因此它依然是可用的</p></li><li><p><strong>Gap Locks（间隙锁）</strong></p><p>锁定索引之间的间隔，不包含索引本身</p></li><li><p><strong>Next-Key Locks</strong></p><p>是上面两种锁的结合，既锁定索引本身，也锁定记录之间的间隔</p></li></ol><h2 id="2-对比InnoDB和MyISAM"><a href="#2-对比InnoDB和MyISAM" class="headerlink" title="2. 对比InnoDB和MyISAM"></a>2. 对比InnoDB和MyISAM</h2><p><strong>相同之处</strong>：</p><p>首先他们的底层数据结构都是B+树，在非叶子结点中不存储数据，所有的数据都存储在叶子节点上。</p><p><strong>不同之处</strong>：</p><p>其不同之处在于对事务的支持、外键约束的支持、以及对高并发的支持，此外，其存储数据的方式也是不一样的</p><ol><li><p>myisam</p><p>不支持事务，不支持外键约束。</p><p>在myisam存储引擎的索引中，<strong>每个叶子节点的data存放的是数据行的物理地址</strong>。进行数据查询时，先是索引文件里搜索，得到数据在文件里的定位，然后再去文件的指定位置获取到数据。</p><p>这样在内存里可以缓存更多的索引，对查询的性能会更好，适用于那种少量的插入，大量查询的场景。比如一次性批量导入，接下来一天之内就是纯查询的那种应用场景。</p></li><li><p>innodb</p><p>主要特点就是<strong>支持事务</strong>，支持外键约束，而且还可以进行分库分表、读写分离、主备切换</p><p><strong>强制要求有主键，其默认会根据主键创建一个索引，叫做聚集索引，同时它的数据文件本身也是通过这个聚集索引（主键）建立的</strong>。而myisam则不需要强制有主键</p><p>另外一点，innodb存储引擎下，如果对某个非主键的字段创建索引，那么该索引的<strong>叶子节点中存储的就是主键的值</strong>，然后再用主键的值到聚簇索引里查找到数据，即所谓的<strong>回表</strong>。</p><p>因此在一般innodb表里，一般都是用自增值作为主键的，因为这样可以使得更新聚簇索引时直接往里面加记录，如果用那种不是单调递增的主键值，在添加数据更新聚集索引时可能会导致b+树分裂后重新组织，会浪费时间。</p></li></ol><h1 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h1><p>数据库的索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加到内存中，只能注意加载每个磁盘页，因此要减少IO的次数，对于树来说，IO次数就是树的高度，而矮胖就是b树的特征之一，它的每个节点最多包含m个孩子，m为b树的阶，m的大小取决于磁盘页的大小</p><h2 id="1-B树"><a href="#1-B树" class="headerlink" title="1. B树"></a>1. B树</h2><p>树中的每个节点有n个key和n+1个指针构成，key左边的指针指向的节点中的key都小于当前的key，key右边的指针指向的节点中的key都大于当前的key</p><p>另外一点是，B树的data是存在树的节点中的，因此搜索可能在非叶子结点结束。要在B树中查找某个数据，先与根节点的关键字比较，选定下一步走哪一个子树，直到找到结果。</p><h2 id="2-B-树"><a href="#2-B-树" class="headerlink" title="2. B+树"></a>2. B+树</h2><p>B+树与B树是比较类似的，只不过有一点不同，就是非叶子节点不存储data，只用作索引，所有的data都在叶子节点，并且叶子节点构成一个链表，按照key的大小进行顺序连接。</p><p><strong>对于Innodb而言，叶子节点中存储的内容是聚集索引，也可以理解为数据行的物理地址</strong></p><p>它的数据文件是单独放一个文件的。</p><h2 id="3-对比B-树和B树"><a href="#3-对比B-树和B树" class="headerlink" title="3. 对比B+树和B树"></a>3. 对比B+树和B树</h2><ol><li><strong>B+树的磁盘读写代价更低</strong>：B+树内部节点不是数据节点，也没有指向关键字的具体指针，因此在磁盘中存储时，一个盘块就能存储更多的内部节点，使得B+树从磁盘中读写中间节点的IO读写次数更少</li><li><strong>B+树的查询比B树稳定</strong>：因为B树可能在查询的过程中就结束，而B+树一定会查询到叶子节点，使得每次查询的路径长度相同，效率相当。</li><li><strong>B+树的查询效率高</strong>：所有的数据都出现在叶子节点上，并且通过链表连接，因此，对于范围查询会更高效，而B树需要中序遍历才可以完成范围的查询</li></ol><h2 id="4-对比B-树和红黑树-平衡树"><a href="#4-对比B-树和红黑树-平衡树" class="headerlink" title="4. 对比B+树和红黑树/平衡树"></a>4. 对比B+树和红黑树/平衡树</h2><p>红黑树或者其他的平衡树也可以用来实现索引，但是文件系统和数据库中普遍使用B+树，原因是：</p><ol><li><strong>更少的查找次数</strong>：平衡树每个节点的出度为2，而B+树的出度可以很大，会使得B+树普遍比较矮胖，可以降低树的深度，也就是降低了查找的次数</li><li><strong>利用磁盘的预读特性</strong>：每次从磁盘中读取的时候，会读取固定大小的块，因此可能使得一次IO操作就完全载入一个节点，甚至可以预先载入其相邻的节点</li></ol><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p>数据库的索引类似于目录，可以用于快速进行特定值的定位和查找，是一种数据结构，以某种方式指向数据，可以进行高效查找</p><h2 id="1-索引的优劣势"><a href="#1-索引的优劣势" class="headerlink" title="1. 索引的优劣势"></a>1. 索引的优劣势</h2><p><strong>优势</strong>：</p><ul><li>提高数据的检索效率，降低数据库的IO成本</li><li>通过索引对数据排序，降低数据的排序成本，降低CPU的消耗</li></ul><p><strong>劣势</strong>：</p><ul><li>索引也是一张表，需要占用空间来保存主键与索引字段</li><li>虽然提高了查询效率，但是降低了更新速度，因为更新表的同时也需要更新索引</li></ul><p><strong>不适用索引的场景</strong>：</p><ul><li>数据的行数较少</li><li>数据的重复度很高（如男女性别）</li></ul><h2 id="2-索引的分类"><a href="#2-索引的分类" class="headerlink" title="2. 索引的分类"></a>2. 索引的分类</h2><ol><li><p>根据物理实现</p><ul><li><strong>聚集索引</strong>：每行数据是存在InnoDB聚集索引的叶子节点上的，因此InnoDB必须要有且只有一个聚集索引。数据的物理存储顺序与聚集索引的顺序相同</li><li><strong>非聚集索引</strong>：索引项顺序存储，但是索引项对应的内容是随机存储的</li></ul><p><strong>聚集索引一般是主键索引</strong>。可以将聚集索引比作字典中的按拼音查字，非聚集索引比作字典中的按偏旁查字，字在字典中的顺序和拼音的顺序一致，但是和偏旁没关系。</p></li><li><p>根据字段个数</p><ul><li><strong>单值索引</strong>：索引列为1列</li><li><strong>联合索引</strong>：索引值为多个列组合在一起创建的列，一般来说不是对一个一个的字段进行索引的，而是针对多个字段创建一个联合索引，<strong>联合索引在使用的时候需要遵循最左前缀原则</strong>。</li></ul></li><li><p>根据形式</p><ul><li><strong>普通索引</strong>：允许索引列中的值重复</li><li><strong>唯一索引</strong>：（满足UNIQUE）索引列的值必须唯一，允许有空值</li><li><strong>主键索引</strong>：（满足UNIQUE + NOT NULL）索引值必须唯一，并且不能为空</li><li><strong>全文索引</strong>：将存储在整个数据库中的任意信息查询出来</li></ul></li><li><p>根据稀疏程度</p><ul><li><strong>稀疏索引</strong>：对于排好序的记录，只针对某一些记录创建索引</li><li><strong>稠密索引</strong>：每一条记录都创建一个索引</li></ul></li></ol><h3 id="2-1-hash索引"><a href="#2-1-hash索引" class="headerlink" title="2.1 hash索引"></a>2.1 hash索引</h3><p>B+树对比hash索引</p><ul><li>哈希索引对于确定值的查询效率比B+树要高</li><li>哈希索引不能进行范围查询，因为哈希索引指向的数据是无序的</li><li>哈希索引无法进行模糊查询</li></ul><h3 id="2-2-聚集索引与普通索引"><a href="#2-2-聚集索引与普通索引" class="headerlink" title="2.2 聚集索引与普通索引"></a>2.2 聚集索引与普通索引</h3><p>每一个索引在 InnoDB 里面对应一棵 B+ 树。</p><p>假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。这个表的建表语句是：</p><pre><code class="mysql">create table T(    id int primary key,     k int not null,     name varchar(16),    index (k))engine=InnoDB;</code></pre><p>索引类型分为<strong>主键索引</strong>和<strong>非主键索引</strong>。</p><ul><li><p>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引</p></li><li><p>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611223118674.png" alt="非主键索引（普通索引）" style="zoom:80%;"></li></ul><p>如果使用主键查询方式，则只需要搜索 ID 这棵 B+ 树，如果是普通索引查询方式，则需要先搜索这棵普通索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为<strong>回表</strong>。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</p><h3 id="2-3-覆盖索引"><a href="#2-3-覆盖索引" class="headerlink" title="2.3 覆盖索引"></a>2.3 覆盖索引</h3><p>如果一个<strong>索引覆盖（包含）了所有需要查询的字段的值，这个索引就是覆盖索引</strong>。因为索引中已经包含了要查询的字段的值，因此查询的时候直接返回索引中的字段值就可以了，不需要再到表中查询，避免了回表，也就提高了查询的效率。</p><p>实现覆盖索引的方式可分为两种：</p><ol><li><p><strong>减少查询字段，只查询索引有的字段</strong></p><p>例如我们上面提到的使用limit查询，我们只查了id字段，这样几百万条数据就不会<strong>回表查询</strong>，外层查询时只有50条数据去聚集索引里进行了查询。又如上面的user表 优化sql为不查询name字段。</p></li><li><p><strong>修改表创建的索引，增加需要查询的字段</strong></p><p>如上面user表，把name也加到索引中，设置（name，code）两个字段的联合索引 。</p></li></ol><p><strong>覆盖索引的定义与注意事项</strong></p><p>要注意的是，不是所有类型的索引都可以成为覆盖索引的。因为覆盖索引必须要存储索引的列值，而哈希索引、空间索引和全文索引等都不存储索引列值，索引MySQL只能使用B-Tree索引做覆盖索引。</p><p>另外，当发起一个被索引覆盖的查询（索引覆盖查询）时，在explain（执行计划）的Extra列可以看到【Using Index】的信息。</p><h3 id="2-4-唯一索引和普通索引"><a href="#2-4-唯一索引和普通索引" class="headerlink" title="2.4 唯一索引和普通索引"></a>2.4 唯一索引和普通索引</h3><ol><li><p><strong>查询过程</strong></p><p>唯一索引和普通索引二者之间的差距就在于，唯一索引是唯一的，在数据库中只存在一条这样的记录，因此，通过唯一索引查到结果之后会立即将结果返回，而通过普通索引查到第一个结果之后，还会继续往后查询，直到查询到所有的结果为止。</p><p>但是这二者之间的查询效率的差异可以忽略不计，因为InnoDB是按照数据页为单位进行读写的，一个数据页中可能就有上千个key，因此二者之间的效率差异较小</p></li><li><p><strong>更新过程</strong></p><p>相关的一个概念是change buffer</p><blockquote><p><strong>change buffer</strong>：当需要更新一个数据页时：</p><ol><li>如果数据页在内存中就直接更新</li><li>如果数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。</li></ol><p>在下次查询需要访问这个数据页的时候，<strong>将数据页读入内存，然后执行change buffer中与这个页有关的操作</strong>，通过这种方式就能保证这个数据逻辑的正确性。</p><p>将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。</p></blockquote><p>将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611120429357.png" alt="有change buffer的更新操作" style="zoom:80%;"><p>唯一索引的更新就不能使用change buffer，因为对于唯一索引来说，<strong>所有的更新操作都要先判断这个操作是否违反唯一性约束</strong>。而<strong>必须要将数据页读入内存才能判断</strong>。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。</p><p>只有普通索引可以使用change buffer。</p><p><strong>change buffer用的是buffer pool里的内存</strong>，因此不能无限增大，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置，这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。</p><p>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一，change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p></li></ol><p><strong>change buffer 的适用场景</strong></p><ul><li>对于<strong>写多读少</strong>的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。</li><li>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。</li></ul><h3 id="2-5-前缀索引"><a href="#2-5-前缀索引" class="headerlink" title="2.5 前缀索引"></a>2.5 前缀索引</h3><p><strong>很长的字段，想做索引我们怎么去优化他呢？</strong></p><p>就是使用前缀索引，如果前缀区分度不大，可以做一个哈希，或者截取区分度较大的一部分子串作为索引</p><h2 id="3-最左前缀原则"><a href="#3-最左前缀原则" class="headerlink" title="3. 最左前缀原则"></a>3. 最左前缀原则</h2><p>对于一个联合索引，索引项是按照索引定义里面出现的字段顺序排序的。</p><p>因为可以支持最左前缀，所以<strong>当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了</strong>。如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611230109068.png" alt="最左前缀原则" style="zoom:80%;"><p>当你的逻辑需求是<strong>查到所有名字是“张三”的人</strong>时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。</p><p>如果你要查的是<strong>所有名字第一个字是“张”的人</strong>，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。</p><p>这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</p><p>因此需要考虑的是：<strong>在建立联合索引的时候，如何安排索引内的字段顺序</strong>？</p><ol><li>如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</li><li>空间原则，字段比较大的索引往往放在前面，避免建立冗余索引的时候占用过多的空间</li></ol><p>创建索引的时候一般都不是只对单个属性创建索引的，一般会使用联合索引，MySQL查询进行索引匹配时，会从左往右进行匹配，直到遇到范围查询就停下来，范围查询后面的键是用不到索引的。例如对于一个联合索引 <code>(a, b, c, d)</code>，某个查询为 <code>a = 1, b = 1, c &gt; 1, d = 1</code>，则a，b，c都可以走索引，但是d不能走索引，但是如果建立的索引是 <code>(a, b, d, c)</code>，则a，b，c，d都可以走索引。=的查询之间可以乱序，MySQL的查询优化器可以将索引优化成可以识别的形式。</p><p>注意，<strong>最左前缀原则是针对索引而言的</strong>，同样的字段，用不同的顺序创建索引，会导致不同的效率，而对于查询，则可以通过查询优化器将其优化为最佳的状态。</p><h2 id="4-索引下推"><a href="#4-索引下推" class="headerlink" title="4. 索引下推"></a>4. 索引下推</h2><p>在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。比如索引是name和age，有一个搜索是找name为某个值，age为某个值，ismale为某个值的数据，要走这个索引，如果没有下推优化，则会先根据name回一次表，然后根据age回一次表，如果有了索引下推优化，会在回表之前先判断一下索引中的另一个字段age是否满足要求，如果满足的话才进行回表，否则不回表，这样就减少了回表的次数。</p><p>对于下面这条SQL语句</p><pre><code class="mysql">select * from tuser where name like &#39;张%&#39; and age=10 and ismale=1;</code></pre><p>如果没有索引下推优化，则过程如下：</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611231536746.png" alt="索引下推（未优化）" style="zoom:80%;"><p>如果有索引下推，则过程如下：</p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611231555371.png" alt="索引下推（已优化）" style="zoom:80%;"><h1 id="MySQL优化"><a href="#MySQL优化" class="headerlink" title="MySQL优化"></a>MySQL优化</h1><h2 id="1-总体思路"><a href="#1-总体思路" class="headerlink" title="1. 总体思路"></a>1. 总体思路</h2><p>数据库的结构图：</p><p><img src="/2020/05/12/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93/image-20200611105026003.png" alt="查询流程"></p><p>客户端通过连接器进行查询，先到缓存中查找是否存在结果，如果存在则直接返回查询结果，如果不存在，则进行数据库的查询操作，查询操作主要分为4步：分析器、优化器、执行器、引擎。</p><p>所谓的优化就是在<strong>执行器</strong>之前的分析器、优化器部分进行优化的。一般在开发涉及SQL的业务都会去本地环境跑一遍SQL，用explain去看一下执行计划，看看分析的结果是否符合自己的预期，用没用到相关的索引，然后再去线上环境跑一下看看执行时间（这里只有查询语句，修改语句也无法在线上执行）。</p><p>在本地跑的时候需要注意把缓存关掉，不然跑出来的时间都很短，测不出来效果</p><h2 id="2-explain"><a href="#2-explain" class="headerlink" title="2. explain"></a>2. explain</h2><ul><li>table：哪个表</li><li>type：这个很重要，是说类型，all（全表扫描），const（读常量，最多一条记录匹配），eq_ref（走主键，一般就最多一条记录匹配），index（扫描全部索引），range（扫描部分索引）</li><li>possible_keys：显示可能使用的索引</li><li>key：实际使用的索引，索引<strong>也不一定就是走最优的，是可能走错的</strong>。可以使用 force index 强制走正确的索引，或者优化SQL，最后实在不行，可以新建索引，或者删掉错误的索引。</li><li>key_len：使用索引的长度</li><li>ref：联合索引的哪一列被用了</li><li>rows：一共扫描和返回了多少行，这个<strong>行数只是一个接近的数字，不是完全正确的</strong></li><li>extra：using filesort（需要额外进行排序），using temporary（mysql构建了临时表，比如排序的时候），using where（就是对索引扫出来的数据再次根据where来过滤出了结果）</li></ul><h2 id="1-索引优化"><a href="#1-索引优化" class="headerlink" title="1. 索引优化"></a>1. 索引优化</h2><ol><li><p>建立聚集索引：数据库的物理存储顺序是按照聚集索引顺序排列的，通过聚集索引的B+树，可以快速查找到任何一行的全部信息</p></li><li><p>长查询的数据建立索引或者组合索引</p></li><li><p>最左匹配原则：建立组合索引优化查询时，要考虑最左匹配原则，不然创建的索引就没有意义</p></li><li><p>较长的数据列建立前缀索引</p><blockquote><p>当索引是很长的字符序列时，这个索引将会很占内存，而且会很慢，这时候就会用到前缀索引了。所谓的前缀索引就是去索引的前面几个字母作为索引，但是要降低索引的重复率，索引我们还必须要判断前缀索引的重复率。</p></blockquote></li><li><p>不要建立无意义的索引：对于查询次数很少的语句中的字段索引，或者大字段的索引</p></li></ol><h2 id="2-查询优化"><a href="#2-查询优化" class="headerlink" title="2. 查询优化"></a>2. 查询优化</h2><ol><li><p><strong>使用Explain分析执行计划</strong></p><p>Explain用来分析SELECT查询语句，<strong>一般其实就是看SQL有没有走索引，走了哪些索引，扫描了多少行，有没有排序等等</strong>，</p></li><li><p><strong>优化数据访问</strong></p><ul><li><p>减少请求的数据量</p><p>只返回必要的列，最好不要使用select *</p><p>只返回必要的行，使用LIMIT语句来限制返回的数据</p><p>缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升会非常明显</p></li><li><p>减少服务器端扫描的行数</p><p>使用索引来覆盖查询</p></li></ul></li><li><p><strong>重构查询方式</strong></p><p>一个大查询如果一次性执行的话，可能会锁住很多的数据，这样就会阻塞住很多小的但是重要的查询，因此可以将一个大的查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处是：</p><p>让缓存更高效，对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用，而分解后的多个查询，即使其中一个表发生变化，对其他的查询缓存依然可以可以使用。分解成多个单表查询，这些单表查询的缓存可能会被其他的查询使用到，就可以减少冗余记录的查询</p></li></ol><h2 id="3-优化例子1"><a href="#3-优化例子1" class="headerlink" title="3. 优化例子1"></a>3. 优化例子1</h2><p>数据库使用的MySQL，有一个日志表，需要进行分页查询，于是很容易就想到了limit [offset偏移量] [count数量]这个查询方式,当我们偏移量比较小时,似乎是没什么问题</p><pre><code class="mysql">SELECT    * FROM    t_log WHERE    type = 1 LIMIT 5, 50查询时间:0.45s</code></pre><p>但是随着offset的增加,就出现了查询时间越来越长，但是每次查出的数据都只有50条，这就让我特别不理解</p><pre><code class="mysql">SELECT    * FROM    t_log WHERE    type = 1 LIMIT 500000, 50查询时间:57.252sSELECT    * FROM    t_log WHERE    type = 1 LIMIT 1000000, 50查询时间:89.15s</code></pre><p>查阅资料发现“limit”的工作方式是：</p><ol><li>先查询offset+count条数据；</li><li>再抛弃前offset条数据</li></ol><p>但是全字段查询肯定会有回表查询操作，这就导致了进行百万次的回表查询，速度肯定会很慢，于是我的解决思路是，在“第一步”时不进行回表查询，这样会不会效率提高很多，于是把sql改成下面的等效查询。</p><pre><code class="mysql">SELECT        *FROM        t_log t RIGHT JOIN (        SELECT uid        FROM t_log        WHERE type = 1        LIMIT 1000000,50    ) tmp ON tmp.uid = t.uid查询时间：0.64</code></pre><h2 id="4-优化例子2"><a href="#4-优化例子2" class="headerlink" title="4. 优化例子2"></a>4. 优化例子2</h2><p>SQL1:</p><pre><code class="mysql">select     brand from     index_basedata where     year = 2018 group by     day limit 5;</code></pre><p>使用了索引“year”, 则索引列为year，但是select brand from..中brand并不是索引列，就需要回表。</p><p>通过explain发现进行了table_scan，然后IndexLookUp进行了回表</p><p>SQL2:</p><pre><code class="mysql">select     brand from     index_basedata where     year = 2018 group by     year limit 5;</code></pre><p>使用了索引“year”, 则索引列为year，但是select brand from..中brand并不是索引列，就需要回表（通过图也可以看出，进行了tablescan,另外其中的IndexLookUp也说明了进行了回表），所以花费时间长.</p><p>另外，对于sql2中的group by使用的是索引列，所以使用的StreamAgg，不同于sql1</p><p>SQL3:</p><pre><code class="MYSQL">select     year from     index_basedata where     year = 2018 group by     year limit 5;</code></pre><p>没有tablescan，也没有使用IndexLookUp而是IndexReader说明直接从索引中读取索引列并使用。</p><p><strong>在上述案例中，sql3使用了索引列，没有进行回表，sql1与sql2进行了回表，所以花费时间长。所以说，发生严重的回表的时候，查询速度比不使用索引还慢。</strong></p><p>SQL1  2执行的时间（20s+）是SQL3（2s）的10倍以上</p><h1 id="分库分表（高并发层面数据库应该如何设计）"><a href="#分库分表（高并发层面数据库应该如何设计）" class="headerlink" title="分库分表（高并发层面数据库应该如何设计）"></a>分库分表（高并发层面数据库应该如何设计）</h1><p>分库分表是两个概念，可能只分库或者只分表。</p><p>如果说到高并发，肯定需要提到一点就是分库分表</p><h2 id="1-分库"><a href="#1-分库" class="headerlink" title="1. 分库"></a>1. 分库</h2><p><strong>单表数据量太大</strong>，会极大影响你的 sql <strong>执行的性能</strong>，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。</p><p>分表就是将同一个表中的记录拆分到多个结构相同的表中，然后查询的时候你就查一个表。</p><p>比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。</p><h2 id="2-分表"><a href="#2-分表" class="headerlink" title="2. 分表"></a>2. 分表</h2><p>将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。</p><h2 id="3-水平拆分与垂直拆分"><a href="#3-水平拆分与垂直拆分" class="headerlink" title="3. 水平拆分与垂直拆分"></a>3. 水平拆分与垂直拆分</h2><ul><li><strong>水平拆分</strong>的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。</li><li><strong>垂直拆分</strong>的意思，就是<strong>把一个有很多字段的表给拆分成多个表</strong>，<strong>或者是多个库上去</strong>。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会<strong>将较少的访问频率很高的字段放到一个表里去</strong>，然后<strong>将较多的访问频率很低的字段放到另外一个表里去</strong>。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。</li></ul><p><strong>水平切分的问题</strong></p><ul><li>分布式事务问题：使用分布式事务来解决</li><li>ID唯一性问题：使用全局唯一ID，为每一个分片指定一个ID范围，分布式ID生成器（如雪花算法）</li></ul><p><strong>分库分表的方式</strong></p><ul><li>一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如<strong>时间范围</strong>来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。</li><li>或者是按照某个字段 hash 一下均匀分散，这个较为常用。坏处在于说<strong>扩容起来比较麻烦</strong>，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。</li></ul><h1 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h1><p>就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。</p><h2 id="1-主从复制过程"><a href="#1-主从复制过程" class="headerlink" title="1. 主从复制过程"></a>1. 主从复制过程</h2><p>主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。</p><h2 id="2-主从同步延时问题"><a href="#2-主从同步延时问题" class="headerlink" title="2. 主从同步延时问题"></a>2. 主从同步延时问题</h2><p>这里有一个非常重要的一点，就是从库同步主库数据的过程是<strong>串行化</strong>的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，<strong>在高并发场景下，从库的数据一定会比主库慢一些，是有延时</strong>的。所以经常出现刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。</p><p>可以通过<strong>并行复制</strong>的机制来解决主从同步的延时问题。所谓<strong>并行复制</strong>，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后<strong>并行重放不同库的日志</strong>，这是库级别的并行。</p><h2 id="3-主库宕机问题"><a href="#3-主库宕机问题" class="headerlink" title="3. 主库宕机问题"></a>3. 主库宕机问题</h2><p>而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。</p><p>可以通过半同步复制来解决主库宕机的问题。这个所谓<strong>半同步复制</strong>，指的就是主库写入 binlog 日志之后，就会将<strong>强制</strong>此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到<strong>至少一个从库</strong>的 ack 之后才会认为写操作完成了。</p><h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><h2 id="1-char与varchar的区别"><a href="#1-char与varchar的区别" class="headerlink" title="1. char与varchar的区别"></a>1. char与varchar的区别</h2><ol><li><p>char的长度是固定的，varchar2的长度是可变的。</p><p>例如：要存储字符串”abc”，对于char(10)，表示存储的字符将占10个字节，其中有7个字节是空的，但依然需要占这个空间。varchar(10)，则只占用了3个字节的长度，10只是最大值，当存储的字符长度小于10时，会按照实际的长度存储</p></li><li><p>char的效率比varchar2的效率更高</p><p>varchar2比char更省空间，但是在效率上char会更高一些。</p></li></ol><h2 id="2-一行数据中的多个NULL字段在磁盘如何存储"><a href="#2-一行数据中的多个NULL字段在磁盘如何存储" class="headerlink" title="2. 一行数据中的多个NULL字段在磁盘如何存储"></a>2. 一行数据中的多个NULL字段在磁盘如何存储</h2><h1 id="热备份和冷备份"><a href="#热备份和冷备份" class="headerlink" title="热备份和冷备份"></a>热备份和冷备份</h1><ol><li><p><strong>冷备份</strong></p><p>冷备份发生在数据库已经关闭的情况下，当正常关闭时会提供一个完整的数据库，冷备份就是将关键性文件拷贝到另一个位置的一种说法。对于备份数据库信息而言，冷备份是最快最安全的一种方式</p><ul><li><strong>优点</strong>：<ol><li>快速，只需要拷贝文件</li><li>容易归档，只需要简单拷贝即可</li><li>容易恢复到某个时间节点上</li><li>能与归档的方式相结合，作为数据库最新状态的恢复</li><li>低度维护，高度安全</li></ol></li><li><strong>缺点</strong>：<ol><li>单独使用时，只能提供到某一个时间点上的恢复</li><li>在实施备份的全过程中，数据库必须用作备份，不能用于其他工作，也就是说，必须在关闭的情况下才可以冷备份</li><li>若磁盘的空间有限，只能拷贝到其他的存储设备上，速度会很慢</li></ol></li></ul></li><li><p><strong>热备份</strong></p><p>在数据库运行的情况下，备份数据库操作的SQL语句，当数据库发生问题时，可以重新执行一遍备份的SQL语句</p><ul><li><strong>优点</strong>：<ol><li>可以在已经有一个数据库的情况下备份，备份的时间短</li><li>备份的时候数据库依然可用</li><li>可以在秒级时间恢复到某个时间点</li><li>可以对几乎所有的数据库实体作恢复</li><li>恢复是快速的，在大多数情况下，在数据库仍工作时恢复</li></ol></li><li><strong>缺点</strong>：<ol><li>不能出错</li><li>如果热备份不成功，所得的结果不可以用于时间点的恢复</li><li>维护困难</li></ol></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【笔记】Redis</title>
      <link href="/2020/05/07/%E7%AC%94%E8%AE%B0/redis/"/>
      <url>/2020/05/07/%E7%AC%94%E8%AE%B0/redis/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h1><h2 id="1-为啥要使用缓存"><a href="#1-为啥要使用缓存" class="headerlink" title="1. 为啥要使用缓存"></a>1. 为啥要使用缓存</h2><p>用缓存，主要有两个用途：<strong>高性能</strong>、<strong>高并发</strong>。在我们的项目中主要是为了高性能，把一些复杂的查询结果放进缓存中，这样可以使得后面再进行相同查询的时候可以提高性能。</p><h2 id="2-用缓存的缺点"><a href="#2-用缓存的缺点" class="headerlink" title="2. 用缓存的缺点"></a>2. 用缓存的缺点</h2><ul><li>缓存与数据库双写不一致</li><li>缓存雪崩、缓存穿透</li><li>缓存并发竞争</li></ul><h1 id="Redis基础"><a href="#Redis基础" class="headerlink" title="Redis基础"></a>Redis基础</h1><h2 id="1-Redis的线程模型"><a href="#1-Redis的线程模型" class="headerlink" title="1. Redis的线程模型"></a>1. Redis的线程模型</h2><p>redis 内部使用<strong>文件事件处理器</strong>，因为这个<strong>文件事件处理器是单线程的，所以 redis 才叫做单线程的模型</strong>。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。</p><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p><img src="/2020/05/07/%E7%AC%94%E8%AE%B0/redis/image-20200603183858929.png" alt="Redis线程模型"></p><p>多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。</p><p>首先，redis 服务端进程初始化的时候，会将 server socket 的 <code>AE_READABLE</code> 事件与连接应答处理器关联。</p><p>客户端 socket01 向 redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 <code>AE_READABLE</code> 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给<strong>连接应答处理器</strong>。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 <code>AE_READABLE</code> 事件与命令请求处理器关联。</p><p>假设此时客户端发送了一个 <code>set key value</code> 请求，此时 redis 中的 socket01 会产生 <code>AE_READABLE</code> 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 <code>AE_READABLE</code> 事件，由于前面 socket01 的 <code>AE_READABLE</code> 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 <code>key value</code> 并在自己内存中完成 <code>key value</code> 的设置。操作完成后，它会将 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器关联。</p><p>如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 <code>AE_WRITABLE</code> 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 <code>ok</code>，之后解除 socket01 的 <code>AE_WRITABLE</code> 事件与命令回复处理器的关联。</p><h2 id="2-Redis与Memcached对比-为什么要使用Redis"><a href="#2-Redis与Memcached对比-为什么要使用Redis" class="headerlink" title="2. Redis与Memcached对比 / 为什么要使用Redis"></a>2. Redis与Memcached对比 / 为什么要使用Redis</h2><ol><li><p><strong>redis 支持复杂的数据结构</strong></p><p>redis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。</p></li><li><p><strong>redis 原生支持集群模式</strong></p><p>在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p></li><li><p><strong>性能对比</strong></p><p>由于 redis 只使用<strong>单核</strong>，而 memcached 可以使用<strong>多核</strong>，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。</p></li></ol><h2 id="3-为什么说Redis性能高"><a href="#3-为什么说Redis性能高" class="headerlink" title="3. 为什么说Redis性能高"></a>3. 为什么说Redis性能高</h2><ol><li>数据存储在内存中，避免从硬盘中读取数据。</li><li>数据结构是专门设计的，比如SDS结构中字符串长度len，压缩链表等</li><li>采用单线程，避免了不必要的上下文切换和竞争条件（这里的单线程是工作线程仅1个，但是会有其他的辅助线程，比如哨兵线程）</li><li>使用非阻塞的IO多路复用模型。</li><li>C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。</li></ol><h2 id="4-如何部署Redis"><a href="#4-如何部署Redis" class="headerlink" title="4. 如何部署Redis"></a>4. 如何部署Redis</h2><p>采用redis cluster的方式来部署，用到了10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，一共有 50g 内存。因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。</p><p>你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。</p><p>每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。</p><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="1-五大数据类型"><a href="#1-五大数据类型" class="headerlink" title="1. 五大数据类型"></a>1. 五大数据类型</h2><ol><li><p>string</p><p>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。</p><pre><code>set college szu</code></pre></li></ol><ol start="2"><li><p>hash</p><p>这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的<strong>某个字段</strong>。</p><pre><code>hset person name bingohset person age 20hset person id 1hget person nameperson = {    &quot;name&quot;: &quot;bingo&quot;,    &quot;age&quot;: 20,    &quot;id&quot;: 1}</code></pre></li></ol><ol start="3"><li><p>list</p><p>list 是有序列表，这个可以玩儿出很多花样。</p><p>比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p><p>比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。</p><p>比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。</p><pre><code># 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。lrange mylist 0 -1lpush mylist 1lpush mylist 2lpush mylist 3 4 5# 1rpop mylist</code></pre></li></ol><ol start="4"><li><p>set</p><p>set 是无序集合，自动去重。</p><p>直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。</p><p>可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。</p><p>把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。</p><pre><code>#-------操作一个set-------# 添加元素sadd mySet 1# 查看全部元素smembers mySet# 判断是否包含某个值sismember mySet 3# 删除某个/些元素srem mySet 1srem mySet 2 4# 查看元素个数scard mySet# 随机删除一个元素spop mySet#-------操作多个set-------# 将一个set的元素移动到另外一个setsmove yourSet mySet 2# 求两set的交集sinter yourSet mySet# 求两set的并集sunion yourSet mySet# 求在yourSet中而不在mySet中的元素sdiff yourSet mySet</code></pre></li></ol><ol start="5"><li><p>zset</p><p>sorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p><pre><code>zadd board 85 zhangsanzadd board 72 lisizadd board 96 wangwuzadd board 63 zhaoliu# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）zrevrange board 0 3# 获取某用户的排名zrank board zhaoliu</code></pre></li></ol><h2 id="2-简单动态字符串SDS与C语言的自带字符串"><a href="#2-简单动态字符串SDS与C语言的自带字符串" class="headerlink" title="2. 简单动态字符串SDS与C语言的自带字符串"></a>2. 简单动态字符串SDS与C语言的自带字符串</h2><ol><li>SDS有常熟复杂度获取字符串长度</li><li>避免缓冲区溢出</li><li>减少修改字符串的内存重新分配次数</li><li>二进制安全</li><li>兼容部分C字符串函数</li></ol><h2 id="3-字典的底层实现和hashTable的问题"><a href="#3-字典的底层实现和hashTable的问题" class="headerlink" title="3. 字典的底层实现和hashTable的问题"></a>3. 字典的底层实现和hashTable的问题</h2><ol><li>解决冲突：链地址法，与java的hashmap一样</li><li>扩容：复制出另一个hash表，重新计算hash值，进行渐进式hash，即扩容和收缩是分多次完成的，因为如果保存在Redis中的键值对数量很多，则一次性进行rehash必然会造成Redis在一段时间内不能执行别的操作，因此Redis采用渐进式rehash，这样在进行渐进式rehash期间，字典的删除查找更新操作可能会在2个哈希表上进行，第一个哈希表中没有找到，就去第二个哈希表中查找。但是进行增加操作时，一定是在新哈希表上进行的</li></ol><h2 id="4-压缩链表ziplist"><a href="#4-压缩链表ziplist" class="headerlink" title="4. 压缩链表ziplist"></a>4. 压缩链表ziplist</h2><p>ziplist是Redis为了节省内存而开发的，是一系列特殊编码的连续内存块组成的顺序性数据结构，一个压缩列表可以包含任意多个节点，每个节点可以保存一个字节数组或者一个整数值</p><h2 id="5-zset与跳表"><a href="#5-zset与跳表" class="headerlink" title="5. zset与跳表"></a>5. zset与跳表</h2><p>跳表本质就是多级链表，并且是有序的</p><p>跳表与平衡树、哈希表的比较：</p><ol><li>跳表和各种平衡树（AVL、红黑树）的元素是有序排列的，而哈希表不是有序排列的，因此在哈希表上只能做单个key的查找，不适宜做范围查找</li><li>在做范围查找的时候，平衡树比跳表的操作要复杂，在平衡树上，找到指定范围的最小值后，还需要中序遍历继续寻找不超过最大值的节点，而在跳表中，找到最小值之后，对第一层链表进行若干步的遍历就可以实现</li><li>平衡树的插入和删除操作可能会引起子树的调整，逻辑复杂，但是跳表的插入和删除只需要对相邻节点的指针进行修改，快速又简单</li><li>查找单个key，跳表和平衡树的时间复杂度都是O(logN)，大体相当，哈希表在保持较低的哈希冲突概率的前提下，查找时间复杂度接近O(1)，性能更高。</li><li>跳表的实现难度较低</li></ol><h1 id="Redis删除与淘汰"><a href="#Redis删除与淘汰" class="headerlink" title="Redis删除与淘汰"></a>Redis删除与淘汰</h1><p>通常情况下采用删除策略，如果删除策略不足以使得内存够用，则需要走缓存淘汰机制。</p><h2 id="1-过期策略"><a href="#1-过期策略" class="headerlink" title="1. 过期策略"></a>1. 过期策略</h2><ol><li><p><strong>定期删除</strong></p><p>Redis每隔100ms检查，是否有过期的key，如果有，则删除。这里不是对所有的key都检测，而是进行<strong>抽查</strong>，如果查到某个key已经过期，则将其删除，因此这样会导致很多key过期却不能被删除</p></li><li><p><strong>惰性删除</strong></p><p>获取某个key的时候，redis会检查一下，如果过期了就删除</p></li></ol><p>存在的问题是：如果定期删除漏掉了很多的key，并且也没有及时去获取key，从而导致大量的key堆积在内存中，最终导致redis内存耗尽，因此不能仅仅走删除策略，而需要通过缓存淘汰机制来解决这一问题。</p><h2 id="2-缓存淘汰机制"><a href="#2-缓存淘汰机制" class="headerlink" title="2. 缓存淘汰机制"></a>2. 缓存淘汰机制</h2><p>定义了当内存不足以容纳新写入的数据时，执行的操作。</p><p>LRU：<strong>距离上次使用的时间最久</strong></p><p>LFU：<strong>使用次数最少</strong></p><ol><li>noeviction：不操作，报错</li><li>allkeys-lru：在键空间中，移除最近最少使用的key</li><li>allkeys-random：在键空间中，随机移除某个key</li><li>allkeys-lfu：挑选最近使用次数最少的数据</li><li>volatile-lru：在设置了过期时间的键空间中，移除最近最少使用的key</li><li>volatile-random：在设置了过期时间的键空间中，随机移除一个key</li><li>volatile-lfu：在设置了过期时间的键空间中，挑选<strong>最近使用次数最少</strong>的数据淘汰</li><li>volatile-ttl：在设置了过期时间的键空间中，优先删除马上要过期的key</li></ol><h1 id="持久化机制（故障恢复）"><a href="#持久化机制（故障恢复）" class="headerlink" title="持久化机制（故障恢复）"></a>持久化机制（故障恢复）</h1><p>redis 要是挂了再重启，内存里的数据不就全丢了？能不能重启的时候把数据给恢复了？</p><p>Redis持久化的意义就是在于故障恢复。如果没有持久化，则一旦发生故障，再重启的时候，所有的数据都会丢失，就需要重新把数据写到redis里面，而采用了持久化，则损失会降低一些，在重启的时候会从硬盘中将数据再读取到内存中去，还是可以恢复一部分数据的。因此对于一个企业级的Redis，持久化是不可缺少的</p><h2 id="1-RDB"><a href="#1-RDB" class="headerlink" title="1. RDB"></a>1. RDB</h2><p>就是快照，做一次全量备份，定时生成内存数据的全量快照文件。（Redis会fork一个子进程，持久化操作交给子进程处理，父进程继续处理线上业务）</p><h2 id="2-AOF"><a href="#2-AOF" class="headerlink" title="2. AOF"></a>2. AOF</h2><p>AOF日志记录的是<strong>数据操作修改的指令</strong>，通过追加的方式将新的指令追加到AOF文件中，AOF随着时间的推移只会无限量增加。由于redis中存在缓存替换机制，某些数据会被逐出内存，但是这些数据还是写在AOF文件中的，就会造成空间的浪费。</p><h2 id="3-RDB-AOF"><a href="#3-RDB-AOF" class="headerlink" title="3. RDB+AOF"></a>3. RDB+AOF</h2><p>混合持久化，将RDB的文件和局部增量AOF相结合，RDB可以使用相隔较长的时间保存策略，AOF不是全量的日志，只保存前一次RDB存储开始到现在这段时间内增量AOF日志即可，一般来说这个增量是比较小的</p><h1 id="高并发与高可用"><a href="#高并发与高可用" class="headerlink" title="高并发与高可用"></a>高并发与高可用</h1><ul><li><p>高并发</p><p>缓存一般都是用来支撑<strong>读高并发</strong>的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的<strong>读请求全部走从节点</strong>。这样也可以很轻松实现<strong>水平扩容</strong>，<strong>支撑读高并发</strong>。</p></li><li><p>高可用</p><p>如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。</p></li></ul><h2 id="1-主从复制（高并发）"><a href="#1-主从复制（高并发）" class="headerlink" title="1. 主从复制（高并发）"></a>1. 主从复制（高并发）</h2><p><strong>作用</strong>：</p><p>读写分离（Master写，Slave读），提高服务器的读写负载能力</p><p>为了避免单点Redis服务器故障，需要准备多台服务器，相互连通，<strong>做成一个主从架构</strong>。同时，对数据进行冗余备份。</p><p>master 每次接收到写命令之后，先在内部写入数据，然后<strong>异步</strong>发送给 slave node。</p><p>如果采用了主从架构，那么建议必须<strong>开启</strong> master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，<strong>可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了</strong>。</p><p>另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能<strong>确保启动的时候，是有数据的</strong>，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。</p><p><strong>步骤</strong>：</p><p>当启动一个 slave node 的时候，它会发送一个请求同步的命令给 master node。</p><ul><li>如果这是 slave node 初次连接到 master node，那么会触发一次<strong>全量复制</strong>。此时 master 会启动一个后台线程，开始生成一份 <code>RDB</code> 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。<code>RDB</code> 文件生成完毕后， master 会将这个 <code>RDB</code> 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存</strong>中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。</li><li>slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</li></ul><p>也就是说，主从复制实际上是先做了一次全量复制，然后又做了一次增量复制</p><h3 id="1-1-断点续传"><a href="#1-1-断点续传" class="headerlink" title="1.1 断点续传"></a>1.1 断点续传</h3><p>如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。</p><p>master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 <code>resynchronization</code>。</p><h3 id="1-2-无磁盘化复制"><a href="#1-2-无磁盘化复制" class="headerlink" title="1.2 无磁盘化复制"></a>1.2 无磁盘化复制</h3><p>master 在内存中直接创建 <code>RDB</code>，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 <code>repl-diskless-sync yes</code> 即可。</p><h3 id="1-3-过期key处理"><a href="#1-3-过期key处理" class="headerlink" title="1.3 过期key处理"></a>1.3 过期key处理</h3><p>slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。</p><h3 id="1-4-完整的复制流程"><a href="#1-4-完整的复制流程" class="headerlink" title="1.4 完整的复制流程"></a>1.4 完整的复制流程</h3><p>slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的<code>host</code>和<code>ip</code>，但是复制流程没开始。</p><p>slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 <code>ping</code> 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node <strong>第一次执行全量复制</strong>，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。</p><img src="/2020/05/07/%E7%AC%94%E8%AE%B0/redis/image-20200604163306620.png" alt="完整的复制流程" style="zoom:80%;"><p>全量复制：</p><ul><li>master 执行 bgsave ，在本地生成一份 rdb 快照文件。</li><li>master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)</li><li>master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。</li><li>如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。</li></ul><pre><code>client-output-buffer-limit slave 256MB 64MB 60</code></pre><ul><li>slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时<strong>基于旧的数据版本</strong>对外提供服务。</li><li>如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。</li></ul><p>增量复制：</p><ul><li>如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。</li><li>master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。</li><li>master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。</li></ul><h2 id="2-哨兵模式（高可用）"><a href="#2-哨兵模式（高可用）" class="headerlink" title="2. 哨兵模式（高可用）"></a>2. 哨兵模式（高可用）</h2><p>如果master node死掉了，则没有办法写数据了，写缓存的时候全部失效，相当于系统不可用了。</p><p>哨兵是一个分布式系统，用于对主从结构的每台服务器进行监控，当Master出现故障时，通过投票机制选择新的Master，并且将所有的Slave连接到新的Master上。</p><p>哨兵也是Redis服务器，只不过不提供数据服务，并且哨兵的数量通常被配置为单数</p><h3 id="2-1-主备切换数据丢失问题"><a href="#2-1-主备切换数据丢失问题" class="headerlink" title="2.1 主备切换数据丢失问题"></a>2.1 主备切换数据丢失问题</h3><p>主备切换的过程，有两种情况可能会导致数据丢失：</p><ul><li><p><strong>异步复制导致的数据丢失</strong></p><p>因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。</p></li><li><p><strong>脑裂导致的数据丢失</strong></p><p>脑裂，也就是说，某个 master 所在机器突然<strong>脱离了正常的网络</strong>，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会<strong>认为</strong> master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的<strong>脑裂</strong>。</p><p>此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。</p></li></ul><p><strong>数据丢失问题的解决方法：</strong></p><p>完全解决是不可能的，只能降低数据丢失的影响。</p><p><strong>主要就是通过以下两个参数来控制的</strong>：</p><pre><code>min-slaves-to-write 1min-slaves-max-lag 10</code></pre><p>表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了，此时的Client需要停顿一段时间再去写。</p><ul><li><p><strong>减少异步复制数据的丢失</strong></p><p>有了 <code>min-slaves-max-lag</code> 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p></li><li><p><strong>减少脑裂的数据丢失</strong></p><p>如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给<strong>指定数量的 slave</strong> 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。</p></li></ul><h3 id="2-2-sdown与odown"><a href="#2-2-sdown与odown" class="headerlink" title="2.2 sdown与odown"></a>2.2 sdown与odown</h3><ul><li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li><li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li></ul><p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 <code>is-master-down-after-milliseconds</code> 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p><h3 id="2-3-哨兵集群的自动发现机制"><a href="#2-3-哨兵集群的自动发现机制" class="headerlink" title="2.3 哨兵集群的自动发现机制"></a>2.3 哨兵集群的自动发现机制</h3><p>哨兵互相之间的发现，是通过 redis 的 <code>pub/sub</code> 系统实现的，每个哨兵都会往 <code>__sentinel__:hello</code> 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。</p><p>每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 <code>__sentinel__:hello</code> channel 里<strong>发送一个消息</strong>，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p><p>每个哨兵也会去<strong>监听</strong>自己监控的每个 master+slaves 对应的 <code>__sentinel__:hello</code> channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。</p><p>每个哨兵还会跟其他哨兵交换对 <code>master</code> 的监控配置，互相进行监控配置的同步。</p><h3 id="2-4-slave-配置的自动纠正"><a href="#2-4-slave-配置的自动纠正" class="headerlink" title="2.4 slave 配置的自动纠正"></a>2.4 slave 配置的自动纠正</h3><p>哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。</p><h3 id="2-5-主从切换过程"><a href="#2-5-主从切换过程" class="headerlink" title="2.5 主从切换过程"></a>2.5 主从切换过程</h3><ol><li><p>每个哨兵以一定频率向它所知的Master、Slave、其他哨兵发送心跳信息，以确认对方是否存活</p></li><li><p>如果某一个实例距离最后一次有效回复时间超过阈值，会被哨兵标记为<strong>主观下线</strong>。</p></li><li><p>如果某个Master被标记为主观下线，则所有监视它的哨兵就要去验证它是否真的挂掉，如果超过半数的哨兵认为Master挂掉，则将其标记为客观下线</p></li><li><p>在哨兵的组群中先进行选举，最终有一个哨兵当选为处理Master选举的节点</p></li><li><p>由这个被选举出来的哨兵从服务器列表中选择新的Master</p><p>选择的准则是：在线的，响应快的，与原Master断开时间长的（表示其网络好，很快感知到master下线）</p></li></ol><h1 id="Redis集群（海量数据）"><a href="#Redis集群（海量数据）" class="headerlink" title="Redis集群（海量数据）"></a>Redis集群（海量数据）</h1><h2 id="1-集群与主从复制"><a href="#1-集群与主从复制" class="headerlink" title="1. 集群与主从复制"></a>1. 集群与主从复制</h2><p>前面提到的主从复制指的是用于保证高并发的一种读写分离的策略，master节点用于写数据，slave节点用于读数据。但是这样的话，master和slave节点就需要存储相同的数据，这样的话，是没有办法做横向扩容来支持海量数据的。</p><p>而Redis的集群则是为了解决海量数据问题的一种方案。</p><h2 id="2-集群架构"><a href="#2-集群架构" class="headerlink" title="2. 集群架构"></a>2. 集群架构</h2><p>支撑N个Redis Master节点，每个master节点可以挂载多个slave 节点，用来做读写分离。其高可用，因为每个master都有slave节点，如果master挂掉，redis cluster这套机制，就会自动将某个slave切换为master</p><p>redis cluster 功能强大，<strong>直接集成了 replication 和 sentinel 的功能</strong>。</p><p>Redis集群指的是<strong>在多台机器上，部署多个 redis 实例</strong>，每个实例存储<strong>一部分</strong>的数据，同时每个 redis 主实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到 redis 从实例上来。</p><h2 id="3-分布式寻址算法"><a href="#3-分布式寻址算法" class="headerlink" title="3. 分布式寻址算法"></a>3. 分布式寻址算法</h2><h3 id="3-1-一致性哈希"><a href="#3-1-一致性哈希" class="headerlink" title="3.1 一致性哈希"></a>3.1 一致性哈希</h3><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。</p><p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。</p><h3 id="3-2-hash-slot算法"><a href="#3-2-hash-slot算法" class="headerlink" title="3.2 hash slot算法"></a>3.2 hash slot算法</h3><p>redis cluster 有固定的 <code>16384</code> （一万多）个 hash slot，对每个 <code>key</code> 计算 <code>CRC16</code> 值，然后对 <code>16384</code> （一万多）取模，可以获取 key 对应的 hash slot。</p><p>redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 <code>hash tag</code> 来实现。</p><p>任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。</p><h2 id="4-redis-cluster-的高可用与主备切换原理"><a href="#4-redis-cluster-的高可用与主备切换原理" class="headerlink" title="4. redis cluster 的高可用与主备切换原理"></a>4. redis cluster 的高可用与主备切换原理</h2><p>redis cluster 的高可用的原理，几乎跟哨兵是类似的。</p><h3 id="判断节点宕机"><a href="#判断节点宕机" class="headerlink" title="判断节点宕机"></a>判断节点宕机</h3><p>如果一个节点认为另外一个节点宕机，那么就是<strong>主观宕机</strong>。如果多个节点都认为另外一个节点宕机了，那么就是<strong>客观宕机</strong>。</p><p>在规定的时间范围之内都没有收到节点的回复，则认为该节点宕机，若认为某个节点 pfail 了，那么会在 gossip ping 消息中，ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail。</p><p>如果一个节点认为某个节点 <code>pfail</code> 了，那么会在 <code>gossip ping</code> 消息中，<code>ping</code> 给其他节点，如果<strong>超过半数</strong>的节点都认为 <code>pfail</code> 了，那么就会变成 <code>fail</code>。</p><h3 id="从节点过滤"><a href="#从节点过滤" class="headerlink" title="从节点过滤"></a>从节点过滤</h3><p>对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。</p><h3 id="从节点选举"><a href="#从节点选举" class="headerlink" title="从节点选举"></a>从节点选举</h3><p>每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p><p>所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node<code>（N/2 + 1）</code>都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。</p><p>从节点执行主备切换，从节点切换为主节点。</p><h2 id="5-基于Redis的服务注册中心"><a href="#5-基于Redis的服务注册中心" class="headerlink" title="5. 基于Redis的服务注册中心"></a>5. 基于Redis的服务注册中心</h2><p>假如用Redis做注册中心，就是将对应的key写进redis，然后需要获取的时候向Redis请求相关的数据即可。</p><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="1-分布式锁"><a href="#1-分布式锁" class="headerlink" title="1. 分布式锁"></a>1. 分布式锁</h2><h3 id="1-1-并发竞争问题"><a href="#1-1-并发竞争问题" class="headerlink" title="1.1 并发竞争问题"></a>1.1 并发竞争问题</h3><p><strong>多客户端同时并发写</strong>一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。</p><p>某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。</p><p>你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。</p><p>每次要<strong>写之前，先判断</strong>一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。</p><p>当多个进程不再同一个系统中，用分布式锁控制多个分布式进程对资源的访问，用Redis来实现分布式锁</p><h3 id="1-2-Redis-分布式锁"><a href="#1-2-Redis-分布式锁" class="headerlink" title="1.2 Redis 分布式锁"></a>1.2 Redis 分布式锁</h3><ol><li><p>加锁：在Redis中，给key键设置一个值，为了避免死锁，给定一个过期时间</p><pre><code>SET lock_key random_val NX PX 5000NX：键不存在时才设置值PX 5000：键的过期时间设置为5000ms</code></pre><p>如果上述操作成功，则可以证明客户端获得了锁</p></li><li><p>解锁：解锁的过程就是将key键删除，但是必须是加锁的客户端来删除，不能乱删，通过random_val来实践</p></li></ol><p>问题：锁的不可重入性</p><p>需要在加锁的时候判断，如果加锁的线程是当前线程，则可以证明重入，加锁也会成功，并且会维护一个重入次数的变量， 在解锁时，将变量减少为0才表示成功解锁</p><p>应用：避免不同进程重复的工作，例如多个线程对同一个订单操作，可能导致订单状态错误覆盖（避免重复下单）</p><h2 id="2-分布式自增ID"><a href="#2-分布式自增ID" class="headerlink" title="2. 分布式自增ID"></a>2. 分布式自增ID</h2><p>对于分布式自增ID，有以下几种实现方式：</p><ol><li><p><strong>利用数据库的自增ID属性</strong></p><p>使得项目依赖数据库，影响性能， 并且一旦数据库挂掉，服务将不可再用</p></li><li><p><strong>使用UUID实现唯一ID的生成</strong></p><p>使用UUID可以保证全局唯一，但是生成的是无序的ID，会导致入库的性能较差。这是因为涉及到了B+树的索引结构（索引分裂），以ID字段为例，索引树的每个节点都存储着若干ID，如果ID按照顺序来插入，则新的ID都只会插入到最后一个节点中，最后一个节点满了之后再分裂出新的节点，这样节点的分裂次数较少，充分地利用了每个节点的空间</p><p>如果插入完全无序，不仅会导致中间节点的分裂，也有可能会造成一些中间节点不饱和，降低了数据库的性能</p></li><li><p><strong>SnowFlake算法</strong></p><p>它的ID分成四个部分：</p><ul><li>占用1bit，始终为0</li><li>时间戳41bit</li><li>工作机器ID：10bit，前5bit是数据中心的id，后5bit是工作节点id，最多1024个节点</li><li>序列号：12bit，在同一个毫秒的同一个节点上从0开始不断增加，最多增加到4096</li></ul><p><strong>优点</strong>：</p><ul><li>生成ID时不再依赖于DB，完全在内存中生成，高性能，高可用</li><li>ID递增，后续插入索引树时的性能好</li></ul><p><strong>缺点</strong>：</p><ul><li>依赖于系统时钟的一致性，如果某台机器的系统时钟回拨，会导致ID冲突或乱序</li></ul><p><strong>解决时钟回拨问题</strong>：</p><p>源码中，如果当前时间&lt;上一秒的时间戳，则直接抛出异常表示时钟回拨，拒绝生成</p><ul><li>添加一个<strong>最大容忍时间</strong>，如果时钟只是回拨了该变量指定的时间，那么可以等待响应的时间之后，再使用，否则就需要人工干预</li><li>使用<strong>备用服务器</strong>的策略，原本的工作机器最多有1024个节点，可以将其一分为二，当出现问题时，就使用它的备份机</li></ul></li><li><p><strong>使用Redis生成唯一ID</strong></p><p>由于Redis采用单进程单线程的架构，不会因为多个取号方的递增导致取号重复，因此使用INCR命令可以满足全局唯一与单调递增</p></li></ol><h2 id="3-分布式Session"><a href="#3-分布式Session" class="headerlink" title="3. 分布式Session"></a>3. 分布式Session</h2><p>Session：就是浏览器和服务器的交互的会话，</p><p>给 sping session 配置基于 redis 来存储 session 数据，然后配置了一个 spring session 的过滤器，这样的话，session 相关操作都会交给 spring session 来管了。接着在代码中，就用原生的 session 操作，就是直接基于 spring sesion 从 redis 中获取数据了。</p><h1 id="缓存雪崩、穿透、击穿"><a href="#缓存雪崩、穿透、击穿" class="headerlink" title="缓存雪崩、穿透、击穿"></a>缓存雪崩、穿透、击穿</h1><h2 id="1-雪崩"><a href="#1-雪崩" class="headerlink" title="1. 雪崩"></a>1. 雪崩</h2><p>缓存统一时间内大面积失效，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而挂掉</p><p>解决方法：</p><p>缓存数据的过期时间设置为随机值，防止同一时间大量数据过期的现象发生</p><p>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的服务器上</p><h2 id="2-穿透"><a href="#2-穿透" class="headerlink" title="2. 穿透"></a>2. 穿透</h2><p>指的是请求缓存和数据库中都没有的数据，用户不断发起请求，比如黑客攻击，发起id=-1的数据，或者id不可能存在的数据，导致服务器压力过大</p><p>解决方法：</p><p>接口层增加校验，检测用户权限，id做基础校验，也可以对不存在的数据进行缓存比如，key=null的值也缓存，但是做缓存可能会造成大量的不存在key被缓存，造成性能下降，因此可以把这个key设置的复杂一些，对key是否符合某个规范，进行正则校验，如果key不符合规范，就不回去查redis。这也相当于是做了一个过滤器的功能。</p><p><strong>使用布隆过滤器</strong></p><p>布隆过滤器：是一种哈希算法，它可以告诉你某种东西<strong>一定不存在</strong>或者<strong>可能存在</strong>。主要用来判断一个元素是否在集合中存在。可能会出现检测存在的结果但是实际上可能是不存在的，但是肯定不会出现实际上不存在然后反馈存在的结果。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。</p><p>Redis中布隆过滤器的数据结构就是一个很大的bit数组和几个不一样的无偏哈希函数（能把元素的哈希值算得比较平均，能让元素被哈希到位数组中的位置比较随机）。</p><p>向布隆过滤器中添加元素时，会使用多个无偏哈希函数对元素进行哈希，算出一个整数索引值，然后对位数组长度进行取模运算得到一个位置，每个无偏哈希函数都会得到一个不同的位置。再把位数组的这几个位置都设置为1，这就完成了<code>bf.add</code>命令的操作。</p><p>向布隆过滤器查询元素是否存在时，和添加元素一样，也会把哈希的几个位置算出来，然后看看位数组中对应的几个位置是否都为1，只要有一个位为0，那么就说明布隆过滤器里不存在这个元素。如果这几个位置都为1，并不能完全说明这个元素就一定存在其中，有可能这些位置为1是因为其他元素的存在，这就是布隆过滤器会出现误判的原因。</p><p>在Redis中，布隆过滤器有两个基本命令，分别是：</p><ul><li><code>bf.add</code>：添加元素到布隆过滤器中，类似于集合的<code>sadd</code>命令，不过<code>bf.add</code>命令只能一次添加一个元素，如果想一次添加多个元素，可以使用<code>bf.madd</code>命令。</li><li><code>bf.exists</code>：判断某个元素是否在过滤器中，类似于集合的<code>sismember</code>命令，不过<code>bf.exists</code>命令只能一次查询一个元素，如果想一次查询多个元素，可以使用<code>bf.mexists</code>命令。</li></ul><h2 id="3-击穿"><a href="#3-击穿" class="headerlink" title="3. 击穿"></a>3. 击穿</h2><p>系统平稳运行，Redis没有大量的key过期，内存平稳，但是数据库崩了</p><p>问题是：某个key过期，但是这个key高热，有多个请求到达Redis后未命中，于是会在短时间内发起大量的对数据库中同一数据的访问。</p><p>击穿与雪崩的起因是类似的，只不过雪崩是大规模的key失效，而击穿是某个key失效，造成的结果是类似的。</p><p><strong>用互斥锁，保证缓存失效时，只有1个线程去更新缓存，其他线程等待</strong>。例如使用Redis的setnx来互斥</p><h1 id="缓存一致性问题"><a href="#缓存一致性问题" class="headerlink" title="缓存一致性问题"></a>缓存一致性问题</h1><h2 id="1-不一致的情况分类"><a href="#1-不一致的情况分类" class="headerlink" title="1. 不一致的情况分类"></a>1. 不一致的情况分类</h2><ul><li>数据库中有数据，缓存中没有数据</li><li>数据库中没有数据，缓存中有数据</li><li>数据库中有数据，缓存中也有数据，但是数据不相等</li></ul><h2 id="2-缓存-数据库的读写模式"><a href="#2-缓存-数据库的读写模式" class="headerlink" title="2. 缓存+数据库的读写模式"></a>2. 缓存+数据库的读写模式</h2><p>一种经典的使用缓存的方法：</p><ol><li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li><li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li></ol><p>问题：先更新数据库，再删除缓存。<strong>如果删除缓存失败了</strong>，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p><p>为什么是删除缓存而不是更新缓存？</p><ul><li>很多时候，在复杂点的缓存场景，<strong>缓存不单单是数据库中直接取出来的值</strong>。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</li><li>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></li></ul><p>其实删除缓存，而不是更新缓存，就是一个 <strong>lazy 计算的思想</strong>，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。</p><h2 id="3-不一致的解决方法"><a href="#3-不一致的解决方法" class="headerlink" title="3. 不一致的解决方法"></a>3. 不一致的解决方法</h2><h3 id="3-1-简单的不一致"><a href="#3-1-简单的不一致" class="headerlink" title="3.1 简单的不一致"></a>3.1 简单的不一致</h3><p><strong>问题</strong>：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。</p><p><strong>方案</strong>：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。</p><h3 id="3-2-高并发场景下的不一致"><a href="#3-2-高并发场景下的不一致" class="headerlink" title="3.2 高并发场景下的不一致"></a>3.2 高并发场景下的不一致</h3><p><strong>问题</strong>：数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，<strong>查到了修改前的旧数据</strong>，放到了缓存中。随后数据变更的程序完成了数据库的修改。这样数据库和缓存的数据又不一样了。</p><p><strong>方案</strong>：根据<strong>数据的唯一标识</strong>，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。<strong>每个队列对应不同的工作线程</strong>，每个工作线程<strong>串行</strong>拿到对应的操作，然后一条一条的执行。这样的话，对于同一个数据的变更和更新缓存的操作都会落到同一个JVM中来串行化执行，就不会出现这个问题了。</p><p>但是这种方案可能会出现一些问题，比如说高并发场景下，队列中可能会积压大量的更新操作，造成用户的阻塞时间过长。万一某个数据的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。</p><h1 id="Redis的事务机制"><a href="#Redis的事务机制" class="headerlink" title="Redis的事务机制"></a>Redis的事务机制</h1><p>Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p><p>总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。　　</p><p><strong>Redis事务没有隔离级别的概念：</strong></p><p>批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到。</p><p><strong>Redis不保证原子性：</strong></p><p>Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【笔记】java并发</title>
      <link href="/2020/04/25/%E7%AC%94%E8%AE%B0/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
      <url>/2020/04/25/%E7%AC%94%E8%AE%B0/%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="java对象布局"><a href="#java对象布局" class="headerlink" title="java对象布局"></a>java对象布局</h1><p>普通对象包含四个部分：</p><ol><li><strong>MarkWord</strong>（8字节）：用于存储自身的运行时数据，比如锁的信息，GC的分代信息等</li><li><strong>类型指针</strong>：指向该对象数据哪个类</li><li><strong>实例数据</strong>：就是成员变量的内容</li><li><strong>对齐padding</strong>：由于JVM读取数据是按照块的单位来读取的，一个块就是8字节，如果前面3部分的大小加起来不足8字节，就将其补齐为可以被8整除的长度</li></ol><h1 id="线程与守护线程"><a href="#线程与守护线程" class="headerlink" title="线程与守护线程"></a>线程与守护线程</h1><p>默认情况下，java的进程需要等待所有线程都执行完成才会结束。有一种特殊的线程叫做守护线程，只要其他的非守护线程执行完毕了，即使守护线程没有执行完成，也会强制结束</p><h1 id="创建线程的方式"><a href="#创建线程的方式" class="headerlink" title="创建线程的方式"></a>创建线程的方式</h1><h2 id="1-继承Thread类，并重写run方法"><a href="#1-继承Thread类，并重写run方法" class="headerlink" title="1. 继承Thread类，并重写run方法"></a>1. 继承Thread类，并重写run方法</h2><h2 id="2-实现Runnable接口，并实现run方法"><a href="#2-实现Runnable接口，并实现run方法" class="headerlink" title="2. 实现Runnable接口，并实现run方法"></a>2. 实现Runnable接口，并实现run方法</h2><p>Runnable接口是被 <code>@FunctionalInterface</code> 注解的，因此，他可以支持lambda表达式，使用lambda表达式放在Runnable实现类对应的位置上。</p><h2 id="3-使用FutureTask-Callable配合Thread来创建线程"><a href="#3-使用FutureTask-Callable配合Thread来创建线程" class="headerlink" title="3. 使用FutureTask + Callable配合Thread来创建线程"></a>3. 使用FutureTask + Callable配合Thread来创建线程</h2><ol><li>先创建Callable接口的实现类，实现其中的call方法，该call方法将会作为线程的执行体，并且有返回值。</li><li>创建Callable实现类的对象，并且使用FutureTask类来包装Callable对象，该对象中封装了Callable对象的call方法的返回值（FutureTask是一个包装器，它通过接受Callable来创建，同时实现了Future和Runnable接口）</li><li>使用FutureTask对象作为Thread对象的target创建并启动新线程</li><li>调用FutureTask对象的get()方法获得子线程执行结果（阻塞等待）</li></ol><pre><code class="java">class Task implements Callable&lt;Integer&gt; {    @Override    public Integer call() throws Exception {        return 100;    }}public class CreateThread {    public static void main(String[] args) {        Task task = new Task();        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(task);        Thread thread = new Thread(futureTask);        thread.start();        try {            Integer i = futureTask.get();            System.out.println(i);        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><p>这些创建线程的方法，在调用时都需要与Thread类配合，通过Thread对象中的start()方法来开启线程，并执行run方法中的代码。</p><h2 id="4-使用线程池"><a href="#4-使用线程池" class="headerlink" title="4. 使用线程池"></a>4. 使用线程池</h2><h2 id="5-对比"><a href="#5-对比" class="headerlink" title="5. 对比"></a>5. 对比</h2><h3 id="5-1-Runnable-与-Callable"><a href="#5-1-Runnable-与-Callable" class="headerlink" title="5.1 Runnable 与 Callable"></a>5.1 Runnable 与 Callable</h3><ol><li>Callable接口重写的是call方法，Runnable重写的时run方法</li><li>Callable的任务执行后可以返回值，而Runnable任务不能返回值</li><li>call方法可以抛出异常，run方法不可以</li><li>运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算完成。</li></ol><h3 id="5-2-Runnable-与-Thread"><a href="#5-2-Runnable-与-Thread" class="headerlink" title="5.2 Runnable 与 Thread"></a>5.2 Runnable 与 Thread</h3><p>使用Runnable可以让任务类脱离Thread的继承体系，使用更加灵活。也就是使用继承Thread的方式不能多继承，因此灵活性较低。</p><h1 id="Thread类的常见方法"><a href="#Thread类的常见方法" class="headerlink" title="Thread类的常见方法"></a>Thread类的常见方法</h1><h2 id="1-对象方法"><a href="#1-对象方法" class="headerlink" title="1. 对象方法"></a>1. 对象方法</h2><h3 id="1-1-start-与-run"><a href="#1-1-start-与-run" class="headerlink" title="1.1 start() 与 run()"></a>1.1 start() 与 run()</h3><ul><li><p><strong>start：启动一个新线程， 让线程进入可运行（RUNNABLE）状态</strong></p><p>start只是让线程进入就绪状态，里面的代码不一定立刻就能运行（CPU可能没有分配时间片）。每个线程对象的start方法只能调用一次，因为<strong>处于Runnable状态的线程是不可以被start的</strong>。如果多次调用start方法，会出现 <code>IllegalThreadStateException</code> 异常。</p></li><li><p><strong>run：新线程启动后会调用的方法</strong></p><p>如果在构造Thread对象的时候传递了Runnable参数，则线程启动后会调用Runnable中的run方法。否则默认不执行任何操作。可以创建Thread的子类对象来覆盖默认行为。</p></li></ul><h3 id="1-2-join-等待线程运行结束"><a href="#1-2-join-等待线程运行结束" class="headerlink" title="1.2 join 等待线程运行结束"></a>1.2 join 等待线程运行结束</h3><p>分为 <code>join</code> 和 <code>join(long n)</code> 两个方法，等待线程运行结束，带有参数的版本中n是毫秒，表示最多等待n毫秒</p><h3 id="1-3-interrupt-打断线程"><a href="#1-3-interrupt-打断线程" class="headerlink" title="1.3 interrupt 打断线程"></a>1.3 interrupt 打断线程</h3><p>（在后面写）</p><h2 id="2-静态方法"><a href="#2-静态方法" class="headerlink" title="2. 静态方法"></a>2. 静态方法</h2><h3 id="2-1-sleep-线程休眠"><a href="#2-1-sleep-线程休眠" class="headerlink" title="2.1 sleep 线程休眠"></a>2.1 sleep 线程休眠</h3><p>该方法有一个long类型的参数n，表示让当前执行的线程休眠n毫秒，休眠时让出CPU的时间片给其他线程。</p><p>sleep方法<strong>将当前线程从 RUNNING 切换到 TIME_WATING 状态</strong>。</p><p>其他线程可以使用 interrupt 方法打断正在sleep的线程，并且这个sleep的线程解除休眠状态之后并不会立刻被执行，依然需要被CPU调度。</p><h3 id="2-2-sleep方法和wait方法有什么区别"><a href="#2-2-sleep方法和wait方法有什么区别" class="headerlink" title="2.2 sleep方法和wait方法有什么区别"></a>2.2 sleep方法和wait方法有什么区别</h3><ul><li><p>sleep方法是Thread类的静态方法，wait方法是Object类的一个方法，sleep自己就可以使用，而wait方法则需要配合notify / notifyAll方法来使用。</p></li><li><p>wait + notify 的方法需要在同步代码块中执行，也就是这两类方法要执行，需要首先获取对象的锁，而sleep方法则不需要获取获取锁即可使用。</p><p>同时需要注意：wait() 方法<strong>立即</strong>释放对象监视器，notify()/notifyAll() 方法则会<strong>等待线程剩余代码执行完毕</strong>才会放弃对象监视器。</p></li></ul><h3 id="2-3-interrupted-判断线程是否打断"><a href="#2-3-interrupted-判断线程是否打断" class="headerlink" title="2.3 interrupted 判断线程是否打断"></a>2.3 interrupted 判断线程是否打断</h3><p>（在后面写）</p><h1 id="打断线程"><a href="#打断线程" class="headerlink" title="打断线程"></a>打断线程</h1><h2 id="0-为什么不能使用stop方法"><a href="#0-为什么不能使用stop方法" class="headerlink" title="0. 为什么不能使用stop方法"></a>0. 为什么不能使用stop方法</h2><p>stop()方法太过于暴力，会强行把执行一半的线程终止。这样会就<strong>不会保证线程的资源正确释放</strong>，通常是没有给与线程完成资源释放工作的机会，因此会导致程序工作在不确定的状态下。</p><h2 id="1-interrupt打断的方式"><a href="#1-interrupt打断的方式" class="headerlink" title="1. interrupt打断的方式"></a>1. interrupt打断的方式</h2><p>interrupt标记是一个boolean类型的变量，可以通过 <code>isInterrupted</code> 方法来查看标记情况。</p><p>线程<strong>通过检查自身是否被中断来进行响应</strong>，线程通过方法isInterrupted()来进行判断是否被中断。</p><pre><code class="java">Thread t = new Thread(()-&gt;{    while(true){        // 线程自己判断自己是否被打断        if (Thread.currentThread().isInterrupted())            break;    }});t.start();Thread.sleep(1000);t.interrupt();System.out.println(t.isInterrupted());</code></pre><h2 id="2-interrupt方法"><a href="#2-interrupt方法" class="headerlink" title="2. interrupt方法"></a>2. interrupt方法</h2><p>对某个线程对象调用interrupt方法，则表示将该对象对应的线程进行打断。</p><p>根据被打断线程的状态，interrupt方法执行后有以下几种可能的效果：</p><ul><li>如果线程处于<strong>被阻塞状态</strong>，那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常。</li><li>如果线程处于正常活动状态，那么会将该线程的interrupt标志为设置为true。被设置中断标志的线程将正常运行，不受影响。</li><li>park的线程被打段，会<strong>设置interrupt标记</strong>。（true）</li></ul><h2 id="3-isInterrupt方法"><a href="#3-isInterrupt方法" class="headerlink" title="3. isInterrupt方法"></a>3. isInterrupt方法</h2><p>返回interrupt标记，使用该方法<strong>不会清除interrupt标记</strong>。</p><h2 id="4-Thread-interrupted-静态方法"><a href="#4-Thread-interrupted-静态方法" class="headerlink" title="4. Thread.interrupted()静态方法"></a>4. Thread.interrupted()静态方法</h2><p>判断当前线程是否被打断，该方法<strong>会清除打断标记</strong>（false）</p><h2 id="5-对比isInterrupt和interrupted"><a href="#5-对比isInterrupt和interrupted" class="headerlink" title="5. 对比isInterrupt和interrupted"></a>5. 对比isInterrupt和interrupted</h2><p>主要就是二者一个是静态方法，一个是对象的成员方法，一个会清除打断标记，一个不会清除打断标记。</p><h1 id="线程的状态有哪些"><a href="#线程的状态有哪些" class="headerlink" title="线程的状态有哪些"></a>线程的状态有哪些</h1><ul><li><p><strong>NEW：新建</strong></p><p>线程刚被创建，还没有调用 <code>start()</code> 方法</p></li><li><p><strong>RUNNABLE：可运行</strong></p><p>调用了 <code>start()</code> 方法之后，所处的状态。包含了正在运行的和等待调度的状态。</p></li><li><p><strong>BLOCKED：阻塞</strong></p><ul><li>t 线程用 <code>synchronized(obj)</code> 获取了对象锁时如果竞争失败，从 <code>RUNNABLE --&gt; BLOCKED</code></li><li>持obj锁线程的同步代码块执行完毕，会唤醒该对象上所有 <code>BLOCKED</code> 的线程重新竞争<ul><li>如果其中t线程竞争成功，则从 <code>BLOCKED --&gt; RUNNABLE</code></li><li>如果竞争失败，则仍然为 <code>BLOCKED</code> 状态</li></ul></li></ul></li><li><p><strong>WAITING：等待</strong></p><ul><li><p><strong>join</strong></p><p>调用 <code>join(t)</code> 的线程会等待 t 线程运行完成</p></li><li><p><strong>wait / notify</strong></p><p>使用synchronized获取到对象锁之后，执行wait可以进入等待状态，</p><p>调用 <code>obj.notify()</code>、<code>obj.notifyAll()</code>、<code>t.interrupt()</code> 时</p><ul><li>如果竞争锁成功，<code>t</code> 线程从 <code>WAITING --&gt; RUNNABLE</code></li><li>如果竞争锁失败，<code>t</code> 线程从 <code>WAITING --&gt; BLOCKED</code>，进入EntryList，与其他竞争锁的线程一起竞争</li></ul></li><li><p>park / unpark</p><ul><li>当线程调用 <code>LockSupport.park()</code> 方法，会让当前线程从 <code>RUNNABLE --&gt; WAITING</code></li><li>调用 <code>LockSupport.unpartk()</code> 方法，会让当前线程从 <code>WAITING --&gt; RUNNABLE</code></li></ul></li></ul></li><li><p><strong>TIME_WAITING：限时等待</strong></p><p>使用带long参数的join、wait、parkNanos或者Thread.sleep方法即可使线程进入该状态。</p></li><li><p><strong>TERMINATED：终止</strong></p><p>当线程的代码运行结束时，处于该状态。</p></li></ul><h1 id="什么是线程安全"><a href="#什么是线程安全" class="headerlink" title="什么是线程安全"></a>什么是线程安全</h1><p>多个线程对共享资源进行读写的时候，<strong>由于上下文切换引起的指令交错</strong>，导致多线程访问共享资源时出现安全性问题，如果不存在线程安全性问题，就称为线程安全的。</p><h2 id="1-临界区"><a href="#1-临界区" class="headerlink" title="1. 临界区"></a>1. 临界区</h2><p>一个程序运行多个线程本身是没有问题的，问题可能会出现在多个线程访问共享资源：</p><p><strong>如果一段代码块内存在对共享资源的多线程读写操作</strong>，就将这段代码称为<strong>临界区</strong>。</p><h2 id="2-竞态条件"><a href="#2-竞态条件" class="headerlink" title="2. 竞态条件"></a>2. 竞态条件</h2><p>多个线程在临界区内执行，由于<strong>代码的执行序列不同</strong>而导致结果无法预测，称为发生了<strong>竞态条件</strong>。</p><h2 id="3-解决方法"><a href="#3-解决方法" class="headerlink" title="3. 解决方法"></a>3. 解决方法</h2><p>为了避免临界区的竞态条件发生，有多重手段可以达到目的：</p><ul><li>阻塞式的解决方案：synchronized， Lock</li><li>非阻塞式的解决方案：原子变量</li></ul><h2 id="4-为什么线程安全类还是会出现线程安全问题"><a href="#4-为什么线程安全类还是会出现线程安全问题" class="headerlink" title="4. 为什么线程安全类还是会出现线程安全问题"></a>4. 为什么线程安全类还是会出现线程安全问题</h2><p>线程安全类中的安全指的是：多个线程调用他们<strong>同一个实例的某个方法时</strong>，是线程安全的。这样，每个方法是线程安全的，但是方法的组合是线程不安全的。</p><h2 id="5-不可变类的线程安全性"><a href="#5-不可变类的线程安全性" class="headerlink" title="5. 不可变类的线程安全性"></a>5. 不可变类的线程安全性</h2><p>String Integer等类都是不可变类，因为内部的状态不可改变，因此他们都是线程安全的。即使被多线程共享，但是因为没有改变，因此也是线程安全。</p><h1 id="如何保证并发安全（多线程访问共享数据）"><a href="#如何保证并发安全（多线程访问共享数据）" class="headerlink" title="如何保证并发安全（多线程访问共享数据）"></a>如何保证并发安全（多线程访问共享数据）</h1><ol><li>使用synchronized</li><li>CAS</li><li>ConcurrentHashMap等并发数据类</li><li>基于AQS的Lock，如ReentrantLock</li></ol><h1 id="活跃性问题"><a href="#活跃性问题" class="headerlink" title="活跃性问题"></a>活跃性问题</h1><h2 id="1-死锁"><a href="#1-死锁" class="headerlink" title="1. 死锁"></a>1. 死锁</h2><p>以两个线程为例，死锁就是线程互相持有对方线程所需要的资源，并且请求对方所需要的资源，这样两个线程都处于阻塞状态，若无外力作用，它们都将无法推进下去。</p><h3 id="1-1-死锁产生的条件"><a href="#1-1-死锁产生的条件" class="headerlink" title="1.1 死锁产生的条件"></a>1.1 死锁产生的条件</h3><p>如果死锁是肯定满足这四个条件的，但是如果只满足其中的某些条件则不会造成死锁。</p><ol><li><p><strong>互斥条件</strong></p><p>进程对资源的使用是排他性的使用，某资源只能由一个进程使用，其他进程需要使用只能等待。</p></li><li><p><strong>请求保持条件</strong></p><p>进程至少保持一个资源，又提出新的资源请求，新资源被占用，请求被阻塞，并且被阻塞的进程不释放自己保持的资源。</p></li><li><p><strong>不可剥夺条件</strong></p><p>进程获得的资源在未完成使用前不能被剥夺，获得的资源只能由进程自身释放。</p></li><li><p><strong>环路等待条件</strong></p><p>发生死锁时，必然存在进程-资源环形链。</p></li></ol><h3 id="1-2-预防死锁的方法"><a href="#1-2-预防死锁的方法" class="headerlink" title="1.2 预防死锁的方法"></a>1.2 预防死锁的方法</h3><p>由于前面死锁产生需要4个必要条件，因此只要破坏其中一个条件，就可以预防死锁</p><ol><li><p><strong>破坏请求保持条件</strong></p><p>系统规定进程运行之前，一次性申请所有需要的资源，并且进程在运行期间不会提出资源请求，从而摒弃请求保持条件。</p></li><li><p><strong>破坏不可剥夺条件</strong></p><p>当一个进程请求新的资源得不到满足时，必须释放占有的资源，进程运行时占有的资源可以被释放，意味着可以被剥夺。</p></li><li><p><strong>破坏环路等待条件</strong></p><p>可用资源线性排序，申请必须按照需要递增申请，线性申请不再形成环路，从而摒弃了环路等待条件。</p><p>例如下面这样的等待条件：</p></li></ol><h3 id="1-3-哲学家进餐问题"><a href="#1-3-哲学家进餐问题" class="headerlink" title="1.3 哲学家进餐问题"></a>1.3 哲学家进餐问题</h3><h4 id="1-3-1-说明"><a href="#1-3-1-说明" class="headerlink" title="1.3.1 说明"></a>1.3.1 说明</h4><p>有五位哲学家，围坐在圆桌旁</p><ul><li>他们只做两件事：思考和吃饭，思考完一会之后吃饭，吃完饭后接着思考</li><li>桌上一共有5根筷子，每位哲学家左右手边各有一只筷子</li><li>吃饭的时候需要用两个拿筷子吃</li></ul><p><strong>分析：</strong></p><p>筷子其实就是锁，要拿到左右筷子的意思就是要获取两个锁。</p><p>五个哲学家也就是五个线程，五个筷子就是五个锁，这样就比较清晰了。</p><h4 id="1-3-2-筷子类"><a href="#1-3-2-筷子类" class="headerlink" title="1.3.2 筷子类"></a>1.3.2 筷子类</h4><pre><code class="java">public class Chopsticks {    private String name;    public Chopsticks(String name) {        this.name = name;    }    public String getName() {        return name;    }}</code></pre><h4 id="1-3-3-哲学家类"><a href="#1-3-3-哲学家类" class="headerlink" title="1.3.3 哲学家类"></a>1.3.3 哲学家类</h4><pre><code class="java">public class Phil extends Thread{    private Chopsticks left;    private Chopsticks right;    public Phil(Chopsticks left, Chopsticks right) {        this.left = left;        this.right = right;    }    @Override    public void run() {        while (true) {            synchronized (left) {                synchronized (right) {                    System.out.println(Thread.currentThread() + &quot;获取两个锁成功！正在吃呢&quot;);                    try {                        Thread.sleep(1000);                    } catch (InterruptedException e) {                        e.printStackTrace();                    }                }            }        }    }}</code></pre><h4 id="1-3-4-模拟流程"><a href="#1-3-4-模拟流程" class="headerlink" title="1.3.4 模拟流程"></a>1.3.4 模拟流程</h4><pre><code class="java">public static void main(String[] args) {    Chopsticks c1 = new Chopsticks(&quot;c1&quot;);    Chopsticks c2 = new Chopsticks(&quot;c2&quot;);    Chopsticks c3 = new Chopsticks(&quot;c3&quot;);    Chopsticks c4 = new Chopsticks(&quot;c4&quot;);    Chopsticks c5 = new Chopsticks(&quot;c5&quot;);    Phil p1 = new Phil(c1, c2);    Phil p2 = new Phil(c2, c3);    Phil p3 = new Phil(c3, c4);    Phil p4 = new Phil(c4, c5);    Phil p5 = new Phil(c5, c1);    p1.start();    p2.start();    p3.start();    p4.start();    p5.start();}</code></pre><h2 id="2-活锁"><a href="#2-活锁" class="headerlink" title="2. 活锁"></a>2. 活锁</h2><p>活锁出现在两个线程互相改变对方的结束条件，最后谁也无法结束。两个线程都没有停止，但是却都无法继续下去。</p><pre><code class="java">public class LiveLock {    // 使用volatile的变量，作为结束条件    static volatile int count = 10;    // 锁，一个Object就行    static final Object lock = new Object();    public static void main(String[] args) {        new Thread(() -&gt; {            while(count &gt; 0) {                try {                    Thread.sleep(500);                } catch (InterruptedException e) {                    e.printStackTrace();                }                // 改变结束条件                count--;                System.out.println(&quot;[Thread 1] count: &quot; + count);            }        }).start();        new Thread(() -&gt; {            while(count &lt; 20) {                try{                    Thread.sleep(500);                } catch (InterruptedException e) {                    e.printStackTrace();                }                count++;                System.out.println(&quot;[Thread 2] count: &quot; + count);            }        }).start();    }}</code></pre><h2 id="3-饥饿"><a href="#3-饥饿" class="headerlink" title="3. 饥饿"></a>3. 饥饿</h2><p>一个线程由于优先级太低，始终得不到CPU调度执行，也不能够结束。</p><h1 id="BlockingQueue"><a href="#BlockingQueue" class="headerlink" title="BlockingQueue"></a>BlockingQueue</h1><h1 id="java内存模型"><a href="#java内存模型" class="headerlink" title="java内存模型"></a>java内存模型</h1><h2 id="1-什么是-Java-内存模型"><a href="#1-什么是-Java-内存模型" class="headerlink" title="1. 什么是 Java 内存模型"></a>1. 什么是 Java 内存模型</h2><p>内存模型主要是<strong>定义程序中各个变量的访问规则</strong>，即：在JVM中将变量存储到内存中和从内存中取出来这样的底层细节。</p><p>JMM规定所有的变量都存储在主内存中，每个线程都有自己的工作内存，在工作内存中保存了该线程用到的变量的主内存副本。线程对变量所做的操作都是对这个副本做的，不能直接读写主内存的变量，不同线程之间也无法直接访问对方的工作内存的变量，<strong>线程间变量值的传递需要通过主内存完成</strong></p><p>JMM是围绕在并发过程中，如何处理原子性、可见性、有序性这三个特性来建立的。</p><h2 id="2-原子性、可见性、有序性"><a href="#2-原子性、可见性、有序性" class="headerlink" title="2. 原子性、可见性、有序性"></a>2. 原子性、可见性、有序性</h2><ul><li><p><strong>原子性</strong></p><p><strong>定义</strong>：指令在执行的时候不会受到线程上下文切换的影响（一个操作要么全部执行，要么全不执行，在执行的时候不会被打断）</p><p>Java规范规定所有变量写操作都是原子的，32位Java虚拟机中的long和double变量写操作不是原子的，因为long和double是64位的，如果多个线程同时并发的执行long i = 30，long是64位的，就会导致有的线程在修改i的高32位，有的线程在修改i的低32位，多线程并发给long类型的变量进行赋值操作，在32位的虚拟机下，就可能会导致<strong>多线程给long i = 30赋值之后，导致i的值不是30</strong></p><p><strong>volatile可以保证long 和 double类型变量写操作的原子性</strong>，但是对于i++等比较复杂的一些场景，是没有办法保证原子性的。</p><blockquote><p>比如说，i = x * y 这个运算，它的计算过程是：</p><ol><li>先把x和y分别从主内存里加载到工作内存里面来</li><li>然后再从工作内存里加载出来执行计算（处理器）</li><li>计算后的结果写回到工作内存里去</li><li>最后还要从工作内存里把i的最新的值刷回主内存</li></ol></blockquote><p>因此为了保证一些简单的变量赋值的原子性，可以采用Atomic或者用CAS，使用volatile的开销相对来说是比较大的。</p></li><li><p><strong>可见性</strong></p><p><strong>定义</strong>：多个不同的线程会将共享数据读取到各自的缓存中，导致一个线程操作完成数据后，对另一个线程不能立即可见</p></li><li><p><strong>有序性</strong></p><p><strong>定义</strong>：由于编译优化，指令可能会受到CPU指令重排序的影响，将某些不能先执行的指令重排到了前面而先执行了，比如JIT即时编译会造成大量的指令重排</p></li></ul><h1 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h1><p>要讲清楚volatile关键字，必须要先从JMM的原子性、可见性、有序性三个角度说起，要说这三个特性，就需要先讲到内存模型，在将内存模型讲清楚之后，再来讲volatile关键字的原理。</p><p>volatile关键字是用来解决可见性和有序性问题的，加上volatile最主要的目的是让变量具备可见性</p><p>作用：保证可见性、解决有序性问题</p><h2 id="1-可见性原理"><a href="#1-可见性原理" class="headerlink" title="1. 可见性原理"></a>1. 可见性原理</h2><p>对于volatile写操作，会将这个值通过flush操作刷回主存，同时还会发送一个消息到主线bus，通知其他处理器某个变量的值被修改了。其他处理器收到这个消息之后，会把这个值在自己工作内存中的副本给失效掉。</p><p>对于volatile读操作，因为有MESI缓存一致性协议，各个CPU都会对总线进行嗅探，自己本地缓存中的数据是否被修改。如果发现别人修改了某个缓存的数据，CPU就会将自己的本地缓存数据过期掉，然后本CPU上的线程再执行读取操作的时候就会通过refresh操作从CPU中读取数据了</p><h2 id="2-有序性原理"><a href="#2-有序性原理" class="headerlink" title="2. 有序性原理"></a>2. 有序性原理</h2><p>通过禁止指令重排，可以通过内存屏障来解决，内存屏障是字节码之间的一个屏障，不允许屏障前后的指令交换顺序。</p><p>关于内存屏障，有两种不同的理解方式，一种是Load和Store屏障的排列组合构成的4种屏障类型，另一种是Load、Store、Acquire、Release这四个屏障，不过他们的本质是一样的，只不过说法不同</p><h3 id="2-1-Load和Store屏障的排列组合"><a href="#2-1-Load和Store屏障的排列组合" class="headerlink" title="2.1 Load和Store屏障的排列组合"></a>2.1 Load和Store屏障的排列组合</h3><ul><li>LoadLoad屏障：屏障后的Load指令要保证屏障前的Load指令执行完毕</li><li>StoreStore屏障：屏障后的Store指令要保证屏障前的Store指令执行完毕</li><li>LoadStore屏障：屏障后的Store指令要保证屏障前的Load指令执行完毕</li><li>StoreLoad屏障：屏障后的Load指令要保证屏障前的Store指令执行完毕</li></ul><p>对于Volatile而言：</p><ol><li><p>volatile写操作：写操作前加StoreStore屏障，写操作后加StoreLoad屏障</p><p>表示：上面写完了我才写，我写完了别人才能读</p></li><li><p>volatile读操作：读操作前加LoadLoad屏障，读操作后加LoadStore屏障</p><p>表示：上面读完了我才读，我读完了别人才能写</p></li></ol><h3 id="2-2-Load、Store、Acquire、Release"><a href="#2-2-Load、Store、Acquire、Release" class="headerlink" title="2.2 Load、Store、Acquire、Release"></a>2.2 Load、Store、Acquire、Release</h3><ol><li>对于volatile的写操作，前面会加一个Release屏障，然后之后会加上一个Store屏障，保证volatile写操作跟Release屏障之前的任何读写操作都不会指令重排，然后Store屏障保证了，写完数据之后立刻会执行flush操作来将数据从工作内存刷到主存中</li><li>对于volatile的读操作，前面会加一个Load屏障，读完之后会加一个Acquire屏障，禁止volatile的读操作与Acquire屏障之后的任何读写操作都不会指令重排，前面的Load屏障保证了对这个变量进行读取时，如果被别的处理器修改过了，必须执行refresh操作从主存中将最新的数据加载到自己的工作内存中，保证读取到的是最新数据</li></ol><p>这里的Acquire屏障其实就是LoadLoad屏障+LoadStore屏障，Release屏障就是StoreStore屏障+StoreLoad屏障</p><h2 id="3-happens-before"><a href="#3-happens-before" class="headerlink" title="3. happens before"></a>3. happens before</h2><p>程序中的代码如果满足条件，就一定会按照这个规则来保证指令的顺序。规则制定了<strong>在一些特殊情况下，不允许编译器、指令器对你写的代码进行指令重排，必须保证你的代码的有序性</strong>，但是如果没满足上面的规则，那么就可能会出现指令重排，就这个意思。</p><ol><li><strong>程序次序规则</strong>：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作</li><li><strong>锁定规则</strong>：一个unLock操作先行发生于后面对同一个锁的lock操作，比如说在代码里有先对一个lock.lock()，lock.unlock()，lock.lock()不会放在unlock()后面</li><li><strong>volatile变量规则</strong>：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作，volatile变量写，再是读，必须保证是先写，再读</li><li><strong>传递规则</strong>：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C</li><li><strong>线程启动规则</strong>：Thread对象的start()方法先行发生于此线程的每个一个动作，thread.start()，thread.interrupt()</li><li><strong>线程中断规则</strong>：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生</li><li><strong>线程终结规则</strong>：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行</li><li><strong>对象终结规则</strong>：一个对象的初始化完成先行发生于他的finalize()方法的开始</li></ol><h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h1><h2 id="1-简述"><a href="#1-简述" class="headerlink" title="1. 简述"></a>1. 简述</h2><p>synchronized用来进行线程同步，也可以说是加锁，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。</p><p>操作系统实现加锁需要从用户态转换到内核态，这个状态之间的转换需要较长的时间，早期的JDK对synchronized的优化非常有限，导致了时间开销成本较高。在JDK1.6之后，对锁进行了大量的优化，引入了自旋锁、锁升级、偏向锁等技术操作来减少锁的操作开销</p><h2 id="2-使用位置"><a href="#2-使用位置" class="headerlink" title="2. 使用位置"></a>2. 使用位置</h2><ol><li>同步普通方法，锁是当前实例的对象</li><li>同步静态方法：锁是当前类的class文件</li><li>同步方法块：锁是自定义的对象</li></ol><h2 id="3-原理"><a href="#3-原理" class="headerlink" title="3. 原理"></a>3. 原理</h2><p>synchronized的底层<strong>通过两个 JVM 字节码指令monitorenter，monitorexit 、 Monitor 对象、以及内存屏障实现的</strong>。</p><p>其中原子性主要是通过monitor对象来实现，可见性主要是通过Load、Store内存屏障实现，有序性主要是通过Acquire、Release内存屏障来实现</p><p>JVM将monitorenter指令插入到synchronized同步代码块的开始位置，monitorexit指令插入到synchronized同步代码块的结束位置，保证每一个monitorenter都有一个monitorexit与之相对应。</p><p><strong>monitorenter的作用：获取到锁对象的监视器monitor</strong>，它的底层是一个CAS操作。</p><p><strong>总的来说synchronized的流程可以分成以下几步：</strong></p><ol><li>首先monitorenter指令是插入在同步代码块开始的位置的</li><li>进入同步代码块之后添加Load屏障来执行refresh操作，强制将数据从主存中读取到工作内存</li><li>然后加上Acquire屏障，用来防止同步代码块中的读操作与外部的读写操作发生指令重排</li><li>在离开同步代码块即执行monitorexit之前，加上Release屏障，用来防止同步代码块中的写操作与外部的读写操作发生指令重排</li><li>同步代码块执行完成后，就到了monitorexit字节码指令的位置</li><li>在monitorexit字节码指令之后加上一层Store屏障，用来执行flush操作，将数据从工作内存中刷回主存</li></ol><pre><code class="java">synchronized() { // monitorenter字节码指令    // Load屏障    // Acquire屏障    // Release屏障} // monitorexit字节码指令// Store屏障</code></pre><p><strong>对象头的markword中包含了monitor指针</strong>，指向一个monitor对象，在Monitor中有几个比较重要的参数：</p><ul><li>WaitSet：表示之前获取过锁，但是由于条件不满足又进入Waiting状态的线程</li><li>EntryList：处于Blocked状态的线程列表</li><li>Owner：当前持有锁，正在运行的线程（只有1个）</li><li>Recursions：表示当前锁重入的次数</li></ul><h3 id="3-1-保证原子性原理"><a href="#3-1-保证原子性原理" class="headerlink" title="3.1 保证原子性原理"></a>3.1 保证原子性原理</h3><p>执行到monitorenter指令时，线程通过锁对象的MarkWord获取 Monitor 对象，判断Monitor对象中的Owner是否为空：</p><ul><li>如果为空，将Monitor中的Owner置为当前线程，通过CAS将Recursions重入次数置为1。</li><li>如果不为空，则先判断Owner是否为自己，如果是的话，就将重入次数加1，否则将会进入EntryList中阻塞。</li></ul><p>执行完成后执行的字节码指令为 <code>monitorexit</code>，将Owner恢复，并且重置Recursions重入次数，然后唤醒 EntryList 中的线程来竞争锁，注意，这里的<strong>竞争是非公平的</strong>，也就意味着此时来了一个新的线程来获取锁，这个新的线程是可以抢先于EntryList中的线程优先获取到锁的。</p><p><strong>如果同步代码块发生了异常，也会释放锁</strong>。检测一个范围内，如果出现了异常，也会去释放锁。</p><h4 id="3-1-1-wait的处理"><a href="#3-1-1-wait的处理" class="headerlink" title="3.1.1 wait的处理"></a>3.1.1 wait的处理</h4><p>如果获取锁的线程执行wait，就会将计数器递减，同时_owner设置为null，然后自己进入waitset中等待唤醒，别人获取了锁执行notify的时候就会唤醒waitset中的线程竞争尝试获取锁</p><h4 id="3-1-2-可重入原理"><a href="#3-1-2-可重入原理" class="headerlink" title="3.1.2 可重入原理"></a>3.1.2 可重入原理</h4><p>每一个锁关联一个线程持有者Owner和计数器，当计数器为0表示没有线程持有锁，当某一个线程请求成功后，JVM会记下该锁的持有线程，并且将计数器+1。此时其他线程请求该锁时，必须等待。持有该锁的线程如果再次请求这个锁，就会将计数器+1，如果退出代码块，计数器将会-1。如果计数器减为零，则释放该锁。</p><h3 id="4-可见性原理"><a href="#4-可见性原理" class="headerlink" title="4. 可见性原理"></a>4. 可见性原理</h3><p>通过内存屏障（<strong>Load屏障和Store屏障</strong>）来保证可见性</p><ul><li>在进入同步代码块的时候，会执行monitorenter字节码指令，在这个字节码指令之后会加一层load屏障，强制执行refresh操作，从主存中读取变量最新的值。</li><li>在离开同步代码块的时候，会执行monitorexit字节码指令，在这个字节码指令之后会加上一层read屏障，强制执行flush操作，将工作内存的修改写入主存中</li></ul><h3 id="5-有序性原理"><a href="#5-有序性原理" class="headerlink" title="5. 有序性原理"></a>5. 有序性原理</h3><p>通过内存屏障（<strong>Acquire屏障和Release屏障</strong>）来保证有序性的</p><ul><li>在monitorenter指令执行之后，首先加的时load屏障保证可见性，在load屏障加完之后会加一层acquire屏障，作用是禁止synchronized内部的读操作和外部的任何读写操作之间发生指令重排</li><li>在monitorexit指令执行之前，会加一层release屏障，作用是禁止synchronized内部的写操作和外部的任何读写操作之间发生指令重排</li></ul><p>但是synchronized同步代码块内部也可能会发生指令重排</p><h2 id="5-synchronized-与-volatile"><a href="#5-synchronized-与-volatile" class="headerlink" title="5. synchronized 与 volatile"></a>5. synchronized 与 volatile</h2><ol><li>关于三大特性：<ul><li>volatile可以保证<strong>可见性与有序性</strong>，对于原子性，只能保证double long类型变量的赋值操作是原子性的，对于一些复杂的操作比如i++是没有办法保证原子性的；</li><li>synchronized可以保证变量修改的<strong>可见性、原子性和有序性</strong>，需要注意的时这个有序性指的是同步代码块内部和外部之间不会发生指令重排，而在同步代码块内部是不保证有序性的，synchronized内部的代码依然会重排。</li></ul></li><li>级别：<ul><li>volatile只能用在变量级别</li><li>synchronized可以用在变量、方法上</li></ul></li></ol><h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><h2 id="1-乐观锁、悲观锁"><a href="#1-乐观锁、悲观锁" class="headerlink" title="1. 乐观锁、悲观锁"></a>1. 乐观锁、悲观锁</h2><ul><li>CAS基于乐观锁的思想：指的是最乐观的估计，不怕其他线程来修改共享变量，就算修改了也没关系，可以重新再试</li><li>synchronized基于悲观锁：防着其他线程修改共享变量，仅自己可以修改变量，其他人不允许使用</li></ul><h2 id="2-用户态与内核态"><a href="#2-用户态与内核态" class="headerlink" title="2. 用户态与内核态"></a>2. 用户态与内核态</h2><p>JVM是运行在用户空间的，OS运行在内核态。JDK早期版本的synchronized是重量级锁，因为申请锁资源必须经过内核，经过系统调用。</p><h2 id="3-锁升级"><a href="#3-锁升级" class="headerlink" title="3. 锁升级"></a>3. 锁升级</h2><p>因为一个方法设为synchronized，但是只有一个线程用了它，就给他上重量级锁，就需要经过内核态才能完成，开销是很大的。如果使用偏向锁、轻量级锁，则不需要经过内核，开销较小，在没必要上重量级锁的时候可以节省一定的开销</p><p><strong>锁升级的过程</strong>：</p><p>由于JVM可以设置是否开启偏向锁，因此根据是否启用偏向锁有两种不同的锁升级流程</p><ol><li><p><strong>开启了偏向锁</strong>：</p><ul><li><p>新创建一个对象，由于开启了偏向锁，但是又不知道偏向哪个线程，此时的状态变化为匿名偏向。</p></li><li><p>接着，一个线程给该对象加锁，此时该对象就从匿名偏向升级为偏向锁，并且将线程的ID写入对象的markword中</p></li><li><p>然后，又来了新的线程来竞争锁，JVM会将markword上的偏向线程ID给消除，让这两个线程使用CAS去竞争这把锁，即轻度竞争，将偏向锁升级为轻量级锁。</p></li><li><p>如果是重度竞争则升级为重量级锁，同时，如果一开始是轻量级锁，由于竞争越来越激烈，是可以升级为重量级锁的</p><p>在JDK1.6之前，升级为重量锁的条件有2个：某线程自旋次数超过10次，或者自旋的线程个数超过CPU核数的一半时，在JDK1.6之后，这个升级条件由JDK根据线程的情况来决定，采用自适应自旋。</p></li></ul></li><li><p><strong>没有开启偏向锁</strong></p><ul><li>新创建的对象就是一个普通的对象</li><li>当有对象给它加锁时，就升级为轻量级锁</li></ul></li></ol><h2 id="4-锁消除"><a href="#4-锁消除" class="headerlink" title="4. 锁消除"></a>4. 锁消除</h2><p>是JIT对synchronized锁做的优化，在编译的时候，通过逃逸分析技术，来分析synchronized锁对象，是不是只可能被一个线程来加锁，如果没有第二个线程来竞争锁，则编译的时候就不加monitorenter和monitorexit指令了</p><p>仅仅一个线程来争用锁的情况会进行锁消除</p><h2 id="5-锁粗化"><a href="#5-锁粗化" class="headerlink" title="5. 锁粗化"></a>5. 锁粗化</h2><p>JIT编译器如果发现代码中有连续多次加锁解锁的代码，会将他们合并成一个。比如下面这样</p><pre><code class="java">synchronized(this) {}synchronized(this) {}synchronized(this) {}</code></pre><h2 id="6-偏向锁"><a href="#6-偏向锁" class="headerlink" title="6. 偏向锁"></a>6. 偏向锁</h2><p>monitorenter和monitorexit是通过CAS操作加锁和解锁的，开销较大，因此如果发现大概率只有一个线程会竞争这个锁，就会给锁维护一个偏好bias，后面它加锁和解锁都是基于偏向来执行，不需要通过CAS</p><p>如果发现有偏好之外的线程来竞争锁，就要收回之前的偏好。</p><h2 id="7-轻量级锁"><a href="#7-轻量级锁" class="headerlink" title="7. 轻量级锁"></a>7. 轻量级锁</h2><p>如果偏向锁没能成功实现，就是因为竞争太频繁，就尝试采用轻量级锁的方式来加锁，将markword中的一个轻量级锁指针指向持锁线程，然后判断一下是不是自己加的锁，如果是自己就执行代码，如果不是自己就是加锁失败，此时升级为重量级锁。</p><h2 id="8-适应性锁"><a href="#8-适应性锁" class="headerlink" title="8. 适应性锁"></a>8. 适应性锁</h2><p>如果各个线程持有锁的时间很短，那么一个线程竞争不到锁就会暂停，发生上下文切换，让其他线程来执行，如果其他线程很快释放了锁，然后暂停的线程重新被唤醒。</p><p>这样会导致频繁的上下文切换。</p><p>对这种持有锁时间很短的情况，是可以采取忙等策略的，也就是一个线程没有竞争到锁，进入一个while循环不停等待，不会暂停，不会发生上下文切换，等到机会获取锁继续执行。</p><h1 id="LockSupport"><a href="#LockSupport" class="headerlink" title="LockSupport"></a>LockSupport</h1><h2 id="1-park、unpark"><a href="#1-park、unpark" class="headerlink" title="1. park、unpark"></a>1. park、unpark</h2><h1 id="Java-中用到的线程调度算法是什么"><a href="#Java-中用到的线程调度算法是什么" class="headerlink" title="Java 中用到的线程调度算法是什么"></a>Java 中用到的线程调度算法是什么</h1><p>抢占式。一个线程用完 CPU 之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。</p><h1 id="什么是自旋"><a href="#什么是自旋" class="headerlink" title="什么是自旋"></a>什么是自旋</h1><p>很多 synchronized 里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然 synchronized 里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在 synchronized 的边界做忙循环，这就是自旋。如果做了多次忙循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。</p><h1 id="线程同步的方式"><a href="#线程同步的方式" class="headerlink" title="线程同步的方式"></a>线程同步的方式</h1><h1 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h1><h2 id="1-CAS原理"><a href="#1-CAS原理" class="headerlink" title="1. CAS原理"></a>1. CAS原理</h2><p>CAS，全称为 Compare and Swap，即比较-替换。假设有三个操作数：当前内存中的值 V、旧的预期值 A、要修改的值B，当且仅当预期值 A 和当前内存中的值 V 相同时，才会将内存值修改为 B 并返回 true，否则什么都不做并返回 false。</p><p>CAS 一定要 volatile 变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次 CAS 操作失败，永远都不可能成功。</p><p>从最本质上来说，CAS的原子性是通过CPU指令来实现的。<strong>CAS的底层是 <code>lock cmpxchg</code> 指令（x86架构下），在单核CPU和多核CPU下都能保证【比较和交换】的原子性</strong>，这也是保证CAS正确性的一个基础。</p><h2 id="2-为什么CAS无锁高效"><a href="#2-为什么CAS无锁高效" class="headerlink" title="2. 为什么CAS无锁高效"></a>2. 为什么CAS无锁高效</h2><p>因为无锁状态下，即使重试，线程也一直在运行，<strong>减少了上下文切换的时间</strong>，但是线程一直运行需要由CPU的支持，如果线程数&gt;CPU的核数，也是会发生线程切换的，这时候的效率就不高了。</p><h2 id="3-ABA问题"><a href="#3-ABA问题" class="headerlink" title="3. ABA问题"></a>3. ABA问题</h2><p>如果一个变量V初次读取的时候值是A，并且在准备赋值的时候检查到它的值仍然是A，但是这个值可能被其他线程先修改为B，然后再修改为A，这时候虽然最终的结果是A，但是他被修改过了。</p><p>解决的方案是加上时间戳来标记不同阶段的值。比如可以使用AtomicStampedReference，通过控制变量值的版本来保证CAS的正确性。也可以通过传统的加synchronized的方式来解决。</p><h1 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h1><h2 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h2><p>AQS是AbstractQueuedSynchronizer，<strong>抽象队列同步器</strong>，是基于队列的一种多线程同步组件，用来构建锁和其他同步对象，多个线程同时来加锁的时候只有一个线程能够加锁成功，其他的线程会进入等待队列。</p><p>其中有两个重要的成员：</p><ul><li>int类型的成员变量state来表示同步状态</li><li>FIFO的等待队列，对前来获取资源的线程进行排序</li></ul><h2 id="2-原理（流程）"><a href="#2-原理（流程）" class="headerlink" title="2. 原理（流程）"></a>2. 原理（流程）</h2><ol><li>获取锁：假设在某个场景下有很多个线程过来都要执行lock.lock()来获取锁，他们尝试通过CAS将state设置为1，在CPU的硬件层面可以保证同一时间只有1个线程可以成功，然后这个成功加锁的线程，会将AQS的加锁线程设置为自己。其他没有获取到锁的线程将会进入FIFO等待队列中挂起</li><li>释放锁：就是将state设置为0，将AQS的当前线程设置为null，并且唤醒等待队列的队头元素，队头元素继续使用CAS获取锁。默认情况下使用<strong>非公平锁</strong>，也就是说虽然队头线程被唤醒，但是他还没来得及加锁，就有另一个线程来竞争锁，这个新来的线程也是有可能竞争成功的。而公平锁则新线程进来之后需要先判断等待队列中是否有人在等待，如果有的话就需要先入队，让队头的线程被唤醒去加锁。</li></ol><h2 id="3-使用"><a href="#3-使用" class="headerlink" title="3. 使用"></a>3. 使用</h2><p>AQS是一个抽象类，其本身没有实现任何同步接口，仅定义了同步状态的获取和设置方法</p><ul><li>getState 用于获取同步状态的信息</li><li>setState、compareAndSetState 用于设置同步状态，后者是通过CAS操作来设置state变量的</li></ul><p>不同的自定义同步器争用共享资源的方式也不同。自定义<strong>同步器</strong>在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：</p><p>AQS使用了<strong>模板设计模式</strong>，在AQS抽象类中实现了一些公用的方法，仅仅独占或共享的方式需要自己定义。如果某个自定义同步器要使用AQS，则需要重写几个AQS提供的方法</p><ol><li>isHeldExclusively()：判断线程是否正在独占资源</li><li>tryAcquire</li><li>tryRelease</li><li>tryAcquireShared</li><li>tryReleaseShared</li></ol><h2 id="4-访问方式"><a href="#4-访问方式" class="headerlink" title="4. 访问方式"></a>4. 访问方式</h2><p>AQS 有独占和共享两种访问模式，独占指的是仅1个线程可以访问资源，而共享指的是有多个线程可以访问资源。</p><p>独占和共享的模式可以设置，通过state的数值来表现出来的</p><p>JUC中</p><ul><li>ReentrantLock与CyclicBarrier为独占锁，</li><li>CountDownLatch与Semaphore为共享锁，</li><li>ReentrantReadWriteLock中writeLock为独占锁，ReadLock为共享锁。</li></ul><p>AQS供<strong>自定义同步组件</strong>继承使用。</p><h2 id="5-可重入"><a href="#5-可重入" class="headerlink" title="5. 可重入"></a>5. 可重入</h2><p>当一个线程A获取锁之后，在释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。</p><h1 id="JUC"><a href="#JUC" class="headerlink" title="JUC"></a>JUC</h1><h2 id="1-ReentrantLock"><a href="#1-ReentrantLock" class="headerlink" title="1. ReentrantLock"></a>1. ReentrantLock</h2><p>ReentrantLock是一个独占锁，其实现的基础就是AQS，流程为：</p><ul><li>state初始化为0，表示未锁定的状态，A线程lock的时候，会调用tryAcquire通过CAS尝试获取锁（去修改state属性的值），如果此时已经有线程占了锁（state不等于0），就要先判断占有锁的线程是不是当前线程（通过exclusiveOwnerThread来获取当前持有锁的线程），如果是，就将state+1，如果不是，则将其加入AQS队列并挂起如果获取成功。</li><li>当一个线程获取锁成功之后，其他线程再tryAcquire就会失败，并且加入AQS的CLH队列中挂起。</li><li>直到A线程执行unlock直到state=0，才算是释放掉该锁。</li><li>当锁被释放时，排在CLH队首的线程B会被唤醒，然后尝试获取锁。此时如果同时还有另一个线程C来尝试获取锁，则：<ul><li>如果是非公平锁：线程B和线程C会发生竞争，新来的线程可能会获取到锁</li><li>如果是公平锁：新来的线程C会将自己加入到队列尾部，并且由队首的线程先获取到锁</li></ul></li></ul><p><strong>实现原理可以概括为</strong>：先通过CAS尝试获取锁（去修改state属性的值），如果此时已经有线程占了锁，就要先判断占有线程的锁是不是当前线程，如果不是，则将其加入AQS队列并挂起，当锁被释放时，排在队列头部的线程被唤醒，然后再用CAS尝试获得锁，同时根据其公平或非公平的设置来与新来的线程进行竞争。</p><p><strong>公平与非公平</strong>：</p><p>ReentrantLock中，公平锁与非公平锁的区别就在于tryAcquire方法的实现</p><p>公平锁在tryAcquire的时候，<strong>会先检查AQS队列中是否有前驱结点，如果没有才会去竞争</strong></p><h3 id="1-1-synchronized-和-ReentrantLock-的区别"><a href="#1-1-synchronized-和-ReentrantLock-的区别" class="headerlink" title="1.1 synchronized 和 ReentrantLock 的区别"></a>1.1 synchronized 和 ReentrantLock 的区别</h3><p>ReentrantLock可以分为公平和非公平的实现，其默认的实现为非公平的，而synchronized只能是非公平的。</p><h2 id="2-ReentrantReadWriteLock"><a href="#2-ReentrantReadWriteLock" class="headerlink" title="2. ReentrantReadWriteLock"></a>2. ReentrantReadWriteLock</h2><p>在没有任何读写锁时，才可以获得写锁，如果一直有读锁存在，则无法执行写锁，导致饥饿。</p><p>定义是：当读操作远高于写操作时，可以使用读写锁，让读-读操作可以并发，提高性能，而读-写或者写-写操作则会互斥</p><h2 id="3-Condition"><a href="#3-Condition" class="headerlink" title="3. Condition"></a>3. Condition</h2><p>通过newCondition方法创建Condition对象，其前提是实现AQS的Lock类</p><p>每一个Condition都有一个等待队列，其中的：</p><ul><li>await方法表示线程从AQS中移除，释放锁，并进入对应的Condition等待队列中等待被signal</li><li>signal方法表示唤醒Condition等待队列的线程，将其加入AQS中，准备去获取锁</li></ul><h2 id="4-CountDownLatch"><a href="#4-CountDownLatch" class="headerlink" title="4. CountDownLatch"></a>4. CountDownLatch</h2><p>用于线程同步协作，等待所有线程完成倒计时</p><p>任务分为N个子线程去执行，<strong>state也初始化为N</strong>（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。</p><pre><code class="java">CountDownLatch countDownLatch = new CountDownLatch(3);new Thread(() -&gt; {    try {Thread.sleep(1000);} catch (InterruptedException e){e.printStackTrace();}    System.out.println(&quot;t1 OK&quot;);    countDownLatch.countDown();}).start();new Thread(() -&gt; {    try {Thread.sleep(2000);} catch (InterruptedException e){e.printStackTrace();}    System.out.println(&quot;t2 OK&quot;);    countDownLatch.countDown();}).start();new Thread(() -&gt; {    try {Thread.sleep(3000);} catch (InterruptedException e){e.printStackTrace();}    System.out.println(&quot;t3 OK&quot;);    countDownLatch.countDown();}).start();try {    countDownLatch.await();    System.out.println(&quot;All OK!!!&quot;);} catch (InterruptedException e) {    e.printStackTrace();}</code></pre><p>注意：CountDownLatch需要在计数器=0之后新建一个对象才可以继续使用</p><h2 id="5-Semaphore"><a href="#5-Semaphore" class="headerlink" title="5. Semaphore"></a>5. Semaphore</h2><p>即信号量，用来限制能够同时访问共享资源的线程数量上限</p><p>使用方法是在构造方法中指定最多允许的线程数，然后在线程中使用acquire和release方法</p><pre><code class="java">// 同一个时刻只允许三个线程同时访问共享资源// 第二个参数表示是否公平，可以不写Semaphore s = new Semaphore(3);for (int i = 0; i &lt; 10; ++i) {    new Thread(() -&gt; {        try {            s.acquire();        } catch (InterruptedException e) {            e.printStackTrace();        } finally {            s.release();        }    }).start();}</code></pre><p>应用：使用Semaphore限流，在访问的高峰期，让请求线程阻塞，高峰期过去后再释放许可。它限制的是线程的数量而不是资源的数量</p><h2 id="6-CyclicBarrier"><a href="#6-CyclicBarrier" class="headerlink" title="6. CyclicBarrier"></a>6. CyclicBarrier</h2><p>等待线程满足某个计数，让线程开启，并卡在await的地方等待，当await的线程数量达到设置的值后，继续执行cb里面设定的操作</p><p>它和CountDownLatch不同的是，它的线程计数可以为0，不必在计数完成后新建对象</p><p>下面这个例子就是，让两个线程开启，第一个线程先卡在 <code>await()</code> 的地方，第二个线程等待1秒之后再执行到 <code>await()</code> 的地方，这样可以更直观的看出 <code>await()</code> 处的线程到达2个的时候，这两个线程可以同时开始往下运行。</p><pre><code class="java">CyclicBarrier cb = new CyclicBarrier(2, ()-&gt;{    System.out.println(&quot;两个线程已执行完毕！&quot;);});new Thread(() -&gt; {    System.out.println(&quot;线程1开始执行&quot;);    try {        cb.await();    } catch (InterruptedException | BrokenBarrierException e) {        e.printStackTrace();    }    System.out.println(&quot;线程1继续执行&quot;);}).start();new Thread(() -&gt; {    System.out.println(&quot;线程2开始执行&quot;);    try {Thread.sleep(1000);} catch (InterruptedException e) {e.printStackTrace();}    try {        cb.await();    } catch (InterruptedException | BrokenBarrierException e) {        e.printStackTrace();    }    System.out.println(&quot;线程2继续执行&quot;);}).start();</code></pre><h1 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h1><p>一般来说系统不会无限制地构建很多个线程，而是构建一个线程池，有一定数量的线程，让他们执行各种的任务，每个线程执行完任务之后不要销毁掉自己，继续去等待执行下一个任务，就可以避免频繁创建、销毁线程造成的性能消耗。</p><p>线程池中的线程执行完一个任务之后，会阻塞在队列，去等待看有没有新的任务过来，如果没有就会一直卡在这里。这时候又来了一个新的任务，它首先检测线程池中已经创建的线程数量，如果小于corePoolSize，则会创建新的线程去执行他。如果当前已经创建的线程数量超过corePoolSize，则<strong>会加到阻塞队列中</strong>，之前阻塞的线程就能拿到任务了。</p><h2 id="1-线程池的五个状态"><a href="#1-线程池的五个状态" class="headerlink" title="1. 线程池的五个状态"></a>1. 线程池的五个状态</h2><ol><li>RUNNING：线程正在运行</li><li>SHUTDOWN：不会接收新任务，但是会处理阻塞队列剩余任务</li><li>STOP：会中断正在执行的任务，并且抛弃阻塞队列任务</li><li>TIDYING：任务全部执行完毕</li><li>TERMINATED：  终结状态</li></ol><h2 id="2-ThreadPoolExecutor"><a href="#2-ThreadPoolExecutor" class="headerlink" title="2. ThreadPoolExecutor"></a>2. ThreadPoolExecutor</h2><p>构造方法</p><pre><code class="java">public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory,                          RejectedExecutionHandler handler)</code></pre><ul><li>corePoolSize：核心线程数目（最多保留的线程数）</li><li>maximumPoolSize：线程池维护线程的最大数量（将除了核心线程）</li><li>keepAliveTime：生存时间——针对救急线程</li><li>unit：时间单位——针对救急线程</li><li>workQueue：阻塞队列</li><li>threadFactory：线程工厂——可以为线程创建时取名字</li><li>handler：拒绝策略</li></ul><h3 id="2-1-线程池中的线程分类"><a href="#2-1-线程池中的线程分类" class="headerlink" title="2.1 线程池中的线程分类"></a>2.1 线程池中的线程分类</h3><p>在线程池参数中有2个size，一个是核心线程数，一个是最大线程数，这两个之间有一个差值，就是用最大线程数减去核心线程数，将这个差值的线程记为救急线程。</p><p>一开始都是没有被创建的（懒惰创建），有任务来的时候，优先交给核心线程去执行，如果核心线程已满，则任务放入阻塞队列中，<strong>如果阻塞队列也满的话，将会交给救急线程去执行任务</strong>。如果任务执行完毕，则救急线程在一段时间后（保活时间），就会销毁。而<strong>核心线程是没有生存时间的</strong>，只要被创建出来就会一直存在。</p><p>如果救急线程也满了，会执行拒绝策略。</p><h3 id="2-2-拒绝策略"><a href="#2-2-拒绝策略" class="headerlink" title="2.2 拒绝策略"></a>2.2 拒绝策略</h3><ol><li><strong>CallerRunsPolicy</strong>：提交任务的线程自己去执行该任务。</li><li><strong>AbortPolicy</strong>：默认的拒绝策略，会 throws RejectedExecutionException。</li><li><strong>DiscardPolicy</strong>：放弃本次任务，相较于第二种，行为类似，但是它不会抛出异常。</li><li><strong>DiscardOldestPolicy</strong>：丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，新任务取而代之。</li></ol><p>还有一种策略是可以将任务持久化，写入磁盘中，当有条件执行的时候再从磁盘中获取任务并执行之。</p><h3 id="2-3-执行顺序（增长策略）"><a href="#2-3-执行顺序（增长策略）" class="headerlink" title="2.3 执行顺序（增长策略）"></a>2.3 执行顺序（增长策略）</h3><p>当一个任务通过 <code>execute(Runnable)</code> 的方式提交后：</p><ol><li>如果此时线程池中的线程数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也会创建新的线程来处理被添加的任务</li><li>如果此时线程池中的数量等于corePoolSize，但是缓冲队列workQueue未满，那么任务被放入缓冲队列</li><li>如果此时线程池中的数量大于corePoolSize，并且缓冲队列workQueue也满了，但是线程池中的线程数量小于maximumPoolSize，则创建新的线程来处理被添加的任务</li><li>如果此时的线程池的数量大于corePoolSize，并且workQueue满了，线程池中的线程数量等于maximumPoolSize，则会执行指定的拒绝策略来处理此任务。</li></ol><p>也就是说，处理任务的优先级为：核心线程、workQueue，最大线程。如果三者都满了，则使用handler来处理被拒绝的任务</p><p>当线程池中的数量大于corePoolSize时，如果某个线程空闲时间超过keepAliveTime，则线程会被终止，线程数量将会被减少为corePoolSize。</p><h3 id="2-4-提交任务"><a href="#2-4-提交任务" class="headerlink" title="2.4 提交任务"></a>2.4 提交任务</h3><ol><li><p><strong>execute</strong></p><p>提交无返回值的任务</p></li><li><p><strong>submit</strong></p><p>提交有返回值的任务</p></li></ol><p>这两种提交任务的方法最终调用的都是execute方法，这里的submit方法相当于把任务包装了一下，会将Runnable和Callable全部包装成FutureTask，submit方法提交过后，会返回给用户一个Future句柄，这个句柄就是FutureTask对象，这样，外部的线程就可以通过调用Future句柄的get方法来获取结果。这个get方法会阻塞在这里等待获取结果，直到FutureTask真正被执行完，阻塞可以拿到结果为止。</p><p>要交给线程池的任务是封装在Runnable或者Callable中的，其中的run()方法和call()方法分别作为线程执行的入口。其中Callable可以返回值，通过FutureTask来实现</p><h3 id="2-5-对比Runnable、Callable、FutureTask"><a href="#2-5-对比Runnable、Callable、FutureTask" class="headerlink" title="2.5 对比Runnable、Callable、FutureTask"></a>2.5 对比Runnable、Callable、FutureTask</h3><ol><li><p>Runnable</p><p>其中的run()方法没有返回值，</p><ul><li>Runnable对象可以直接扔给Thread创建线程实例，并且创建的线程实例与Runnable绑定，线程实例调用start()方法时，Runnable任务就开始真正在线程中执行。</li><li>Runnable对象也可以直接扔给线程池对象的execute方法和submit方法，让线程池为其绑定池中的线程来执行。</li><li>Runnable对象也可以进一步封装成FutureTask对象之后再扔给线程池的execute方法和submit方法。</li></ul></li><li><p>Callable</p><p>功能相比Runnable来说少很多，不能用来创建线程，也不能直接扔给线程池的execute方法。但是其中的call方法有返回值。</p></li><li><p>FutureTask</p><p>是对Runnable和Callable的进一步封装，并且这种任务是有返回值的，通过get方法获取。这个get方法可以支持多个线程调用，会查询线程执行的状态，如果当前线程已经执行完成，则直接返回结果，如果没有执行完成，则回加入到等待队列，然后park住，等待线程执行完成被unpark唤醒。</p><p>在FutureTask内，将业务层面提交的Runnable使用适配器模式转换成了Callable接口，只不过转换的这个Callable接口的返回值是一个null，这样调用FutureTask的get方法会拿到一个null值</p><p>相比直接把Runnable和Callable扔给线程池，FutureTask的功能更多，它可以监视任务在池子中的状态。用Runnable和Callable创建FutureTask的方法稍有不同。</p><ul><li><p>使用Callable来创建</p><p>由于call方法本身有返回值，这个返回值也就是Callable对象的返回值，于是可以把这个返回值当做FutureTask的返回值，也就是拿call方法的返回值去初始化outcome字段（是Object的引用，可以理解成引用的Future对象），这个真正初始化过程要在submit方法把任务扔给池子之后并且该任务在池子中分配到了线程并且在线程中执行完了产生了结果之后。但是在这一系列动作之前会有一个伪初始化，submit方法一旦提交任务到线程池马上会得到一个返回值（Future对象，用来指代刚才提交的任务的结果，相当于付钱买了商品但是没货了，暂时拿了一个票据，到了货再真的的取货，这个Future对象就相当于票据），submit方法不会真正等到上面的那一系列动作执行完才返回，所以需要使用这个任务执行结果的那些线程就可以拿着这个返回值（Future对象）去该怎么用就怎么用了。（之所以叫伪初始化，因为call方法也许还没有开始执行，任务还在线程池的任务队列中排队呢。）所以在创建FutureTask的时候只用给FutureTask的构造方法传一个Callable对象既可。</p></li><li><p>使用Runnable来创建</p><p>run方法没有返回值，也就是Runnable任务没有返回值，通过这种方法创建的FutureTask对象并不是把run的返回值当成自己的返回值，而是在创建FutureTask对象时就已经手动指定了这个FutureTask对象的返回值了。若不希望FutureTask对象有真正意义上的返回值，我们可以在调用用FutureTask的构造方法时指定第二个参数为null，对应构造方法使用FutureTask<Void>。</Void></p></li></ul></li></ol><h3 id="2-6-任务队列BlockingQueue"><a href="#2-6-任务队列BlockingQueue" class="headerlink" title="2.6 任务队列BlockingQueue"></a>2.6 任务队列BlockingQueue</h3><ol><li><p><strong>直接提交队列</strong></p><p>设置为synchronousQueue队列，synchronousQueue是一个特殊的BlockingQueue，他没有容量，每执行一个插入操作都会阻塞，需要在执行一个删除操作才能唤醒，反之，每一个删除操作也都要等待对应的插入操作</p></li><li><p><strong>有界的任务队列</strong></p><p>有界的任务队列可以使用ArrayBlockingQueue实现，如果有新的任务要执行时，线程池会创建新的线程，直到创建的线程数量达到corePoolSize，将把线程加入到等待队列中，如果线程池已满，即超过了ArrayBlockingQueue初始化的容量，则会继续创建线程，直到达到maximumPoolSize之后执行拒绝策略</p></li><li><p><strong>无界的任务队列</strong></p><p>可以使用LinkedBlockingQueue实现，在使用的时候，线程池的任务队列<strong>可以无限制的添加新的任务</strong>，此时的maximumPoolSize参数是无效的，因为等待队列都加不满，更不可能创建corePoolSize以上的线程了。这种情况下一定要注意提交与处理之间的协调，否则可能会出现队列中的任务无法被即使消耗而无限增长，最终导致内存被耗尽</p><p><strong>高负载情境下，无界队列很容易导致 OOM，而 OOM 会导致所有请求都无法处理，这是致命问题。所以强烈建议使用有界队列。</strong></p></li><li><p><strong>优先任务队列</strong></p><p>通过PriorityBlockingQueue实现，他也是一个特殊的无界队列，无论添加了多少个任务，也不会多于corePoolSize的数量，只不过他可以按照自定义的顺序来决定出队顺序</p></li></ol><h2 id="3-Executors线程池"><a href="#3-Executors线程池" class="headerlink" title="3. Executors线程池"></a>3. Executors线程池</h2><p>Executors是一个<strong>静态工厂类</strong>，可以快速创建线程，但是通常不建议使用。不建议使用 Executors 的最重要的原因是：</p><ul><li><strong>Executors 提供的很多方法默认使用的都是无界的 LinkedBlockingQueue，高负载情境下，无界队列很容易导致 OOM，而 OOM 会导致所有请求都无法处理，这是致命问题。所以强烈建议使用有界队列。</strong> </li></ul><h3 id="3-1-newFixedThreadPool"><a href="#3-1-newFixedThreadPool" class="headerlink" title="3.1 newFixedThreadPool"></a>3.1 newFixedThreadPool</h3><p>对于Fixed队列来说，它使用的是LinkedBlockingQueue，也就是一个<strong>无界的阻塞队列</strong></p><pre><code class="java">ExecutorService threadPool = Executors.newFixedThreadPool(10);</code></pre><p>特点：</p><ol><li>核心线程数=最大线程数（没有救急线程被创建，因此无需设置超时时间）</li><li>阻塞队列是无界的，可以放置任意数量的任务</li></ol><p>场景：</p><p>适用于业务量已知，相对耗时的任务</p><h3 id="3-2-newCachedThreadPool"><a href="#3-2-newCachedThreadPool" class="headerlink" title="3.2 newCachedThreadPool"></a>3.2 newCachedThreadPool</h3><p>带缓冲的线程池</p><p>特点：</p><ol><li>核心线程数是0，最大线程数是Integer.MAX_VALUE，也就是说创建出来的全都是救急线程。救急线程的空闲生存时间是60s。</li><li>没有容量，<strong>没有线程来取poll是放put不进去的</strong>。也就是说，只要有新任务，才会创建新的线程。</li></ol><p>场景：</p><p>适用于任务数比较密集，但是每个任务执行时间较短的情况。</p><h3 id="3-3-newSingleThreadExecutor"><a href="#3-3-newSingleThreadExecutor" class="headerlink" title="3.3 newSingleThreadExecutor"></a>3.3 newSingleThreadExecutor</h3><p>单线程线程池</p><p>使用场景：</p><p>希望个任务排队执行。线程数固定为1，任务数多于1时会放入无界的队列排队。任务执行完毕，这个唯一的线程也不会被释放。</p><p>区别：</p><ol><li>自己创建一个单线程串行执行任务，如果任务执行失败而终止，那么没有任何的补救措施。而线程池还会新建一个线程，保证线程池的正常工作</li><li>线程池中只能有一个线程</li></ol><h3 id="3-4-newScheduledThreadPool"><a href="#3-4-newScheduledThreadPool" class="headerlink" title="3.4 newScheduledThreadPool"></a>3.4 newScheduledThreadPool</h3><p><strong>延时执行</strong>：</p><p>可以延迟调度，比如如果希望在1秒后执行，可以使用下面的线程池调度方法：</p><pre><code class="java">ScheduledExecutorService pool2 = Executors.newScheduledThreadPool(2);pool2.schedule(() -&gt; {    System.out.println(&quot;666&quot;);    Thread.sleep(1000);}, 1, TimeUnit.SECONDS);</code></pre><p><strong>定时执行</strong>：</p><p>比如每隔一段时间执行一次</p><ul><li><p>第一个时间参数表示<strong>延时时间</strong></p></li><li><p>第二个时间参数表示<strong>执行的时间间隔</strong></p><p>每次执行都需要等上一次任务执行完成才可以重新开始执行，中间的时间间隔可能会被执行时间给抵消掉。</p></li></ul><pre><code class="java">pool2.scheduleAtFixedRate(() -&gt; {    System.out.println(&quot;666&quot;);    Thread.sleep(1000);}, 1, 2, TimeUnit.SECONDS);</code></pre><p><strong>固定延时执行</strong>：</p><p>delay是上一次任务结束的时间开始算的，延时1秒再继续执行下次任务，它与FixedRate有一些区别。</p><pre><code class="java">ScheduledExecutorService pool2 = Executors.newScheduledThreadPool(2);pool2.scheduleWithFixedDelay(() -&gt; {    System.out.println(&quot;任务2&quot;);    try {        Thread.sleep(4000);    } catch (InterruptedException e) {        e.printStackTrace();    }}, 1, 2, TimeUnit.SECONDS);</code></pre><h2 id="4-Worker"><a href="#4-Worker" class="headerlink" title="4. Worker"></a>4. Worker</h2><p>在java线程中，真正执行计算操作的内容是在一个worker类中。</p><p>worker其实就是一个Runable，其也是需要构造成一个Thread对象，然后调用Thread start方法运行的。只不过在worker的run方法中是定一个了一个<code>runWoker</code>的方法。这个方法的主要内容从 for 循环的不停的从task队列中获取对应的runable的task，然后同步调用这个task的run()方法。<strong>其实就是在某个线程中，不停的拿队列中的任务进行执行。</strong></p><h2 id="5-如果线上的机器宕机，阻塞队列中的任务怎么办"><a href="#5-如果线上的机器宕机，阻塞队列中的任务怎么办" class="headerlink" title="5. 如果线上的机器宕机，阻塞队列中的任务怎么办"></a>5. 如果线上的机器宕机，阻塞队列中的任务怎么办</h2><p>实际上来说<strong>阻塞队列中积压的任务都会丢失</strong>。解决方法是：在提交到线程池之前，就在数据库中插入任务的信息，更新它的状态，之后再提交。</p><p>系统重启之后，使用一个后台线程去扫描这个数据库中的线程的信息，把任务的信息读取出来，重新提交到线程池中继续执行。</p><h1 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h1><p>提供了线程内部变量，在多线程环境下，每个线程中的变量都不同于其他线程</p><p>作用：</p><ol><li>传递数据：在同一个线程的不同组件中传递公共变量，使得变量在需要的时候可以直接获取，避免传参造成代码的耦合性问题</li><li>线程隔离：每个线程的变量都独立，互不影响，避免同步带来的性能损失</li></ol><p>spring对事务的处理用到了ThreadLocal</p><h2 id="1-ThreadLocal与synchronized"><a href="#1-ThreadLocal与synchronized" class="headerlink" title="1. ThreadLocal与synchronized"></a>1. ThreadLocal与synchronized</h2><p>二者的处理思路不同：</p><p>synchronized：它是只提供一份变量， 不同的线程要访问这个变量需要排队</p><p>ThreadLocal：每个线程都提供一份变量，不同线程之间的这个变量是隔离的</p><h2 id="2-内部结构"><a href="#2-内部结构" class="headerlink" title="2. 内部结构"></a>2. 内部结构</h2><ol><li>JDK1.8之前，<strong>每个ThreadLocal变量创建一个Map</strong>，用线程作为Map的key，要存储的局部变量作为Map的value</li><li>JDK1.8以后，<strong>每个线程维护一个Map</strong>，用ThreadLocal变量作为Map的key，要存储的局部变量作为Map的value</li></ol><p>好处是：</p><ol><li>每个Map存储的Entry数量变少，在实际的应用中，ThreadLocal的数量少于Thread</li><li>当Thread销毁时，ThreadLocalMap也会跟着一起销毁，减少内存的使用，如果维护的是ThreadLocal的Map，则会一直维护一个Map，即使线程执行完，也不会销毁这个Map</li></ol><h2 id="3-使用-1"><a href="#3-使用-1" class="headerlink" title="3. 使用"></a>3. 使用</h2><p>使用的时候主要是通过4个方法：get、set、remove、initialValue（返回当前线程局部变量的初值，只有重写之后才能使用）</p><h2 id="4-内存泄漏"><a href="#4-内存泄漏" class="headerlink" title="4. 内存泄漏"></a>4. 内存泄漏</h2><p>在线程中，ThreadLocal中有2条引用链：第一条是栈中的ThreadLocal引用，指向它的实体对象，第二条是CurrentThread的引用，指向堆中的CurrentThread，该Thread持有一个ThreadLocalMap，在这个Map中存有一个Entry，这个Entry的key为ThreadLocal，value为实体对象。</p><p>通过两个不同的角度来分析内存泄漏：</p><ol><li><p>假设ThreadLocalMap的Key是强引用</p><img src="/2020/04/25/%E7%AC%94%E8%AE%B0/%E5%A4%9A%E7%BA%BF%E7%A8%8B/image-20200608181429658.png" alt="ThreadLocalMap的Key是强引用" style="zoom: 50%;"><p>如果在业务代码中用完了ThreadLocal，它的引用被回收，此时还有Entry中的key强引用ThreadLocal，导致ThreadLocal实体对象无法被GC</p></li><li><p>假设ThreadLocalMap的key是弱引用</p><img src="/2020/04/25/%E7%AC%94%E8%AE%B0/%E5%A4%9A%E7%BA%BF%E7%A8%8B/image-20200608181652167.png" alt="ThreadLocalMap的key是弱引用" style="zoom: 50%;"><p>如果业务代码用完了ThreadLocal，则它的引用被回收，此时的ThreadLocal实体对象仅有一个弱引用指向他，可以被顺利GC，此时的Entry的key为null。如果没有手动删除这个Entry，则这个Entry的value是不会被回收的，但是它已经无法被访问到了， 最终导致value的内存泄漏</p></li></ol><p>综上所述，内存泄漏的根源在于：由于ThreadLocalMap的生命周期与Thread一样长，如果没有手动删除对应的Entry会导致内存泄漏</p><p>因此为了避免内存泄漏：</p><ol><li>使用完ThreadLocal之后，调用其remove方法， 删除对应的Entry</li><li>使用完ThreadLocal之后，对应的Thread也要随之结束</li></ol><p>JDK使用的是弱引用，因为使用完ThreadLocal之后，线程可能还要运行，使用弱引用之后，指向的ThreadLocal会被清除掉，并且在下一次调用ThreadLocal的方法时会将key为null的Entry的value也设置为null，避免内存泄漏</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【hadoop 2】hadoop三种模式使用</title>
      <link href="/2020/03/18/hadoop/2_%E4%BD%BF%E7%94%A8hadoop/"/>
      <url>/2020/03/18/hadoop/2_%E4%BD%BF%E7%94%A8hadoop/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="1-单机模式"><a href="#1-单机模式" class="headerlink" title="1. 单机模式"></a>1. 单机模式</h1><p>默认情况下，hadoop的配置是运行在非分布式的模式（单机模式），可以用一个例程来试一试：</p><pre><code class="bash">mkdir inputcp etc/hadoop/*.xml inputbin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output &#39;dfs[a-z.]+&#39;cat output/*</code></pre><ul><li>也就是使用hadoop这个应用程序</li><li>执行一个jar包</li><li>被执行的jar包的名字叫做<code>share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar</code></li><li>此时的主类叫做<code>grep</code>，同时这里主类也可以是<code>wordcount</code></li><li>后面的input和output分别是输入输出文件夹，其中<strong>输出文件夹必须是一个不存在的目录</strong>。</li><li><code>&#39;dfs[a-z.]+&#39;</code>这个是正则表达式，查询dfs开头的，后面跟1个或1个以上的字母，比如 dfsa dfsb dfsc </li></ul><p>该模式一般只用于调试测试，在实际的生产环境中不会使用本模式。</p><p>下面测试一下wordcount</p><pre><code class="bash">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput# 然后使用cat查看结果cat wcoutput/*</code></pre><h1 id="2-伪分布式模式"><a href="#2-伪分布式模式" class="headerlink" title="2. 伪分布式模式"></a>2. 伪分布式模式</h1><h2 id="2-1-启动HDFS并运行MapReduce程序"><a href="#2-1-启动HDFS并运行MapReduce程序" class="headerlink" title="2.1 启动HDFS并运行MapReduce程序"></a>2.1 启动HDFS并运行MapReduce程序</h2><p>只有一个节点的分布式，叫做伪分布式，将所有节点运行在同一个机器上面。</p><ol><li><p><strong>配置集群</strong></p><ol><li><p><code>etc/hadoop/core-site.xml</code>:指定HDFS中namenode的地址</p><p>注意，这里默认是没有配置的，默认表示使用本地模式，如果这里配置了，就使用指定的地址。</p><p>下面的那个配置指定临时数据存储的位置</p></li></ol><pre><code class="xml">&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hadoop001:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;&lt;/property&gt;</code></pre><ol start="2"><li><code>etc/hadoop/hdfs-site.xml</code>:  指定HDFS中副本的数量为1，因为只在一个节点上运行，虽然Hadoop是多副本机制，但是单一节点至多存储一个副本。</li></ol><pre><code class="xml">&lt;!-- 指定HDFS副本的数量 --&gt;&lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p>检查是否可以在没有密码的情况下SSH到本地主机</p><pre><code class="bash">ssh localhost</code></pre></li><li><p><strong>格式化namenode</strong></p><p>这个格式化只能在首次启动之前格式化</p><pre><code class="bash">bin/hdfs namenode -format</code></pre><p>要注意，不能多次格式化namenode。因为格式化NameNode会产生新的集群id,导致NameNode和DataNode的集群id不一致，集群找不到以往数据。所以，格式NameNode时，<strong>一定要先删除data数据和log日志</strong>，然后再格式化NameNode。</p><pre><code class="bash">sudo rm -rf logssudo rm -rf data</code></pre></li><li><p><strong>启动namenode和datanode</strong></p><pre><code class="bash">sbin/start-dfs.sh# 也可以通过下面两句分别启动sbin/hadoop-daemon.sh start namenodesbin/hadoop-daemon.sh start datanode</code></pre><p>此时使用jps就可以看到namenode和datanode都已经启动了</p></li></ol><p><strong>查看HDFS文件系统</strong></p><p>首先需要在windows的host里面改一下映射</p><pre><code>192.168.186.130 hadoop001192.168.186.131 hadoop002192.168.186.132 hadoop003</code></pre><p>然后在浏览器里面查看</p><pre><code>hadoop001:50070</code></pre><p><strong>操作集群</strong></p><ol><li><p>在HDFS文件系统上<strong>创建</strong>一个input文件夹</p><pre><code class="bash">bin/hdfs dfs -mkdir -p /user/hadoopUser/input</code></pre></li><li><p>将测试文件内容<strong>上传</strong>到文件系统上</p><pre><code class="bash">bin/hdfs dfs -put wcinput/wc.input /user/hadoopUser/input/</code></pre></li><li><p><strong>查看</strong>上传的文件是否正确</p><pre><code class="bash">bin/hdfs dfs -ls /user/hadoopUser/input/bin/hdfs dfs -cat /user/hadoopUser/input/wc.input</code></pre></li><li><p>运行MapReduce程序</p><pre><code class="bash">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/hadoopUser/input/ /user/hadoopUser/output</code></pre></li><li><p>查看输出结果</p><pre><code>bin/hdfs dfs -cat /user/atguigu/output/*</code></pre></li></ol><h2 id="2-2-启动YARN并运行MapReduce"><a href="#2-2-启动YARN并运行MapReduce" class="headerlink" title="2.2 启动YARN并运行MapReduce"></a>2.2 启动YARN并运行MapReduce</h2><ol><li><p><strong>配置集群</strong></p><ol><li><p><strong>配置yarn</strong>：<code>etc/hadoop/yarn-env.sh</code></p><p>在下面的位置将 <code>JAVA_HOME</code> 给换掉</p><pre><code class="bash"># some Java parametersexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre></li><li><p><strong>配置 <code>yarn-site.xml</code></strong></p><pre><code class="xml">&lt;!-- Reducer获取数据的方式 --&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;hadoop001&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p><strong>配置 <code>mapred-env.sh</code></strong></p><p>配置 <code>JAVA_HOME</code></p><pre><code class="bash">export JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre></li><li><p><strong>配置 <code>mapred-site.xml</code></strong> (将 <code>mapred-site.xml.template</code> 重新命名为该文件) </p><pre><code class="bash">mv mapred-site.xml.template mapred-site.xml</code></pre><p>然后添加配置：</p><pre><code class="xml">&lt;!-- 指定MR运行在YARN上 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre></li></ol></li><li><p><strong>启动集群</strong></p><ol><li><p>启动前必须保证NameNode和DataNode已经启动</p></li><li><p>启动ResourceManager</p><pre><code class="bash">sbin/yarn-daemon.sh start resourcemanager</code></pre></li><li><p>启动NodeManager</p><pre><code class="bash">sbin/yarn-daemon.sh start nodemanager</code></pre></li></ol></li><li><p><strong>集群操作</strong></p><ul><li>使用浏览器访问下面地址可以查看集群</li></ul><pre><code>hadoop001:8088/cluster</code></pre><ul><li><p>删除文件系统上的output文件</p><pre><code class="bash">bin/hdfs dfs -rm -R /user/hadoopUser/output</code></pre></li><li><p>执行MapReduce程序</p><pre><code class="bash">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/hadoopUser/input  /user/hadoopUser/output</code></pre></li><li><p>查看运行结果</p><pre><code class="bash">bin/hdfs dfs -cat /user/hadoopUser/output/*</code></pre></li></ul></li></ol><h2 id="2-3-配置历史服务器"><a href="#2-3-配置历史服务器" class="headerlink" title="2.3 配置历史服务器"></a>2.3 配置历史服务器</h2><p>为了查看程序的历史运行情况，需要配置一下历史服务器。</p><ol><li><p>配置 <code>etc/hadoop/mapred-site.xml</code></p><pre><code class="xml">&lt;!-- 历史服务器端地址 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;    &lt;value&gt;hadoop101:10020&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史服务器web端地址 --&gt;&lt;property&gt;    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;    &lt;value&gt;hadoop101:19888&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p>启动历史服务器</p><pre><code class="bash">sbin/mr-jobhistory-daemon.sh start historyserver</code></pre></li><li><p>查看历史服务器是否启动</p><pre><code class="bash">jps</code></pre></li><li><p>查看JobHistory</p><pre><code>http://hadoop001:19888/jobhistory</code></pre></li></ol><h2 id="2-4-配置日志的聚集"><a href="#2-4-配置日志的聚集" class="headerlink" title="2.4 配置日志的聚集"></a>2.4 配置日志的聚集</h2><p>日志聚集概念：应用运行完成以后，将<strong>程序运行日志信息</strong>上传到HDFS系统上。</p><p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p><p>注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。</p><ol><li><p>配置yarn-site.xml</p><pre><code class="xml">&lt;!-- 日志聚集功能使能 --&gt;&lt;property&gt;    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 日志保留时间设置7天 --&gt;&lt;property&gt;    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;    &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p>关闭NodeManager 、ResourceManager和HistoryManager</p><pre><code class="bash">sbin/yarn-daemon.sh stop resourcemanagersbin/yarn-daemon.sh stop nodemanagersbin/mr-jobhistory-daemon.sh stop historyserver</code></pre></li><li><p>启动NodeManager 、ResourceManager和HistoryManager</p><pre><code class="bash">sbin/yarn-daemon.sh start resourcemanagersbin/yarn-daemon.sh start nodemanagersbin/mr-jobhistory-daemon.sh start historyserver</code></pre></li><li><p>删除HDFS上已经存在的输出文件</p><pre><code class="bash">bin/hdfs dfs -rm -R /user/hadoopUser/output</code></pre></li><li><p>执行WordCount程序</p><pre><code class="bash">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/hadoopUser/input /user/hadoopUser/output</code></pre></li><li><p>查看日志</p><pre><code>http://hadoop001:19888/jobhistory</code></pre></li></ol><h2 id="2-5-配置文件说明"><a href="#2-5-配置文件说明" class="headerlink" title="2.5 配置文件说明"></a>2.5 配置文件说明</h2><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p><ol><li><p><strong>默认配置文件</strong></p><table><thead><tr><th>要获取的默认文件</th><th>文件存放在Hadoop的jar包中的位置</th></tr></thead><tbody><tr><td>[core-default.xml]</td><td>hadoop-common-2.7.2.jar/  core-default.xml</td></tr><tr><td>[hdfs-default.xml]</td><td>hadoop-hdfs-2.7.2.jar/  hdfs-default.xml</td></tr><tr><td>[yarn-default.xml]</td><td>hadoop-yarn-common-2.7.2.jar/  yarn-default.xml</td></tr><tr><td>[mapred-default.xml]</td><td>hadoop-mapreduce-client-core-2.7.2.jar/  mapred-default.xml</td></tr></tbody></table></li><li><p><strong>自定义配置文件</strong></p><ul><li>core-site.xml</li><li>hdfs-site.xml</li><li>yarn-site.xml</li><li>mapred-site.xml</li></ul><p>四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p></li></ol><h1 id="3-全分布式模式"><a href="#3-全分布式模式" class="headerlink" title="3. 全分布式模式"></a>3. 全分布式模式</h1><h2 id="3-1-scp实现集群安全拷贝"><a href="#3-1-scp实现集群安全拷贝" class="headerlink" title="3.1 scp实现集群安全拷贝"></a>3.1 scp实现集群安全拷贝</h2><p>scp可以实现服务器与服务器之间的数据拷贝。</p><p>命令：</p><pre><code class="bash">scp    -r        $pdir/$fname            $user@hadoop$host:$pdir/$fname命令   递归       要拷贝的文件路径/名称    目的用户@主机:目的路径/名称</code></pre><ol><li><p>在hadoop001上，将hadoop001中/opt/module目录下的软件拷贝到hadoop002上。</p><pre><code class="bash">scp -r /opt/module  root@hadoop002:/opt</code></pre></li><li><p>在hadoop003上，将hadoop001服务器上的/opt/module目录下的软件拷贝到hadoop003上。</p><pre><code class="bash">sudo scp -r hadoopUser@hadoop001:/opt/module root@hadoop003:/opt</code></pre></li><li><p>在hadoop004上，将hadoop001服务器上的/opt/module目录下的软件拷贝到hadoop003上。</p><pre><code class="bash">sudo scp -r hadoopUser@hadoop001:/opt/module root@hadoop004:/opt</code></pre></li><li><p>将hadoop001中/etc/profile文件拷贝到hadoop002的/etc/profile上。</p><pre><code class="bash">sudo scp /etc/profile root@hadoop002:/etc/profile</code></pre></li><li><p>将hadoop001中/etc/profile文件拷贝到hadoop003的/etc/profile上。</p><pre><code class="bash">sudo scp /etc/profile root@hadoop003:/etc/profile</code></pre></li><li><p>将hadoop001中/etc/profile文件拷贝到hadoop004的/etc/profile上。</p><pre><code class="bash">sudo scp /etc/profile root@hadoop004:/etc/profile</code></pre></li></ol><p>移动完成之后，要source一下/etc/profile</p><h2 id="3-2-rsync-远程同步工具"><a href="#3-2-rsync-远程同步工具" class="headerlink" title="3.2 rsync 远程同步工具"></a>3.2 rsync 远程同步工具</h2><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p><p>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p><p>命令：</p><pre><code class="bash">rsync    -rvl       $pdir/$fname              $user@hadoop$host:$pdir/$fname命令     选项参数    要拷贝的文件路径/名称       目的用户@主机:目的路径/名称</code></pre><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-r</td><td>递归</td></tr><tr><td>-v</td><td>显示复制过程</td></tr><tr><td>-l</td><td>拷贝符号连接</td></tr></tbody></table><ol><li><p>把hadoop001机器上的/opt/software目录同步到hadoop002服务器的root用户下的/opt/目录</p><pre><code class="bash">rsync -rvl /opt/software/ root@hadoop002:/opt/software</code></pre></li></ol><h2 id="3-3-xsync集群分发脚本"><a href="#3-3-xsync集群分发脚本" class="headerlink" title="3.3 xsync集群分发脚本"></a>3.3 xsync集群分发脚本</h2><p>需求：循环复制文件到所有节点的相同目录</p><ol><li><p>rsync命令原始拷贝：</p><pre><code class="bash">rsync -rvl   /opt/module        root@hadoop003:/opt/</code></pre></li><li><p>期望脚本：</p><pre><code>xsync 要同步的文件名称</code></pre><p>说明：在/home/hadoopUser/bin这个目录下存放的脚本，hadoopUser用户可以在系统任何地方直接执行。</p><pre><code class="bash">mkdir bincd bin/touch xsyncvim xsync</code></pre></li><li><p>在xsync中添加bash脚本：</p><pre><code class="bash">#!/bin/bash#1 获取输入参数个数，如果没有参数，直接退出pcount=$#if((pcount==0)); then    echo no args;    exit;fi#2 获取文件名称p1=$1fname=`basename $p1`echo fname=$fname#3 获取上级目录到绝对路径pdir=`cd -P $(dirname $p1); pwd`echo pdir=$pdir#4 获取当前用户名称user=`whoami`#5 循环for((host=1; host&lt;5; host++)); do    echo ------------------- hadoop$host --------------    rsync -rvl $pdir/$fname $user@hadoop00$host:$pdirdone</code></pre></li><li><p>修改脚本 xsync 具有执行权限</p><pre><code class="bash">chmod 777 xsync</code></pre></li><li><p>调用脚本形式：xsync 文件名称</p><pre><code class="bash">xsync /home/hadoopUser/bin</code></pre></li></ol><p>在hadoop002上面进行如上操作，可以测试一下</p><h2 id="3-4-集群配置"><a href="#3-4-集群配置" class="headerlink" title="3.4 集群配置"></a>3.4 集群配置</h2><p>集群配置计划：</p><table><thead><tr><th></th><th>hadoop002</th><th>hadoop003</th><th>hadoop004</th></tr></thead><tbody><tr><td><strong>HDFS</strong></td><td>NameNode 、 DataNode</td><td>DataNode</td><td>SecondaryNameNode、DataNode</td></tr><tr><td><strong>YARN</strong></td><td>NodeManager</td><td>ResourceManager  NodeManager</td><td>NodeManager</td></tr></tbody></table><ol><li><p>核心配置文件</p><pre><code class="bash">sudo vim etc/hadoop/core-site.xml</code></pre><p>编写以下指定配置：</p><pre><code class="xml">&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hadoop002:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p>HDFS配置文件</p><p>设置java版本</p><pre><code class="bash">sudo vim etc/hadoop/hadoop-env.sh# 修改JAVA_HOME为如下内容export JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置hdfs-site.xml</p><pre><code class="bash">sudo vim etc/hadoop/hdfs-site.xml</code></pre><p>然后在配置文件中添加以下内容</p><pre><code class="xml">&lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;    &lt;value&gt;hadoop004:50090&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p>YARN配置文件</p><p>配置yarn-env.sh</p><pre><code class="bash">sudo vim etc/hadoop/yarn-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置yarn-site.xm</p><pre><code class="bash">sudo vim etc/hadoop/yarn-site.xml</code></pre><p>然后在配置文件中添加以下内容</p><pre><code class="xml">&lt;!-- Reducer获取数据的方式 --&gt;&lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt;        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;        &lt;value&gt;hadoop003&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p>MapReduce配置文件</p><p>配置mapred-env.sh</p><pre><code class="bash">sudo vim etc/hadoop/mapred-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre><p>配置mapred-site.xml</p><pre><code class="bash"># 从临时文件中拷贝出来修改后使用cp mapred-site.xml.template mapred-site.xmlsudo vim etc/hadoop/mapred-site.xml</code></pre><p>配置mapred-site.xml</p><pre><code class="xml">&lt;!-- 指定MR运行在Yarn上 --&gt;&lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;</code></pre></li><li><p>分发配置文件</p><pre><code class="bash">xsync /opt/module/hadoop-2.7.2/</code></pre></li><li><p>检查配置文件是否分发成功</p><pre><code class="bash">cat /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml</code></pre><p>查看文件是否修改成功了。</p><p>注意这里分发失败的原因可能是没有权限修改文件，需要通过chmod来加权限。</p></li></ol><h2 id="3-5-集群单点启动"><a href="#3-5-集群单点启动" class="headerlink" title="3.5 集群单点启动"></a>3.5 集群单点启动</h2><ol><li><p>如果集群是第一次启动，需要<strong>格式化NameNode</strong></p><pre><code class="bash">[hadoopUser@hadoop002 hadoop-2.7.2]$ hadoop namenode -format</code></pre></li><li><p>启动namenode</p><pre><code class="bash">[hadoopUser@hadoop002 hadoop-2.7.2]$ hadoop-daemon.sh start namenode</code></pre></li><li><p>在hadoop002、003和004上面都启动datanode</p><pre><code class="bash">[hadoopUser@hadoop002 hadoop-2.7.2]$ hadoop-daemon.sh start datanode</code></pre></li></ol><p>注意，如果单点启动失败，则需要删除 logs文件夹和data文件夹，然后重新格式化namenode</p><h2 id="3-6-群起集群"><a href="#3-6-群起集群" class="headerlink" title="3.6 群起集群"></a>3.6 群起集群</h2><p>在etc/hadoop/slaves文件中编辑如下内容：（也就是将这些主机名记录在该文件中）</p><img src="/2020/03/18/hadoop/2_%E4%BD%BF%E7%94%A8hadoop/image-20200318165520919.png" alt="image-20200318165520919" style="zoom:80%;"><p>然后通过xsync将这个文件同步到各个主机中</p><pre><code class="bash">xsync /opt/module/hadoopxxx/etc/hadoop/slave</code></pre><ol><li><p><strong>启动HDFS（hadoop002）</strong></p><pre><code class="bash">sbin/start-dfs.sh</code></pre></li><li><p><strong>启动YARN</strong></p><pre><code class="bash">sbin/start-yarn.sh</code></pre></li></ol><p>通过执行上面的两个sh，就可以按照配置中指定的主机来启动对应的namenode、datanode和secondary namenode。</p><h2 id="3-7-测试集群"><a href="#3-7-测试集群" class="headerlink" title="3.7 测试集群"></a>3.7 测试集群</h2><ol><li><p>上传文件到集群</p><p>上传小文件</p><pre><code class="bash">hdfs dfs -mkdir -p /user/hadoopUser/inputhdfs dfs -put wcinput/wc.input /user/hadoopUser/input</code></pre><p>上传大文件</p><pre><code class="bash">bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz  /user/hadoopUser/input</code></pre></li><li><p>下载</p><pre><code class="bash">bin/hadoop fs -get /user/hadoopUser/input/hadoop-2.7.2.tar.gz ./</code></pre></li></ol><h2 id="3-8-停止集群"><a href="#3-8-停止集群" class="headerlink" title="3.8 停止集群"></a>3.8 停止集群</h2><p>以下指令如果不存在，说明环境没配好，需要添加sbin，或者直接在指令前面加上sbin也可以。</p><ol><li><p>单点停止</p><ul><li><p>HDFS</p><pre><code class="bash">hadoop-daemon.sh  start / stop  namenode / datanode / secondarynamenode</code></pre></li><li><p>YARN</p><pre><code class="bash">yarn-daemon.sh  start / stop  resourcemanager / nodemanager</code></pre></li></ul></li><li><p>群起群停</p><ul><li><p>HDFS</p><pre><code class="bash">start-dfs.sh   /  stop-dfs.sh</code></pre></li><li><p>YARN</p><pre><code class="bash">start-yarn.sh  /  stop-yarn.sh</code></pre></li></ul></li></ol><h1 id="使用notepad-的插件访问虚拟机"><a href="#使用notepad-的插件访问虚拟机" class="headerlink" title="使用notepad++的插件访问虚拟机"></a>使用notepad++的插件访问虚拟机</h1><p>可以使用notepad++的插件NPPFTP，配置完成后，可以直接以更清晰的方式来访问虚拟机。</p><img src="/2020/03/18/hadoop/2_%E4%BD%BF%E7%94%A8hadoop/image-20200318163040777.png" alt="image-20200318163040777" style="zoom:80%;"><h1 id="无密登录配置"><a href="#无密登录配置" class="headerlink" title="无密登录配置"></a>无密登录配置</h1><ol><li><p>生成公钥和私钥</p><pre><code class="bash">[hadoopUser@hadoop002 .ssh]$ ssh-keygen -t rsa</code></pre></li><li><p>将公钥拷贝到要免密登录的目标机器上</p><pre><code class="bash">ssh-copy-id hadoop002ssh-copy-id hadoop003ssh-copy-id hadoop004</code></pre><p>此后可以实现hadoop002到hadoop002 003 004的无密访问</p><p>可以通过下面的方式来测试</p><pre><code class="bash">ssh hadoop003ssh hadoop004</code></pre></li><li><p>对hadoop003和004重新执行以上两个操作即可。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringBoot 02】配置文件</title>
      <link href="/2020/03/18/springboot/3_springboot%E7%9A%84%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/03/18/springboot/3_springboot%E7%9A%84%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h1><p>SpringBoot使用一个全局的配置文件：</p><ul><li>application.properties</li><li>application.yml</li></ul><p>配置文件的名字是固定的，修改<strong>自动配置的默认值</strong>。放在 <code>src/main/resources</code> 目录下或者 <code>类路径/config</code> 下</p><h1 id="YAML配置"><a href="#YAML配置" class="headerlink" title="YAML配置"></a>YAML配置</h1><h2 id="1-YAML语法"><a href="#1-YAML语法" class="headerlink" title="1. YAML语法"></a>1. YAML语法</h2><ol><li>使用缩进表示层级关系</li><li>缩进时不允许使用tab，只能用空格</li><li>缩进的空格数目不重要，只要相同层级有相同的缩进</li><li>大小写敏感</li></ol><p><strong>数据结构：</strong></p><ol><li><p><strong>对象：键值对的集合</strong></p><p>k: v，还是键值对的形式，在<strong>下一行</strong>来写对象的属性和值。</p><pre><code class="yaml">friends:    lastName: zhangsan    age: 20</code></pre><p>也可以使用行内写法：</p><pre><code class="yaml">friends: {lastName: zhangsan,age: 20}</code></pre></li><li><p><strong>数组：一组按次序排列的值</strong></p><p>短横线-表示数组中的一个元素</p><pre><code class="yaml">pets:    - cat    - dog    - pig</code></pre><p>行内写法：</p><pre><code class="yaml">pets: [cat,dog,pig]</code></pre></li><li><p><strong>字面量：单个的、不可再分的值</strong>（数字、字符串、布尔类型）</p><p>字符串默认不用加上单引号或者双引号。</p><ul><li><p>如果加了双引号，表示不会转义字符串里面的特殊字符，特殊字符会作为本身想表示的意思</p><pre><code class="yaml">name: &quot;hehe \n haha&quot; 输出为：hehe换行haha</code></pre></li><li><p>如果是单引号，会转义特殊字符，特殊字符就变成普通的字符串</p><pre><code class="yaml">name: &#39;hehe \n haha&#39; 输出为：hehe \n haha</code></pre></li></ul></li></ol><h2 id="2-SpringBoot导入yaml配置文件"><a href="#2-SpringBoot导入yaml配置文件" class="headerlink" title="2. SpringBoot导入yaml配置文件"></a>2. SpringBoot导入yaml配置文件</h2><h3 id="2-1-导入配置处理文件的依赖"><a href="#2-1-导入配置处理文件的依赖" class="headerlink" title="2.1 导入配置处理文件的依赖"></a>2.1 导入配置处理文件的依赖</h3><p>添加后，配置文件进行绑定时就会有提示</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;    &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;</code></pre><h3 id="2-2-新建Person类和Dog类"><a href="#2-2-新建Person类和Dog类" class="headerlink" title="2.2 新建Person类和Dog类"></a>2.2 新建Person类和Dog类</h3><p>注意，其中的 <code>@ConfigurationProperties</code> 注解的作用是：告诉SpringBoot<strong>将本类中的所有属性和配置文件的相关配置进行绑定</strong>。</p><pre><code class="java">@Component@ConfigurationProperties(prefix = &quot;person&quot;)public class Person {    private String lastName;    private Integer age;    private Boolean boss;    private Date birth;    private Map&lt;String, Object&gt; maps;    private List&lt;Object&gt; lists;    private Dog dog;    // toString和getter setter方法public class Dog {    private String name;    private Integer age;    // toString和getter setter方法</code></pre><h3 id="2-3-编写application-yml"><a href="#2-3-编写application-yml" class="headerlink" title="2.3 编写application.yml"></a>2.3 编写application.yml</h3><p>在配置文件中将Person的各个属性进行指定。</p><pre><code class="yaml">person:  lastName: zhangsan  age: 18  boss: false  birth: 2020/1/1  maps: {k1: v1, k2: 12}  lists:    - lisi    - zhaowu  dog:    name: hehe    age: 2</code></pre><h3 id="2-4-测试"><a href="#2-4-测试" class="headerlink" title="2.4 测试"></a>2.4 测试</h3><p>可以在测试期间实现很方便的类似容器注入的功能。</p><p>在SpringBoot的单元测试类中，进行如下配置：</p><pre><code class="java">@RunWith(SpringRunner.class)@SpringBootTestclass Springboot001ApplicationTests {    @Autowired    Person person;    @Test    void contextLoads() {        System.out.println(person);    }}</code></pre><p>就可以看到控制台输出了正确的值</p><pre><code>Person{lastName=&#39;zhangsan&#39;, age=18, boss=false, birth=Wed Jan 01 00:00:00 CST 2020, maps={k1=v1, k2=12}, lists=[lisi, zhaowu], dog=Dog{name=&#39;hehe&#39;, age=2}}</code></pre><img src="/2020/03/18/springboot/3_springboot%E7%9A%84%E9%85%8D%E7%BD%AE/image-20200318103654168.png" alt="目录结构" style="zoom:80%;"><h1 id="Properties配置"><a href="#Properties配置" class="headerlink" title="Properties配置"></a>Properties配置</h1><h2 id="1-写配置"><a href="#1-写配置" class="headerlink" title="1. 写配置"></a>1. 写配置</h2><p>还是使用之前的配置，只不过将yaml文件换成properties文件进行配置</p><p>可以看到直接就有补全了</p><img src="/2020/03/18/springboot/3_springboot%E7%9A%84%E9%85%8D%E7%BD%AE/image-20200318104009823.png" alt="自动补齐" style="zoom:80%;"><pre><code class="properties">person.last-name=张三person.age=18person.birth=2020/1/1person.boss=falseperson.dog.name=heheperson.dog.age=3person.maps.k1=v1person.maps.k2=15person.lists=a,b,c</code></pre><p>需要注意的是，last-name加-表示大写，也可以使用<code>latName</code>，这一个特性叫做<strong>松散语法绑定</strong>。</p><p>但是在 <code>@Value</code> 注解中只能使用 <code>last-name</code>，也就是<strong>Value注解不支持松散语法绑定</strong>。</p><h2 id="2-乱码问题"><a href="#2-乱码问题" class="headerlink" title="2. 乱码问题"></a>2. 乱码问题</h2><p>但是会发现输出的结果中有乱码：</p><img src="/2020/03/18/springboot/3_springboot%E7%9A%84%E9%85%8D%E7%BD%AE/image-20200318104156790.png" alt="image-20200318104156790" style="zoom:80%;"><p>这是由于idea默认对于properties文件使用系统自带的编码，因此需要修改配置</p><img src="/2020/03/18/springboot/3_springboot%E7%9A%84%E9%85%8D%E7%BD%AE/image-20200318104253975.png" alt="修改idea的默认编码方式" style="zoom:80%;"><p>再运行就没有乱码了。</p><h2 id="3-ConfigurationProperties与Value注解"><a href="#3-ConfigurationProperties与Value注解" class="headerlink" title="3. ConfigurationProperties与Value注解"></a>3. ConfigurationProperties与Value注解</h2><p>除了使用 <code>@ConfigurationProperties</code> 注解进行注入之外，还可以使用 <code>@Value</code> 注解</p><pre><code class="java">@Componentpublic class Person {    @Value(&quot;${person.last-name}&quot;)    private String lastName;    @Value(&quot;#{11*2}&quot;)    private Integer age;    @Value(&quot;true&quot;)    private Boolean boss;    private Date birth;    private Map&lt;String, Object&gt; maps;    private List&lt;Object&gt; lists;    private Dog dog;</code></pre><p>可以看出，如果使用 <code>@ConfigurationProperties</code> 注解，就会将所有的内容注入，但是使用 <code>@Value</code> 注解虽然需要一个一个指定，但是可选择某些不指定。</p><h2 id="4-三个常用注解"><a href="#4-三个常用注解" class="headerlink" title="4. 三个常用注解"></a>4. 三个常用注解</h2><h3 id="4-1-PropertySource注解"><a href="#4-1-PropertySource注解" class="headerlink" title="4.1 @PropertySource注解"></a>4.1 @PropertySource注解</h3><p>之前写配置文件的时候都是放在application.properties文件下，这个文件是SpringBoot的配置文件，但是有些配置是与SpringBoot无关的，不希望将这些配置放进该文件，这时就需要使用这一配置来指定配置的其他路径。</p><p>例如，将person的信息全部放到person.properties文件中，此时对于Person类来说，就需要添加这条注解。</p><pre><code class="java">@Component// 添加这个注解，用于指定properties文件位置，可以是一个数组@PropertySource(value = {&quot;classpath:person.properties&quot;})@ConfigurationProperties(prefix = &quot;person&quot;)public class Person {    private String lastName;    private Integer age;    private Boolean boss;    private Date birth;    private Map&lt;String, Object&gt; maps;    private List&lt;Object&gt; lists;    private Dog dog;</code></pre><h3 id="4-2-ImportResource注解"><a href="#4-2-ImportResource注解" class="headerlink" title="4.2 @ImportResource注解"></a>4.2 @ImportResource注解</h3><p><strong>导入Spring的配置文件</strong>，让配置文件里面的内容生效。</p><h3 id="4-3-Bean注解"><a href="#4-3-Bean注解" class="headerlink" title="4.3 @Bean注解"></a>4.3 @Bean注解</h3><p>如果采用全注解的方式，之前使用 <code>@Configuration</code> 注解，指明当前类是一个配置类，替代之前的Spring配置文件。在配置文件中，使用bean标签来添加组件。</p><p>它作用是将方法的返回值添加到容器中，容器中这个组件的默认id就是方法名。</p><h1 id="配置文件占位符"><a href="#配置文件占位符" class="headerlink" title="配置文件占位符"></a>配置文件占位符</h1><p>配置文件占位符在YAML和properties配置文件中均可使用，使用方式如下：</p><p>可使用random来获取随机数，也可以通过引用前面的配置内容来获取配置文件中前面的配置。</p><pre><code class="properties">person.last-name=李四person.age=${random.int}person.dog.name=${person.last-name}_heheperson.dog.age=${person.age:20}_hehe</code></pre><ul><li><code>${}</code>：其中的内容就是一个表达式，可以是函数，也可以是前文出现的配置</li><li>如果没有属性，则会表现为字面意义</li><li>可以设置默认值，就是在属性后面加冒号，后面跟默认值</li></ul><h1 id="Profile"><a href="#Profile" class="headerlink" title="Profile"></a>Profile</h1><p>Profile是SpringBoot对不同环境提供不同配置功能的支持，可以通过激活、指定参数等方式快速切换环境。</p><h2 id="1-多Profile文件"><a href="#1-多Profile文件" class="headerlink" title="1. 多Profile文件"></a>1. 多Profile文件</h2><p>在主配置文件编写的时候，文件名可以是application-{profile}.properties/yml</p><p>例如，在开发环境下，使用application-dev.properties，在生产环境下，使用application-prod.properties，在里面可以配置不同的端口之类的属性。默认使用的是application.properties</p><p><strong>激活方式</strong></p><p>在application.properties配置文件中指定要激活哪种方式</p><pre><code class="properties">spring.profiles.active=dev</code></pre><h2 id="2-yml支持多文档块方式"><a href="#2-yml支持多文档块方式" class="headerlink" title="2. yml支持多文档块方式"></a>2. yml支持多文档块方式</h2><p>使用三个横线—可以将文档分隔，并且在每个文档块中定义其环境，使用profiles</p><pre><code class="yaml">server:  port: 8081spring:  profiles:    active: dev---server:  port: 8082spring:  profiles: dev---server:  port: 8083spring:  profiles: prod</code></pre><p><strong>激活方式</strong></p><p>在第一个文档块中添加active，表示激活的项。</p><pre><code class="yaml">spring:  profiles:    active: dev</code></pre><h2 id="3-其他激活方式"><a href="#3-其他激活方式" class="headerlink" title="3. 其他激活方式"></a>3. 其他激活方式</h2><ol><li>可以使用<strong>命令行</strong>的方式指定：<code>--spring.profiles.active=dev</code>（打成jar包后运行时指定）</li><li>使用虚拟机参数：<code>-Dspring.profiles.active=dev</code></li></ol><h1 id="配置文件的加载位置"><a href="#配置文件的加载位置" class="headerlink" title="配置文件的加载位置"></a>配置文件的加载位置</h1><p>SpringBoot启动会扫描以下位置的application.properties/yml文件作为SpringBoot的默认配置</p><ul><li><p>file:./config/</p></li><li><p>file:./</p><p>（上面两个file:位置就是和src同级的目录）</p></li><li><p>classpath:/config/</p></li><li><p>classpath:/</p></li></ul><p>以上是按照优先级从高到低的顺序，所有位置的文件都会被加载，<strong>采取互补的配置形式</strong>。</p><p>高优先级配置内容会覆盖低优先级配置内容。</p><p>也可以通过spring.config.location来改变默认配置。</p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringBoot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringBoot 01】HelloWorld</title>
      <link href="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/"/>
      <url>/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="导入依赖"><a href="#导入依赖" class="headerlink" title="导入依赖"></a>导入依赖</h1><h2 id="1-导入父项目"><a href="#1-导入父项目" class="headerlink" title="1. 导入父项目"></a>1. 导入父项目</h2><pre><code class="xml">&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;</code></pre><p>这个项目主要是用于定义几乎所有插件的各个版本的依赖。用于管理springboot应用里面所有依赖，叫做springboot的版本仲裁中心，因此以后导入依赖默认是不需要写版本的。但如果没有在这里面管理的话则需要声明版本号。</p><h2 id="2-导入依赖"><a href="#2-导入依赖" class="headerlink" title="2. 导入依赖"></a>2. 导入依赖</h2><pre><code class="xml">&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>starater的作用：</p><ul><li>spring-boot-starter-web：springboot场景启动器，在它里面也定义了很多关于<strong>web模块</strong>的很多依赖，这些依赖通过父项目进行版本仲裁。</li><li>spring将所有的功能场景都抽取出来，做成一个一个的starter，只要在项目中引入这些starter，则其对应的相关场景的所有依赖都会被导入进来，需要用什么功能，就导入什么场景的启动器。</li></ul><h1 id="Hello-World项目"><a href="#Hello-World项目" class="headerlink" title="Hello World项目"></a>Hello World项目</h1><h2 id="1-编写主程序，用于启动SpringBoot应用"><a href="#1-编写主程序，用于启动SpringBoot应用" class="headerlink" title="1. 编写主程序，用于启动SpringBoot应用"></a>1. 编写主程序，用于启动SpringBoot应用</h2><p>使用 <code>@SpringBootApplication</code> 标注主程序类，说明这是springboot的<strong>主配置类</strong>，springboot就应该运行这个类的main方法来启动springboot应用。</p><pre><code class="java">// 标注主程序类，说明这是一个springboot应用@SpringBootApplicationpublic class Springboot001Application {    // spring应用启动起来，相当于只需要使用一个springbootApplication注解    public static void main(String[] args) {        SpringApplication.run(Springboot001Application.class, args);    }}</code></pre><p>运行main方法。会看到下面的输出。</p><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318085416962.png" alt="SpringBoot启动" style="zoom:67%;"><p>此时已经在8080端口部署了tomcat服务器，只需要访问 <code>localhost:8080</code> 就可以查看了。由于此时没有部署任何Controller，因此是如下的页面</p><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318085449158.png" alt="访问SpringBoot的8080端口" style="zoom:67%;"><h2 id="2-编写相关的Controller和Service"><a href="#2-编写相关的Controller和Service" class="headerlink" title="2. 编写相关的Controller和Service"></a>2. 编写相关的Controller和Service</h2><p>在com.xiong.controller包下创建一个新的类HelloController，将controller包放在与springbootApplication同级的目录下（<strong>注意一定要放到此目录下</strong>）。</p><blockquote><p>因为springboot是将主配置类（SpringBootConfituration注解标注的类）所在的包以及其下所有自爆的所有组件扫描到spring容器。会给容器中导入非常多的自动配置类，就是给容器中导入这个场景需要的所有组件，并且配置好这些组件。</p></blockquote><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318085901281.png" alt="项目结构" style="zoom:80%;"><p>然后将文件写成如下形式：</p><pre><code class="java">@Controllerpublic class HelloController {    @ResponseBody    @RequestMapping(&quot;/hello&quot;)    public String hello() {        return &quot;Hello World!&quot;;    }}</code></pre><p>然后直接运行main方法，访问 <code>localhost:8080/hello</code> 就可以直接在浏览器上看到返回的字符串了。</p><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318090038610.png" alt="再次访问8080端口" style="zoom: 80%;"><h2 id="3-简化部署"><a href="#3-简化部署" class="headerlink" title="3. 简化部署"></a>3. 简化部署</h2><p>springboot不需要打war包，只需要创建一个可执行的jar包。</p><p>只需要在pom文件中导入一个maven的插件，该插件的作用是将应用打包为一个可执行的jar包，无需在服务器安装tomcat环境。</p><pre><code class="xml">&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;</code></pre><p>然后在maven插件中选择lifecycle的package功能，就可以自动打包了</p><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318090540583.png" alt="使用maven打包" style="zoom:80%;"><p>最终生成的jar包放在如下位置</p><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318090736225.png" alt="包存储位置" style="zoom:80%;"><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318090824881.png" alt="包存储位置" style="zoom:80%;"><p>然后将这个jar包放在任意位置，就可以使用java -jar命令来执行了。</p><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318090959882.png" alt="使用命令行启动SpringBoot的jar包" style="zoom:80%;"><h1 id="快速创建springboot项目"><a href="#快速创建springboot项目" class="headerlink" title="快速创建springboot项目"></a>快速创建springboot项目</h1><p>使用创建向导Spring Initializer快速创建springboot项目，选中需要的场景即可。</p><p>创建完成后，在resources文件夹下有以下几个目录：</p><img src="/2020/03/17/springboot/2_springboot%E7%9A%84helloworld/image-20200318094543325.png" alt="resources文件夹目录" style="zoom:80%;"><ul><li><p>static</p><p>保存所有的静态资源，比如js，css，图片等</p></li><li><p>templates</p><p>保存所有的模板页面，比如springboot默认以jar包使用嵌入式tomcat，不支持jsp，但是可以使用模板引擎来开启使用</p></li><li><p>application.properties</p><p>springboot的应用配置文件，可以指定一些默认的属性</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringBoot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SSM实战】SSM框架整合</title>
      <link href="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/"/>
      <url>/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="创建数据库与数据表"><a href="#创建数据库与数据表" class="headerlink" title="创建数据库与数据表"></a>创建数据库与数据表</h1><pre><code class="mysql">CREATE DATABASE ssm;USE ssm;CREATE TABLE account(    id int PRIMARY KEY AUTO_INCREMENT,    name varchar(20),    money double);</code></pre><h1 id="创建maven工程"><a href="#创建maven工程" class="headerlink" title="创建maven工程"></a>创建maven工程</h1><h2 id="1-配置pom"><a href="#1-配置pom" class="headerlink" title="1. 配置pom"></a>1. 配置pom</h2><pre><code class="xml">&lt;properties&gt;    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt;    &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt;    &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt;    &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt;    &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.aspectj&lt;/groupId&gt;        &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;        &lt;version&gt;1.6.8&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-web&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-test&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;4.12&lt;/version&gt;        &lt;scope&gt;compile&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;        &lt;version&gt;${mysql.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;        &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;        &lt;version&gt;2.5&lt;/version&gt;        &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt;        &lt;artifactId&gt;jsp-api&lt;/artifactId&gt;        &lt;version&gt;2.0&lt;/version&gt;        &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;jstl&lt;/groupId&gt;        &lt;artifactId&gt;jstl&lt;/artifactId&gt;        &lt;version&gt;1.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;!-- log start --&gt;    &lt;dependency&gt;        &lt;groupId&gt;log4j&lt;/groupId&gt;        &lt;artifactId&gt;log4j&lt;/artifactId&gt;        &lt;version&gt;${log4j.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;        &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;        &lt;version&gt;${slf4j.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.slf4j&lt;/groupId&gt;        &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;        &lt;version&gt;${slf4j.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mybatis&lt;/groupId&gt;        &lt;artifactId&gt;mybatis&lt;/artifactId&gt;        &lt;version&gt;${mybatis.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mybatis&lt;/groupId&gt;        &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;        &lt;version&gt;1.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.mchange&lt;/groupId&gt;        &lt;artifactId&gt;c3p0&lt;/artifactId&gt;        &lt;version&gt;0.9.5.2&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><h2 id="2-创建各个层"><a href="#2-创建各个层" class="headerlink" title="2. 创建各个层"></a>2. 创建各个层</h2><p>整个项目创建完成后，应该有如下的几个包，分别表示不同的层</p><img src="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/image-20200305162010506.png" alt="image-20200305162010506" style="zoom:80%;"><p>在下面的几个步骤执行完成后，整个项目的框架应该为：</p><img src="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/image-20200305162638407.png" alt="image-20200305162638407" style="zoom:80%;"><h3 id="2-1-在domain中创建Account的JavaBean"><a href="#2-1-在domain中创建Account的JavaBean" class="headerlink" title="2.1 在domain中创建Account的JavaBean"></a>2.1 在domain中创建Account的JavaBean</h3><pre><code class="java">public class Account implements Serializable {    private Integer id;    private String name;    private Double money;    // 生成相关的getter setter toString方法}</code></pre><h3 id="2-2-在dao中创建AccountDao"><a href="#2-2-在dao中创建AccountDao" class="headerlink" title="2.2 在dao中创建AccountDao"></a>2.2 在dao中创建AccountDao</h3><pre><code class="java">public interface AccountDao {    // 查询所有账户信息    List&lt;Account&gt; findAll();    // 保存账户信息    void saveAccount(Account account);}</code></pre><p>这里由于框架可以实现相应的查询工作，这里不需要写实现类，只需要写一个接口就行</p><h3 id="2-3-在service中创建AccountService"><a href="#2-3-在service中创建AccountService" class="headerlink" title="2.3 在service中创建AccountService"></a>2.3 在service中创建AccountService</h3><p>其实在AccountService中也是两个接口，和AccountDao的一样</p><pre><code class="java">public interface AccountService {    // 查询所有账户信息    List&lt;Account&gt; findAll();    // 保存账户信息    void saveAccount(Account account);}</code></pre><p>然后在相应的impl包中把实现给加上，这里暂时不写内容，只打印一句话</p><pre><code class="java">public class AccountServiceImpl implements AccountService {    @Override    public List&lt;Account&gt; findAll() {        System.out.println(&quot;业务层，查询所有账户&quot;);        return null;    }    @Override    public void saveAccount(Account account) {        System.out.println(&quot;业务层，保存账户&quot;);    }}</code></pre><h3 id="2-4-在controller中创建AccountController"><a href="#2-4-在controller中创建AccountController" class="headerlink" title="2.4 在controller中创建AccountController"></a>2.4 在controller中创建AccountController</h3><p>这里不需要写太多东西，只是创建一下就可以了。</p><pre><code class="java">// web层public class AccountController {}</code></pre><h1 id="搭建Spring框架"><a href="#搭建Spring框架" class="headerlink" title="搭建Spring框架"></a>搭建Spring框架</h1><p>Spring用于处理业务层（Service）框架</p><h2 id="1-创建spring的配置文件"><a href="#1-创建spring的配置文件" class="headerlink" title="1. 创建spring的配置文件"></a>1. 创建spring的配置文件</h2><p>在resources中创建一个配置文件applicationContext，表示是spring的配置文件，然后在其中添加相应的约束。</p><p>开启注解扫描，<strong>要扫描的是service和dao层的注解，要忽略web层注解</strong>，因为web层让SpringMVC框架去管理</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xmlns:context=&quot;http://www.springframework.org/schema/context&quot;    xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;    xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans.xsd    http://www.springframework.org/schema/context    http://www.springframework.org/schema/context/spring-context.xsd    http://www.springframework.org/schema/aop    http://www.springframework.org/schema/aop/spring-aop.xsd    http://www.springframework.org/schema/tx    http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt;    &lt;!--开启注解扫描--&gt;    &lt;context:component-scan base-package=&quot;com.xiong&quot;&gt;        &lt;!-- 配置要忽略的注解 --&gt;        &lt;!--也就是与Controller相关的都不要扫描--&gt;        &lt;context:exclude-filter type=&quot;annotation&quot;                                 expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;    &lt;/context:component-scan&gt;&lt;/beans&gt;</code></pre><h2 id="2-在AccountService类上加注解"><a href="#2-在AccountService类上加注解" class="headerlink" title="2. 在AccountService类上加注解"></a>2. 在AccountService类上加注解</h2><p>加的注解也是在实现类上面添加的，也就是会变成下面这样，此后就会将AccountService交给IOC容器来管理。</p><pre><code class="java">@Service(&quot;accountService&quot;)public class AccountServiceImpl implements AccountService {    //... 省略}</code></pre><h2 id="3-测试"><a href="#3-测试" class="headerlink" title="3. 测试"></a>3. 测试</h2><pre><code class="java">public class TestSpring {    @Test    public void run1() {        // 加载spring配置文件        ApplicationContext ac = new             ClassPathXmlApplicationContext(&quot;classpath:applicationContext.xml&quot;);        // 获取对象        AccountService as = (AccountService) ac.getBean(&quot;accountService&quot;);        // 调用方法        as.findAll();    }}</code></pre><p>如果正确的话将会输出查询所有账户方法中的内容。</p><h1 id="搭建SpringMVC框架"><a href="#搭建SpringMVC框架" class="headerlink" title="搭建SpringMVC框架"></a>搭建SpringMVC框架</h1><h2 id="1-在web-xml中配置前端控制器"><a href="#1-在web-xml中配置前端控制器" class="headerlink" title="1. 在web.xml中配置前端控制器"></a>1. 在web.xml中配置前端控制器</h2><p>他就是一个servlet，在这里需要配置三个内容</p><ul><li>加载springmvc的配置文件</li><li>启动该servlet</li><li>解决中文乱码问题</li></ul><pre><code class="xml">&lt;!--配置前端控制器--&gt;&lt;servlet&gt;    &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;    &lt;!--加载springmvc.xml配置文件--&gt;    &lt;init-param&gt;        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;        &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;    &lt;/init-param&gt;    &lt;!--启动服务器，创建本servlet--&gt;    &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;    &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;    &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;!--解决中文乱码问题--&gt;&lt;filter&gt;    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;    &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;    &lt;init-param&gt;        &lt;param-name&gt;encoding&lt;/param-name&gt;        &lt;param-value&gt;UTF-8&lt;/param-value&gt;    &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;</code></pre><h2 id="2-创建springmvc-xml配置文件"><a href="#2-创建springmvc-xml配置文件" class="headerlink" title="2. 创建springmvc.xml配置文件"></a>2. 创建springmvc.xml配置文件</h2><p>配置头为：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/mvc        http://www.springframework.org/schema/mvc/spring-mvc.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;/beans&gt;</code></pre><p>需要进行四个配置，将这四个配置写在beans的大标签内就可以了。</p><ul><li><p>开启注解扫描，只扫描Controller注解</p><pre><code class="xml">&lt;context:component-scan base-package=&quot;com.xiong&quot;&gt;    &lt;context:include-filter type=&quot;annotation&quot;                            expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;&lt;/context:component-scan&gt;</code></pre></li><li><p>配置视图解析器对象</p><pre><code class="xml">&lt;!--配置视图解析器对象--&gt;&lt;bean id=&quot;viewResolver&quot;       class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;    &lt;!-- JSP文件所在的目录 --&gt;    &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/pages/&quot; /&gt;    &lt;!-- 文件的后缀名 --&gt;    &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt;&lt;/bean&gt;</code></pre></li><li><p>过滤静态资源</p><pre><code class="xml">&lt;mvc:resources location=&quot;/css/&quot; mapping=&quot;/css/**&quot; /&gt;&lt;mvc:resources location=&quot;/images/&quot; mapping=&quot;/images/**&quot; /&gt;&lt;mvc:resources location=&quot;/js/&quot; mapping=&quot;/js/**&quot; /&gt;</code></pre></li><li><p>开启springmvc注解支持</p><pre><code class="xml">&lt;mvc:annotation-driven /&gt;</code></pre></li></ul><h2 id="3-配置index-jsp页面"><a href="#3-配置index-jsp页面" class="headerlink" title="3. 配置index.jsp页面"></a>3. 配置index.jsp页面</h2><p>在该页面上添加一个超链接，链接到相应的Controller方法中</p><pre><code class="jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;    &lt;head&gt;        &lt;title&gt;Title&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;a href=&quot;account/testStringFindAll&quot;&gt;测试findAll&lt;/a&gt;    &lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="4-编写Controller类"><a href="#4-编写Controller类" class="headerlink" title="4. 编写Controller类"></a>4. 编写Controller类</h2><p>通过下面的方法，可得最终返回的list根据视图解析器将会跳转到pages下的list.jsp页面上。</p><pre><code class="java">@Controller@RequestMapping(&quot;/account&quot;)public class AccountController {    @RequestMapping(&quot;/findAll&quot;)    public String findAll() {        return &quot;list&quot;;    }}</code></pre><h2 id="5-测试"><a href="#5-测试" class="headerlink" title="5. 测试"></a>5. 测试</h2><p>对应的跳转list.jsp文件如下：</p><pre><code class="jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;    &lt;head&gt;        &lt;title&gt;Title&lt;/title&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;h3&gt;哈哈&lt;/h3&gt;    &lt;/body&gt;&lt;/html&gt;</code></pre><p>经过测试，则index页面上面点击超链接，就可以跳转到指定的list.jsp页面上。</p><h1 id="搭建MyBatis框架"><a href="#搭建MyBatis框架" class="headerlink" title="搭建MyBatis框架"></a>搭建MyBatis框架</h1><p>mybatis有两种实现的方式，第一种是通过编写 AccountDao 映射配置文件，在这个配置文件中写SQL语句，另一种方式是通过注解，将注解写在AccountDao接口上面，来实现映射的。这里使用注解的方式来实现。</p><h2 id="1-给接口添加注解"><a href="#1-给接口添加注解" class="headerlink" title="1. 给接口添加注解"></a>1. 给接口添加注解</h2><pre><code class="java">public interface AccountDao {    // 查询所有账户信息    @Select(&quot;select * from account&quot;)    List&lt;Account&gt; findAll();    // 保存账户信息    @Insert(&quot;insert into account (name, money) values (#{name}, #{money})&quot;)    void saveAccount(Account account);}</code></pre><h2 id="2-编写-SqlMapConfig-配置文件"><a href="#2-编写-SqlMapConfig-配置文件" class="headerlink" title="2. 编写 SqlMapConfig 配置文件"></a>2. 编写 SqlMapConfig 配置文件</h2><p>这个核心配置文件是<strong>核心的配置文件</strong>，在该文件中添加文档标签和相关的约束条件。</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;!--配置环境--&gt;    &lt;properties resource=&quot;jdbcConfig.properties&quot;&gt;&lt;/properties&gt;    &lt;environments default=&quot;mysql&quot;&gt;        &lt;environment id=&quot;mysql&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;&gt;&lt;/transactionManager&gt;            &lt;dataSource type=&quot;pooled&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;${jdbc.driver}&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;${jdbc.username}&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;!--引入映射文件--&gt;    &lt;mappers&gt;        &lt;!--&lt;mapper class=&quot;com.xiong.dao.AccountDao&quot;/&gt;--&gt;        &lt;!--在这个包下创建任何的dao都会被默认地扫描，可以替代上面的--&gt;        &lt;package name=&quot;com.xiong.dao&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;</code></pre><p>然后创建相关的properties配置文件</p><pre><code class="properties">jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/ssm?useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC&amp;useSSL=falsejdbc.username=rootjdbc.password=</code></pre><h2 id="3-测试-1"><a href="#3-测试-1" class="headerlink" title="3. 测试"></a>3. 测试</h2><pre><code class="java">@Testpublic void run1() throws Exception{    // 加载mybatis的配置文件    InputStream in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;);    // 创建SqlSessionFactory工厂对象    SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(in);    // 创建SqlSession对象    SqlSession session = factory.openSession();    // 获取代理对象    AccountDao dao = session.getMapper(AccountDao.class);    // 查询所有数据    List&lt;Account&gt; accountList = dao.findAll();    for (Account account : accountList) {        System.out.println(account);    }    // 如果是提交数据，则需要一定要提交事务    session.commit();    // 关闭资源    session.close();    in.close();}</code></pre><img src="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/image-20200305175215552.png" alt="image-20200305175215552" style="zoom:80%;"><h1 id="Spring整合SpringMVC"><a href="#Spring整合SpringMVC" class="headerlink" title="Spring整合SpringMVC"></a>Spring整合SpringMVC</h1><p>在Controller中需要调用业务层Service的方法，如果能够成功调用Service的方法，则表示整合成功。</p><p>前端控制器会加载springmvc，只扫描Controller的注解，说明spring的配置文件并没有加载过，Service类就不能被加载到IOC容器中。因此需要<strong>在启动TomCat服务器的时候将spring的配置文件也加载进来</strong>。这样就可以把Service对象放到容器中，就可以在Controller中使用了。</p><h2 id="1-配置监听器实现启动服务创建容器"><a href="#1-配置监听器实现启动服务创建容器" class="headerlink" title="1. 配置监听器实现启动服务创建容器"></a>1. 配置监听器实现启动服务创建容器</h2><p>服务器启动的时候，会创建ServletContext对象，当服务器关闭的时候该对象才销毁。</p><p>做法也就是通过配置一个监听器，如果检测到ServletContext域对象创建，就执行监听器的内容，让这个监听器去加载Spring的配置文件。创建WEB版本工厂，存储ServletContext对象。</p><p>在web.xml文件中配置监听器（在web-app标签下添加Listener标签）</p><pre><code class="xml">&lt;!--配置Spring的监听器--&gt;&lt;listener&gt;    &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;</code></pre><p>但是这个监视器默认只加载WEB-INF目录下的applicationContext.xml文件，其他的加载不到，可以给它传参，来设置配置文件的路径。</p><pre><code class="xml">&lt;!--配置Spring的监听器--&gt;&lt;listener&gt;    &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!--设置配置文件路径--&gt;&lt;context-param&gt;    &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;    &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;</code></pre><h2 id="2-Controller中使用Service对象"><a href="#2-Controller中使用Service对象" class="headerlink" title="2. Controller中使用Service对象"></a>2. Controller中使用Service对象</h2><p>在AccountController类中添加一个对象，用spring注入</p><pre><code class="java">@Controller@RequestMapping(&quot;/account&quot;)public class AccountController {    @Autowired    private AccountService accountService;    @RequestMapping(&quot;/testFindAll&quot;)    public String findAll() {        System.out.println(&quot;表现层，查询所有账户&quot;);        accountService.findAll();        return &quot;list&quot;;    }}</code></pre><p>此时输出将会有两个输出</p><img src="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/image-20200305172658916.png" alt="image-20200305172658916" style="zoom:80%;"><p>说明在Controller中已经成功调用了Service的findAll方法</p><h1 id="Spring整合MyBatis"><a href="#Spring整合MyBatis" class="headerlink" title="Spring整合MyBatis"></a>Spring整合MyBatis</h1><p>Service能够调用Dao的对象就说明整合成功了。</p><h2 id="1-Spring-接管-MyBatis-的-Session-工厂"><a href="#1-Spring-接管-MyBatis-的-Session-工厂" class="headerlink" title="1. Spring 接管 MyBatis 的 Session 工厂"></a>1. Spring 接管 MyBatis 的 Session 工厂</h2><p>就是将SqlMapConfig.xml配置文件中的相关配置转交给Spring来做。</p><p>在applicationContext.xml文件中进行如下配置：</p><pre><code class="xml">&lt;!-- 加载配置文件 --&gt;&lt;context:property-placeholder location=&quot;classpath:jdbcConfig.properties&quot; /&gt;&lt;!-- 配置数据源 --&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;    &lt;property name=&quot;driverClass&quot; value=&quot;${jdbc.driver}&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;jdbcUrl&quot; value=&quot;${jdbc.url}&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;user&quot; value=&quot;${jdbc.username}&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置 MyBatis 的 Session 工厂 --&gt;&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;    &lt;!-- 数据库连接池 --&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;</code></pre><p>同时，将mybatis的配置文件直接删掉。</p><h2 id="2-配置自动扫描所有-Mapper-接口和文件"><a href="#2-配置自动扫描所有-Mapper-接口和文件" class="headerlink" title="2. 配置自动扫描所有 Mapper 接口和文件"></a>2. 配置自动扫描所有 Mapper 接口和文件</h2><p>配置AccountDao接口所在的包</p><p>在applicationContext.xml文件中进行如下配置：</p><pre><code class="xml">&lt;bean id=&quot;mapperScanner&quot; class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;    &lt;property name=&quot;basePackage&quot; value=&quot;com.xiong.dao&quot;/&gt;&lt;/bean&gt;</code></pre><p>然后将AccountDao前面加上一个 <code>@Repository</code> 注解，将它交给IOC容器去管。</p><pre><code class="java">@Repositorypublic interface AccountDao {    // 查询所有账户信息    @Select(&quot;select * from account&quot;)    List&lt;Account&gt; findAll();    // 保存账户信息    @Insert(&quot;insert into account (name, money) values (#{name}, #{money})&quot;)    void saveAccount(Account account);}</code></pre><p>最后在Service的实现类中，将这个accountDao加进来使用就行了</p><pre><code class="java">@Service(&quot;accountService&quot;)public class AccountServiceImpl implements AccountService {    @Autowired    private AccountDao accountDao;    @Override    public List&lt;Account&gt; findAll() {        System.out.println(&quot;业务层，查询所有账户&quot;);        return accountDao.findAll();    }    @Override    public void saveAccount(Account account) {        System.out.println(&quot;业务层，存储账户信息&quot;);        accountDao.saveAccount(account);    }}</code></pre><h2 id="3-测试findAll"><a href="#3-测试findAll" class="headerlink" title="3. 测试findAll"></a>3. 测试findAll</h2><p>在AccountController中进行测试：</p><pre><code class="java">@Controller@RequestMapping(&quot;/account&quot;)public class AccountController {    @Autowired    private AccountService accountService;    @RequestMapping(&quot;/testFindAll&quot;)    public String findAll(Model model) {        System.out.println(&quot;表现层，查询所有账户&quot;);        List&lt;Account&gt; list = accountService.findAll();        model.addAttribute(&quot;list&quot;, list);        return &quot;list&quot;;    }}</code></pre><p>经过测试可以得到正确的结果</p><img src="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/image-20200305183005577.png" alt="image-20200305183005577" style="zoom:80%;"><h2 id="4-配置-spring-的事务"><a href="#4-配置-spring-的事务" class="headerlink" title="4. 配置 spring 的事务"></a>4. 配置 spring 的事务</h2><p>需要进行以下三个配置，在applicationContext.xml文件中进行配置</p><ul><li><p>配置事务管理器</p><pre><code class="xml">&lt;bean id=&quot;transactionManager&quot;       class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;&lt;/bean&gt;</code></pre></li><li><p>配置事务通知</p><pre><code class="xml">&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt;    &lt;tx:attributes&gt;        &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot; read-only=&quot;false&quot;/&gt;        &lt;tx:method name=&quot;find*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot;/&gt;    &lt;/tx:attributes&gt;&lt;/tx:advice&gt;</code></pre></li><li><p>配置AOP增强</p><pre><code class="xml">&lt;aop:config&gt;    &lt;!-- 配置切入点表达式 --&gt;    &lt;aop:pointcut expression=&quot;execution(* com.xiong.service.impl.*.*(..))&quot; id=&quot;pt1&quot;/&gt;    &lt;!-- 建立通知和切入点表达式的关系 --&gt;    &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;pt1&quot;/&gt;&lt;/aop:config&gt;</code></pre></li></ul><h2 id="5-测试saveAccount"><a href="#5-测试saveAccount" class="headerlink" title="5. 测试saveAccount"></a>5. 测试saveAccount</h2><p>在index.jsp中添加一个表单，将name和money传入Controller</p><pre><code class="jsp">&lt;form action=&quot;account/testSave&quot; method=&quot;post&quot;&gt;    姓名：&lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt;&lt;br/&gt;    金额：&lt;input type=&quot;text&quot; name=&quot;money&quot;/&gt;&lt;br/&gt;    &lt;input type=&quot;submit&quot; name=&quot;保存&quot;/&gt;&lt;br/&gt;&lt;/form&gt;</code></pre><p>在AccountController中定义方法，这个意思是经过save方法之后，将重定向到findAll方法中，继续执行findAll的内容：</p><pre><code class="java">@RequestMapping(&quot;/testSave&quot;)public String testSave(Account account,                        HttpServletRequest request,                        HttpServletResponse response) throws IOException {    System.out.println(&quot;表现层，查询所有账户&quot;);    accountService.saveAccount(account);    response.sendRedirect(request.getContextPath() + &quot;/account/testFindAll&quot;);    return &quot;list&quot;;}</code></pre><p>经过测试，在数据库中增加了这条记录，测试成功。</p><img src="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/image-20200305185056220.png" alt="image-20200305185056220" style="zoom:80%;"><p>数据库中也进行了对应的更新：</p><img src="/2020/03/05/3-SpringMVC/1_%E6%90%AD%E5%BB%BAspring/image-20200305185116391.png" alt="image-20200305185116391" style="zoom:80%;">]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SSM整合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringMVC实战6】异常处理与拦截器</title>
      <link href="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/"/>
      <url>/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h1><p>在默认情况下，整个系统的架构如下所示，如果在底层出现了异常，这个异常就会一层一层向上抛，直到将这个异常抛到客户端（浏览器）</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305141007138.png" alt="image-20200305141007138" style="zoom:80%;"><p>可以通过异常处理，在前端控制器将捕获到的异常发送给异常处理器，经过异常处理器处理之后，客户端可以得到友好的提示页面。</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305141019610.png" alt="image-20200305141019610" style="zoom:80%;"><h2 id="1-异常演示"><a href="#1-异常演示" class="headerlink" title="1. 异常演示"></a>1. 异常演示</h2><p>在页面上增加一个Controller方法的入口</p><pre><code class="jsp">&lt;a href=&quot;user/testException&quot;&gt;异常处理&lt;/a&gt;</code></pre><p>可以在Controller中模拟一个异常，注意这里的方法需要写一个throws Exception来将异常抛出去</p><pre><code class="java">@Controller@RequestMapping(&quot;/user&quot;)public class UserController {    @RequestMapping(&quot;/testException&quot;)    public String testException() throws Exception{        System.out.println(&quot;testException执行了&quot;);        // 在这里模拟一个异常        int i = 10 / 0;        return &quot;success&quot;;    }}</code></pre><p>如果不设置异常处理器，则通过web点击页面可以发现页面上报错是不太友好的。</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305142812691.png" alt="image-20200305142812691" style="zoom:80%;"><h2 id="2-异常处理器"><a href="#2-异常处理器" class="headerlink" title="2. 异常处理器"></a>2. 异常处理器</h2><ul><li><p>编写一个自定义异常类（用于做提示信息）</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305143206251.png" alt="image-20200305143206251" style="zoom:80%;"></li></ul><ul><li><p>编写异常处理器</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305144652611.png" alt="image-20200305144652611" style="zoom:80%;"><p>然后把error页面设置一下：</p><pre><code class="jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; isELIgnored=&quot;false&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;Error&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    ${errorMsg}&lt;/body&gt;&lt;/html&gt;</code></pre><p>之后再可能出现异常的地方加上throw就可以了，把SystemException异常给抛出去。</p><pre><code class="java">@Controller@RequestMapping(&quot;/user&quot;)public class UserController {    @RequestMapping(&quot;/testException&quot;)    public String testException() throws Exception{        System.out.println(&quot;testException执行了&quot;);        try {            // 在这里模拟一个异常            int i = 10 / 0;        } catch (Exception e) {            // 在控制台打印异常信息            e.printStackTrace();            // 向上抛出自定义异常信息            throw new SysException(&quot;出现了错误...&quot;);        }        return &quot;success&quot;;    }}</code></pre></li></ul><ul><li><p>配置异常处理器（决定跳转到友好页面去）</p><p>需要在springmvc.xml文件中进行配置</p><pre><code class="xml">&lt;!--配置异常处理器--&gt;&lt;bean id=&quot;sysExceptionResolver&quot; class=&quot;com.xiong.exception.SysExceptionResolver&quot;/</code></pre></li></ul><p>经过测试，可以得到预想的结果</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305144848499.png" alt="image-20200305144848499" style="zoom:80%;"><h1 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h1><h2 id="1-拦截器的作用"><a href="#1-拦截器的作用" class="headerlink" title="1. 拦截器的作用"></a>1. 拦截器的作用</h2><p>Spring MVC 的处理器拦截器类似于 Servlet 开发中的过滤器 Filter，用于<strong>对处理器（Controller）进行预处理和后处理</strong>。</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305151217519.png" alt="image-20200305151217519" style="zoom:80%;"><p>用户可以自己定义一些拦截器来实现特定的功能。</p><p>拦截器链（Interceptor Chain）。拦截器链就是将拦截器按一定的顺序联结成一条链。在访问被拦截的方法或字段时，拦截器链中的拦截器就会按其之前定义的顺序被调用。</p><p>拦截器和过滤器是有几分相似，但是也有区别：</p><ul><li>过滤器是 servlet 规范中的一部分， 任何 java web 工程都可以使用。</li><li>拦截器是 SpringMVC 框架自己的，只有使用了 SpringMVC 框架的工程才能用。</li><li>过滤器在 url-pattern 中配置了/*之后，可以对所有要访问的资源拦截。</li><li>拦截器<strong>只会拦截访问的Controller的方法</strong>，如果访问的是 jsp, html,css,image 或者 js 是不会进行拦截的。</li></ul><p>拦截器能做的，过滤器都能做，但是过滤器能做的，拦截器不一定能做。</p><p>它也是 <strong>AOP 思想的具体应用</strong>。</p><h2 id="2-编写拦截器类"><a href="#2-编写拦截器类" class="headerlink" title="2. 编写拦截器类"></a>2. 编写拦截器类</h2><p>要想自定义拦截器， 要求必须实现： HandlerInterceptor 接口。该接口有三个方法：</p><ul><li><strong>预处理</strong>：Controller方法执行前应该执行该方法，其return值如果为true，则表示放行，可以执行下一个拦截器，否则就执行Controller中的方法，如果return为false，则不放行，可以使用request和response跳转到某个页面中</li><li>post可以跳转页面，指定新的跳转，比如本来在Controller中指定跳转到success，但是post拦截器中拦截后指定跳转到error页面，则最终是会跳转到error页面的</li><li>after拦截可以进行一些后续处理工作。</li></ul><pre><code class="java">// 预处理@Overridepublic boolean preHandle(HttpServletRequest request,                         HttpServletResponse response,                         Object handler) throws Exception {    System.out.println(&quot;拦截器执行了&quot;);    return true;    /*    下面是false，即不放行的情况    request.getRequestDispatcher(&quot;/WEB-INF/pages/error.jsp&quot;).forward(request, response);    return false;    */}// 后处理@Overridepublic void postHandle(HttpServletRequest request,                       HttpServletResponse response,                       Object handler,                       ModelAndView modelAndView) throws Exception {    System.out.println(&quot;post拦截方法执行了&quot;);}// 页面结束后执行@Overridepublic void afterCompletion(HttpServletRequest request,                            HttpServletResponse response,                            Object handler,                            Exception ex) throws Exception {    System.out.println(&quot;after拦截方法执行了&quot;);}</code></pre><h2 id="3-配置拦截器"><a href="#3-配置拦截器" class="headerlink" title="3. 配置拦截器"></a>3. 配置拦截器</h2><p>在springmvc.xml文件中配置拦截器</p><pre><code class="xml">&lt;mvc:interceptors&gt;    &lt;mvc:interceptor&gt;        &lt;!--要拦截的具体方法--&gt;        &lt;mvc:mapping path=&quot;/user/**&quot;/&gt;        &lt;bean class=&quot;com.xiong.controller.com.xiong.interceptor.MyInterceptor1&quot;/&gt;        &lt;!--不要拦截的方法--&gt;        &lt;!--&lt;mvc:exclude-mapping path=&quot;&quot;/&gt;--&gt;    &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;</code></pre><p>然后就可以通过jsp文件进行调用了</p><pre><code class="jsp">&lt;a href=&quot;user/testInterceptor&quot;&gt;测试拦截器&lt;/a&gt;</code></pre><p>java文件中直接写一个处理就行了</p><pre><code class="java">@Controller@RequestMapping(&quot;/user&quot;)public class UserController {    @RequestMapping(&quot;/testInterceptor&quot;)    public String testInterceptor() {        System.out.println(&quot;testInterceptor执行了&quot;);        return &quot;success&quot;;    }}</code></pre><p>运行结果为：</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305155106609.png" alt="image-20200305155106609" style="zoom:80%;"><p>因此就可以看出各个拦截器执行的时机。</p><h2 id="4-多个拦截器"><a href="#4-多个拦截器" class="headerlink" title="4. 多个拦截器"></a>4. 多个拦截器</h2><p>如果有多个拦截器，例如2个，他们的运行顺序关系如下：</p><img src="/2020/03/05/3-SpringMVC/7_SpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E4%B8%8E%E6%8B%A6%E6%88%AA%E5%99%A8/image-20200305155937116.png" alt="image-20200305155937116" style="zoom:80%;"><p>需要在springmvc.xml文件中进行配置，就是多加一个标签而已</p><pre><code class="xml">&lt;!--配置拦截器--&gt;&lt;mvc:interceptors&gt;    &lt;!--第一个拦截器--&gt;    &lt;mvc:interceptor&gt;        &lt;!--要拦截的具体方法--&gt;        &lt;mvc:mapping path=&quot;/user/**&quot;/&gt;        &lt;bean class=&quot;com.xiong.controller.com.xiong.interceptor.MyInterceptor1&quot;/&gt;    &lt;/mvc:interceptor&gt;    &lt;!--第二个拦截器--&gt;    &lt;mvc:interceptor&gt;        &lt;!--要拦截的具体方法--&gt;        &lt;mvc:mapping path=&quot;/user/**&quot;/&gt;        &lt;bean class=&quot;com.xiong.controller.com.xiong.interceptor.MyInterceptor2&quot;/&gt;    &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringMVC实战5】响应</title>
      <link href="/2020/03/04/3-SpringMVC/6_SpringMVC%E5%93%8D%E5%BA%94/"/>
      <url>/2020/03/04/3-SpringMVC/6_SpringMVC%E5%93%8D%E5%BA%94/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="响应返回类型"><a href="#响应返回类型" class="headerlink" title="响应返回类型"></a>响应返回类型</h1><h2 id="1-返回值是String"><a href="#1-返回值是String" class="headerlink" title="1. 返回值是String"></a>1. 返回值是String</h2><p>controller 方法返回字符串可以指定逻辑视图名，通过视图解析器解析为物理视图地址。</p><p>从页面的超链接入手，映射到java的方法。</p><pre><code class="jsp">&lt;a href=&quot;user/testString&quot;&gt;testString&lt;/a&gt;</code></pre><p>java方法写成下面这样：通过Model来传递对象值。</p><pre><code class="java">@Controller@RequestMapping(&quot;/user&quot;)public class UserController {    @RequestMapping(&quot;/testString&quot;)    public String testString(Model model) {        System.out.println(&quot;testString执行了&quot;);        // 模拟从数据库中查询出了用户对象，在页面上展示数据        User user = new User();        user.setUsername(&quot;蔡徐坤&quot;);        user.setPassword(&quot;abcd&quot;);        user.setAge(27);        model.addAttribute(&quot;user&quot;, user);        return &quot;success&quot;;    }}</code></pre><p>在success页面将结果展示：</p><pre><code class="jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; isELIgnored=&quot;false&quot; %&gt;&lt;html&gt;    &lt;head&gt;        &lt;title&gt;success&lt;/title&gt;&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;h3&gt;执行成功&lt;/h3&gt;        &lt;b/&gt;        ${user.username}        ${user.password}        ${user.age}    &lt;/body&gt;&lt;/html&gt;</code></pre><p>经过执行后，结果如下</p><img src="/2020/03/04/3-SpringMVC/6_SpringMVC%E5%93%8D%E5%BA%94/image-20200305101630580.png" alt="image-20200305101630580" style="zoom:80%;"><h2 id="2-返回值是void"><a href="#2-返回值是void" class="headerlink" title="2. 返回值是void"></a>2. 返回值是void</h2><h3 id="2-1-默认跳转"><a href="#2-1-默认跳转" class="headerlink" title="2.1 默认跳转"></a>2.1 默认跳转</h3><p>如果没有返回值，则跳转的默认页面是请求路径的jsp。比如说，用下面的类和方法进行测试，结果如图：</p><pre><code class="java">@Controller@RequestMapping(&quot;/user&quot;)public class UserController {    // 返回值为void    @RequestMapping(&quot;/testVoid&quot;)    public void testVoid() {        System.out.println(&quot;testVoid执行了&quot;);    }}</code></pre><img src="/2020/03/04/3-SpringMVC/6_SpringMVC%E5%93%8D%E5%BA%94/image-20200305102406199.png" alt="image-20200305102406199" style="zoom:80%;"><p>当然，也可以通过相关的设置来指定路径</p><h3 id="2-2-转发跳转"><a href="#2-2-转发跳转" class="headerlink" title="2.2 转发跳转"></a>2.2 转发跳转</h3><p>此时的方法需要引入两个参数，<code>HttpServletRequest request</code> 和 <code>HttpServletResponse response</code>。然后通过手动调用转发进行跳转：这里是转发一次请求，不需要写项目的名称</p><pre><code class="java">@RequestMapping(&quot;/testVoid&quot;)public void testVoid(HttpServletRequest request,                      HttpServletResponse response) throws Exception {    System.out.println(&quot;testVoid执行了&quot;);    // 编写请求转发的程序    request.getRequestDispatcher(&quot;/WEB-INF/pages/success.jsp&quot;).forward(request, response);}</code></pre><p>注意：手动调用转发的时候，不会执行视图解析器，因此这里的路径需要写全称。</p><h3 id="2-3-重定向"><a href="#2-3-重定向" class="headerlink" title="2.3 重定向"></a>2.3 重定向</h3><p>重定向，相当于重新发了个新的请求，不能够直接进到项目的目录中，因此需要将项目名也加上。</p><p>通过 <code>request.getContextPath()</code> 获取项目名称</p><pre><code class="java">// 返回值为void@RequestMapping(&quot;/testVoid&quot;)public void testVoid(HttpServletRequest request,                      HttpServletResponse response) throws Exception {    System.out.println(&quot;testVoid执行了&quot;);    //     response.sendRedirect(request.getContextPath() + &quot;/WEB-INF/pages/success.jsp&quot;);}</code></pre><h3 id="2-4-直接进行响应"><a href="#2-4-直接进行响应" class="headerlink" title="2.4 直接进行响应"></a>2.4 直接进行响应</h3><p>之前都是通过tomcat生成html响应给用户，这里的直接进行响应也就是不跳转jsp，直接将结果响应给用户</p><pre><code class="java">@RequestMapping(&quot;/testVoid&quot;)public void testVoid(HttpServletRequest request, HttpServletResponse response) throws Exception {    System.out.println(&quot;testVoid执行了&quot;);    // 直接响应    // 设置中文乱码问题    response.setCharacterEncoding(&quot;utf-8&quot;);    // 解析的编码问题    response.setContentType(&quot;application/json;charset=utf-8&quot;);    response.getWriter().write(&quot;json 串&quot;);}</code></pre><p>结果是：</p><img src="/2020/03/04/3-SpringMVC/6_SpringMVC%E5%93%8D%E5%BA%94/image-20200305104252792.png" alt="image-20200305104252792" style="zoom:80%;"><h2 id="3-返回值是ModelAndView"><a href="#3-返回值是ModelAndView" class="headerlink" title="3. 返回值是ModelAndView"></a>3. 返回值是ModelAndView</h2><p>springmvc提供的对象，用来调整具体的jsp页面。</p><pre><code class="java">@RequestMapping(&quot;/testModelAndView&quot;)public ModelAndView testModelAndView() {    System.out.println(&quot;testModelAndView执行了&quot;);    ModelAndView mv = new ModelAndView();    // 模拟从数据库中查询出了用户对象    User user = new User();    user.setUsername(&quot;蔡徐坤&quot;);    user.setPassword(&quot;abcd&quot;);    user.setAge(27);    // 把user对象存储到mv对象中，底层会把user对象存入request域当中    mv.addObject(&quot;user&quot;, user);    // 跳转到哪个页面,这里使用视图解析器，来跳转    mv.setViewName(&quot;success&quot;);    return mv;}</code></pre><p>在success页面展示相应的信息：</p><pre><code class="jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; isELIgnored=&quot;false&quot; %&gt;&lt;html&gt;    &lt;head&gt;        &lt;title&gt;success&lt;/title&gt;&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;h3&gt;执行成功&lt;/h3&gt;        &lt;b/&gt;        ${user.username}        ${user.password}        ${user.age}    &lt;/body&gt;&lt;/html&gt;</code></pre><img src="/2020/03/04/3-SpringMVC/6_SpringMVC%E5%93%8D%E5%BA%94/image-20200305105447621.png" alt="image-20200305105447621" style="zoom:80%;"><h2 id="4-返回值是json"><a href="#4-返回值是json" class="headerlink" title="4. 返回值是json"></a>4. 返回值是json</h2><p>在方法的返回值前面增加一个注解 <code>@ResponseBody</code> 可以将 controller 方法返回对象转换为 json 响应给客户端。</p><pre><code class="java">@Controller(&quot;jsonController&quot;)public class JsonController {    @RequestMapping(&quot;/testResponseJson&quot;)    public @ResponseBody Account testResponseJson(@RequestBody Account account) {        System.out.println(&quot;异步请求： &quot;+account);        return account;    }}</code></pre><h1 id="使用关键字进行页面跳转"><a href="#使用关键字进行页面跳转" class="headerlink" title="使用关键字进行页面跳转"></a>使用关键字进行页面跳转</h1><h2 id="1-使用forward转发"><a href="#1-使用forward转发" class="headerlink" title="1. 使用forward转发"></a>1. 使用forward转发</h2><pre><code class="java">// 使用关键字的方式进行转发或者重定向@RequestMapping(&quot;/testForwardOrRedirect&quot;)public String testForwardOrRedirect() {    System.out.println(&quot;testForwardOrRedirect执行了&quot;);    // 请求的转发，这里不能使用视图解析器，因此需要将页面的路径写详细了    return &quot;forward:/WEB-INF/pages/success.jsp&quot;;}</code></pre><h2 id="2-使用redirect重定向"><a href="#2-使用redirect重定向" class="headerlink" title="2. 使用redirect重定向"></a>2. 使用redirect重定向</h2><pre><code class="java">// 使用关键字的方式进行转发或者重定向@RequestMapping(&quot;/testForwardOrRedirect&quot;)public String testForwardOrRedirect() {    System.out.println(&quot;testForwardOrRedirect执行了&quot;);    // 注意这里不需要加项目名称，框架已经默认加好了    return &quot;redirect:index.jsp&quot;;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringMVC实战3】常用注解</title>
      <link href="/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/"/>
      <url>/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="RequestMapping建立映射"><a href="#RequestMapping建立映射" class="headerlink" title="RequestMapping建立映射"></a>RequestMapping建立映射</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>用于建立请求 URL 和处理请求方法之间的对应关系</p><h2 id="出现位置"><a href="#出现位置" class="headerlink" title="出现位置"></a>出现位置</h2><p><strong>类上：</strong></p><ul><li><p>请求 URL 的第一级访问目录。</p><p>此处不写的话，就相当于<strong>应用的根目录</strong>。 写的话需要以/开头。</p><p>它出现的目的是为了使 URL 可以按照模块化管理:</p><p>例如：</p><pre><code>账户模块：/account/add/account/update/account/delete...订单模块：/order/add/order/update/order/delete</code></pre><p>其中，<code>/account</code> 和 <code>/order</code> 就是把 RequsetMappding 写在类上，称为一级目录，<code>/add</code> <code>/update</code> <code>/delete</code> 是第二级访问目录。</p></li></ul><p><strong>方法上：</strong></p><ul><li>请求 URL 的第二级访问目录。</li></ul><p>例如，下面将重新创建一个方法，想要访问该方法，就需要在index.jsp里面将超链接的路径写成下面</p><pre><code class="jsp">&lt;a href=&quot;user/testReqMapping&quot;&gt;Requesting Mapping 注解&lt;/a&gt;</code></pre><img src="/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/image-20200302152925940.png" alt="image-20200302152925940" style="zoom:80%;"><h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><ul><li><p><code>value</code></p><p><strong>作用</strong>：用于指定请求的 URL。 它和 path 属性的作用是一样的。</p></li><li><p><code>method</code></p><p><strong>作用</strong>：用于指定请求的方式。</p><p>其中可用的属性为：</p><pre><code class="java">public enum RequestMethod {    GET,    HEAD,    POST,    PUT,    PATCH,    DELETE,    OPTIONS,    TRACE;    private RequestMethod() {    }}</code></pre><p><strong>例子</strong>：前面一致在用的点击超链接的方式，都是GET方法，但是可以通过其他的方式指定请求方式，例如POST等。</p><pre><code class="java">@RequestMapping(path = &quot;/testReqMapping&quot;, method = {RequestMethod.POST})public  String testRequestingMapping() {    System.out.println(&quot;测试注解&quot;);    return &quot;success&quot;;}</code></pre></li><li><p><code>params</code></p><p><strong>作用</strong>：用于指定限制请求参数的条件。 它支持简单的表达式。 要求请求参数的 key 和 value 必须和配置的一模一样。</p><p><strong>例如</strong>：</p><p><code>params = {&quot;accountName&quot;}</code>，表示请求参数必须有 accountName</p><p><code>params = {&quot;moeny=100&quot;}</code>，表示请求参数中 money 必须是 100</p><p><code>params = {&quot;moeny!100&quot;}</code>，表示请求参数中 money 不能是 100</p><pre><code class="java">@RequestMapping(path = &quot;/testReqMapping&quot;, params = {&quot;username&quot;})public  String testRequestingMapping() {    System.out.println(&quot;测试注解&quot;);    return &quot;success&quot;;}</code></pre><p>此时请求需要更换为下面：</p><pre><code class="jsp">&lt;a href=&quot;user/testReqMapping?username=hehe&quot;&gt;Requesting Mapping 注解&lt;/a&gt;</code></pre></li><li><p><code>headers</code></p><p><strong>作用</strong>：发送的请求中必须包含的请求头。</p><p>请求头在浏览器的F12中可以查看</p><img src="/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/image-20200302155056117.png" alt="image-20200302155056117" style="zoom:80%;"></li></ul><p>注意：<br>以上四个属性只要出现多个，他们的关系是<strong>与</strong>的关系。  </p><h1 id="RequestParam给形参赋指定名称"><a href="#RequestParam给形参赋指定名称" class="headerlink" title="RequestParam给形参赋指定名称"></a>RequestParam给形参赋指定名称</h1><h2 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h2><p>把请求中指定名称的参数给控制器中的形参赋值。</p><h2 id="属性-1"><a href="#属性-1" class="headerlink" title="属性"></a>属性</h2><p>value： 请求参数中的名称。</p><p>required：请求参数中是否必须提供此参数。 默认值： true。表示必须提供，如果不提供将报错。</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>在jsp文件中传参：</p><pre><code class="jsp">&lt;body&gt;    &lt;%--常用注解--%&gt;    &lt;a href=&quot;anno/testRequestParam?name=haha&quot;&gt;TestRequestParam&lt;/a&gt;&lt;/body&gt;</code></pre><p>在对应Controller的参数列表中写增加注解</p><pre><code class="java">@Controller@RequestMapping(&quot;/anno&quot;)public class AnnoController {    @RequestMapping(&quot;/testRequestParam&quot;)    public String testRequestParam(        @RequestParam(name = &quot;name&quot;,  required = false) String username    ) {        System.out.println(username);        return &quot;success&quot;;    }}</code></pre><p>就可以将请求中的name参数映射为函数中的username参数了。</p><h1 id="RequestBody获取请求体内容"><a href="#RequestBody获取请求体内容" class="headerlink" title="RequestBody获取请求体内容"></a>RequestBody获取请求体内容</h1><h2 id="作用-2"><a href="#作用-2" class="headerlink" title="作用"></a>作用</h2><p>用于获取<strong>请求体</strong>内容。 直接使用得到是 key=value&amp;key=value…结构的数据。</p><p>get 请求方式不适用。可以用表单来测试</p><h2 id="属性-2"><a href="#属性-2" class="headerlink" title="属性"></a>属性</h2><p>required：是否必须有请求体。默认值是:true。当取值为 true 时,get 请求方式会报错。如果取值为 false， get 请求得到是 null。  </p><h2 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h2><p>在jsp中创建一个表单：</p><pre><code class="jsp">&lt;form action=&quot;anno/testRequestBody&quot; method=&quot;post&quot;&gt;    姓名：&lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt; &lt;br/&gt;    年龄：&lt;input type=&quot;text&quot; name=&quot;age&quot; /&gt; &lt;br/&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;br/&gt;&lt;/form&gt;</code></pre><p>在对应的Controller进行测试：</p><pre><code class="java">@RequestMapping(&quot;/testRequestBody&quot;)public String testRequestBody(@RequestBody(required = true) String body) {    System.out.println(body);    return &quot;success&quot;;}</code></pre><p>测试结果就是：</p><pre><code>username=hehe&amp;age=321</code></pre><h1 id="PathVariable绑定URL占位符"><a href="#PathVariable绑定URL占位符" class="headerlink" title="PathVariable绑定URL占位符"></a>PathVariable绑定URL占位符</h1><h2 id="作用-3"><a href="#作用-3" class="headerlink" title="作用"></a>作用</h2><p>用于绑定 url 中的占位符。 例如：请求 url 中 <code>/delete/{id}</code>， 这个{id}就是 url 占位符。</p><p>使用REST风格也就表示这里不需要写 <code>/id=10</code>，而是直接写一个 <code>/10</code> 就可以了</p><p>url 支持占位符是 spring3.0 之后加入的。是 springmvc 支持 rest 风格 URL 的一个重要标志。</p><h2 id="属性-3"><a href="#属性-3" class="headerlink" title="属性"></a>属性</h2><p>value： 用于指定 url 中占位符名称。</p><p>required：是否必须提供占位符。  </p><h2 id="例子-2"><a href="#例子-2" class="headerlink" title="例子"></a>例子</h2><p>jsp文件中的定义：</p><pre><code class="jsp">&lt;a href=&quot;anno/testVariable/10&quot;&gt;testPathVariable&lt;/a&gt;</code></pre><p>在Controller类中的定义：</p><pre><code class="java">@RequestMapping(&quot;/testVariable/{id}&quot;)public String testPathVariable(@PathVariable(name = &quot;id&quot;) String id) {    System.out.println(id);    return &quot;success&quot;;}</code></pre><h1 id="RequestHeader获取请求头"><a href="#RequestHeader获取请求头" class="headerlink" title="RequestHeader获取请求头"></a>RequestHeader获取请求头</h1><h2 id="作用-4"><a href="#作用-4" class="headerlink" title="作用"></a>作用</h2><p>用于获取请求消息头。</p><h2 id="属性-4"><a href="#属性-4" class="headerlink" title="属性"></a>属性</h2><p>value：提供消息头名称</p><p>required：是否必须有此消息头  </p><h2 id="例子-3"><a href="#例子-3" class="headerlink" title="例子"></a>例子</h2><p>在jsp文件中定义：</p><pre><code class="jsp">&lt;a href=&quot;anno/testRequestHeader&quot;&gt;testRequestHeader&lt;/a&gt;</code></pre><p>在Controller类中定义：</p><pre><code class="java">@RequestMapping(&quot;/testRequestHeader&quot;)public String testRequestHeader(@RequestHeader(value = &quot;Accpet&quot;) String header) {    System.out.println(header);    return &quot;success&quot;;}</code></pre><p>得到的结果为：</p><pre><code>text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9</code></pre><h1 id="CookieValue获取指定cookie的值"><a href="#CookieValue获取指定cookie的值" class="headerlink" title="CookieValue获取指定cookie的值"></a>CookieValue获取指定cookie的值</h1><h2 id="作用-5"><a href="#作用-5" class="headerlink" title="作用"></a>作用</h2><p>用于把指定 cookie 名称的值传入控制器方法参数。</p><h2 id="属性-5"><a href="#属性-5" class="headerlink" title="属性"></a>属性</h2><p>value：指定 cookie 的名称。</p><p>required：是否必须有此 cookie。  </p><h2 id="例子-4"><a href="#例子-4" class="headerlink" title="例子"></a>例子</h2><p>在jsp文件中添加下面语句</p><pre><code class="jsp">&lt;a href=&quot;anno/testCookieValue&quot;&gt;testCookieValue&lt;/a&gt;</code></pre><p>在Controller中添加：</p><pre><code class="java">@RequestMapping(&quot;/testCookieValue&quot;)public String testCookieValue(@CookieValue(value = &quot;JSESSIONID&quot;) String cookie) {    System.out.println(cookie);    return &quot;success&quot;;}</code></pre><p>得到的结果是：</p><pre><code>330A894BCD72B8FF4719E7D82E501F32</code></pre><p>拿到了指定的cookie值</p><h1 id="ModelAttribute控制参数"><a href="#ModelAttribute控制参数" class="headerlink" title="ModelAttribute控制参数"></a>ModelAttribute控制参数</h1><h2 id="作用-6"><a href="#作用-6" class="headerlink" title="作用"></a>作用</h2><p>该注解是 SpringMVC4.3 版本以后新加入的。它可以用于修饰方法和参数。</p><ul><li>出现在方法上，表示当前方法会在控制器的方法执行之前，先执行。它可以修饰没有返回值的方法，也可<br>以修饰有具体返回值的方法。</li><li>出现在参数上，获取指定的数据给参数赋值。</li></ul><h2 id="属性-6"><a href="#属性-6" class="headerlink" title="属性"></a>属性</h2><p>value：用于获取数据的 key。 key 可以是 POJO 的属性名称，也可以是 map 结构的 key。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>当表单提交数据不是完整的实体类数据时，保证没有提交数据的字段使用数据库对象原来的数据。</p><p>例如，用户的POJO类型为：</p><img src="/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/image-20200304183432289.png" alt="image-20200304183432289" style="zoom:80%;"><p>提交表单的时候，user和date两个属性没有提交，则通过这个注解可以将空缺的字段置为指定值（比如从数据库中查询）。</p><h2 id="例子-5"><a href="#例子-5" class="headerlink" title="例子"></a>例子</h2><p>在jsp中提交一个表单，这个表单是不完整的，例如下面：</p><pre><code class="jsp">&lt;form action=&quot;anno/testModelAttribute&quot; method=&quot;post&quot;&gt;    姓名：&lt;input type=&quot;text&quot; name=&quot;uname&quot; /&gt; &lt;br/&gt;    年龄：&lt;input type=&quot;text&quot; name=&quot;age&quot; /&gt; &lt;br/&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;br/&gt;&lt;/form&gt;</code></pre><p>在Controller里面增加的内容有两种：带返回值的和不带返回值的</p><p><strong>第一种：带返回值的</strong></p><pre><code class="java">@RequestMapping(&quot;/testModelAttribute&quot;)public String testModelAttribute(User user) {    System.out.println(user);    return &quot;success&quot;;}// 该方法先执行@ModelAttributepublic User showUser(String uname) {    System.out.println(&quot;执行了ModelAttribute&quot; + uname);    User user = new User();    user.setDate(new Date());    // 通过数据库查询    // ... 省略查询代码    return user;}</code></pre><p>最终的执行结果：</p><img src="/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/image-20200304183406762.png" alt="image-20200304183406762" style="zoom:80%;"><p>可以看出，是限制性了ModelAttribute里面的方法，才转交给指定方法的，并且，这里只能对null数据进行补全，比如表单中提交了age=4，方法中虽然可以设置setAge=5，但是最终提供给方法的User对象里面age值仍然是4，不能被修改。</p><p><strong>第二种：不带返回值的</strong></p><pre><code class="java">@RequestMapping(&quot;/testModelAttribute&quot;)public String testModelAttribute(@ModelAttribute(&quot;abc&quot;) User user) {    System.out.println(user);    return &quot;success&quot;;}// 该方法先执行@ModelAttributepublic void showUser(String uname, Map&lt;String, User&gt; map) {    System.out.println(&quot;执行了ModelAttribute&quot; + uname);    User user = new User();    user.setDate(new Date());    // 通过数据库查询    // ... 省略查询代码    map.put(&quot;abc&quot;, user);}</code></pre><p>执行结果为：</p><img src="/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/image-20200304184022882.png" alt="image-20200304184022882" style="zoom:80%;"><h1 id="SessionAttributes"><a href="#SessionAttributes" class="headerlink" title="SessionAttributes"></a>SessionAttributes</h1><h2 id="作用-7"><a href="#作用-7" class="headerlink" title="作用"></a>作用</h2><p>用于多次执行控制器方法间的<strong>参数共享</strong>。</p><p>session域是会话域，如果有多次请求，可以多次使用。注意这个注解需要在类上面使用。</p><h2 id="属性-7"><a href="#属性-7" class="headerlink" title="属性"></a>属性</h2><p>value：用于指定存入的属性名称</p><p>type：用于指定存入的数据类型。  </p><h2 id="例子-6"><a href="#例子-6" class="headerlink" title="例子"></a>例子</h2><p>可以在success页面上面打印下面的域信息，通过这些信息，进行测试</p><pre><code class="jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; isELIgnored=&quot;false&quot; %&gt;&lt;html&gt;    &lt;head&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;h3&gt;入门成功&lt;/h3&gt;        &lt;b/&gt;        ${msg}        ${sessionScope}    &lt;/body&gt;&lt;/html&gt;</code></pre><p>调用的jsp</p><pre><code class="jsp">&lt;a href=&quot;anno/setSessionAttributes&quot;&gt;testsetSessionAttributes&lt;/a&gt;&lt;a href=&quot;anno/getSessionAttributes&quot;&gt;testGetSessionAttributes&lt;/a&gt;</code></pre><p>然后在相应的Controller中进行如下定义：</p><pre><code class="java">@Controller@RequestMapping(&quot;/anno&quot;)@SessionAttributes(value = {&quot;msg&quot;}) // 把msg存入到session域对中public class AnnoController {    // 向session中存入值    @RequestMapping(&quot;/setSessionAttributes&quot;)    public String setSessionAttributes(ModelMap modelMap) {        System.out.println(&quot;setSessionAttributes执行了&quot;);        modelMap.addAttribute(&quot;msg&quot;, &quot;哈哈&quot;);        return &quot;success&quot;;    }    // 从session域中获取值    @RequestMapping(&quot;/getSessionAttributes&quot;)    public String getSessionAttributes(ModelMap modelMap) {        String msg = (String) modelMap.get(&quot;msg&quot;);        System.out.println(&quot;getSessionAttributes执行了&quot;);        System.out.println(msg);        return &quot;success&quot;;    }    // 删除    // 会将session域删除    @RequestMapping(&quot;/delSessionAttributes&quot;)    public String delSessionAttributes(SessionStatus status) {        status.setComplete();        return &quot;success&quot;;    }}</code></pre><p>在控制台运行之后，可以发现两次请求能够共享本次session的数据：</p><img src="/2020/03/03/3-SpringMVC/4_SpringMVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/image-20200304205938554.png" alt="image-20200304205938554" style="zoom:80%;">]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringMVC实战4】请求参数绑定</title>
      <link href="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/"/>
      <url>/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="请求参数绑定的意义"><a href="#请求参数绑定的意义" class="headerlink" title="请求参数绑定的意义"></a>请求参数绑定的意义</h1><p>请求参数绑定实际上就是</p><p>表单中请求参数都是基于 key=value 的。</p><p>SpringMVC 绑定请求参数的过程是通过把表单提交请求参数，作为控制器中方法参数进行绑定的。  </p><pre><code class="jsp">&lt;a href=&quot;account/findAccount?accountId=10&quot;&gt;查询账户&lt;/a&gt;</code></pre><p>其中请求参数是：<code>accountId=10</code>。</p><pre><code class="java">/*** 查询账户* @return*/@RequestMapping(&quot;/findAccount&quot;)public String findAccount(Integer accountId) {    System.out.println(&quot;查询了账户。。。。 &quot;+accountId);    return &quot;success&quot;;}</code></pre><p>如果方法的参数名与请求参数是相同的，则springmvc会自动将传进来的参数赋值到java的参数列表中。</p><blockquote><p>如果想要新建一个新的页面，然后在这个新页面测试，只需要输入这个新页面的地址就可以访问了。</p><p>例如，创建一个params.jsp文件用于测试参数绑定，这可以通过这种方式来访问params.jsp</p><pre><code>http://localhost:8080/SpringMVC_1_war/params.jsp</code></pre></blockquote><h1 id="支持的数据类型"><a href="#支持的数据类型" class="headerlink" title="支持的数据类型"></a>支持的数据类型</h1><h2 id="1-基本数据类型、字符串类型"><a href="#1-基本数据类型、字符串类型" class="headerlink" title="1. 基本数据类型、字符串类型"></a>1. 基本数据类型、字符串类型</h2><p>要求参数名称必须和控制器中方法的形参名称保持一致。 (严格区分大小写)  </p><h2 id="2-实体类型（JavaBean）"><a href="#2-实体类型（JavaBean）" class="headerlink" title="2. 实体类型（JavaBean）"></a>2. 实体类型（JavaBean）</h2><p>要求表单中参数名称和 POJO 类的属性名称保持一致。并且控制器方法的参数类型是 POJO 类型。  </p><p><strong>例子</strong>：</p><p>新建一个数据类型Account，其中包含username、password、money三个基本类型的属性，一个引用类型的User类型，这个类型是自定义的类型。以及这四个属性的getter、setter、toString方法。</p><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302170125012.png" alt="image-20200302170125012" style="zoom:80%;"><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302170438373.png" alt="image-20200302170438373" style="zoom:80%;"><p>然后，在页面上面输入四个参数进行提交：注意，引用类型的数据可以通过 <code>.</code> 运算符来进行区分并输入。</p><pre><code class="jsp">&lt;form action=&quot;params/saveAccount&quot; method=&quot;post&quot;&gt;    姓名：&lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt; &lt;br/&gt;    密码：&lt;input type=&quot;text&quot; name=&quot;password&quot; /&gt; &lt;br/&gt;    金额：&lt;input type=&quot;text&quot; name=&quot;money&quot; /&gt; &lt;br/&gt;    用户名称：&lt;input type=&quot;text&quot; name=&quot;user.uname&quot; /&gt; &lt;br/&gt;    用户年龄：&lt;input type=&quot;text&quot; name=&quot;user.age&quot; /&gt; &lt;br/&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;br/&gt;&lt;/form&gt;</code></pre><p>在对应的方法中进行显示：</p><pre><code class="java">// 将请求参数绑定把数据封装到JavaBean的类中@RequestMapping(&quot;/saveAccount&quot;)public String saveAccount(Account account) {    System.out.println(account);    return &quot;success&quot;;}</code></pre><p>就可以得到结果了</p><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302170410612.png" alt="image-20200302170410612" style="zoom:80%;"><p>但是，如果使用中文，则可能会出现乱码问题，处理方式在后面解决。</p><h2 id="3-集合类型（List-Map等）"><a href="#3-集合类型（List-Map等）" class="headerlink" title="3. 集合类型（List Map等）"></a>3. 集合类型（List Map等）</h2><h3 id="3-1-POJO"><a href="#3-1-POJO" class="headerlink" title="3.1 POJO"></a>3.1 POJO</h3><p>要求集合类型的请求参数必须在 POJO 中。在表单中请求参数名称要和 POJO 中集合属性名称相同。</p><p>给 List 集合中的元素赋值， 使用下标。</p><p>给 Map 集合中的元素赋值， 使用键值对。</p><p><strong>例子</strong>：</p><p>在前面的那个Account类中增加两个参数，都是集合类型，分别为List和Map，并且重新生成getter、setter、 toString</p><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302171916744.png" alt="image-20200302171916744" style="zoom:80%;"><p>此时的表单应该写成下面这样：</p><pre><code class="jsp">&lt;form action=&quot;params/saveAccount&quot; method=&quot;post&quot;&gt;    姓名：&lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt; &lt;br/&gt;    密码：&lt;input type=&quot;text&quot; name=&quot;password&quot; /&gt; &lt;br/&gt;    金额：&lt;input type=&quot;text&quot; name=&quot;money&quot; /&gt; &lt;br/&gt;    用户名称：&lt;input type=&quot;text&quot; name=&quot;user.uname&quot; /&gt; &lt;br/&gt;    用户年龄：&lt;input type=&quot;text&quot; name=&quot;user.age&quot; /&gt; &lt;br/&gt;    用户名称：&lt;input type=&quot;text&quot; name=&quot;list[0].uname&quot; /&gt; &lt;br/&gt;    用户年龄：&lt;input type=&quot;text&quot; name=&quot;list[0].age&quot; /&gt; &lt;br/&gt;    用户名称：&lt;input type=&quot;text&quot; name=&quot;map[&#39;one&#39;].uname&quot; /&gt; &lt;br/&gt;    用户年龄：&lt;input type=&quot;text&quot; name=&quot;map[&#39;one&#39;].age&quot; /&gt; &lt;br/&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;br/&gt;&lt;/form&gt;</code></pre><p>注意，List和Map的书写方式。</p><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302172548514.png" alt="image-20200302172548514" style="zoom:80%;"><h3 id="3-2-json"><a href="#3-2-json" class="headerlink" title="3.2 json"></a>3.2 json</h3><p>接收的请求参数是 json 格式数据。需要借助一个注解实现。  </p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="1-POST请求中文乱码问题"><a href="#1-POST请求中文乱码问题" class="headerlink" title="1. POST请求中文乱码问题"></a>1. POST请求中文乱码问题</h2><p>如果使用POST请求进行表单提交，则中文会出现乱码。</p><p>可以在web.xml配置一个过滤器：</p><pre><code class="xml">&lt;!-- 解决中文乱码问题的过滤器--&gt;&lt;filter&gt;    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;    &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;&gt;    &lt;!--初始化参数--&gt;    &lt;init-param&gt;        &lt;param-name&gt;encoding&lt;/param-name&gt;        &lt;param-value&gt;UTF-8&lt;/param-value&gt;    &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;</code></pre><p>这样，再使用表单提交就不会出现乱码问题了</p><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302171335876.png" alt="image-20200302171335876" style="zoom:80%;"><h2 id="2-类型转换"><a href="#2-类型转换" class="headerlink" title="2. 类型转换"></a>2. 类型转换</h2><p>表单提交的过程中，数据本来都是字符串类型，SpringMVC会自动将这些字符串转换成合适的数据类型。</p><p>例如，对于2000-1-1这种类型的日期数据，没有办法直接将其转为日期数据，需要通过一个自定义的类型转换方法进行转换。该方法需要实现 <code>Converter&lt;?, ?&gt;</code> 接口，在这个类里面具体进行类型转化。</p><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302175205765.png" alt="image-20200302175205765" style="zoom:80%;"><p>为了启用这个类型转换，需要在springmvc.xml配置文件中进行如下配置：</p><pre><code class="xml">&lt;bean id=&quot;conversionService&quot;       class=&quot;org.springframework.context.support.ConversionServiceFactoryBean&quot;&gt;    &lt;property name=&quot;converters&quot;&gt;        &lt;set&gt;            &lt;bean class=&quot;com.xiong.util.StringToDateConverter&quot;/&gt;        &lt;/set&gt;    &lt;/property&gt;&lt;/bean&gt;</code></pre><p>然后，在开启SpringMVC框架注解支持的标签里增加类型转换的内容</p><pre><code class="xml">&lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot;/&gt;</code></pre><p>之后就可以通过标签测试了</p><pre><code class="jsp">&lt;form action=&quot;params/saveAccount&quot; method=&quot;post&quot;&gt;    姓名：&lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt; &lt;br/&gt;    密码：&lt;input type=&quot;text&quot; name=&quot;password&quot; /&gt; &lt;br/&gt;    金额：&lt;input type=&quot;text&quot; name=&quot;money&quot; /&gt; &lt;br/&gt;    日期：&lt;input type=&quot;text&quot; name=&quot;date&quot; /&gt; &lt;br/&gt;    用户名称：&lt;input type=&quot;text&quot; name=&quot;user.uname&quot; /&gt; &lt;br/&gt;    用户年龄：&lt;input type=&quot;text&quot; name=&quot;user.age&quot; /&gt; &lt;br/&gt;    用户名称：&lt;input type=&quot;text&quot; name=&quot;list[0].uname&quot; /&gt; &lt;br/&gt;    用户年龄：&lt;input type=&quot;text&quot; name=&quot;list[0].age&quot; /&gt; &lt;br/&gt;    用户名称：&lt;input type=&quot;text&quot; name=&quot;map[&#39;one&#39;].uname&quot; /&gt; &lt;br/&gt;    用户年龄：&lt;input type=&quot;text&quot; name=&quot;map[&#39;one&#39;].age&quot; /&gt; &lt;br/&gt;    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;br/&gt;&lt;/form&gt;</code></pre><img src="/2020/03/03/3-SpringMVC/5_%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/image-20200302181559003.png" alt="image-20200302181559003" style="zoom:80%;">]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringMVC实战2】执行流程</title>
      <link href="/2020/03/02/3-SpringMVC/3_SpringMVC%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/"/>
      <url>/2020/03/02/3-SpringMVC/3_SpringMVC%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h1><p>通过一套注解，让一个简单的Java类称为处理请求的控制器，而无需实现任何接口，同时它支持RESTful编程风格的请求。</p><h2 id="1-角色划分"><a href="#1-角色划分" class="headerlink" title="1. 角色划分"></a>1. 角色划分</h2><ul><li><p><strong>前端控制器</strong> <code>DispatcherServlet</code></p><p>用户请求到达前端控制器，它就相当于 mvc 模式中的 c，是整个流程控制的中心，由它调用其它组件处理用户的请求， dispatcherServlet 的存在降低了组件之间的耦合性。</p></li><li><p><strong>处理器映射器</strong> <code>HandlerMapping</code></p><p>负责根据用户请求找到 Handler（即处理器）， SpringMVC 提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。</p></li><li><p><strong>处理器</strong> <code>Handler</code></p><p>开发中要编写的具体业务控制器。由 DispatcherServlet 把用户请求转发到 Handler。由 Handler 对具体的用户请求进行处理。</p></li><li><p><strong>处理器适配器</strong> <code>HandlerAdapter</code></p><p>通过 HandlerAdapter 对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。</p></li><li><p><strong>视图解析器</strong> <code>ViewResolver</code></p><p>负责将处理结果生成 View 视图， View Resolver 首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成 View 视图对象，最后对 View 进行渲染将处理结果通过页面展示给用户。</p></li><li><p><strong>视图</strong> <code>View</code></p><p>SpringMVC 框架提供了很多的 View 视图类型的支持，包括： jstlView、 freemarkerView、 pdfView等。最常用的视图就是 jsp。</p><p>一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。</p></li></ul><h2 id="2-SpringMVC的执行流程"><a href="#2-SpringMVC的执行流程" class="headerlink" title="2. SpringMVC的执行流程"></a>2. SpringMVC的执行流程</h2><img src="/2020/03/02/3-SpringMVC/3_SpringMVC%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/image-20200223095631540.png" alt="image-20200223095631540" style="zoom:80%;"><ol><li><p>客户端发送一个request请求，该请求中带有 <code>/hello</code> ，到达前端控制器（指挥中心）中，</p></li><li><p>前端控制器向处理器映射器发送请求，处理器映射器可以让Controller中的方法去执行。</p><img src="/2020/03/02/3-SpringMVC/3_SpringMVC%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/image-20200223101148001.png" alt="image-20200223101148001" style="zoom:80%;"></li><li><p>将Controller类中的sayHello方法返回</p></li><li><p>前端控制器将Controller中的sayHello方法交给处理器适配器去执行</p></li><li><p>执行Controller中的sayHello方法</p></li><li><p>返回sayHello方法的结果</p></li><li><p>返回sayHello方法的结果到前端控制器中</p></li><li><p>前端控制器向视图解析器发送解析视图的请求</p><img src="/2020/03/02/3-SpringMVC/3_SpringMVC%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/image-20200223102539970.png" alt="image-20200223102539970" style="zoom:80%;"></li><li><p>视图解析器根据结果跳转到某个视图页面（这里就是success.jsp）</p></li><li><p>前端控制器将结果响应给客户端</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SpringMVC实战1】入门案例</title>
      <link href="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/"/>
      <url>/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><h2 id="1-搭建环境"><a href="#1-搭建环境" class="headerlink" title="1. 搭建环境"></a>1. 搭建环境</h2><p>选择一个webAPP作为模板创建项目</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200222101612574.png" alt="image-20200222101612574" style="zoom:80%;"><p>搭建的时候可能会卡在Generating project in Batch mode这个指令上，这是因为连接被墙了，需要在maven中配置镜像库，在setting.xml中配置阿里云的镜像：</p><pre><code class="xml">  &lt;mirrors&gt;    &lt;mirror&gt;        &lt;id&gt;alimaven&lt;/id&gt;        &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;        &lt;name&gt;aliyun maven&lt;/name&gt;        &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt;    &lt;/mirror&gt;  &lt;/mirrors&gt;</code></pre><p>随后项目就创建成功了，下面图中的java和resources两个文件夹是手动创建的</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200222112803806.png" alt="image-20200222112803806" style="zoom:80%;"><p>接下来是在pom中导入相关的坐标：</p><pre><code class="xml">&lt;!-- 锁定版本，可以通过这个版本号提取出来，下面所有与spring相关的版本号全部统一在这里写 --&gt;&lt;properties&gt;    &lt;spring.version&gt;5.2.3.RELEASE&lt;/spring.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-web&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework&lt;/groupId&gt;        &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;        &lt;version&gt;${spring.version}&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet&lt;/groupId&gt;        &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;        &lt;version&gt;2.5&lt;/version&gt;        &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt;        &lt;artifactId&gt;jsp-api&lt;/artifactId&gt;        &lt;version&gt;2.0&lt;/version&gt;        &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;4.12&lt;/version&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><h2 id="2-配置前端控制器"><a href="#2-配置前端控制器" class="headerlink" title="2. 配置前端控制器"></a>2. 配置前端控制器</h2><p>前端控制器全程为：DispatcherServlet，也就是一个servlet，在web.xml中配置servlet相关的内容：</p><pre><code class="xml">&lt;!--这是一个固定的类，spring提供的DispatcherServlet--&gt;&lt;servlet&gt;    &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;    &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;    &lt;!--这里用/表示发任何请求都会经过前端控制器servlet，即拦截所有请求--&gt;    &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;</code></pre><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302134954010.png" alt="image-20200302134954010" style="zoom:80%;"><h2 id="3-配置Spring"><a href="#3-配置Spring" class="headerlink" title="3. 配置Spring"></a>3. 配置Spring</h2><p>在resources文件夹下，新建一个xml文件，用来进行spring的配置。这里先创建好，后面会详细进行配置。</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302141501844.png" alt="image-20200302141501844" style="zoom:80%;"><h2 id="4-配置tomcat服务器"><a href="#4-配置tomcat服务器" class="headerlink" title="4. 配置tomcat服务器"></a>4. 配置tomcat服务器</h2><p>新建配置中添加一个本地的tomcat服务器</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302135801508.png" alt="image-20200302135801508" style="zoom:80%;"><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302135825008.png" alt="image-20200302135825008" style="zoom:80%;"><h1 id="入门程序"><a href="#入门程序" class="headerlink" title="入门程序"></a>入门程序</h1><p>主要的目的是在前端发起请求，后端写一个类用来处理这个请求，处理成功之后跳转到执行成功页面。</p><h2 id="1-在页面上创建超链接按钮"><a href="#1-在页面上创建超链接按钮" class="headerlink" title="1. 在页面上创建超链接按钮"></a>1. 在页面上创建超链接按钮</h2><p>在index.xml中写上代码：</p><pre><code class="xml">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;a href=&quot;&quot;&gt;点击这里&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="2-创建控制器（Controller）类"><a href="#2-创建控制器（Controller）类" class="headerlink" title="2. 创建控制器（Controller）类"></a>2. 创建控制器（Controller）类</h2><p>在指定的包路径下创建一个类，并且将想要执行的操作写进方法内。比如后端执行操作的时候想要运行一下类中的sayHello方法：</p><pre><code class="java">// 控制器的类public class HelloController {    public String sayHello() {        System.out.println(&quot;Hello World!&quot;);        return null;    }}</code></pre><h2 id="3-建立超链接与控制器方法的连接"><a href="#3-建立超链接与控制器方法的连接" class="headerlink" title="3. 建立超链接与控制器方法的连接"></a>3. 建立超链接与控制器方法的连接</h2><p>如下所示，想要从index.jsp页面中的超链接点击后开始执行HelloController.java中的sayHello方法。</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302141101270.png" alt="image-20200302141101270" style="zoom:80%;"><p>首先需要将这个HelloController类变成一个对象。</p><h3 id="3-1-配置spring创建对象"><a href="#3-1-配置spring创建对象" class="headerlink" title="3.1 配置spring创建对象"></a>3.1 配置spring创建对象</h3><ol><li><p>开启注解扫描.</p><p>首先需要导入spring相关的配置。在resources文件夹下的springmvc.xml配置文件中添加如下的配置：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;        http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/mvc        http://www.springframework.org/schema/mvc/spring-mvc.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;/beans&gt;</code></pre></li><li><p>接下来开启注解扫描：</p><pre><code class="xml">&lt;!--开启注解扫描--&gt;&lt;context:component-scan base-package=&quot;com.xiong&quot;/&gt;</code></pre><p>加上之后，位于 com.xiong 包下的 HelloController 这个类就可以被扫描到了。</p></li><li><p>在HelloController类上面加上注解，并且在方法上也增加注解</p><p>在方法前面添加一个RequestMapping注解，表示<strong>请求映射</strong>。也就是前面发请求，后台就可以映射到这里执行了。</p><p>该注解的一个参数 <code>path=&quot;&quot;</code> 就表示请求路径。配置以后，一旦收到这个请求，就会被映射到这里。</p><pre><code class="java">// 控制器的类@Controllerpublic class HelloController {    @RequestMapping(path=&quot;/hello&quot;)    public String sayHello() {        System.out.println(&quot;Hello World!&quot;);        return null;    }}</code></pre></li></ol><h3 id="3-2-加载spring配置文件"><a href="#3-2-加载spring配置文件" class="headerlink" title="3.2 加载spring配置文件"></a>3.2 加载spring配置文件</h3><p>前面配好了spring的对象，但是还没有加载springmvc.xml这个配置文件，也就是之前做的配置都没法生效。</p><p>在前端控制器（servlet）中进行加载spring的配置。也就是在web.xml文件中进行配置：</p><pre><code class="xml">&lt;servlet&gt;    &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt;    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;    &lt;init-param&gt;        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;        &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;    &lt;/init-param&gt;    &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;</code></pre><p>配置的意思，就是给DispatcherServlet添加一个初始化属性，并且从springmvc.xml这里去寻找配置，并且，load-on-startup的标签标示第一次创建的时候执行初始化。</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302142655317.png" alt="image-20200302142655317" style="zoom:80%;"><p>加载完成之后，扫描这个类就会执行，HelloController这个类就会生效并且创建该类的一个Bean对象。</p><h3 id="3-3-配置跳转"><a href="#3-3-配置跳转" class="headerlink" title="3.3 配置跳转"></a>3.3 配置跳转</h3><p>springmvc的默认映射规则是，映射到的方法返回值是一个字符串的时候，就表示jsp文件的名字。</p><p>例如下图中进行的映射（这里先在WEB-INF文件夹下创建了一个名为 <code>success.jsp</code> 的页面），这里期望可以通过springmvc的默认映射规则，映射到这个页面上去。</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302143112064.png" alt="image-20200302143112064" style="zoom:80%;"><p>要想达到这个效果，需要先在springmvc.xml配置文件中配置<strong>视图解析器</strong>。这个视图解析器是spring中一个固定的类，只需要将其加载进来就可以了。同时需要在里面配置两个参数，分别为前缀和后置，也就是文件的目录和后缀名。</p><p>在success.jsp文件中写上相应的配置，此后如果跳转成功，就会得到一个新的页面，标题为“入门成功”。</p><pre><code class="xml">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;入门成功&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p>同时，还需要开启SpringMVC框架的注解支持。</p><blockquote><p>实际上，这个注解框架支持的标签，可以自动加载<strong>处理器映射器、处理器适配器</strong>这两个组件（详细内容在springmvc的执行流程中有）。</p></blockquote><pre><code class="xml">&lt;!--配置视图解析器--&gt;&lt;bean id=&quot;internalResourceViewResolver&quot;      class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;    &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/pages/&quot;/&gt;    &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;&lt;/bean&gt;&lt;!--springmvc框架的注解支持--&gt;&lt;mvc:annotation-driven/&gt;</code></pre><p>配置完成之后，只要在ResultMapping的返回值为字符串时，就可以通过这个字符串找到指定的页面了。</p><h2 id="4-在index页面上设置链接地址"><a href="#4-在index页面上设置链接地址" class="headerlink" title="4. 在index页面上设置链接地址"></a>4. 在index页面上设置链接地址</h2><p>经过前面的配置，只需要在index.jsp中把之前空出来的引用地址填上就行了。</p><p>这里的hello是一个相对地址。因为当前页面就是在 <code>/</code> 位置，因此只需要写一个hello就行了。</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302144553827.png" alt="image-20200302144553827" style="zoom:80%;"><p>运行一下，点击按钮之后，结果如下：</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302144845376.png" alt="image-20200302144845376" style="zoom:80%;"><h1 id="流程梳理"><a href="#流程梳理" class="headerlink" title="流程梳理"></a>流程梳理</h1><p>前面的入门案例实际上执行了以下步骤：</p><ul><li><p>启动服务器，并加载一些配置文件</p><ol><li>DispatcherServlet对象创建</li><li>springmvc.xml配置文件被加载<ol><li>开启注解扫描，此后可以将后台执行的类创建成bean对象加载进容器</li><li>配置视图解析器对象，以后视图解析器（InternalResourceViewResolver）就可以直接工作了</li><li>开启springmvc框架注解的支持</li></ol></li></ol></li><li><p>发送请求，后台对请求进行处理</p><ol><li><p>在页面上的请求首先会经过DispatcherServlet（前端控制器），在这个servlet中，通过请求的path来找到具体需要执行的方法。</p><p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302150509791.png" alt="image-20200302150509791"></p></li><li><p>DispatcherServlet前端控制器将返回的success通过视图解析器对象，跳转到指定的页面去</p><img src="/2020/03/02/3-SpringMVC/2_%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/image-20200302150805624.png" alt="image-20200302150805624" style="zoom:80%;"></li><li><p>DispatcherServlet前端控制器将结果返回。</p></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> SpringMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战8】事务控制</title>
      <link href="/2020/02/21/13-Spring/8_%E4%BA%8B%E5%8A%A1%E6%8E%A7%E5%88%B6/"/>
      <url>/2020/02/21/13-Spring/8_%E4%BA%8B%E5%8A%A1%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="spring的事务控制"><a href="#spring的事务控制" class="headerlink" title="spring的事务控制"></a>spring的事务控制</h1><h2 id="1-采用AOP进行事务控制的问题"><a href="#1-采用AOP进行事务控制的问题" class="headerlink" title="1. 采用AOP进行事务控制的问题"></a>1. 采用AOP进行事务控制的问题</h2><p>由于之前发现的一个问题就是<strong>基于注解的AOP</strong>执行顺序是错误的，也就是<strong>最终通知会先于异常通知和后置通知</strong>。因为最终通知中将连接关闭，而后置通知中执行提交操作，肯定是有问题的。</p><pre><code class="java">// 开启事务public void beginTX() {    try {        // 设置事务为非自动提交        connectionUtils.getThreadConnection().setAutoCommit(false);    } catch (Exception e) {        e.printStackTrace();    }}// 提交事务public void commit() {    try {        connectionUtils.getThreadConnection().commit();    } catch (Exception e) {        e.printStackTrace();    }}// 回滚事务public void rollback() {    try {        connectionUtils.getThreadConnection().rollback();    } catch (Exception e) {        e.printStackTrace();    }}// 释放连接public void release() {    try {        // 这里的close并不是真正的关闭连接，而是将连接还回连接池中        connectionUtils.getThreadConnection().close();        // 将线程与连接解绑        connectionUtils.removeConnection();    } catch (Exception e) {        e.printStackTrace();    }}</code></pre><p>spring也有自己的事务控制，而自己写的事务控制可能会出现问题。</p><h2 id="2-spring的事务控制"><a href="#2-spring的事务控制" class="headerlink" title="2. spring的事务控制"></a>2. spring的事务控制</h2><p>spring中提供的事务控制在spring-tx-5.2.3.RELEASE.jar中。并且其事务控制都是基于AOP的，既可以使用编程的方式实现，也可以使用配置的方式实现。</p><h3 id="2-1-PlatformTransactionManager"><a href="#2-1-PlatformTransactionManager" class="headerlink" title="2.1 PlatformTransactionManager"></a>2.1 PlatformTransactionManager</h3><p>这个<strong>接口</strong>提供事务操作的方法，包含以下三个具体的操作：</p><ol><li><p>获取事务状态信息</p><pre><code class="java">TransactionStatus getTransaction(TransactionDefinition definition)</code></pre></li><li><p>提交事务</p><pre><code class="java">void commit(TransactionStatus status)</code></pre></li><li><p>回滚事务</p><pre><code class="java">void rollback(TransactionStatus status)</code></pre></li></ol><p>但这只是个接口，平时使用的时候常用以下这些实现类进行操作：</p><pre><code class="java">// 使用spring jdbc或者ibatis进行持久化数据的时候使用org.springframework.jdbc.datasource.DataSourceTransactionManager;// 使用Hibernate版本进行持久化数据时使用org.springframework.orm.hibernate5.HibernateTransactionManager;</code></pre><h3 id="2-2-TransactionDefinition"><a href="#2-2-TransactionDefinition" class="headerlink" title="2.2 TransactionDefinition"></a>2.2 TransactionDefinition</h3><p>事务的定义信息对象，里面有如下方法：</p><ol><li><p><strong>获取事务的对象名称</strong></p><pre><code class="java">String getName()</code></pre></li><li><p><strong>获取事务隔离级别</strong></p><p>事务的隔离级别：</p><ul><li><p><strong>ISOLATION_DEFAULT</strong></p><p>默认级别，属于以下的某一种</p></li><li><p><strong>ISOLATION_READ_UNCOMMITTED</strong></p><p>可以读取未提交数据</p></li><li><p><strong>ISOLATION_READ_COMMITTED</strong></p><p>只能读取已提交数据，可以解决脏读问题（ORACLE的默认级别）</p></li><li><p><strong>ISOLATION_REPEATABLE_READ</strong></p><p>是否读取其他事务提交修改后的数据，解决不可重复读的问题（MySQL的默认级别）</p></li><li><p><strong>ISOLATION_SERIALIZABLE</strong></p><p>是否读取其他事务提交添加后的数据，解决幻读问题</p></li></ul><pre><code class="java">int getIsolationLevel()</code></pre></li><li><p><strong>获取事务传播行为</strong></p><p>有以下这些传播行为：</p><ul><li><p><strong>REQUIRED</strong></p><p>如果当前没有事务，就新建一个事务，如果已经在一个事务中，就加入这个事务，是默认选择</p></li><li><p><strong>SUPPORTS</strong></p><p>支持当前事务，如果当前没有事务，就以非事务的方式执行（没有事务）</p></li><li><p><strong>MANDATORY</strong></p><p>使用当前的事务，如果当前没有事务，就抛出异常</p></li><li><p><strong>REQUERS_NEW</strong></p><p>新建事务，如果当前在事务中，就把当前事务挂起</p></li><li><p><strong>NOT_SUPPORTED</strong></p><p>以非事务方式执行操作，如果当前存在事务，就把当前事务挂起</p></li><li><p><strong>NEVER</strong></p><p>以非事务方式运行，如果当前存在事务，则抛出异常</p></li><li><p><strong>NESTED</strong></p><p>如果当前存在事务，则在嵌套事务内执行，如果当前没有事务，则执行REQUIRED类似的操作</p></li></ul><pre><code class="java">int getPropagationBehavior()</code></pre></li><li><p><strong>获取事务超时时间</strong></p><pre><code class="java">int getTimeout()</code></pre></li><li><p><strong>获取事务是否只读</strong></p><pre><code class="java">boolean isReadOnly()</code></pre></li></ol><h3 id="2-3-TransactionStatus"><a href="#2-3-TransactionStatus" class="headerlink" title="2.3 TransactionStatus"></a>2.3 TransactionStatus</h3><p>此接口提供的时事务具体的运行状态，有以下这些操作：</p><ol><li><p><strong>刷新事务</strong></p><pre><code class="java">void flush()</code></pre></li><li><p><strong>获取是否存在存储点</strong></p><p>事务是按步提交，一旦设置了存储点，每个存储点就是事务的一步，如果在某一步执行不成功，则只回滚到存储点，而不是回滚到最开始的地方</p><pre><code class="java">boolean hasSavepoint()</code></pre></li><li><p><strong>获取事务是否完成</strong></p><pre><code class="java">boolean isCompleted()</code></pre></li><li><p><strong>获取事务是否为新事务</strong></p><pre><code class="java">boolean isNewTransaction()</code></pre></li><li><p><strong>获取事务是否回滚</strong></p><pre><code class="java">boolean isRollbackOnly()</code></pre></li><li><p><strong>设置是否回滚</strong></p><pre><code class="java">void setRollbackOnly()</code></pre></li></ol><h1 id="基于xml的声明式事务控制"><a href="#基于xml的声明式事务控制" class="headerlink" title="基于xml的声明式事务控制"></a>基于xml的声明式事务控制</h1><h2 id="1-导入事务约束"><a href="#1-导入事务约束" class="headerlink" title="1. 导入事务约束"></a>1. 导入事务约束</h2><p>此时需要导入事务的约束（在beans中加上标签）：也就是tx相关的标签</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xsi:schemaLocation=&quot;        http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/tx        http://www.springframework.org/schema/tx/spring-tx.xsd        http://www.springframework.org/schema/aop        http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;&lt;/beans&gt;</code></pre><h2 id="2-配置事务管理器"><a href="#2-配置事务管理器" class="headerlink" title="2. 配置事务管理器"></a>2. 配置事务管理器</h2><pre><code class="xml">&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><h2 id="3-配置事务的通知"><a href="#3-配置事务的通知" class="headerlink" title="3. 配置事务的通知"></a>3. 配置事务的通知</h2><p>使用tx:advice标签</p><p>第一个属性id是给事务通知起一个唯一标志（名字）</p><p>第二个属性transaction-manager给事务通知提供一个事务管理器引用</p><pre><code class="xml">&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt;&lt;/tx:advice&gt;</code></pre><h2 id="4-配置AOP中的通用切入点表达式"><a href="#4-配置AOP中的通用切入点表达式" class="headerlink" title="4. 配置AOP中的通用切入点表达式"></a>4. 配置AOP中的通用切入点表达式</h2><pre><code class="xml">&lt;aop:pointcut id=&quot;pt1&quot; expression=&quot;execution(* com.xiong.service.impl.*.*(..))&quot;&gt;&lt;/aop:pointcut&gt;</code></pre><h2 id="5-建立3、4步的关系"><a href="#5-建立3、4步的关系" class="headerlink" title="5. 建立3、4步的关系"></a>5. 建立3、4步的关系</h2><pre><code class="xml">&lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;pt1&quot;&gt;&lt;/aop:advisor&gt;</code></pre><h2 id="6-配置事务的属性"><a href="#6-配置事务的属性" class="headerlink" title="6. 配置事务的属性"></a>6. 配置事务的属性</h2><p>在事务的通知txAdvice标签内部（第3步）进行配置</p><img src="/2020/02/21/13-Spring/8_%E4%BA%8B%E5%8A%A1%E6%8E%A7%E5%88%B6/image-20200221121411699.png" alt="image-20200221121411699" style="zoom:80%;"><p>这些属性就在前面已经见过的</p><ul><li>isolation：用于指定事务的隔离级别，默认值是DEFAULT，表示使用数据库的默认隔离级别</li><li>propagation：用于指定事务的传播行为，默认值是REQUIRED，表示一定会有事务，增删改查的选择，查询方法可以选择SUPPORTS</li><li>readonly：用于指定事务是否只读，只有查询方法才能设置为true，默认为false，表示读写。</li><li>timeout：用于指定事务的超时时间，默认值是-1，表示永不超时。如果指定了数值，则以秒为单位。</li><li>rollback-for：用于指定一个异常，当产生该异常时，事务回滚，产生其他异常时，事务不会滚，没有默认值，表示任何异常都<strong>回滚</strong>。</li><li>no-rollback-for：用于指定一个异常，当产生该异常时，事务不会滚，产生其他异常时，事务回滚，没有默认值，表示任何异常都<strong>回滚</strong>。</li></ul><p>这里这样配置：</p><pre><code class="xml">&lt;!--配置事务通知--&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt;    &lt;!--配置事务的属性--&gt;    &lt;tx:attributes&gt;        &lt;tx:method name=&quot;transfer&quot; propagation=&quot;REQUIRED&quot; read-only=&quot;false&quot;/&gt;    &lt;/tx:attributes&gt;&lt;/tx:advice&gt;</code></pre><h2 id="7-总配置"><a href="#7-总配置" class="headerlink" title="7. 总配置"></a>7. 总配置</h2><p>经过前面6步的配置，最终的xml文件配置如下：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xsi:schemaLocation=&quot;        http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/tx        http://www.springframework.org/schema/tx/spring-tx.xsd        http://www.springframework.org/schema/aop        http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;    &lt;!-- 配置业务层--&gt;    &lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;        &lt;property name=&quot;accountDao&quot; ref=&quot;accountDao&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 配置账户的持久层--&gt;    &lt;bean id=&quot;accountDao&quot; class=&quot;com.xiong.dao.impl.AccountDaoImpl&quot;&gt;&lt;!--        &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplate&quot;&gt;&lt;/property&gt;--&gt;&lt;!--        注入DataSource，会触发类中的setDataSource方法--&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!--配置数据源--&gt;    &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt;        &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/db1?useUnicode=true&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;username&quot; value=&quot;root&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;password&quot; value=&quot;&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!--配置事务通知--&gt;    &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt;        &lt;!--配置事务的属性--&gt;        &lt;tx:attributes&gt;            &lt;tx:method name=&quot;transfer&quot; propagation=&quot;REQUIRED&quot; read-only=&quot;false&quot;/&gt;        &lt;/tx:attributes&gt;    &lt;/tx:advice&gt;    &lt;!--配置aop--&gt;    &lt;aop:config&gt;        &lt;aop:pointcut id=&quot;pt1&quot; expression=&quot;execution(* com.xiong.service.impl.*.*(..))&quot;&gt;&lt;/aop:pointcut&gt;        &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;pt1&quot;&gt;&lt;/aop:advisor&gt;    &lt;/aop:config&gt;&lt;/beans&gt;</code></pre><h1 id="基于注解的声明式事务控制"><a href="#基于注解的声明式事务控制" class="headerlink" title="基于注解的声明式事务控制"></a>基于注解的声明式事务控制</h1><h2 id="1-添加约束"><a href="#1-添加约束" class="headerlink" title="1. 添加约束"></a>1. 添加约束</h2><p>主要就是导入context的IOC约束，</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;        http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/tx        http://www.springframework.org/schema/tx/spring-tx.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd        http://www.springframework.org/schema/aop        http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;</code></pre><p>添加spring创建容器时要扫描的包</p><pre><code class="xml">&lt;context:component-scan base-package=&quot;com.xiong&quot;&gt;&lt;/context:component-scan&gt;</code></pre><h2 id="2-配置jdbcTemplate"><a href="#2-配置jdbcTemplate" class="headerlink" title="2. 配置jdbcTemplate"></a>2. 配置jdbcTemplate</h2><pre><code class="xml">&lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><h2 id="3-配置事务管理器"><a href="#3-配置事务管理器" class="headerlink" title="3. 配置事务管理器"></a>3. 配置事务管理器</h2><pre><code class="xml">&lt;bean id=&quot;transactionManager&quot;       class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><h2 id="4-开启spring对注解事务的支持"><a href="#4-开启spring对注解事务的支持" class="headerlink" title="4. 开启spring对注解事务的支持"></a>4. 开启spring对注解事务的支持</h2><pre><code class="xml">&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;&gt;&lt;/tx:annotation-driven&gt;</code></pre><h2 id="5-在需要事务支持的地方使用注解"><a href="#5-在需要事务支持的地方使用注解" class="headerlink" title="5. 在需要事务支持的地方使用注解"></a>5. 在需要事务支持的地方使用注解</h2><p>使用 <code>@Transactional</code> 的注解</p><img src="/2020/02/21/13-Spring/8_%E4%BA%8B%E5%8A%A1%E6%8E%A7%E5%88%B6/image-20200221143844255.png" alt="image-20200221143844255" style="zoom:80%;"><h2 id="6-总配置"><a href="#6-总配置" class="headerlink" title="6. 总配置"></a>6. 总配置</h2><p>经过前面5步的配置，最终的xml文件如下：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;        http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/tx        http://www.springframework.org/schema/tx/spring-tx.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd        http://www.springframework.org/schema/aop        http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;    &lt;context:component-scan base-package=&quot;com.xiong&quot;&gt;&lt;/context:component-scan&gt;    &lt;!--    配置jdbctemplate--&gt;    &lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt;        &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/db1?useUnicode=true&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;username&quot; value=&quot;root&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;password&quot; value=&quot;&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!--开启spring对注解事务的支持--&gt;    &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;&gt;&lt;/tx:annotation-driven&gt;&lt;/beans&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战7】JdbcTemplate</title>
      <link href="/2020/02/20/13-Spring/7_JdbcTemplate/"/>
      <url>/2020/02/20/13-Spring/7_JdbcTemplate/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="JdbcTemplate"><a href="#JdbcTemplate" class="headerlink" title="JdbcTemplate"></a>JdbcTemplate</h1><p>是spring框架中提供的一个对象，是对原始的Jdbc API对象的简单封装。spring框架提供了很多操作模板类</p><ul><li><p>操作关系型数据库</p><p>JdbcTemplate</p><p>HibernateTemplate</p></li><li><p>操作nosql数据库</p><p>RedisTemplate</p></li><li><p>操作消息队列</p><p>JmsTemplate</p></li></ul><p>作用：与数据库交互，实现CRUD方法</p><h2 id="1-导入pom依赖"><a href="#1-导入pom依赖" class="headerlink" title="1. 导入pom依赖"></a>1. 导入pom依赖</h2><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-context&lt;/artifactId&gt;    &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;    &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;    &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;mysql&lt;/groupId&gt;    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;    &lt;version&gt;8.0.11&lt;/version&gt;&lt;/dependency&gt;</code></pre><h2 id="2-创建账户实体类"><a href="#2-创建账户实体类" class="headerlink" title="2. 创建账户实体类"></a>2. 创建账户实体类</h2><p>创建一个java类，其中包含了三个属性：id，name，money，并且为其生成getter、setter、toString方法。</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220085748269.png" alt="image-20200220085748269" style="zoom:80%;"><h2 id="3-使用jdbc进行相关操作"><a href="#3-使用jdbc进行相关操作" class="headerlink" title="3. 使用jdbc进行相关操作"></a>3. 使用jdbc进行相关操作</h2><pre><code class="java">public class JdbcTemplateDemo {    public static void main(String[] args) {        // 准备数据源：使用spring的内置数据源        DriverManagerDataSource ds = new DriverManagerDataSource();        ds.setDriverClassName(&quot;com.mysql.jdbc.Driver&quot;);        ds.setUrl(&quot;jdbc:mysql://localhost:3306/db1?useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC&quot;);        ds.setUsername(&quot;root&quot;);        ds.setPassword(&quot;&quot;);        // 1. 创建jdbctemplate对象，并且在构造函数中设置数据源        JdbcTemplate jt = new JdbcTemplate(ds);        // 2. 执行操作        jt.execute(&quot;insert into account(name, money)values(&#39;ccc&#39;, 1000)&quot;);    }}</code></pre><p>由于其中使用了大量的new和写死的参数，因此希望通过spring IOC来对项目进行优化</p><h2 id="4-在项目中使用IOC"><a href="#4-在项目中使用IOC" class="headerlink" title="4. 在项目中使用IOC"></a>4. 在项目中使用IOC</h2><p>首先需要在创建一个配置文件，名字无所谓，这里叫做bean.xml，然后现在里面加上bean的标头</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;/beans&gt;</code></pre><p>接着配置jdbcTemplate的注入信息，因为其中有一个属性是dataSource，因此需要继续配置dataSource，这两个部分全部配置完成后就是下面这样：</p><pre><code class="xml">&lt;!--配置jdbctemplate--&gt;&lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt;    &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/db1?useUnicode=true&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;username&quot; value=&quot;root&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;password&quot; value=&quot;&quot;&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><p>然后在测试方法中进行相关的调用</p><pre><code class="java">public class JdbcTemplateDemo2 {    public static void main(String[] args) {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean123.xml&quot;);        // 2. 获取对象        JdbcTemplate jt = ac.getBean(&quot;jdbcTemplate&quot;, JdbcTemplate.class);        // 3. 执行操作        jt.execute(&quot;insert into account(name, money)values(&#39;ddd&#39;, 1000)&quot;);    }}</code></pre><p>这样就把最开始的很多依赖关系变成了IOC控制的bean注入模式了。</p><h2 id="5-JdbcTemplate的CRUD操作"><a href="#5-JdbcTemplate的CRUD操作" class="headerlink" title="5. JdbcTemplate的CRUD操作"></a>5. JdbcTemplate的CRUD操作</h2><p>增删改都是update方法，只是SQL语句不同，查询则使用query方法。</p><h3 id="5-1-保存"><a href="#5-1-保存" class="headerlink" title="5.1 保存"></a>5.1 保存</h3><pre><code class="java">jt.update(&quot;insert into account(name, money) values(?, ?)&quot;, &quot;eee&quot;, 3333);</code></pre><h3 id="5-2-更新"><a href="#5-2-更新" class="headerlink" title="5.2 更新"></a>5.2 更新</h3><pre><code class="java">jt.update(&quot;update account set name=?, money=? where id=?&quot;, &quot;test&quot;, 4567, 7);</code></pre><h3 id="5-3-删除"><a href="#5-3-删除" class="headerlink" title="5.3 删除"></a>5.3 删除</h3><pre><code class="java">jt.update(&quot;delete from account where id=?&quot;, 8);</code></pre><h3 id="5-4-查询所有"><a href="#5-4-查询所有" class="headerlink" title="5.4 查询所有"></a>5.4 查询所有</h3><p>查询query的方法有很多都是执行查询方法的，需要根据参数列表和返回值来确定到底选用哪一个重载版本。</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220093229256.png" alt="image-20200220093229256" style="zoom:80%;"><p>对于查询所有，一共有两个query的重载可用：</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220094245664.png" alt="image-20200220094245664" style="zoom:80%;"><p>这两个的区别就在于第一个的参数是固定的，第二个的参数args是可变数量参数。只不过第二个需要jdk的版本为1.6以上。其中的两个重载都有一个参数是 <code>RowMapper&lt;T&gt;</code> 类型的，因此这里需要说明一下RowMapper：</p><p>可以定义一个类来实现RowMapper接口，该类是用来<strong>定义Account封装策略</strong>的，因此可以写成这样</p><pre><code class="java">class AccountRowMapper implements RowMapper&lt;Account&gt; {    /*    * 把结果集的数据封装的account中，然后由spring把每个account加到集合中    * */    @Override    public Account mapRow(ResultSet resultSet, int i) throws SQLException {        Account account = new Account();        account.setId(resultSet.getInt(&quot;id&quot;));        account.setName(resultSet.getString(&quot;name&quot;));        account.setMoney(resultSet.getFloat(&quot;money&quot;));        return account;    }}</code></pre><p>定义之后，就可以写query了</p><pre><code class="java">List&lt;Account&gt; accountList = jt.query(&quot;select * from account where money &gt; ?&quot;,                                      new AccountRowMapper(),                                      1000);for(Account account : accountList) {    System.out.println(account);}</code></pre><p>当然这个RowMapper也可以使用spring来实现，就是把 <code>new AccountRowMapper&lt;&gt;()</code> 替换成相应的对象，查询的结果与之前是相同的。注意其中需要填写相关的参数信息。</p><pre><code class="java">List&lt;Account&gt; accountList = jt.query(&quot;select * from account where money &gt; ?&quot;,                                      new BeanPropertyRowMapper&lt;Account&gt;(Account.class),                                      1000);for(Account account : accountList) {    System.out.println(account);}</code></pre><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220095541402.png" alt="image-20200220095541402" style="zoom:80%;"><p>因此以后如果想要将结果封装到集合里，可以使用spring提供的方法来解决。</p><h3 id="5-5-查询一个"><a href="#5-5-查询一个" class="headerlink" title="5.5 查询一个"></a>5.5 查询一个</h3><pre><code class="java">List&lt;Account&gt; accounts = jt.query(&quot;select * from account where id = ?&quot;,                                   new BeanPropertyRowMapper&lt;Account&gt;(Account.class),                                   1);System.out.println(accounts.isEmpty() ? &quot;没有内容&quot; : accounts.get(0));</code></pre><p>这里也是使用上面的参数来进行的，只不过需要判断一下返回结果集，如果为空则表示没有，如果不为空，则返回第一个结果，这个结果就是需要查询的那一个。</p><h3 id="5-6-返回一行一列"><a href="#5-6-返回一行一列" class="headerlink" title="5.6 返回一行一列"></a>5.6 返回一行一列</h3><p>使用聚合函数，但是不加group by子句</p><pre><code class="java">Integer count = jt.queryForObject(&quot;select count(*) from account where money &gt; ?&quot;,                                  Integer.class ,                                   2000);System.out.println(count);</code></pre><p>参数中第二个是返回值的类型字节码。</p><h2 id="6-使用Dao"><a href="#6-使用Dao" class="headerlink" title="6. 使用Dao"></a>6. 使用Dao</h2><h3 id="6-1-设置接口"><a href="#6-1-设置接口" class="headerlink" title="6.1 设置接口"></a>6.1 设置接口</h3><pre><code class="java">public interface AccountDao {    // 根据id查询账户    Account findAccountByID(Integer id);    // 根据名称查询用户    Account findAccountByName(String name);    // 更新账户    void updateAccount(Account account);}</code></pre><h3 id="6-2-实现方法"><a href="#6-2-实现方法" class="headerlink" title="6.2 实现方法"></a>6.2 实现方法</h3><pre><code class="java">// 账户的持久层实现类public class AccountDaoImpl implements AccountDao {    private JdbcTemplate jdbcTemplate;    public void setJdbcTemplate(JdbcTemplate jdbcTemplate) {        this.jdbcTemplate = jdbcTemplate;    }    @Override    public Account findAccountByID(Integer id) {        List&lt;Account&gt; accountList = jdbcTemplate.query(&quot;select * from account where id = ?&quot;, new BeanPropertyRowMapper&lt;Account&gt;(Account.class), id);        return accountList.isEmpty() ? null : accountList.get(0);    }    @Override    public Account findAccountByName(String name) {        List&lt;Account&gt; accountList = jdbcTemplate.query(&quot;select * from account where name = ?&quot;, new BeanPropertyRowMapper&lt;Account&gt;(Account.class), name);        if (accountList.isEmpty()) {            return null;        }        if (accountList.size() &gt; 1) {            throw new RuntimeException(&quot;结果集不唯一&quot;);        }        return accountList.get(0);    }    @Override    public void updateAccount(Account account) {        jdbcTemplate.update(&quot;update account set name = ?, money = ? where id = ?&quot;, account.getName(), account.getMoney(), account.getId());    }}</code></pre><h3 id="6-3-通过spring注入"><a href="#6-3-通过spring注入" class="headerlink" title="6.3 通过spring注入"></a>6.3 通过spring注入</h3><pre><code class="xml">&lt;!-- 配置账户的持久层--&gt;&lt;bean id=&quot;accountDao&quot; class=&quot;com.xiong.dao.impl.AccountDaoImpl&quot;&gt;    &lt;property name=&quot;jdbcTemplate&quot; ref=&quot;jdbcTemplate&quot;&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><h3 id="6-4-测试"><a href="#6-4-测试" class="headerlink" title="6.4 测试"></a>6.4 测试</h3><pre><code class="java">public class JdbcTemplateDemo4 {    public static void main(String[] args) {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean123.xml&quot;);        // 2. 获取对象        AccountDao accountDao = ac.getBean(&quot;accountDao&quot;, AccountDao.class);        Account account = accountDao.findAccountByID(1);        System.out.println(account);    }}</code></pre><h2 id="7-JdbcDaoSupport"><a href="#7-JdbcDaoSupport" class="headerlink" title="7. JdbcDaoSupport"></a>7. JdbcDaoSupport</h2><p>现在，如果有多个对于不同实体对象的实现类，比如下面这张图的结构：</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220102117409.png" alt="image-20200220102117409" style="zoom:80%;"><p>对于Dao有4种不同的实现类，这样的话，在每个类中都有重复的语句：</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220102256243.png" alt="image-20200220102256243" style="zoom:80%;"><p>因此可以重新定义一个类JdbcDaoSupport，将重复的代码放进去</p><h3 id="7-1-手动写JdbcDaoSupport"><a href="#7-1-手动写JdbcDaoSupport" class="headerlink" title="7.1 手动写JdbcDaoSupport"></a>7.1 手动写JdbcDaoSupport</h3><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220103141877.png" alt="image-20200220103141877" style="zoom:80%;"><p>然后将各个Dao实现类中的那两行重复代码给删掉，同时加上get方法，以便于在其他实现类中使用这个都有的变量。同时，其他的实现类需要继承这个公共的support类，并且把原来的对象换成get方法。</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220103259271.png" alt="image-20200220103259271" style="zoom:80%;"><p>这样就可以把IOC中注入的jdbcTemplate给删掉了，同时也可以把相关的DataSource注入到这里，设置相关的set方法，以完成注入。</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220103517561.png" alt="image-20200220103517561" style="zoom:80%;"><p>这时候只需要将bean.xml配置文件中的相关注入信息换掉就可以了</p><img src="/2020/02/20/13-Spring/7_JdbcTemplate/image-20200220103612534.png" alt="image-20200220103612534" style="zoom:80%;"><h3 id="7-2-使用spring的JdbcDaoSupport"><a href="#7-2-使用spring的JdbcDaoSupport" class="headerlink" title="7.2 使用spring的JdbcDaoSupport"></a>7.2 使用spring的JdbcDaoSupport</h3><p>可以直接导入java的包，而impl类中的相关内容都不变。</p><pre><code class="java">import org.springframework.jdbc.core.support.JdbcDaoSupport;</code></pre><p>但是如果继承了spring的这个daoSupport，则不能够进行基于注解的注入。也就是不能使用 <code>@Autowired</code></p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战6】基于xml和注解的AOP配置</title>
      <link href="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="项目前置配置"><a href="#项目前置配置" class="headerlink" title="项目前置配置"></a>项目前置配置</h1><h2 id="1-业务层及其代码"><a href="#1-业务层及其代码" class="headerlink" title="1. 业务层及其代码"></a>1. 业务层及其代码</h2><p>在业务层接口中创建三个接口，分别代表三种不同的业务层代码</p><ul><li>无返回值、无参数：<code>void saveAccount()</code></li><li>无返回值、有参数：<code>void updateAccount(int i)</code></li><li>有返回值、无参数：<code>int deleteAccount()</code></li></ul><pre><code class="java">public interface AccountService {    void saveAccount();    void updateAccount(int i);    int deleteAccount();}</code></pre><p>这些类的实现方法写在对应的impl文件中，也就是简单地打印一句话。</p><pre><code class="java">public class AccountServiceImpl implements AccountService {    @Override    public void saveAccount() {        System.out.println(&quot;执行了保存&quot;);    }    @Override    public void updateAccount(int i) {        System.out.println(&quot;执行了更新&quot; + i);    }    @Override    public int deleteAccount() {        System.out.println(&quot;执行了删除&quot;);        return 0;    }}</code></pre><h2 id="2-具有公共代码的类"><a href="#2-具有公共代码的类" class="headerlink" title="2. 具有公共代码的类"></a>2. 具有公共代码的类</h2><p>这里设置一个打印日志的公共代码，主要用于在执行业务层方法之前或者之后能够打印一些信息：</p><pre><code class="java">public class Logger {    /*    * 用于打印日志，计划让其在切入点方法执行之前执行（切入点方法就是业务层方法）    * */    public void printLog() {        System.out.println(&quot;Logger类中的printLog方法开始记录日志&quot;);    }}</code></pre><p>此时，整个项目的结构如下所示：</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219213130516.png" alt="image-20200219213130516" style="zoom:80%;"><p>只需要创建业务层代码的代理对象，在执行业务层代码之前执行公共代码。但是如果想要使用spring，那么就需要通过配置AOP来实现</p><h1 id="基于xml的AOP配置"><a href="#基于xml的AOP配置" class="headerlink" title="基于xml的AOP配置"></a>基于xml的AOP配置</h1><h2 id="1-配置pom-xml文件"><a href="#1-配置pom-xml文件" class="headerlink" title="1. 配置pom.xml文件"></a>1. 配置pom.xml文件</h2><p>需要添加以下两个依赖，第一个是spring IOC的依赖，第二个是AOP的依赖</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-context&lt;/artifactId&gt;    &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.aspectj&lt;/groupId&gt;    &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt;    &lt;version&gt;1.8.7&lt;/version&gt;&lt;/dependency&gt;</code></pre><h2 id="2-配置bean-xml文件"><a href="#2-配置bean-xml文件" class="headerlink" title="2. 配置bean.xml文件"></a>2. 配置bean.xml文件</h2><p>导入AOP的约束</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/aop        http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;&lt;/beans&gt;</code></pre><p>需要先配置spring的IOC，把service对象配置进来</p><pre><code class="xml">&lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;&lt;/bean&gt;</code></pre><p>配置AOP的相关信息：</p><ol><li><p>配置通知Bean交给Spring管理，即配置Logger类</p><pre><code class="xml">&lt;bean id=&quot;logger&quot; class=&quot;com.xiong.utils.Logger&quot;&gt;&lt;/bean&gt;</code></pre></li><li><p>使用aop:config标签表明AOP的配置开始</p></li><li><p>使用aop:aspect标签表明开始配置切面</p><ul><li>id属性：给切面提供一个唯一标识</li><li>ref属性：指定通知类的bean id</li></ul></li><li><p>在aop:aspect标签的内部使用对应的标签来配置通知的类型，并且建立通知方法和切入点方法的关联</p><p>现在的示例是让pringLog方法在切入点方法执行之前执行，所以是前置通知，使用aop:before，表示配置前置通知。</p><ul><li><p>method属性：用于指定logger类中哪个方法是前置通知</p></li><li><p>pointcut属性：用于指定切入点表达式，该表达式的含义指的是对业务层中哪些方法增强</p><p>关键字：execution(表达式)。</p><p>表达式：<code>访问修饰符  返回值  包名.包名....类名.方法名(参数列表)</code></p><blockquote><p>下面是一个标准的表达式写法，比如要对saveAccount进行增强</p><pre><code>public void com.xiong.service.impl.AccountServiceImpl.saveAccount()</code></pre></blockquote></li></ul></li></ol><p>第234条放一起配置出来的结果如下：</p><pre><code class="xml">&lt;aop:config&gt;    &lt;aop:aspect id=&quot;logAdvice&quot; ref=&quot;logger&quot;&gt;        &lt;aop:before method=&quot;printLog&quot;                     pointcunt=&quot;execution(public void com.xiong.service.impl.AccountServiceImpl.saveAccount())&quot;&gt;&lt;/aop:before&gt;    &lt;/aop:aspect&gt;&lt;/aop:config&gt;</code></pre><p>通过下面的方法进行测试：</p><pre><code class="java">public class AOPtest {    public static void main(String[] args) {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);        // 2. 获取对象        AccountService as = (AccountService) ac.getBean(&quot;accountService&quot;);        // 3. 执行方法        as.saveAccount();        as.updateAccount(1);        as.deleteAccount();    }}</code></pre><p>运行结果为：</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219213244271.png" alt="image-20200219213244271" style="zoom:80%;"><p>可以看出，由于切入点表达式的原因，只与一个方法进行了关联，因此只在第一个方法打印了log。后面介绍一些新的切入点表达式的写法，就可以对多种方法都进行关联了。</p><h2 id="3-切入点表达式写法"><a href="#3-切入点表达式写法" class="headerlink" title="3. 切入点表达式写法"></a>3. 切入点表达式写法</h2><ol><li><p><strong>标准的表达式写法</strong>：</p><p><code>访问修饰符  返回值  包名.包名....类名.方法名(参数列表)</code></p><p>例如：</p><pre><code>public void com.xiong.service.impl.AccountServiceImpl.saveAccount()</code></pre></li><li><p><strong>通配符的使用</strong>：</p><ul><li><p>访问修饰符可以省略，可以将上面的标准写法简化为：</p><pre><code>void com.xiong.service.impl.AccountServiceImpl.saveAccount()</code></pre></li><li><p>返回值可以使用通配符 <code>*</code> 表示任意返回值，可以将上面的标准写法简化为：</p><pre><code>* com.xiong.service.impl.AccountServiceImpl.saveAccount()</code></pre></li><li><p>包名可以使用通配符 <code>*.</code> 表示任意包，但是有几级包就需要些几个 <code>*.</code>，因此可以简化为：</p><pre><code>* *.*.*.*.AccountServiceImpl.saveAccount()</code></pre></li><li><p>包名可以使用 <code>..</code> 表示当前包及其子包，因此可以简化为：</p><pre><code>* *..AccountServiceImpl.saveAccount()</code></pre></li><li><p>类名和方法名都可以实现通配</p><pre><code>* *..*.saveAccount() // 通配类名* *..*.*() // 通配类名和方法名</code></pre><p>如果同时通配成上面的形式，则只能匹配两个方法，<strong>因为这里的参数是空的</strong>。</p></li><li><p>参数列表可以写数据类型，也可以通配</p><ol><li>基本类型直接写名称</li><li>引用类型写 <code>包名.类名</code> 的方式</li><li>使用 <code>..</code> 进行通配</li></ol><pre><code>* *..*.*(int)* *..*.*(java.lang.String)* *..*.*(..)</code></pre></li></ul></li></ol><p>实际开发的时候，切入点表达式的通常写法是：</p><ul><li><p>切到业务层实现类实现下的所有方法，对于这里就是：</p><pre><code>* com.xiong.service.impl.*.*(..)</code></pre></li></ul><h2 id="4-配置四种通知类型"><a href="#4-配置四种通知类型" class="headerlink" title="4. 配置四种通知类型"></a>4. 配置四种通知类型</h2><p>要配置不同类型的通知，首先需要在公共代码中写四个方法：一个小case是，异常通知和后置通知之中只能执行一个。</p><pre><code class="java">public class Logger {    // 前置通知    public void beforePrintLog() {        System.out.println(&quot;这是一条前置通知&quot;);    }    // 后置通知    public void afterReturningPrintLog() {        System.out.println(&quot;这是一条后置通知&quot;);    }    // 异常通知    public void afterThrowingPrintLog() {        System.out.println(&quot;这是一条异常通知&quot;);    }    // 最终通知    public void afterPrintLog() {        System.out.println(&quot;这是一条最终通知&quot;);    }}</code></pre><p>剩下的事情就是进行xml文件的配置，其实也就是把aop的标签改成对应的标签就可以了，然后指定method</p><h3 id="4-1-前置通知"><a href="#4-1-前置通知" class="headerlink" title="4.1 前置通知"></a>4.1 前置通知</h3><pre><code class="xml">&lt;aop:before method=&quot;beforePrintLog&quot;             pointcut=&quot;execution(* com.xiong.service.impl.*.*(..))&quot;&gt;&lt;/aop:before&gt;</code></pre><h3 id="4-2-后置通知"><a href="#4-2-后置通知" class="headerlink" title="4.2 后置通知"></a>4.2 后置通知</h3><pre><code class="xml">&lt;aop:after-returning method=&quot;afterReturningPrintLog&quot;                      pointcut=&quot;execution(* com.xiong.service.impl.*.*(..))&quot;&gt;&lt;/aop:after-returning&gt;</code></pre><h3 id="4-3-异常通知"><a href="#4-3-异常通知" class="headerlink" title="4.3 异常通知"></a>4.3 异常通知</h3><pre><code class="xml">&lt;aop:after-throwing method=&quot;afterThrowingPrintLog&quot;                     pointcut=&quot;execution(* com.xiong.service.impl.*.*(..))&quot;&gt;&lt;/aop:after-throwing&gt;</code></pre><h3 id="4-4-最终通知"><a href="#4-4-最终通知" class="headerlink" title="4.4 最终通知"></a>4.4 最终通知</h3><pre><code class="xml">&lt;aop:after method=&quot;afterPrintLog&quot;            pointcut=&quot;execution(* com.xiong.service.impl.*.*(..))&quot;&gt;&lt;/aop:after&gt;</code></pre><p>全部配置完成之后，应该是这样的：</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219214032281.png" alt="image-20200219214032281" style="zoom:80%;"><h3 id="4-5-通化切入点表达式"><a href="#4-5-通化切入点表达式" class="headerlink" title="4.5 通化切入点表达式"></a>4.5 通化切入点表达式</h3><p>其实在aspect中还有另一个标签pointcut，其属性有：</p><ul><li>id：指定表达式的唯一标识</li><li>expression：用于指定表达式内容</li></ul><pre><code class="xml">&lt;aop:pointcut id=&quot;pt1&quot; expression=&quot;execution(* com.xiong.service.impl.*.*(..))&quot;/&gt;</code></pre><p>配置完成之后，这个标签应该是下面这样</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219215240226.png" alt="image-20200219215240226" style="zoom:80%;"><p>此标签写在切面标签（aop:aspect内部）只能当前切面使用，如果有新的切面，则需要重新配置，是很麻烦的。</p><p>因此它还可以写在aop:aspect外面，此时就是所有切面可用，只不过需要写在切面之前才可以！也就是下面这样：</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219215327869.png" alt="image-20200219215327869" style="zoom:80%;"><h2 id="5-配置环绕通知"><a href="#5-配置环绕通知" class="headerlink" title="5. 配置环绕通知"></a>5. 配置环绕通知</h2><p>在Logger类中添加一个环绕通知的方法：</p><pre><code class="java">public void aroundPringLog() {    System.out.println(&quot;这是一条环绕通知&quot;);}</code></pre><p>然后在bean.xml文件中进行配置，环绕通知使用的标签是aop:around</p><pre><code class="xml">&lt;aop:around method=&quot;aroundPringLog&quot; pointcut-ref=&quot;pt1&quot;&gt;&lt;/aop:around&gt;</code></pre><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219215754360.png" alt="image-20200219215754360" style="zoom:80%;"><p>可以重新运行一下，发现结果如下：</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219215829691.png" alt="image-20200219215829691" style="zoom:80%;"><p>也就是说，当配置了环绕通知之后，切入点方法没有执行，而通知方法执行了。</p><p><strong>分析</strong>：对比动态代理部分的代码，发现这是因为环绕通知其实就是整个增强后的方法，包括增强部分和原始部分，其中，<strong>在整个环绕通知内部，有显式调用原始业务层部分的代码</strong>。在这里没有，因此只执行了环绕通知的部分。</p><p><strong>解决</strong>：spring框架提供了一个接口：proceedingJoinPoint，该接口有一个方法proceed，此方法就相当于明确调用切入点方法。该接口可以作为环绕通知的方法参数，在程序执行时，spring框架会提供该接口的实现类以供使用，<strong>具体实现类似于之前写的动态代理</strong>。</p><pre><code class="java">public Object aroundPringLog(ProceedingJoinPoint pjp) {    Object returnValue = null;    try {        // 得到方法执行所需的参数        Object[] args = pjp.getArgs();        System.out.println(&quot;这是一条环绕通知中的前置通知&quot;);        // 显式调用业务层方法（切入点方法）        returnValue = pjp.proceed(args);        System.out.println(&quot;这是一条环绕通知中的后置通知&quot;);        return returnValue;    } catch (Throwable t) {        System.out.println(&quot;这是一条环绕通知中的异常通知&quot;);        throw new RuntimeException(t);    } finally {        System.out.println(&quot;这是一条环绕通知中的最终通知&quot;);    }}</code></pre><p><strong>其实，环绕通知是spring框架提供的一种可以手动在代码中控制增强方法何时执行的方式。</strong></p><h1 id="基于注解的AOP配置"><a href="#基于注解的AOP配置" class="headerlink" title="基于注解的AOP配置"></a>基于注解的AOP配置</h1><p>首先需要在bean.xml文件中导入IOC的名称空间（也就是将aop相关的内容复制一遍，并且将aop换成context）</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219221636848.png" alt="image-20200219221636848" style="zoom:80%;"><h2 id="1-配置spring创建容器时要扫描的包"><a href="#1-配置spring创建容器时要扫描的包" class="headerlink" title="1. 配置spring创建容器时要扫描的包"></a>1. 配置spring创建容器时要扫描的包</h2><pre><code class="xml">&lt;context:component-scan base-package=&quot;com.xiong&quot;&gt;&lt;/context:component-scan&gt;</code></pre><h2 id="2-配置spring开启AOP注解的支持"><a href="#2-配置spring开启AOP注解的支持" class="headerlink" title="2. 配置spring开启AOP注解的支持"></a>2. 配置spring开启AOP注解的支持</h2><pre><code class="xml">&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;</code></pre><p>经过前两步操作之后，整个bean.xml文件如下所示：</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219222253351.png" alt="image-20200219222253351" style="zoom:80%;"><h2 id="3-配置Service注解"><a href="#3-配置Service注解" class="headerlink" title="3. 配置Service注解"></a>3. 配置Service注解</h2><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219221833853.png" alt="image-20200219221833853" style="zoom:80%;"><h2 id="3-配置Logger注解"><a href="#3-配置Logger注解" class="headerlink" title="3. 配置Logger注解"></a>3. 配置Logger注解</h2><p>主要的配置就是一下圈红的地方。</p><p>需要注意的是，在Logger类中配置切入点表达式的时候可以通过一个新的注解来实现，这就和通化切入点表达式的时候是一个道理，在后面每个地方都加上相应的通化表达式。</p><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219224059156.png" alt="image-20200219224059156" style="zoom:80%;"><h2 id="4-问题"><a href="#4-问题" class="headerlink" title="4. 问题"></a>4. 问题</h2><img src="/2020/02/19/13-Spring/6_%E5%9F%BA%E4%BA%8Exml%E5%92%8C%E6%B3%A8%E8%A7%A3%E7%9A%84AOP%E9%85%8D%E7%BD%AE/image-20200219224007428.png" alt="image-20200219224007428" style="zoom:80%;"><p><strong>基于注解的AOP在调用上会出现顺序问题</strong>，比如上面的运行结果：<strong>异常通知或者后置通知会后于最终通知执行</strong>，但是在环绕通知中是没问题的，因为环绕通知中的流程是我们自己定的。因此在使用基于注解的AOP最好还是使用环绕通知。</p><h1 id="纯注解"><a href="#纯注解" class="headerlink" title="纯注解"></a>纯注解</h1><p>只需要在配置的类中添加下面的注解就可以了</p><pre><code class="java">@Configuration@ConponentScan(basePackage=&quot;com.xiong&quot;)@EnableAspectJAutoProxy</code></pre>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战5】AOP</title>
      <link href="/2020/02/19/13-Spring/5_AOP/"/>
      <url>/2020/02/19/13-Spring/5_AOP/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="AOP"><a href="#AOP" class="headerlink" title="AOP"></a>AOP</h1><p>AOP指的是面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。是OOP的延续，也是函数式编程的一种衍生范围，利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性。</p><p>简单来说就是把程序中的重复代码抽取出来，在需要的时候，使用动态代理的技术，在不修改源码的基础上，对已有方法进行增强。</p><p>spring中的AOP是通过配置的方式实现动态代理，分为基于注解和基于xml两种。</p><h2 id="1-术语"><a href="#1-术语" class="headerlink" title="1. 术语"></a>1. 术语</h2><ul><li><p><strong>Joinpoint（连接点）</strong></p><p>连接业务和增强方法的点，比如在业务层接口中的所有接口，都是连接点。</p></li><li><p><strong>Pointcut（切入点）</strong></p><p>切入点指的就是要对那些Joinpoint进行拦截。并不是业务层的所有方法都被事务支持，那些被增强的方法叫做切入点，没有被增强的方法就不是切入点。</p></li><li><p><strong>Advice（通知/增强）</strong></p><p>拦截到Joinpoint之后要做的事情就是通知，也就是一些公共代码。通知的类型有：前置通知，后置通知，异常通知，最终通知，环绕通知。在invoke方法中，明确调用业务层方法作为分界线：</p><img src="/2020/02/19/13-Spring/5_AOP/image-20200219185132841.png" alt="image-20200219185132841" style="zoom:80%;"><p>调用切入点方法之前的叫做<strong>前置通知</strong>，之后的叫<strong>后置通知</strong>，catch里面的叫<strong>异常通知</strong>，finally里面的叫<strong>最终通知</strong>。整个invoke方法在执行就是<strong>环绕通知</strong>。在环绕通知中，有明确地切入点方法调用。</p></li><li><p><strong>Introduction（引介）</strong></p><p>是一种特殊的通知，在不修改代码的前提下，Introduction可以在运行期为类动态地添加一些方法或者字段</p></li><li><p><strong>Target（目标对象）</strong></p><p>代理的目标对象，即被代理对象。例如例子中的accountService</p><img src="/2020/02/19/13-Spring/5_AOP/image-20200219185647121.png" alt="image-20200219185647121" style="zoom:80%;"></li><li><p><strong>Weaving（织入）</strong></p><p>把增强应用到目标对象来创建新的代理对象的过程。也就是加入事务的过程叫做织入。</p><p>spring采用动态代理织入，AspectJ采用编译器织入和类装载期织入</p></li><li><p><strong>Proxy（代理）</strong></p><p>一个类被AOP织入增强后，就产生一个结果代理类。target是被代理对象，proxy是代理对象</p></li><li><p><strong>Aspect（切面）</strong></p><p>是切入点和通知（引介）的结合就叫做切面</p></li></ul><h2 id="2-框架"><a href="#2-框架" class="headerlink" title="2. 框架"></a>2. 框架</h2><p>spring框架完成的任务：监控切入点方法的执行。一旦监控到切入点方法被运行，使用代理机制，动态创建目标对象的代理对象，根据通知类别，在代理对象的对应位置，将通知对应的功能织入，完成完整的代码逻辑运行。</p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战4】动态代理</title>
      <link href="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"/>
      <url>/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><h2 id="1-转账案例"><a href="#1-转账案例" class="headerlink" title="1. 转账案例"></a>1. 转账案例</h2><p>现在需要做一个转账的案例，在AccountService中需要添加一个方法，在Impl实现类中进行定义：</p><pre><code class="java">@Overridepublic void transfer(String sourceName, String targetName, Float money) {    // 1. 根据名称查询转出账户    Account source = accountDao.findAccountByName(sourceName);    // 2. 根据名称查询转入账户    Account target = accountDao.findAccountByName(targetName);    // 3. 转出账户减钱    source.setMoney(source.getMoney() - money);    // 4. 转入账户加钱    target.setMoney(target.getMoney() + money);    // 5. 更新转出账户    accountDao.updateAccount(source);    // 6. 更新转入账户    accountDao.updateAccount(target);}</code></pre><p>然后在AccountDao的实现类中添加相应的findbyname方法</p><pre><code class="java">@Overridepublic Account findAccountByName(String name) {    try {        List&lt;Account&gt; accounts = runner.query(&quot;select * from account where name = ?&quot;,                                              new BeanListHandler&lt;Account&gt;(Account.class),                                               name);        // 没有结果        if (accounts == null || accounts.size() == 0) {            return null;        }        if (accounts.size() &gt; 1) {            throw new RuntimeException(&quot;结果集不唯一，数据有问题&quot;);        }        // 如果都没问题，则返回第一个元素        return accounts.get(0);    } catch (Exception e) {        throw new RuntimeException(e);    }}</code></pre><p>接着直接在测试类中调用就可以测试：</p><pre><code class="java">@Testpublic void testTransfer() {    // 1. 获取容器    ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);    // 2. 获取业务层对象    AccountService as = ac.getBean(&quot;accountService&quot;, AccountService.class);    // 3. 执行方法    as.transfer(&quot;aaa&quot;, &quot;bbb&quot;, 100F);}</code></pre><p>结果是可以生效的。结果如下所示，aaa账户减少100，bbb账户增加100.</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218170447092.png" alt="image-20200218170447092" style="zoom:80%;"><p>但是，如果在整个过程中出现了异常，比如第5步和第6步之间出现了问题，比如出现了除数为0的情况，则第5步可以正常完成，第6步会出现异常，这样的话，再次执行就会发现结果如下：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218170532195.png" alt="image-20200218170532195" style="zoom:80%;"><p>也就是说，aaa减少了100，但是bbb没有增加100。</p><p>dbutils的QueryRunner对象在每次查询的时候都会创建一个新的数据库连接，并且执行操作的时候都会从数据源中拿出一个连接。因此还是以这个代码为例，可以分析与数据库的连接次数：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218170901597.png" alt="image-20200218170901597" style="zoom:80%;"><p>上面的流程中，第1,2,5,6步都需要重新建立一个新的连接。同时，<strong>每一个连接都有自己的一个独立的事务</strong>。此时一旦在5和6步之间出现错误，前面的事务都是已经被提交了的，但是第六步没有提交，于是就出现了错误。</p><p>按照正常的逻辑来算，所有的这六步操作应当都放在同一个连接中的，也就是要成功就一起成功，要失败就一起失败。因此需要使用ThreadLocal对象把connect和当前线程绑定，从而使得一个线程中只有一个能控制事务的对象。这样就实现了多个操作使用同一个事务。</p><p>事务控制应当是在业务层处理，而不是在持久层处理的。</p><h2 id="2-连接控制类"><a href="#2-连接控制类" class="headerlink" title="2. 连接控制类"></a>2. 连接控制类</h2><p>新建一个类ConnectionUtils用于连接控制，用于从数据源中获取一个连接，并且实现和线程的绑定与解绑。</p><h3 id="2-1-获取当前线程上的连接"><a href="#2-1-获取当前线程上的连接" class="headerlink" title="2.1 获取当前线程上的连接"></a>2.1 获取当前线程上的连接</h3><pre><code class="java">public Connection getThreadConnection() {    try {        // 1. 先从ThreadLocal上获取        Connection conn = tl.get();        // 2. 判断当前线程上是否有连接        if (conn == null) {            // 当前线程上没有连接，就可以从数据源中获取一个连接，            // 并且和线程绑定，存入ThreadLocal中            conn = dataSource.getConnection();            tl.set(conn);        }        // 3. 返回当前线程上的连接        return conn;    } catch (SQLException e) {        throw new RuntimeException(e);    }}</code></pre><h3 id="2-2-将连接与线程解绑"><a href="#2-2-将连接与线程解绑" class="headerlink" title="2.2 将连接与线程解绑"></a>2.2 将连接与线程解绑</h3><pre><code class="java">public void removeConnection() {    tl.remove();}</code></pre><h2 id="3-事务控制类"><a href="#3-事务控制类" class="headerlink" title="3. 事务控制类"></a>3. 事务控制类</h2><p>通过一个类TransactionManager来用于事务控制，其中包含了开启事务、提交事务、回滚事务、释放连接的操作。只需要在原有的方法中，加上参数。</p><pre><code class="java">public class TransactionManager {    // 获取当前线程上的connection    private ConnectionUtils connectionUtils;    // 提供一个set方法，让spring注入    public void setConnectionUtils(ConnectionUtils connectionUtils) {        this.connectionUtils = connectionUtils;    }    // 开启事务    public void beginTX() {        try {            // 设置事务为非自动提交            connectionUtils.getThreadConnection().setAutoCommit(false);        } catch (Exception e) {            e.printStackTrace();        }    }    // 提交事务    public void commit() {        try {            connectionUtils.getThreadConnection().commit();        } catch (Exception e) {            e.printStackTrace();        }    }    // 回滚事务    public void rollback() {        try {            connectionUtils.getThreadConnection().rollback();        } catch (Exception e) {            e.printStackTrace();        }    }    // 释放连接    public void release() {        try {            // 这里的close并不是真正的关闭连接，而是将连接还回连接池中            connectionUtils.getThreadConnection().close();            // 将线程与连接解绑            connectionUtils.remove();        } catch (Exception e) {            e.printStackTrace();        }    }}</code></pre><h2 id="4-改造Service"><a href="#4-改造Service" class="headerlink" title="4. 改造Service"></a>4. 改造Service</h2><p>利用上面的事务控制，对AccountServiceImpl进行改造。生成一个事务控制类的对象，并且设置setter方法，使得spring可以注入：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218175001813.png" alt="image-20200218175001813" style="zoom:80%;"><p>此后，所有的方法都可以进行事务控制了。具体的方法就是在<strong>每个方法</strong>里面都加上下面的行为：</p><pre><code class="java">try {    // 1. 开启事务    txManager.beginTX();    // 2. 执行操作    此处插入原先事务所执行的操作    // 3. 提交事务    txManager.commit();    // 4. 返回结果    如果有返回结果则在这里返回，否则不写} catch (Exception e) {    // 5. 回滚操作    txManager.rollback();} finally {    // 6. 释放连接    txManager.release();}</code></pre><p>例如，原来的transfer函数就改成下面这样了：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218175756324.png" alt="image-20200218175756324" style="zoom:80%;"><p>可以见得整个代码体系会变得非常庞大。</p><h2 id="5-修改QueryRunner配置"><a href="#5-修改QueryRunner配置" class="headerlink" title="5. 修改QueryRunner配置"></a>5. 修改QueryRunner配置</h2><p>由于bean.xml文件中关于QueryRunner部分的配置都是直接注入连接的，如下所示：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218180021142.png" alt="image-20200218180021142" style="zoom:80%;"><p>因此要修改这种注入，需要<strong>将注入数据源的部分删除</strong>，但是不在配置文件里提供connection对象的话，就需要在使用它的地方让spring注入了。这样的好处就是在配置过程中没有注入数据源，所以不会再数据源中拿连接：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218180736831.png" alt="image-20200218180736831" style="zoom:80%;"><p>同时在AccountDaoImpl类中把连接控制对象引进来，设置setter方法让spring注入：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218180858863.png" alt="image-20200218180858863" style="zoom:80%;"><p>然后，将每一个query查询的第一个参数都换成 <code>connectionUtils.getThreadConnection()</code>。例如对于findAll方法，应该修改成下面这样：</p><pre><code class="java">@Overridepublic List&lt;Account&gt; findAllAccount() {    try{        return runner.query(connectionUtils.getThreadConnection(),                            &quot;select * from account&quot;,                            new BeanListHandler&lt;Account&gt;(Account.class));    }catch (Exception e) {        throw new RuntimeException(e);    }}</code></pre><p>修改完成之后，需要在xml文件中对相应的变量内容进行注入，这里全部都采用setter方法进行注入，<strong>要注意，注入的配置中property的name需要与对象名保持一致</strong>。</p><p>整个bean.xml文件修改完成之后应该是下面这个样子：</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;!-- 配置Service --&gt;    &lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;        &lt;!-- 注入dao --&gt;        &lt;property name=&quot;accountDao&quot; ref=&quot;accountDao&quot;&gt;&lt;/property&gt;        &lt;!-- 注入事务管理器--&gt;        &lt;property name=&quot;txManager&quot; ref=&quot;transactionManager&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!--配置Dao对象--&gt;    &lt;bean id=&quot;accountDao&quot; class=&quot;com.xiong.dao.impl.AccountDaoImpl&quot;&gt;        &lt;!-- 注入QueryRunner --&gt;        &lt;property name=&quot;runner&quot; ref=&quot;runner&quot;&gt;&lt;/property&gt;        &lt;!-- 注入connectionUtils--&gt;        &lt;property name=&quot;connectionUtils&quot; ref=&quot;connectionUtils&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!--配置QueryRunner--&gt;    &lt;bean id=&quot;runner&quot; class=&quot;org.apache.commons.dbutils.QueryRunner&quot; scope=&quot;prototype&quot;&gt;    &lt;/bean&gt;    &lt;!-- 配置数据源 --&gt;    &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt;        &lt;!--连接数据库的必备信息--&gt;        &lt;property name=&quot;driverClass&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/db1?useUnicode=true&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;user&quot; value=&quot;root&quot;&gt;&lt;/property&gt;        &lt;property name=&quot;password&quot; value=&quot;&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 配置ConnectionUtils--&gt;    &lt;bean id=&quot;connectionUtils&quot; class=&quot;com.xiong.utils.ConnectionUtils&quot;&gt;        &lt;!-- 注入数据源 --&gt;        &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 配置tx管理器--&gt;    &lt;bean id=&quot;transactionManager&quot; class=&quot;com.xiong.utils.TransactionManager&quot;&gt;        &lt;!-- 注入connectionUtils--&gt;        &lt;property name=&quot;connectionUtils&quot; ref=&quot;connectionUtils&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>经过这样的修改，这个转账的案例就完成了。</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>操作的时候每次获取一个连接，导致无法进行事务控制。但是如果通过连接控制和事务控制，又会非常复杂，因此希望有一个比较好的解决方法</p><h1 id="动态代理"><a href="#动态代理" class="headerlink" title="动态代理"></a>动态代理</h1><p><strong>特点</strong>：</p><ul><li>字节码随用随创建，随用随加载。</li></ul><p><strong>作用</strong>：</p><ul><li>在不修改源码的基础上对方法进行增强。</li></ul><p><strong>分类</strong>：</p><ul><li><p>基于接口的动态代理</p><p>涉及的类：Proxy</p></li><li><p>基于子类的动态代理</p><p>涉及的类：Enhancer，是第三方cglib提供的库</p></li></ul><h2 id="1-基于接口的动态代理"><a href="#1-基于接口的动态代理" class="headerlink" title="1. 基于接口的动态代理"></a>1. 基于接口的动态代理</h2><h3 id="1-1-创建代理对象"><a href="#1-1-创建代理对象" class="headerlink" title="1.1 创建代理对象"></a>1.1 创建代理对象</h3><p>使用Proxy类中的newProxyInstance方法。</p><p><strong>要求</strong>：</p><ul><li>被代理类至少实现一个接口，如果没有则不能使用</li></ul><p><strong>参数</strong>：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218203431894.png" alt="image-20200218203431894" style="zoom:80%;"><ul><li><p><strong>ClassLoader：类加载器</strong></p><p>用于加载代理对象字节码，写的是被代理对象的类加载器，与被代理对象使用相同的类加载器。也就是说代理谁，就写谁的类加载器。</p><p>比如这里，如果要代理producer，这个参数就写为：</p><pre><code class="java">producer.getClass().getClassLoader()</code></pre></li><li><p><strong>Class[]：字节码数组</strong></p><p>用于让代理对象和被代理对象有相同的方法（如果实现同一个接口，就有相同的方法）。也就是说，代理谁，就写谁的接口。</p><p>比如这里，如果要代理producer，这个参数就写为：</p><pre><code class="java">producer.getClass().getInterface()</code></pre></li><li><p><strong>InvocationHandler：提供增强代码</strong></p><p>表示如何代理。一般写为该接口的一个实现类，通常情况下都是匿名内部类，但不是必须的。也就是说，这个接口的实现类是谁用谁写。</p><p>比如这里，如果要代理producer，这个参数就写为下面这种形式：</p><pre><code class="java">new InvocationHandler() {    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {        return null;    }}</code></pre><p>里面只有一个方法，就是invoke，这个方法的作用：执行被代理对象的任何接口方法都会经过该方法。该方法中涉及了三个参数：</p><ol><li><strong>Object proxy</strong>：代理对象的引用，在方法中用它获取对象</li><li><strong>Method method</strong>：当前执行的方法</li><li><strong>Object[] args</strong>：当前执行方法所需要的参数</li><li><strong>返回值</strong>：和被代理对象有相同的返回值</li></ol><p>同时，一个匿名内部类要访问外部的对象，就要求外部对象是经过final修饰的，也就是procuder用final修饰。</p></li></ul><h3 id="1-2-测试结果"><a href="#1-2-测试结果" class="headerlink" title="1.2 测试结果"></a>1.2 测试结果</h3><p>现有一个方法saleProduct，实现如下：</p><pre><code class="java">public class Producer implements IProducer{    // 销售    @Override    public void saleProduct(Float money) {        System.out.println(&quot;销售产品，并获得：&quot; + money);    }}</code></pre><p>如果要实现的功能是saleProduct，作为代理商，需要从中抽取一部分手续费，此时如果想要创建一个Producer类的代理对象，可以写成下面这样：</p><pre><code class="java">IProducer proxyProducer = (IProducer) Proxy.newProxyInstance(    producer.getClass().getClassLoader(),    producer.getClass().getInterfaces(),    new InvocationHandler() {        @Override        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {            // 在这里提供增强的代码，比如消费者购买产品的时候，经销商需要提取20%的利润            Object returnValue = null;            // 1. 获取方法执行的参数            Float money = (Float) args[0];            // 2. 判断当前的方法是否是销售            if (&quot;saleProduct&quot;.equals(method.getName())) {                returnValue = method.invoke(producer, money * 0.8f);            }            return returnValue;        }    });proxyProducer.saleProduct(100f);</code></pre><p>执行结果为：</p><pre><code>销售产品，并获得：80.0</code></pre><h2 id="2-基于子类的动态代理"><a href="#2-基于子类的动态代理" class="headerlink" title="2. 基于子类的动态代理"></a>2. 基于子类的动态代理</h2><p>首先需要导入依赖</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;cglib&lt;/groupId&gt;    &lt;artifactId&gt;cglib&lt;/artifactId&gt;    &lt;version&gt;2.1_3&lt;/version&gt;&lt;/dependency&gt;</code></pre><h3 id="2-1-创建代理对象"><a href="#2-1-创建代理对象" class="headerlink" title="2.1 创建代理对象"></a>2.1 创建代理对象</h3><p>使用Enhancer类中的create方法</p><p><strong>要求</strong>：</p><ul><li>被代理类不能是最终类，因为最终类不能创建子类。</li></ul><p><strong>参数</strong>：</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218213711491.png" alt="image-20200218213711491" style="zoom:80%;"><ul><li><p><strong>Class</strong>：字节码</p><p>用于指定被代理对象的字节码</p></li><li><p><strong>Class[]</strong>：实现的接口</p><p>由于是在子类，可以不实现任何接口，也就是这个参数可以空着</p></li><li><p><strong>Callback</strong>：用于提供增强的</p><p>一般写的是Callback的子接口的实现类：MethodInterceptor。</p><p>执行被代理对象的任何方法都会经过该方法</p><pre><code class="java">new MethodInterceptor() {    @Override    public Object intercept(Object proxy,                             Method method,                             Object[] args,                             MethodProxy methodProxy) throws Throwable {        return null;    }</code></pre><p>该方法中涉及了4个参数：</p><ol><li><strong>Object proxy</strong>：代理对象的引用，在方法中用它获取对象</li><li><strong>Method method</strong>：当前执行的方法</li><li><strong>Object[] args</strong>：当前执行方法所需要的参数</li><li><strong>MethodProxy methodProxy</strong>：当前执行方法的代理对象</li><li><strong>返回值</strong>：和被代理对象有相同的返回值</li></ol><p>前三个参数和基于接口的动态代理的参数是一样的。</p></li></ul><h3 id="2-2-测试结果"><a href="#2-2-测试结果" class="headerlink" title="2.2 测试结果"></a>2.2 测试结果</h3><p>因此，可以和之前的测试方法一样进行测试</p><pre><code class="java">final Producer producer = new Producer();IProducer cgProducer = (IProducer) Enhancer.create(    producer.getClass(),     new MethodInterceptor() {        @Override        public Object intercept(Object proxy,                                 Method method,                                 Object[] args,                                 MethodProxy methodProxy) throws Throwable {            // 在这里提供增强的代码，比如消费者购买产品的时候，经销商需要提取20%的利润            Object returnValue = null;            // 1. 获取方法执行的参数            Float money = (Float) args[0];            // 2. 判断当前的方法是否是销售            if (&quot;saleProduct&quot;.equals(method.getName())) {                returnValue = method.invoke(producer, money * 0.8f);            }            return returnValue;        }    });cgProducer.saleProduct(1000f);</code></pre><h2 id="3-动态代理的作用"><a href="#3-动态代理的作用" class="headerlink" title="3. 动态代理的作用"></a>3. 动态代理的作用</h2><p>主要就是通过动态代理来实现方法的增强，可以进行事务控制</p><h3 id="3-1-进行事务控制"><a href="#3-1-进行事务控制" class="headerlink" title="3.1 进行事务控制"></a>3.1 进行事务控制</h3><p>前面AccountService业务层中每个方法里面都加了相同的操作：开启事务、关闭事务，因此可以通过动态代理，把这些相同的操作抽取出来，放进增强类里面，就会大幅简化业务层的内容。</p><p>首先创建一个BeacFactory类，这个类用来直接代理原来的AccountService类。在这个类中需要创建被代理的对象accountService以及用于事务控制的txManager对象。然后分别设置其setter方法，用于spring注入。</p><p>需要注意的是，这里的setAccountService需要使用final修饰。</p><img src="/2020/02/18/13-Spring/4_%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/image-20200218221612745.png" alt="image-20200218221612745" style="zoom:80%;"><p>然后在BeanFactory类中设置获取Service的代理对象：</p><pre><code class="java">public AccountService getAccountService() {    Proxy.newProxyInstance(        accountService.getClass().getClassLoader(),        accountService.getClass().getInterfaces(),        new InvocationHandler() {            /*             * 添加事务的支持             * */            @Override            public Object invoke(Object proxy,                                  Method method,                                  Object[] args) throws Throwable {                Object returnValue = null;                try {                    // 1. 开启事务                    txManager.beginTX();                    // 2. 执行操作                    // 其实动态代理包装的核心也就在这里，通过对参数、前后操作进行修改                    // 最终达到增强类的作用                    returnValue = method.invoke(accountService, args);                    // 3. 提交事务                    txManager.commit();                    // 4. 返回结果                    return returnValue;                } catch (Exception e) {                    // 5. 回滚操作                    txManager.rollback();                    // 如果异常就不再继续往下走了                    throw new RuntimeException(e);                } finally {                    // 6. 释放连接                    txManager.release();                }            }        });}</code></pre><p>最终还需要修改配置。在bean.xml文件中，将这两个对象通过xml的方式注入：</p><pre><code class="xml">&lt;!-- 配置Service的代理 --&gt;&lt;bean id=&quot;proxyAccountService&quot;       factory-bean=&quot;beanFactory&quot;       factory-method=&quot;getAccountService&quot;&gt;&lt;/bean&gt;&lt;!--配置beanFactory--&gt;&lt;bean id=&quot;beanFactory&quot; class=&quot;com.xiong.factory.BeanFactory&quot;&gt;    &lt;!-- 注入连接管理器--&gt;    &lt;property name=&quot;accountService&quot; ref=&quot;accountService&quot;&gt;&lt;/property&gt;    &lt;!-- 注入事务管理器--&gt;    &lt;property name=&quot;txManager&quot; ref=&quot;transactionManager&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置Service --&gt;&lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;    &lt;!-- 注入dao --&gt;    &lt;property name=&quot;accountDao&quot; ref=&quot;accountDao&quot;&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><p>之后就是把AccountServiceImpl中相关的类恢复成原状就可以了</p><h1 id="junit测试设置"><a href="#junit测试设置" class="headerlink" title="junit测试设置"></a>junit测试设置</h1><p>需要在test类上面添加以下两个注解：</p><ul><li>@RunWith(SpringJUnit4ClassRunner.class)</li><li>@ContextConfiguration(locations = “classpath:bean.xml”)</li></ul><pre><code class="java">@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:bean.xml&quot;)public class AccountServiceTest {    @Autowired    @Qualifier(&quot;proxyAccountService&quot;)    private AccountService proxyAccountService;    @Test    public void testTransfer() {        proxyAccountService.transfer(&quot;aaa&quot;, &quot;bbb&quot;, 100F);    }}</code></pre><p>经过测试发现结果是正确的，也就是会经过事务处理，在发生异常的时候回滚。</p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战3】IoC注解</title>
      <link href="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/"/>
      <url>/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="Spring中IOC的常用注解"><a href="#Spring中IOC的常用注解" class="headerlink" title="Spring中IOC的常用注解"></a>Spring中IOC的常用注解</h1><p>前一节中对于AccountService的XML配置为：</p><pre><code class="xml">&lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;&lt;/bean&gt;</code></pre><h1 id="常用注解"><a href="#常用注解" class="headerlink" title="常用注解"></a>常用注解</h1><h2 id="1-1-用于创建对象"><a href="#1-1-用于创建对象" class="headerlink" title="1.1 用于创建对象"></a>1.1 用于创建对象</h2><h3 id="1-1-1-Component"><a href="#1-1-1-Component" class="headerlink" title="1.1.1 Component"></a>1.1.1 Component</h3><p>作用与XML配置文件中编写一个<code>&lt;bean&gt;</code>标签的作用相同，在类名前面加上关键字<code>@component</code></p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214205731796.png" alt="image-20200214205731796" style="zoom:80%;"><p><strong>作用</strong>：</p><ul><li>把当前类对象存入容器中</li></ul><p><strong>属性</strong>：</p><ul><li><p>value：用于指定bean的id，当不写的时候，默认值是当前类名，并且首字母小写</p><p>例如，对于默认值，应该使用下面的方法调用：</p><pre><code class="java">public static void main(String[] args) {    // 1. 获取核心容器对象    ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);    // 2. 根据id获取bean对象    // 拿到Object类型并进行强制类型转换    AccountService as = (AccountService) ac.getBean(&quot;accountServiceImpl&quot;);    System.out.println(as);}</code></pre><p>但是，如果要指定value的话，可以把<code>@Component</code>修改为：</p><pre><code class="java">@Component(value = &quot;accountService&quot;)</code></pre><p>然后再使用accountService获取bean对象。</p></li></ul><p><strong>用法</strong>：</p><p>在xml中指定，告知spring在创建容器的时候需要扫描的包，配置所需要的的标签不是在beans的约束中，而是一个名称为context名称空间和约束中，并且指定扫描的包。也就是在bean.xml文件中将原来的beans约束替换成下面这样：</p><pre><code class="xml">&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xmlns:context=&quot;http://www.springframework.org/schema/context&quot;    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;!--加上这个之后就会去扫描整个com.xiong包下带有注解的类--&gt;    &lt;context:component-scan base-package=&quot;com.xiong&quot;&gt;&lt;/context:component-scan&gt;&lt;/beans&gt;</code></pre><h3 id="1-1-2-Controller"><a href="#1-1-2-Controller" class="headerlink" title="1.1.2 Controller"></a>1.1.2 Controller</h3><p>一般用在表现层</p><h3 id="1-1-3-Service"><a href="#1-1-3-Service" class="headerlink" title="1.1.3 Service"></a>1.1.3 Service</h3><p>一般用在业务层</p><h3 id="1-1-4-Repository"><a href="#1-1-4-Repository" class="headerlink" title="1.1.4 Repository"></a>1.1.4 Repository</h3><p>一般用在持久层</p><p>第2、3、4个注解，他们的<strong>作用和属性与第一个是相同的</strong>，他们三个是spring提供的明确三层使用的注解，<strong>使得三层对象更加清晰</strong>。如果有些对象不属于三层中的任何一层，则使用Component来创建</p><h2 id="1-2-用于注入数据"><a href="#1-2-用于注入数据" class="headerlink" title="1.2 用于注入数据"></a>1.2 用于注入数据</h2><p>作用与在XML配置文件中的bean标签中写一个property标签的作用一样。用于注入数据的注解有以下这些：</p><p><code>@Autowired    @Qualifier    @Resource    @Value</code></p><p><strong>注意！！！</strong></p><ul><li><strong>前三个</strong>注解都只能注入其他bean类型的数据，</li><li>基本类型和String类型的注入需要通过<strong>第四个</strong>注解来实现</li><li>集合类型的注入只能通过XML来实现。</li></ul><p>下面详细介绍这些注解：</p><h3 id="1-2-1-Autowired"><a href="#1-2-1-Autowired" class="headerlink" title="1.2.1 Autowired"></a>1.2.1 Autowired</h3><p><strong>作用</strong>：</p><ul><li>自动按照类型注入，只要容器中有唯一的一个bean对象类型和要注入的变量类型相匹配，就可以注入成功</li></ul><p><strong>出现位置</strong>：</p><ul><li><p>可以是变量上，也可以是方法上。</p><p>例如在这个AccountDaoImpl上面加上<code>@Repository(value=&quot;accountDao&quot;)</code>，指定其对象，然后再在service的实现中调用，即可正常获得对象。</p><pre><code class="java">@Component(value = &quot;accountService&quot;)public class AccountServiceImpl implements AccountService {    @Autowired    private AccountDao accountDao;    @Override    public void saveAccount() {        accountDao.saveAccount();    }}</code></pre></li></ul><p><strong>注意</strong>：</p><ul><li><p><strong>case1</strong>：如果IOC容器中<strong>没有任何bean的类型与要注入的变量类型匹配</strong>，则会报错</p></li><li><p><strong>case2</strong>：如果IOC容器中有多个类型匹配时，先按照类型，圈定出来匹配的对象，然后使用变量名称作为bean的id，在圈定出来的对象中继续查找，如果有一样的，也可以注入成功，如果两个都不一样则会报错。</p><p>例子：</p><p>对于AccountDao接口，有AccountDaoImpl1和AccountDaoImpl2两个实现类，它们的属性value分别为accountDao1和accountDao2，如下所示：</p><p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214222905125.png" alt="image-20200214222905125" style="zoom:80%;"><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214223036463.png" alt="image-20200214223036463"><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214222905125.png" alt="image-20200214222905125" style="zoom:80%;"><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214223036463.png" alt="image-20200214223036463"><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214222905125.png" alt="image-20200214222905125" style="zoom:80%;"><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214223036463.png" alt="image-20200214223036463"></p><p>此时，调用在AccountService的实现类AccountServiceImpl中定义的对象为下面这样的时候：</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214223301462.png" alt="image-20200214223301462" style="zoom:80%;"><p>由于AccountDao有两个实现类，并且这里所写的AccountDao并不是Spring容器中的一个，也就是说满足case1。此时是找不到的因此会报错：</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214223527170.png" alt="image-20200214223527170" style="zoom:80%;"><p>不过从他报的这个错中也可以看出，匹配到了两个id，因此，如果在AccountServiceImpl中，将AccountDao变量的名称从accountDao更换为accountDao1或者accountDao2，就能成功运行了！</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214223708697.png" alt="image-20200214223708697" style="zoom:80%;"></li></ul><p><strong>细节</strong>：</p><ul><li>使用注解注入时，set方法不是必须的。</li></ul><h3 id="1-2-2-Qualifier"><a href="#1-2-2-Qualifier" class="headerlink" title="1.2.2 Qualifier"></a>1.2.2 Qualifier</h3><p><strong>作用</strong>：</p><ul><li><p>在按照类中注入的基础上再按照名称注入，它在给类成员注入时<strong>不能够单独使用</strong>，而必须和Autowired一起使用。但是在给方法参数注入时<strong>可以单独使用</strong>。</p><p>例如在上面的那个例子中，可以在这里指定value=accountDao2，而accountDao2就是在前面</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214224147931.png" alt="image-20200214224147931" style="zoom:80%;"></li></ul><p><strong>属性</strong>：</p><ul><li>value：用于指定注入bean的id</li></ul><h3 id="1-2-3-Resource"><a href="#1-2-3-Resource" class="headerlink" title="1.2.3 Resource"></a>1.2.3 Resource</h3><p><strong>作用</strong>：</p><ul><li><p>直接按照bean的id进行注入，<strong>可以独立使用</strong>。使用一个Resource注解就相当于同时使用了Autowired和Qualifier两个注解</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214225815771.png" alt="image-20200214225815771" style="zoom:80%;"></li></ul><p><strong>属性</strong>：</p><ul><li><strong>name</strong>：用于指定bean的id</li></ul><p><strong>注意</strong>：</p><ul><li><p>需要在pom文件中加上java.annotation包依赖</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;javax.annotation&lt;/groupId&gt;    &lt;artifactId&gt;javax.annotation-api&lt;/artifactId&gt;    &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;</code></pre></li></ul><h3 id="1-2-4-Value"><a href="#1-2-4-Value" class="headerlink" title="1.2.4 Value"></a>1.2.4 Value</h3><p><strong>作用</strong>：</p><ul><li>用于注入基本类型和String类型的数据</li></ul><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214232515058.png" alt="image-20200214232515058" style="zoom:80%;"><p><strong>属性</strong>：</p><ul><li><p><strong>value</strong>：用于指定数据的值。他可以使用spring中的SpEL（spring中的EL表达式）</p><blockquote><p>SpEL的写法：<code>${表达式}</code></p></blockquote></li></ul><h2 id="1-3-用于改变作用范围"><a href="#1-3-用于改变作用范围" class="headerlink" title="1.3 用于改变作用范围"></a>1.3 用于改变作用范围</h2><p>作用与在bean标签中使用scope属性实现的功能一样</p><h3 id="1-3-1-Scope"><a href="#1-3-1-Scope" class="headerlink" title="1.3.1 Scope"></a>1.3.1 Scope</h3><p><strong>作用</strong>：</p><ul><li>指定bean的作用范围</li></ul><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214230757647.png" alt="image-20200214230757647" style="zoom:80%;"><p><strong>属性</strong>：</p><ul><li><strong>value</strong>：指定范围的取值，常用的取值有：<ol><li>singleton：单例</li><li>prototype：多例</li></ol></li></ul><h2 id="1-4-与生命周期相关"><a href="#1-4-与生命周期相关" class="headerlink" title="1.4 与生命周期相关"></a>1.4 与生命周期相关</h2><p>作用与在bean标签中使用init-method和destroy-method的作用一样</p><h3 id="1-4-1-PreDestroy"><a href="#1-4-1-PreDestroy" class="headerlink" title="1.4.1 PreDestroy"></a>1.4.1 PreDestroy</h3><p><strong>作用</strong>：</p><ul><li>用于指定销毁方法</li></ul><h3 id="1-4-2-PostConstruct"><a href="#1-4-2-PostConstruct" class="headerlink" title="1.4.2 PostConstruct"></a>1.4.2 PostConstruct</h3><p><strong>作用</strong>：</p><ul><li>用于指定初始化方法</li></ul><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214232015807.png" alt="image-20200214232015807" style="zoom:80%;"><p>使用下面的方式调用：</p><pre><code class="java">public static void main(String[] args) {    // 1. 获取核心容器对象    ClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);    // 2. 根据id获取bean对象    // 拿到Object类型并进行强制类型转换    AccountService as = (AccountService) ac.getBean(&quot;accountService&quot;);    System.out.println(as);    as.saveAccount();    ac.close();}</code></pre><p>可以得到最终的运行结果为：</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200214232308638.png" alt="image-20200214232308638" style="zoom:80%;"><h1 id="案例：进行数据库的CRUD操作"><a href="#案例：进行数据库的CRUD操作" class="headerlink" title="案例：进行数据库的CRUD操作"></a>案例：进行数据库的CRUD操作</h1><h2 id="1-创建数据库"><a href="#1-创建数据库" class="headerlink" title="1. 创建数据库"></a>1. 创建数据库</h2><p>使用下面的sql语句创建数据库表：</p><pre><code class="mysql">create table account(    id int primary key auto_increment,    name varchar(40),    money float)character set utf8 collate utf8_general_ci;insert into account(name,money) values(&#39;aaa&#39;,1000);insert into account(name,money) values(&#39;bbb&#39;,1000);insert into account(name,money) values(&#39;ccc&#39;,1000);</code></pre><p>得到的数据库如下：</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200218132709486.png" alt="image-20200218132709486" style="zoom:80%;"><h2 id="2-配置bean-xml"><a href="#2-配置bean-xml" class="headerlink" title="2. 配置bean.xml"></a>2. 配置bean.xml</h2><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;&lt;/beans&gt;</code></pre><p>然后在该标签里面配置Service。</p><ul><li>由于在accountService的实现中用到了accountDao，因此需要注入accountDao</li><li>由于accountDao的实现中用到了QueryRunner，因此需要注入QueryRunner</li><li>由于QueryRunner需要用到数据源，因此需要注入数据源，这里是通过构造函数注入的，并且是多例对象。如果是单例对象，并且多个线程同时使用，则可能会互相干扰。</li><li>配置数据源的时候需要四大必备信息：<ol><li>配置MySQL的驱动</li><li>jdbc的URL：注意配置URL的时候需要把时区和编码设置一下。</li><li>用户名</li><li>密码</li></ol></li></ul><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200218131223326.png" alt="image-20200218131223326" style="zoom:80%;"><h2 id="3-创建Account实体类"><a href="#3-创建Account实体类" class="headerlink" title="3. 创建Account实体类"></a>3. 创建Account实体类</h2><p>由于数据库中account表中包含了id，name，money三个属性，因此在Account实体类中也添加这3个属性，并且实现相应的getter setter以及toString方法。</p><pre><code class="java">public class Account implements Serializable {    private Integer id;    private String name;    private Float money;    //...相应的方法}</code></pre><h2 id="4-创建AccountService业务层"><a href="#4-创建AccountService业务层" class="headerlink" title="4. 创建AccountService业务层"></a>4. 创建AccountService业务层</h2><p>其中包含查询所有、查询单个、保存、更新、删除五种方法，接口如下：</p><pre><code class="java">public interface AccountService {    List&lt;Account&gt; findAllAccount();    Account findAccountById(Integer accountId);    void saveAccount(Account account);    void updateAccount(Account account);    void deleteAccount(Integer acccountId);}</code></pre><p>具体的实现如下：其中所使用到的AccountDao将在下面进行定义</p><pre><code class="java">public class AccountServiceImpl implements AccountService {    private AccountDao accountDao;    // 下面这个set方法让spring注入该对象    public void setAccountDao(AccountDao accountDao) {        this.accountDao = accountDao;    }    @Override    public List&lt;Account&gt; findAllAccount() {        return accountDao.findAllAccount();    }    @Override    public Account findAccountById(Integer accountId) {        return accountDao.findAccountById(accountId);    }    @Override    public void saveAccount(Account account) {        accountDao.saveAccount(account);    }    @Override    public void updateAccount(Account account) {        accountDao.updateAccount(account);    }    @Override    public void deleteAccount(Integer acccountId) {        accountDao.deleteAccount(acccountId);    }}</code></pre><h2 id="5-创建AccountDao持久层"><a href="#5-创建AccountDao持久层" class="headerlink" title="5. 创建AccountDao持久层"></a>5. 创建AccountDao持久层</h2><p>本次使用的案例是进行数据库的CRUD，因此直接通过业务层调用持久层的相关内容，因此也需要以下5个方法：</p><pre><code class="java">public interface AccountDao {    List&lt;Account&gt; findAllAccount();    Account findAccountById(Integer accountId);    void saveAccount(Account account);    void updateAccount(Account account);    void deleteAccount(Integer acccountId);}</code></pre><p>其具体实现如下，需要通过QueryRunner的对象调用相关的方法。</p><ul><li><p><strong>query方法</strong>：可以用于查询的SQL语句执行，注意第二个参数是返回值类型，后面才是传入的参数。</p><p>并且这里的返回值类型指定方式有以下两种：</p><ol><li>单条数据：<code>new BeanHandler&lt;Account&gt;(Account.class)</code></li><li>多条数据：<code>new BeanListHandler&lt;Account&gt;(Account.class)</code></li></ol></li><li><p><strong>update方法</strong>：可以用于插入、更新、删除的SQL语句执行，注意参数在SQL语句中用问号？表示占位符，在后面可以用参数来补充。</p></li></ul><pre><code class="java">public class AccountDaoImpl implements AccountDao {    private QueryRunner runner;    public void setRunner(QueryRunner runner) {        this.runner = runner;    }    @Override    public List&lt;Account&gt; findAllAccount() {        try{            return runner.query(&quot;select * from account&quot;,                                new BeanListHandler&lt;Account&gt;(Account.class));        }catch (Exception e) {            throw new RuntimeException(e);        }    }    @Override    public Account findAccountById(Integer accountId) {        try{            return runner.query(&quot;select * from account where id = ? &quot;,                                new BeanHandler&lt;Account&gt;(Account.class),                                accountId);        }catch (Exception e) {            throw new RuntimeException(e);        }    }    @Override    public void saveAccount(Account account) {        try{            runner.update(&quot;insert into account(name,money)values(?,?)&quot;,                          account.getName(),                          account.getMoney());        }catch (Exception e) {            throw new RuntimeException(e);        }    }    @Override    public void updateAccount(Account account) {        try{            runner.update(&quot;update account set name=?,money=? where id=?&quot;,                          account.getName(),                          account.getMoney(),                          account.getId());        }catch (Exception e) {            throw new RuntimeException(e);        }    }    @Override    public void deleteAccount(Integer accountId) {        try{            runner.update(&quot;delete from account where id=?&quot;,accountId);        }catch (Exception e) {            throw new RuntimeException(e);        }    }}</code></pre><h2 id="6-使用junit进行单元测试"><a href="#6-使用junit进行单元测试" class="headerlink" title="6. 使用junit进行单元测试"></a>6. 使用junit进行单元测试</h2><pre><code class="java">public class AccountServiceTest {    @Test    public void testFindAll() {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);        // 2. 获取业务层对象        AccountService as = ac.getBean(&quot;accountService&quot;, AccountService.class);        // 3. 执行方法        List&lt;Account&gt; accountList = as.findAllAccount();        for(Account account : accountList) {            System.out.println(account);        }    }    @Test    public void testFindOne() {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);        // 2. 获取业务层对象        AccountService as = ac.getBean(&quot;accountService&quot;, AccountService.class);        // 3. 执行方法        Account account = as.findAccountById(1);        System.out.println(account);    }    @Test    public void testSave() {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);        // 2. 获取业务层对象        AccountService as = ac.getBean(&quot;accountService&quot;, AccountService.class);        // 3. 执行方法        Account account = new Account();        account.setName(&quot;test&quot;);        account.setMoney(1234f);        as.saveAccount(account);    }    @Test    public void testUpdate() {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);        // 2. 获取业务层对象        AccountService as = ac.getBean(&quot;accountService&quot;, AccountService.class);        // 3. 执行方法        Account account = as.findAccountById(4);        account.setMoney(2345f);        as.updateAccount(account);    }    @Test    public void testDelete() {        // 1. 获取容器        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);        // 2. 获取业务层对象        AccountService as = ac.getBean(&quot;accountService&quot;, AccountService.class);        // 3. 执行方法        as.deleteAccount(4);    }}</code></pre><h2 id="7-换为注解配置"><a href="#7-换为注解配置" class="headerlink" title="7. 换为注解配置"></a>7. 换为注解配置</h2><p>在bean.xml文件中将Service和Dao对象的配置删掉，只使用一条配置语句来代替，就是告知spring在创建容器的时候要扫描的包。</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200218144445580.png" alt="image-20200218144445580" style="zoom:80%;"><p>然后在持久层和业务层的实现中添加相应的注解，并且把实现中的set方法换成<code>@Autowired</code>注解就可以了。</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200218145719838.png" alt="image-20200218145719838" style="zoom:80%;"><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200218145746260.png" alt="image-20200218145746260" style="zoom:80%;"><h1 id="新的注解"><a href="#新的注解" class="headerlink" title="新的注解"></a>新的注解</h1><p>不管是基于XML还是基于注解的spring都离不开要在bean.xml文件中进行配置，但是如果想要把这个xml依赖给摆脱掉。</p><p>首先需要创建一个配置类，作用与bean.xml是一样的。</p><h2 id="1-Configuration"><a href="#1-Configuration" class="headerlink" title="1. Configuration"></a>1. Configuration</h2><p><strong>作用</strong>：</p><ul><li>指定当前类是一个配置类</li></ul><p>获取容器的时候需要通过AnnotationConfigApplicationContext来进行。</p><p>例如上面那个，SpringConfiguration类，在创建核心容器的时候需要通过该方法来创建</p><pre><code class="java">ApplicationContext ac = new AnnotationConfigApplicationContext(SpringConfiguration.class);</code></pre><p><strong>细节</strong>：</p><ul><li>当配置类作为AnnotationConfigApplicationContext对象创建的对象时，可以不写这个注解。</li></ul><h2 id="2-ComponentScan"><a href="#2-ComponentScan" class="headerlink" title="2. ComponentScan"></a>2. ComponentScan</h2><p><strong>作用</strong>：</p><ul><li>用于通过注解指定spring在创建容器时要扫描的包</li></ul><p><strong>属性</strong>：</p><ul><li><p><strong>value</strong>：与basePackages的作用一样，都是用于指定创建容器时要扫描的包。使用此注解就等同于在xml中配置。</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200215151237517.png" alt="image-20200215151237517" style="zoom:80%;"><p>这个注解的作用就和下面xml文件中圈住的标签作用是一样的。</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200215151308690.png" alt="image-20200215151308690" style="zoom:80%;"></li></ul><h2 id="3-Bean"><a href="#3-Bean" class="headerlink" title="3. Bean"></a>3. Bean</h2><p><strong>作用</strong>：</p><ul><li>作用就是用于把当前方法的返回值作为Bean对象，并且存入Spring的IoC容器中。</li></ul><p><strong>属性</strong>：</p><ul><li><p><strong>name</strong>：用于指定Bean的id。例如下面创建数据源对象</p><pre><code class="java">@Bean(name=&quot;dataSource&quot;)public DataSource createDataSource() {    try {        ComboPooledDataSource ds = new ComboPooledDataSource();        ds.setDriverClass(&quot;&quot;);        ds.setJdbcUrl(&quot;&quot;);        ds.setUser(&quot;&quot;);        ds.setPassword(&quot;&quot;);        return ds;    } catch(Exception e) {        throw new RuntimeException(e);    }}</code></pre></li></ul><p><strong>细节</strong>：</p><ul><li>使用注解配置方法时，如果方法有参数，spring会去容器中查找有没有可用的bean对象</li><li>查找的方式和Autowired注解的作用是一样的，也就是自动按照类型注入。</li></ul><h2 id="4-Import"><a href="#4-Import" class="headerlink" title="4. Import"></a>4. Import</h2><p><strong>作用</strong>：</p><ul><li>用于导入其他的配置类，可以<strong>把其他的配置类加载到主配置类里面</strong>。</li></ul><p><strong>属性</strong>：</p><ul><li><p><strong>value</strong>：在括号中指定字节码。如果有多个，可以将多个都放进大括号里面。</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200215162210462.png" alt="image-20200215162210462" style="zoom:80%;"><p>也就相当于把分配置文件加到主配置文件里面。</p></li><li><p>使用Import注解之后，有Import的类就叫做父配置类，导入的其他类叫做子配置类。</p></li></ul><h2 id="5-PropertySource-s"><a href="#5-PropertySource-s" class="headerlink" title="5. PropertySource[s]"></a>5. PropertySource[s]</h2><p><strong>作用</strong>：</p><ul><li>就是用于指定properties文件的位置</li></ul><p><strong>属性</strong>：</p><ul><li><p><strong>value</strong>：指定文件名称和文件路径，其中的classpath关键字表示类路径下。</p><img src="/2020/02/14/13-Spring/3_%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84IOC/image-20200215183936368.png" alt="image-20200215183936368" style="zoom:80%;"></li></ul>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战2】IoC与DI</title>
      <link href="/2020/02/13/13-Spring/2_IOC/"/>
      <url>/2020/02/13/13-Spring/2_IOC/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="IoC"><a href="#IoC" class="headerlink" title="IoC"></a>IoC</h1><p><strong>将创建对象的控制权交给工厂</strong>，也就是可以通过工厂模式实现IoC，是框架的一个重要特性。</p><p>IoC包括了<strong>依赖注入 DI</strong>(Dependency Injection) 和<strong>依赖查找 DL</strong>(Dependency Lookup) </p><p>作用是<strong>削减计算机程序之间的耦合，解除代码中的依赖关系</strong>。</p><p><strong>本质：Spring的IoC实质上是一个Map类型的容器，其key是String类型，value是Object类型，通过String的索引来找Spring创建出来对应的对象。</strong></p><h2 id="1-配置"><a href="#1-配置" class="headerlink" title="1. 配置"></a>1. 配置</h2><p>在pom文件中配置spring，增加下面这个dependency：</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-context&lt;/artifactId&gt;    &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>在resources中添加一个bean.xml，在其中配置IoC</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;!--id：获取时的唯一标识，class：反射时的全限定类名--&gt;    &lt;bean id=&quot;accountDao&quot; class=&quot;com.xiong.dao.Impl.AccountDaoImpl&quot;&gt;&lt;/bean&gt;    &lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;&lt;/bean&gt;&lt;/beans&gt;</code></pre><p>在模拟的clinet中做一些改变，需要获取spring的IoC核心容器，并且根据id获取对象。</p><p>注意，通过核心容器，并且根据id获取对象的方法有两种：</p><ul><li>拿到Object类型并进行强制类型转换</li><li>直接给getBean方法传入类型的字节码，直接获取转换后类型的对象</li></ul><pre><code class="java">public class client {    public static void main(String[] args) {        // 1. 获取核心容器对象        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);        // 2. 根据id获取bean对象        // 方法1：拿到Object类型并进行强制类型转换        AccountService as = (AccountService) ac.getBean(&quot;accountService&quot;);        // 方法2：通过第二个参数：字节码，进行强制转换        AccountDao ad = ac.getBean(&quot;accountDao&quot;, AccountDao.class);        System.out.println(as);        System.out.println(ad);    }}</code></pre><p>这样就把前面jdbc例子里面使用BeanFactory创建对象的功能交给Spring来做了。</p><h2 id="2-核心容器的三个实现类"><a href="#2-核心容器的三个实现类" class="headerlink" title="2. 核心容器的三个实现类"></a>2. 核心容器的三个实现类</h2><ul><li><p>ClassPathXmlApplicationContext</p><p>可以加载类路径下的配置文件，要求配置文件必须在类路径下，不在的话，就不能加载</p><pre><code class="java">ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);</code></pre></li><li><p>FileSystemXmlApplicationContext</p><p>可以加载磁盘任意路径下的配置文件（必须有访问权限）</p><pre><code class="java">ApplicationContext ac = new FileSystemXmlApplicationContext(&quot;C:\\Users\\52240\\Desktop\\bean.xml&quot;);</code></pre></li><li><p>AnnotationConfigApplicationContext</p><p>读取注解创建容器</p></li></ul><h2 id="3-BeanFactory与ApplicationContext"><a href="#3-BeanFactory与ApplicationContext" class="headerlink" title="3. BeanFactory与ApplicationContext"></a>3. BeanFactory与ApplicationContext</h2><p>这是两种创建核心容器的方法，下面详细介绍：</p><ul><li><p>ApplicationContext</p><p>创建核心容器时，创建对象采取的策略是<strong>立即加载</strong>的方式。也就是说，只要一读取完配置文件就马上创建配置文件中配置的对象。</p><p>使用场景：单例对象</p><pre><code class="java">ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);AccountService as = (AccountService) ac.getBean(&quot;accountService&quot;);AccountDao ad = ac.getBean(&quot;accountDao&quot;, AccountDao.class);</code></pre></li><li><p>BeanFactory</p><p>创建核心容器时，创建对象采取的策略是<strong>延迟加载</strong>的方式。也就是说，什么时候根据id获取对象，什么时候才真正创建对象。</p><p>使用场景：多例对象</p><pre><code class="java">Resource resource = new ClassPathResource(&quot;bean.xml&quot;);BeanFactory factory = new XmlBeanFactory(resource);AccountService as = (AccountService) factory.getBean(&quot;accountService&quot;);</code></pre></li></ul><h2 id="4-创建bean对象的方式"><a href="#4-创建bean对象的方式" class="headerlink" title="4. 创建bean对象的方式"></a>4. 创建bean对象的方式</h2><p>创建bean有三种方式，在bean.xml中进行创建</p><ul><li><p><strong>使用默认构造函数创建</strong></p><p>在配置文件中使用bean标签配置id和class属性之后，且没有其他属性和标签时，采用的就是默认构造函数创建bean对象。此时如果类中没有默认构造函数，则对象无法创建。</p><pre><code class="xml">&lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;&lt;/bean&gt;</code></pre><p>此时调用的时默认构造函数</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213205633363.png" alt="image-20200213205633363" style="zoom:80%;"><p>因此，生成对象的运行结果为：</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213205703222.png" alt="image-20200213205703222" style="zoom:80%;"><p>相反，如果没有这个无参的构造函数，则会报错。</p></li><li><p><strong>使用普通工厂中的方法创建对象</strong>（使用某个类中的方法创建对象并存入spring容器）</p><p>这种情况一般发生在有外部提供了jar包中带有普通工厂，而我们希望通过这个工厂获取对象，但是因为jar包中的类是不能够修改的，因此如果还想要使用spring容器获取，可以使用这种方式来创建。例如下面这个，在InstanceFactory中有一个getAccountService方法可以返回一个实例对象。</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213210449594.png" alt="image-20200213210449594" style="zoom:80%;"><pre><code class="xml">&lt;bean id=&quot;instanceFactory&quot;       class=&quot;com.xiong.factory.InstanceFactory&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;accountService&quot;       factory-bean=&quot;instanceFactory&quot;      factory-method=&quot;getAccountService&quot;&gt;&lt;/bean&gt;</code></pre><p>首先说明instanceFactory的类是com.xiong.factory.InstanceFactory，然后将它写在下面的factory-bean参数中。这样就可以通过一个普通的工厂函数获取对象了</p></li><li><p><strong>使用工厂中的静态方法创建对象</strong>（使用某个类的静态方法创建对象，并存入spring容器）</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213211847355.png" alt="image-20200213211847355" style="zoom:80%;"><p>此时的bean.xml文件应该写成这样：</p><pre><code class="xml">&lt;bean id=&quot;accountService&quot;       class=&quot;com.xiong.factory.StaticFactory&quot;       factory-method=&quot;getAccountService&quot;&gt;&lt;/bean&gt;</code></pre></li></ul><h2 id="5-bean对象的作用范围"><a href="#5-bean对象的作用范围" class="headerlink" title="5. bean对象的作用范围"></a>5. bean对象的作用范围</h2><p>通常情况下，bean是一个单例的bean，也就是通过核心容器的getBean方法获取同一个id得到的对象也是相同的，可以通过下面的方法进行测试：</p><pre><code class="java">ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);AccountService as = (AccountService) ac.getBean(&quot;accountService&quot;);AccountService as2 = (AccountService) ac.getBean(&quot;accountService&quot;);System.out.println(as);System.out.println(as2);</code></pre><p>运行结果为：</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213212502539.png" alt="image-20200213212502539" style="zoom:80%;"><p>在bean标签的scope属性中有多个取值，可以设置bean不同的作用范围：</p><ul><li><strong>singleton</strong>：单例，也是默认值</li><li><strong>prototype</strong>：多例</li><li><strong>request</strong>：作用于web应用的请求范围</li><li><strong>session</strong>：作用于web应用的会话范围</li><li><strong>global-session</strong>：作用于集群环境的会话范围（全局会话范围），当不是集群环境的时候，就是session</li></ul><h2 id="6-bean对象的生命周期"><a href="#6-bean对象的生命周期" class="headerlink" title="6. bean对象的生命周期"></a>6. bean对象的生命周期</h2><p>根据是单例对象或者多例对象，bean有不同的生命周期</p><ul><li><p><strong>单例对象</strong></p><ol><li><strong>出生</strong>：当核心容器创建的时候，对象就产生了</li><li><strong>活着</strong>：只要容器还在，对象就一直活着</li><li><strong>死亡</strong>：容器销毁，对象死亡</li></ol><p>也就是说：单例对象的生<strong>命周期和核心容器相同</strong>。</p><p>可以通过下面这个例子，在xml文件中指定init和destroy</p><pre><code class="xml">&lt;bean id=&quot;accountService&quot;      scope=&quot;singleton&quot;      init-method=&quot;init&quot;      destroy-method=&quot;destroy&quot;      class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;&lt;/bean&gt;</code></pre><p>同时也需要在相应的类实现文件中写上对应的方法：</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213215521385.png" alt="image-20200213215521385" style="zoom:80%;"><p>但是运行的结果中只执行了init方法，并没有执行destroy方法，这是因为主函数的流程，还没有调用销毁方法，就已经将容器释放了，因此需要手动调用容器的关闭方法才能够执行destroy。</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213215720979.png" alt="image-20200213215720979" style="zoom:80%;"><p>注意，这里的ac如果还是ApplicationContext接口的话是不同调用close方法的，因为close方法属于ClassPath…这个类的，因此需要注意红圈中的部分，要把ac换成这一个类型。</p></li><li><p><strong>多例对象</strong></p><ol><li><strong>出生</strong>：使用对象的时候spring框架为我们创建对象，针对上面那个例子，就是执行getBean的时候才可以</li><li><strong>活着</strong>：只要在使用过程中就一直活着</li><li><strong>死亡</strong>：由于spring框架无法得知何时对象不使用，因此不会自动将其销毁。所以当对象长时间不使用，且没有别的对象引用时，由Java的GC进行回收。</li></ol><p>总的来说：<strong>多例对象使用的时候才创建，并且只能被回收而消亡，不能手动令其死亡</strong>。</p></li></ul><h1 id="依赖注入"><a href="#依赖注入" class="headerlink" title="依赖注入"></a>依赖注入</h1><p>依赖注入：Dependency Injection</p><p>IoC的作用是降低耦合，依赖关系的管理都交给了spring来维护。在当前类中需要用到其他类的对象，只需要在配置文件中说明，<strong>依赖关系的维护就叫做依赖注入</strong>。</p><p>能注入的类型有三类：</p><ul><li>基本类型和String</li><li>其他的bean类型（在配置文件中或者注解配置过的bean）</li><li>复杂类型（集合类型）</li></ul><p>注入的方式</p><ul><li>使用构造函数提供</li><li>使用set方法提供</li><li>使用注解提供</li></ul><h2 id="1-构造函数注入"><a href="#1-构造函数注入" class="headerlink" title="1. 构造函数注入"></a>1. 构造函数注入</h2><p>因为通过xml配置文件中配置的话，会比较麻烦，因为数据可能会经常变化。因此需要通过构造函数进行注入。</p><p>下面将构造函数写成下面这样：</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213223339663.png" alt="image-20200213223339663" style="zoom:80%;"><p>构造函数注入的几个关键点：</p><ul><li><p>使用的标签是constructor-arg，位于bean标签内部。</p></li><li><p>标签中的属性：</p><ol><li><p><strong>type</strong>：用于指定要注入的数据的类型，该属性类型也是构造函数中某个或某些参数的类型。例如：</p><pre><code class="xml">&lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;test&quot;&gt;&lt;/constructor-arg&gt;</code></pre><blockquote><p>上面的这个标签就会将<code>&quot;test&quot;</code>这个字符串赋给String类型的成员。如果有两个String有两个，则不能实现独立注入的功能</p></blockquote></li><li><p><strong>index</strong>：用于指定要注入的数据给构造函数中指定索引位置的参数赋值。（索引的位置是从0开始的）</p></li><li><p><strong>name</strong>：用于指定给构造函数中指定名称的构造函数赋值</p><p>=============以上三个指定给构造函数中那个参数赋值，常用的就是name==============</p></li><li><p><strong>value</strong>：用于给基本类型和String类型</p></li><li><p><strong>ref</strong>：用于指定其他的Bean类型数据，它指的就是<strong>在spring的核心容器中出现过的Bean对象</strong>。</p></li></ol></li></ul><p>对于上面那个例子，<strong>构造函数中有三个参数</strong>，就可以通过下面的方式来写</p><pre><code class="xml">&lt;bean id=&quot;accountService&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl&quot;&gt;    &lt;constructor-arg name=&quot;name&quot; value=&quot;test&quot;&gt;&lt;/constructor-arg&gt;    &lt;constructor-arg name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/constructor-arg&gt;    &lt;constructor-arg name=&quot;birthday&quot; ref=&quot;now&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean id=&quot;now&quot; class=&quot;java.util.Date&quot;&gt;&lt;/bean&gt;</code></pre><p><strong>注意，其中Date类型不属于基本类型或String，需要先配置将其存入核心容器中，然后被ref指定。</strong></p><p>最后一行的含义是：读取全限定类名java.util.Date，反射创建一个对象，并且存入spring的容器中。可以通过它创建出来</p><p>执行的结果为：</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213224332737.png" alt="image-20200213224332737" style="zoom:80%;"><p><strong>构造函数注入的优点</strong>：</p><ul><li>获取bean对象时，注入数据是必须的操作，否则对象无法创建成功。</li></ul><p><strong>缺点</strong>：</p><ul><li>改变了bean对象的实例化方式，使我们在创建对象时，必须将所有的参数全部注入，但是如果用不到这些数据，也必须提供，就造成了浪费。</li></ul><h2 id="2-set方法注入"><a href="#2-set方法注入" class="headerlink" title="2. set方法注入"></a>2. set方法注入</h2><p>下面重新创建一个类，还是用之前AccountServiceImpl类，但是把构造函数去掉，并添加相应的set方法（生成各个属性的set方法就可以了）</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213225059490.png" alt="image-20200213225059490" style="zoom:80%;"><p>xml文件中需要进行如下改动：</p><ul><li><p>涉及的标签：property</p></li><li><p>出现的位置：bean标签内部</p></li><li><p>标签中的属性：</p><ol><li><p><strong>name</strong>：用于指定注入时所调用的<strong>set方法的名称</strong></p><p>注意与属性名称无关，至于set方法的名称相关，需要写成方法名称去掉前面的set，并且将大写换成小写。</p><blockquote><p>例如前面用于设置name的函数叫做setName，那么，先去掉set，然后把N换成n，也就是写成<code>name</code>，同理，如果设置name的函数叫做setUsername，那么就要写成<code>username</code></p></blockquote></li><li><p><strong>value</strong>：用于给基本类型和String类型</p></li><li><p><strong>ref</strong>：用于指定其他的Bean类型数据，它指的就是<strong>在spring的核心容器中出现过的Bean对象</strong>。</p></li></ol></li></ul><p>下面是一个具体使用的例子：</p><pre><code class="xml">&lt;bean id=&quot;accountService1&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl1&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;test&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;age&quot; value=&quot;21&quot;&gt;&lt;/property&gt;    &lt;property name=&quot;birthday&quot; ref=&quot;now&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;now&quot; class=&quot;java.util.Date&quot;&gt;&lt;/bean&gt;</code></pre><p><strong>set方法注入的优势</strong>：</p><ul><li>创建对象的时候没有明确地限制，可以直接使用默认构造函数</li></ul><p><strong>缺点</strong>：</p><ul><li>如果有某个成员必须有值，则set方法<strong>无法保证一定注入</strong>，也就是获得对象时可能set方法没有执行</li></ul><p>相比较于构造函数注入，更常用的时set方法注入。</p><h2 id="3-集合数据注入"><a href="#3-集合数据注入" class="headerlink" title="3. 集合数据注入"></a>3. 集合数据注入</h2><p>新建一个类，该类中有各种集合数据，然后在xml中配置实现set方法注入。</p><p>假定有以下这些集合数据，并且对这些集合数据生成set方法。</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213232310897.png" alt="image-20200213232310897" style="zoom:80%;"><pre><code class="xml">&lt;bean id=&quot;accountService2&quot; class=&quot;com.xiong.service.impl.AccountServiceImpl2&quot;&gt;    &lt;property name=&quot;strs&quot;&gt;        &lt;array&gt;            &lt;value&gt;AAA&lt;/value&gt;            &lt;value&gt;BBB&lt;/value&gt;            &lt;value&gt;CCC&lt;/value&gt;        &lt;/array&gt;    &lt;/property&gt;    &lt;property name=&quot;lists&quot;&gt;        &lt;list&gt;            &lt;value&gt;AAA&lt;/value&gt;            &lt;value&gt;BBB&lt;/value&gt;            &lt;value&gt;CCC&lt;/value&gt;        &lt;/list&gt;    &lt;/property&gt;    &lt;property name=&quot;sets&quot;&gt;        &lt;set&gt;            &lt;value&gt;AAA&lt;/value&gt;            &lt;value&gt;BBB&lt;/value&gt;            &lt;value&gt;CCC&lt;/value&gt;        &lt;/set&gt;    &lt;/property&gt;    &lt;property name=&quot;maps&quot;&gt;        &lt;props&gt;            &lt;prop key=&quot;testProp&quot;&gt;&lt;/prop&gt;            &lt;prop key=&quot;testProp2&quot;&gt;&lt;/prop&gt;        &lt;/props&gt;    &lt;/property&gt;    &lt;property name=&quot;props&quot;&gt;        &lt;map&gt;            &lt;entry key=&quot;key A&quot; value=&quot;val AA&quot;&gt;&lt;/entry&gt;            &lt;entry key=&quot;key B&quot;&gt;                &lt;value&gt;bbb&lt;/value&gt;            &lt;/entry&gt;        &lt;/map&gt;    &lt;/property&gt;&lt;/bean&gt;</code></pre><p>用于给<strong>List结构集合</strong>注入的标签：（List结构集合包括List，Array，Set）</p><ul><li>list</li><li>array</li><li>set</li></ul><p>用于给<strong>Map结构集合</strong>注入的标签：（Map结构集合包括Map，Properties）</p><ul><li>map</li><li>props</li></ul><p>总结：<strong>结构相同，标签可以互换。</strong>List结构或者Map结构的数据下面的那几个标签全部都可以使用。</p><blockquote><p>例如上面map和props的注入，就是互换了顺序，但是依然可以正常执行。</p></blockquote><p>最终将所有的集合全部打印出来，运行的结果为：</p><img src="/2020/02/13/13-Spring/2_IOC/image-20200213233227312.png" alt="image-20200213233227312" style="zoom:80%;"><h1 id="测试类"><a href="#测试类" class="headerlink" title="测试类"></a>测试类</h1><p>使用junit进行spring项目的测试</p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Spring实战1】程序的耦合与解耦</title>
      <link href="/2020/02/13/13-Spring/1_%E7%A8%8B%E5%BA%8F%E8%80%A6%E5%90%88%E4%B8%8E%E8%A7%A3%E8%80%A6/"/>
      <url>/2020/02/13/13-Spring/1_%E7%A8%8B%E5%BA%8F%E8%80%A6%E5%90%88%E4%B8%8E%E8%A7%A3%E8%80%A6/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><p>本部分主要是说明程序的耦合与解耦，通过将jdbc一步步解耦的例子来引入IoC</p><p>使用下面的SQL语句创建一个数据库，该数据库在这一节中使用：</p><pre><code class="mysql">create table account(    id int primary key auto_increment,    name varchar(40),    money float)character set utf8 collate utf8_general_ci;insert into account(name,money) values(&#39;aaa&#39;,1000);insert into account(name,money) values(&#39;bbb&#39;,1000);insert into account(name,money) values(&#39;ccc&#39;,1000);</code></pre><h1 id="1-jdbc解耦的例子"><a href="#1-jdbc解耦的例子" class="headerlink" title="1. jdbc解耦的例子"></a>1. jdbc解耦的例子</h1><h2 id="1-1-典型jdbc流程"><a href="#1-1-典型jdbc流程" class="headerlink" title="1.1 典型jdbc流程"></a>1.1 典型jdbc流程</h2><p>下面是一个典型的jdbc程序流程</p><pre><code class="java">// 1. 注册驱动DriverManager.registerDriver(new com.mysql.jdbc.Driver());// 2. 获取连接Connection conn = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db1?serverTimezone=UTC&quot;, &quot;root&quot;, &quot;&quot;);// 3. 获取操作数据库的预处理对象PreparedStatement pstm = conn.prepareStatement(&quot;select * from account;&quot;);// 4. 执行SQL语句，得到结果集ResultSet rs = pstm.executeQuery();// 5. 遍历结果集while (rs.next()) {    System.out.println(rs.getString(&quot;name&quot;));}// 6. 释放资源rs.close();pstm.close();conn.close();</code></pre><p>在第一步注册驱动的过程中，使用new来注册驱动，这样是非常不方便的，因为代码与这个类密切关联，如果没有这个类，甚至程序都无法通过编译。</p><p>即降低程序间的依赖关系，因为有些关系是可以避免的，有些依赖关系是无法避免的。因此最好是做到<strong>编译期不依赖，运行期才依赖</strong>。</p><p>做法：</p><ol><li><p><strong>使用反射创建对象，避免使用new关键字</strong>。二者之间的区别是，一个依赖于具体类，一个依赖于一个字符串，</p><p>在jdbc注册驱动的时候，换一种方式：</p><pre><code class="java">Class.forName(&quot;com.mysql.jdbc.Driver&quot;);</code></pre></li><li><p><strong>通过读取配置文件来获取要创建的对象全限定类名</strong></p><p>但是上面的方式依然是使用一个固定的字符串来注册驱动，因此可以通过读取配置文件来获取要创建的对象全限定类名。</p></li></ol><p>下面将通过这个项目来进行模拟实际项目中的各个环节</p><img src="/2020/02/13/13-Spring/1_%E7%A8%8B%E5%BA%8F%E8%80%A6%E5%90%88%E4%B8%8E%E8%A7%A3%E8%80%A6/image-20200213131832265.png" alt="image-20200213131832265" style="zoom:80%;"><h2 id="1-2-模拟持久层接入访问"><a href="#1-2-模拟持久层接入访问" class="headerlink" title="1.2 模拟持久层接入访问"></a>1.2 模拟持久层接入访问</h2><p>在图中的第1部分，AccountDao负责模拟持久层的访问，其中AccountDaoImpl中实现了Dao接口中saveAccount方法</p><pre><code class="java">public class AccountDaoImpl implements AccountDao {    // 模拟持久层服务    @Override    public void saveAccount() {        System.out.println(&quot;保存了账户&quot;);    }}</code></pre><p>第2部分中的是服务调用持久层，在AccountServiceImpl中实现AccountService接口的saveAccount方法</p><pre><code class="java">public class AccountServiceImpl implements AccountService {    private AccountDao accountDao = new AccountDaoImpl();    @Override    public void saveAccount() {        accountDao.saveAccount();    }}</code></pre><h2 id="1-3-模拟客户端访问服务"><a href="#1-3-模拟客户端访问服务" class="headerlink" title="1.3 模拟客户端访问服务"></a>1.3 模拟客户端访问服务</h2><p>与前面的类似，在第3部分就是表现层调用服务，在Client中调用AccountService接口的saveAccount方法</p><pre><code class="java">public class client {    // 实际开发中这里是一个servlet    public static void main(String[] args) {        AccountService as = new AccountServiceImpl();        as.saveAccount();    }}</code></pre><h2 id="1-4-通过工厂创建对象"><a href="#1-4-通过工厂创建对象" class="headerlink" title="1.4 通过工厂创建对象"></a>1.4 通过工厂创建对象</h2><ul><li>Bean：在计算机中可以表示：可重用组件。</li><li>JavaBean：用java语言编写的可重用组件，他可以用于创建service和dao对象（即服务和持久层接入对象）</li></ul><h3 id="1-4-1-从配置文件读取配置"><a href="#1-4-1-从配置文件读取配置" class="headerlink" title="1.4.1 从配置文件读取配置"></a>1.4.1 从配置文件读取配置</h3><p>在项目图的第5项，也就是resources文件夹下的bean.properties文件，这个文件存储着相应的配置信息，也就是将创建一个类所需要依赖的字符串放到配置文件中，最大限度地降低程序间的耦合关系</p><pre><code class="properties">accountService=com.xiong.service.impl.AccountServiceImplaccountDao=com.xiong.dao.Impl.AccountDaoImpl</code></pre><p>要项目图中的第4部分，也就是BeanFactory，在其中定义Properties类的对象，从该配置文件中获取各项配置。</p><pre><code class="java">public class BeanFactory {    private static Properties props;    // 定义一个Map，用于存放我们要创建的对象，称之为容器    private static Map&lt;String, Object&gt; beans;    // 使用静态代码块为Properities对象赋值    static {        // 实例化对象        props = new Properties();        String path = &quot;bean.properties&quot;;        // 获取properties文件的流对象        InputStream in = BeanFactory.class.getClassLoader().getResourceAsStream(path);        try {            props.load(in);            // 实例化容器            beans = new HashMap&lt;String, Object&gt;();            Enumeration&lt;Object&gt; keys = props.keys();            // 遍历枚举            while(keys.hasMoreElements()) {                // 取出每个key                String key = keys.nextElement().toString();                // 根据key获取value                String beanPath = props.getProperty(key);                // 反射创建对象                Object value = Class.forName(beanPath).newInstance();                // 把key和value存入容器                beans.put(key, value);            }        } catch (Exception e) {            throw new ExceptionInInitializerError(&quot;初始化properties失败&quot;);        }    }}</code></pre><h3 id="1-4-2-实现javaBean"><a href="#1-4-2-实现javaBean" class="headerlink" title="1.4.2 实现javaBean"></a>1.4.2 实现javaBean</h3><p>有了BeanFactory之后，就可以使用工厂来创建对象了，此时可以在客户端调用服务、服务调用持久层访问的时候将对象生成方式由new改为BeanFactory的方式了！</p><pre><code class="java">public class AccountServiceImpl implements AccountService {    private AccountDao accountDao = (AccountDao) BeanFactory.getBean(&quot;accountDao&quot;);    @Override    public void saveAccount() {        accountDao.saveAccount();    }}public class client {    public static void main(String[] args) {        AccountService as = (AccountService) BeanFactory.getBean(&quot;accountService&quot;);        as.saveAccount();    }}</code></pre><h2 id="1-5-创建对象的方式"><a href="#1-5-创建对象的方式" class="headerlink" title="1.5 创建对象的方式"></a>1.5 创建对象的方式</h2><p>从上面一步步解耦的过程中可以看出创建对象有两种方式：</p><ul><li>通过new创建</li><li>通过工厂模式创建</li></ul><p>其中，通过工厂模式创建，可以将创建工程的任务从APP自身转交给工厂，从而实现了解耦。</p><h3 id="1-5-1-使用new创建对象"><a href="#1-5-1-使用new创建对象" class="headerlink" title="1.5.1 使用new创建对象"></a>1.5.1 使用new创建对象</h3><p>使用这种方式创建对象，实质上是APP直接申请资源，关系可以用下图来表示</p><img src="/2020/02/13/13-Spring/1_%E7%A8%8B%E5%BA%8F%E8%80%A6%E5%90%88%E4%B8%8E%E8%A7%A3%E8%80%A6/image-20200213161638250.png" alt="image-20200213161638250" style="zoom:80%;"><pre><code class="java">AccountService as = new AccountServiceImpl();</code></pre><h3 id="1-5-2-用工厂模式创建对象"><a href="#1-5-2-用工厂模式创建对象" class="headerlink" title="1.5.2 用工厂模式创建对象"></a>1.5.2 用工厂模式创建对象</h3><p>通过工厂模式来创建对象，就把申请资源的任务从APP转移给了工厂，如下图所示</p><img src="/2020/02/13/13-Spring/1_%E7%A8%8B%E5%BA%8F%E8%80%A6%E5%90%88%E4%B8%8E%E8%A7%A3%E8%80%A6/image-20200213161800832.png" alt="image-20200213161800832" style="zoom:80%;"><pre><code class="java">AccountService as = (AccountService) BeanFactory.getBean(&quot;accountService&quot;);</code></pre>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Mybatis实战5】注解开发</title>
      <link href="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/"/>
      <url>/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="注解开发"><a href="#注解开发" class="headerlink" title="注解开发"></a>注解开发</h1><h2 id="1-环境搭建"><a href="#1-环境搭建" class="headerlink" title="1. 环境搭建"></a>1. 环境搭建</h2><p>首先创建一个mysql的配置文件，之前从mysql中读取配置都是通过直接在里面写死实现的，后面开发的过程中可以将这些配置信息写到一个properties文件中，以便于修改后不需要重新编译。</p><pre><code class="properties">jdbc.driver=com.mysql.cj.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/db1?useUnicode=true&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTCjdbc.username=rootjdbc.password=</code></pre><blockquote><p>要注意的是，之前写在xml文件中的符号 <code>&amp;</code> 由于识别不出来，所以要写成 <code>&amp;amp;</code> 但是在这里写到properties文件中的话是可以识别出来的，因此要把之前的 <code>&amp;amp;</code> 全部换成 <code>&amp;</code> 。</p></blockquote><p>然后，主配置文件中，将从这个properties文件中读取相应的参数完成mysql的配置，其中的各项都比较清晰，引入一个外部properties配置文件，并且从这个配置文件中读取相应的参数，然后就是设置别名的部分，就是从指定的包位置找到别名设置，以后再用的时候就不需要写全称了。</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;!--引入外部配置文件--&gt;    &lt;properties resource=&quot;jdbcConfig.properties&quot;/&gt;    &lt;!--配置别名--&gt;    &lt;typeAliases&gt;        &lt;package name=&quot;com.xiong.domain&quot;/&gt;    &lt;/typeAliases&gt;    &lt;!--配置环境--&gt;    &lt;environments default=&quot;mysql&quot;&gt;        &lt;environment id=&quot;mysql&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;${jdbc.driver}&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;${jdbc.username}&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;!-- 引入指定带有注解的dao接口所在位置 --&gt;    &lt;mappers&gt;        &lt;!--表示dao接口的位置--&gt;        &lt;package name=&quot;com.xiong.dao&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;</code></pre><h2 id="2-单表CRUD（代理Dao）"><a href="#2-单表CRUD（代理Dao）" class="headerlink" title="2. 单表CRUD（代理Dao）"></a>2. 单表CRUD（代理Dao）</h2><p>在mybatis中，CRUD一共有4个注解，分别为：</p><ul><li><code>@Select</code></li><li><code>@Insert</code></li><li><code>@Update</code></li><li><code>@Delete</code></li></ul><p>只需要在接口文件中将注解写在接口上，然后把SQL语句作为注解的参数，就可以了</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200206222533214.png" alt="image-20200206222533214" style="zoom:80%;"><p>测试的java方法为：</p><pre><code class="java">public static void main(String[] args) throws IOException {    // 1. 获取字节输入流    InputStream in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;);    // 2. 根据字节输入流构建SqlSessionFactory    SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(in);    // 3. 根据SqlSessionFactory生产一个SqlSession    SqlSession session = factory.openSession();    // 4. 使用SqlSession获取Dao的代理对象    StudentDao studentDao = session.getMapper(StudentDao.class);    // 5. 执行Dao的方法    List&lt;Student&gt; students = studentDao.findAll();    for (Student student : students) {        System.out.println(student);    }    // 6. 释放资源    session.close();    in.close();}</code></pre><p>运行结果就是下面这样，将整个表查出来了：</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200206222450747.png" alt="image-20200206222450747" style="zoom:80%;"><p>至于其他的操作，在StudentDao接口中，注解写成下面这样：</p><pre><code class="java">@Select(&quot;select * from student&quot;)List&lt;Student&gt; findAll();@Insert(&quot;insert into student(name, address) values(#{name}, #{address})&quot;)void saveUser(Student student);@Update(&quot;update student set name=#{name}, address=#{address} where id=#{id}&quot;)void update(Student student);@Delete(&quot;delete from student where id=#{id}&quot;)void delete(Integer id);// 根据ID查询用户@Select(&quot;select * from student where id=#{userId}&quot;)Student findById(Integer userId);// @Select(&quot;select * from student where name like #{name}&quot;)@Select(&quot;select * from student where name like &#39;%${value}%&#39;&quot;)List&lt;Student&gt; findStudentByName(String name);@Select(&quot;select count(*) from student&quot;)int findStudentCount();</code></pre><p>测试类：</p><pre><code class="java">public class InnotationTest {    private InputStream in;    private SqlSessionFactory factory;    private SqlSession session;    private StudentDao studentDao;    @Before    public void init() throws IOException {        in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;);        factory = new SqlSessionFactoryBuilder().build(in);        session = factory.openSession();        studentDao = session.getMapper(StudentDao.class);    }    @After    public void destroy() throws IOException {        session.commit();        session.close();        in.close();    }    @Test    public void testSave() {        Student student = new Student();        student.setName(&quot;Annotation&quot;);        student.setAddress(&quot;北京&quot;);        studentDao.saveUser(student);    }    @Test    public void testUpdate() {        Student student = new Student();        student.setId(11);        student.setName(&quot;唱跳rap篮球&quot;);        student.setAddress(&quot;北京&quot;);        studentDao.update(student);    }    @Test    public void testDelete() {        studentDao.delete(12);    }    @Test    public void testFindById() {        Student student = studentDao.findById(3);        System.out.println(student);    }    @Test    public void testFindByName() {        List&lt;Student&gt; students = studentDao.findStudentByName(&quot;马&quot;);        for (Student student : students)            System.out.println(student);    }    @Test    public void testFindTotal() {        System.out.println(studentDao.findStudentCount());    }}</code></pre><p>如果实体类的属性名与数据库表的列名不同，则需要使用 <code>@Results</code> 注解来解决。</p><p>例如，如果将属性名称前面统一都加上user，则需要在注解里面增加配置才可以。</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207141020025.png" alt="image-20200207141020025" style="zoom:80%;"><p>则在接口中添加注解的时候要改为下面这样：</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207141300777.png" alt="image-20200207141300777" style="zoom:80%;"><p>才可以正常封装返回结果。注意，其中的id属性的id属性需要设置为true，其他部分由于默认值为false不需要手动设定。</p><p>但是，如果想要复用这些映射关系，则不需要每次使用都重新将这部分内容写一遍，而是可以通过记录并使用的方式来设定，在其他地方如果想要使用这个映射关系，则需要通过在自己的注解下面也添加上 <code>@ResultMap</code> 来实现（其中，如果只有一个参数，<code>value={}</code>也是可以删掉的，只留下一个字符串）。</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207141816504.png" alt="image-20200207141816504" style="zoom:80%;"><h2 id="3-多表查询操作"><a href="#3-多表查询操作" class="headerlink" title="3. 多表查询操作"></a>3. 多表查询操作</h2><h3 id="3-1-一对一"><a href="#3-1-一对一" class="headerlink" title="3.1 一对一"></a>3.1 一对一</h3><p>准备一个新的数据类Account，在其中添加account表中的三个属性，以及其对应的Student对象。为其设置getter和setter方法</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207152058122.png" alt="image-20200207152058122" style="zoom:80%;"><p>这时，需要在查询account表的时候顺带把student信息也查询出来，则注解应该这样写：</p><pre><code class="java">@Select(&quot;select * from account&quot;)@Results(id=&quot;accountMap&quot;, value = {    @Result(id=true, column = &quot;id&quot;, property = &quot;id&quot;),    @Result(column = &quot;uid&quot;, property = &quot;uid&quot;),    @Result(column = &quot;money&quot;, property = &quot;money&quot;),    // 表示通过uid查找student表，指向com.xiong.dao.StudentDao.findById    @Result(column = &quot;uid&quot;,             property = &quot;student&quot;,             one=@One(                select = &quot;com.xiong.dao.StudentDao.findById&quot;,                 fetchType= FetchType.EAGER))})List&lt;Account&gt; findAll();</code></pre><p>注意，在表示student对象的结果的时候，需要使用一个one的参数，该参数使用注解 <code>@One</code>，并且此注解中也有两个参数，即其调用的方法注解以及加载机制（立即加载或者延迟加载）。</p><h3 id="3-2-一对多"><a href="#3-2-一对多" class="headerlink" title="3.2 一对多"></a>3.2 一对多</h3><p>与一对一类似，这里的一对多是通过在Student类中增加一个List的Account对象来实现的。</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207152608430.png" alt="image-20200207152608430" style="zoom:80%;"><p>同样，将相关的方法注解写成下面这样：</p><pre><code class="java">@Select(&quot;select * from student&quot;)@Results(id=&quot;userMap&quot;, value = {    @Result(id=true, column = &quot;id&quot;, property = &quot;id&quot;),    @Result(column = &quot;name&quot;, property = &quot;name&quot;),    @Result(column = &quot;age&quot;, property = &quot;age&quot;),    @Result(column = &quot;sex&quot;, property = &quot;sex&quot;),    @Result(column = &quot;address&quot;, property = &quot;address&quot;),    @Result(column = &quot;math&quot;, property = &quot;math&quot;),    @Result(column = &quot;english&quot;, property = &quot;english&quot;),    @Result(column = &quot;id&quot;,             property = &quot;accounts&quot;,             many = @Many(                select = &quot;com.xiong.dao.AccountDao.findAccountByUid&quot;,                 fetchType = FetchType.LAZY))})List&lt;Student&gt; findAll();</code></pre><p>注意，其中的many就表示的是一对多的“多”关系，它通过column=”id”这个属性作为参数来执行操作的参数，<code>@many</code> 注解中的select表示执行方法的全限定类名，fetchType就是加载方式，即延迟加载或者立即加载。</p><p>运行结果如下，是正确的。</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207153559240.png" alt="image-20200207153559240" style="zoom:80%;"><h2 id="4-缓存的配置"><a href="#4-缓存的配置" class="headerlink" title="4. 缓存的配置"></a>4. 缓存的配置</h2><p><strong>一级缓存</strong>：自动开启的，不需要过多关注</p><pre><code class="java">@Testpublic void testFindAccount() {    List&lt;Account&gt; accounts = accountDao.findAll();    List&lt;Account&gt; accounts1 = accountDao.findAll();    System.out.println(accounts==accounts1);}</code></pre><p>返回结果为true。</p><p><strong>二级缓存</strong></p><p>在配置文件中配置二级缓存（不过这个二级缓存默认是开启的）</p><pre><code class="xml">&lt;settings&gt;    &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;&lt;/settings&gt;</code></pre><p>并且在对应的接口前面添加一个注解，表示使用二级缓存</p><pre><code class="java">@CacheNamespace(blocking = true)</code></pre><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207160008500.png" alt="image-20200207160008500" style="zoom:80%;"><p>然后，测试下面的这个方法</p><pre><code class="java">public static void main(String[] args) throws IOException {    // 1. 获取字节输入流    InputStream in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;);    // 2. 根据字节输入流构建SqlSessionFactory    SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(in);    // 3. 根据SqlSessionFactory生产一个SqlSession    SqlSession session = factory.openSession();    // 4. 使用SqlSession获取Dao的代理对象    StudentDao studentDao = session.getMapper(StudentDao.class);    // 5. 执行Dao的方法    Student students = studentDao.findById(3);    session.close();    System.out.println(&quot;--第一次查询执行完毕--&quot;);    SqlSession session1 = factory.openSession();    StudentDao studentDao1 = session1.getMapper(StudentDao.class);    Student students1 = studentDao1.findById(3);    System.out.println(&quot;--第二次查询执行完毕--&quot;);    // 6. 释放资源    session1.close();    in.close();}</code></pre><p>可以从返回结果中看到只执行了一次查询操作</p><img src="/2020/02/07/mybatis/10_%E6%B3%A8%E8%A7%A3%E5%BC%80%E5%8F%91/image-20200207160030757.png" alt="image-20200207160030757" style="zoom:80%;">]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> MyBatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Mybatis实战4】加载与缓存</title>
      <link href="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/"/>
      <url>/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="延迟加载与立即加载"><a href="#延迟加载与立即加载" class="headerlink" title="延迟加载与立即加载"></a>延迟加载与立即加载</h1><p>问题：在一对多中，假设当一个用户有100个账户。</p><ul><li>在查询用户的时候要不要把关联的账户查出来？</li><li>在查询账户的时候要不要把关联的用户查出来？</li></ul><p>如果直接查出来但是不用，则会造成空间浪费，但是如果要用的时候没有查出来，则是不能使用的。因此需要在使用的时候再进行查询，而不是一次性全部都查出来。</p><ul><li><strong>延迟加载</strong>：在真正使用数据的时候才发起查询，不用的时候不查询，也就是按需加载</li><li><strong>立即加载</strong>：不管用不用，只要一调用方法，就立即发起查询</li></ul><p>四种对应的四种表关系：一对多、多对一、一对一、多对多，可以根据关联的对象多少，将这四种关系分成两组：</p><ul><li><strong>一对多、多对多</strong>：对的是多，也就是需要加载的东西比较多，通常采用延迟加载</li><li><strong>多对一、一对一</strong>：对的是一，也就是需要加载的东西不多，通常采用立即加载</li></ul><h2 id="1-单表查询延迟加载"><a href="#1-单表查询延迟加载" class="headerlink" title="1. 单表查询延迟加载"></a>1. 单表查询延迟加载</h2><p>先测试Account的单表测试：之前在一对一的映射过程中，association标签中配置的是将查询结果封装到Student对象中的一个对应映射关系。在这里因为需要延迟加载，所以需要将它换成另外一条select语句，也就是用到的时候才进行加载。在association的配置中有两个配置需要详细解释一下：</p><ul><li>select中指定的内容：查询用户的唯一标志</li><li>column中指定的内容：用户根据id查询时，所需要的参数的值，也就是findById中的id</li></ul><pre><code class="xml">&lt;!--    定义封装account和student的resultmap--&gt;&lt;resultMap id=&quot;accountStudentMap&quot; type=&quot;com.xiong.domain.Account&quot;&gt;    &lt;!-- 保证account对象封装成功 --&gt;    &lt;id property=&quot;aid&quot; column=&quot;id&quot;&gt;&lt;/id&gt;    &lt;result property=&quot;uid&quot; column=&quot;uid&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;money&quot; column=&quot;money&quot;&gt;&lt;/result&gt;    &lt;!-- 一对一的关系映射，也就是配置封装Student的内容         select中指定的内容：查询用户的唯一标志         column中指定的内容：用户根据id查询时，所需要的参数的值，也就是findById中的id--&gt;    &lt;association property=&quot;student&quot;                 column=&quot;uid&quot;                 javaType=&quot;com.xiong.domain.Student&quot;                 select=&quot;com.xiong.dao.StudentDao.findByID&quot;&gt;    &lt;/association&gt;&lt;/resultMap&gt;</code></pre><p>查询的时候就用一个简单的单表查询来测试：</p><pre><code class="xml">&lt;select id=&quot;findAll&quot; resultMap=&quot;accountStudentMap&quot;&gt;    select * from account;&lt;/select&gt;</code></pre><p>测试的java方法为：</p><pre><code class="java">@Testpublic void testFindAll() {    List&lt;Account&gt; accounts = accountDao.findAll();    for (Account account : accounts) {        System.out.println(account);        // 打印出从类中包含的主类相对应的student信息        // 实现了：查询账户，并获取账户对应的用户信息（用户就是Student类的对象）        System.out.println(account.getStudent());    }}</code></pre><p>从下面的执行结果中可以看出，并没有发生延迟加载，因为在一个SQL语句中就直接把这三条子查询都执行了。</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206192557060.png" alt="image-20200206192557060" style="zoom:80%;"><p>可以在mybatis的文档中看到setting中的两个标签</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206193240533.png" alt="image-20200206193240533" style="zoom:80%;"><p>因此需要显式将这个属性给打开，才能实现延迟加载，因此在映射配置文件中进行配置，添加以下内容：</p><pre><code class="xml">&lt;settings&gt;    &lt;!--延迟加载的配置，开启mybatis支持延迟加载--&gt;    &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;    &lt;!--允许触发方法进行立即加载，否则按需加载--&gt;    &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt;&lt;/settings&gt;</code></pre><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206193757089.png" alt="image-20200206193757089" style="zoom:80%;"><p>再次测试可以发现已经执行了延迟加载，也就是用到Student信息的时候才执行查询、</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206193838741.png" alt="image-20200206193838741" style="zoom:80%;"><h2 id="2-一对多查询延迟加载"><a href="#2-一对多查询延迟加载" class="headerlink" title="2. 一对多查询延迟加载"></a>2. 一对多查询延迟加载</h2><p>将StudentDao的xml配置文件的resultMap进行修改，主要也就是修改collection标签，增加select字段，这个select实际上就是AccountDao中findAccountByUid的查询：</p><pre><code class="xml">&lt;resultMap id=&quot;studentAccountMap&quot; type=&quot;com.xiong.domain.Student&quot;&gt;    &lt;id property=&quot;id&quot; column=&quot;id&quot;&gt;&lt;/id&gt;    &lt;result property=&quot;name&quot; column=&quot;name&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;sex&quot; column=&quot;sex&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;address&quot; column=&quot;address&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;math&quot; column=&quot;math&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;english&quot; column=&quot;english&quot;&gt;&lt;/result&gt;    &lt;!--配置accounts集合的映射，其中column是数据库中的列名，property是字段的名称--&gt;    &lt;collection property=&quot;accounts&quot;                ofType=&quot;com.xiong.domain.Account&quot;                select=&quot;com.xiong.dao.AccountDao.findAccountByUid&quot;                column=&quot;id&quot;&gt;    &lt;/collection&gt;&lt;/resultMap&gt;</code></pre><p>还是测试findAll，此时的xml配置写成下面的形式：</p><pre><code class="xml">&lt;select id=&quot;findAll&quot; resultMap=&quot;studentAccountMap&quot;&gt;    &lt;!--使用左外连接，返回左表的所有信息--&gt;    select * from student&lt;/select&gt;</code></pre><p>调用的测试类写为下面：</p><pre><code class="java">@Testpublic void testFindAll() {    // 执行查找所有方法    List&lt;Student&gt; students = studentDao.findAll();    for (Student student : students) {        System.out.println(student);        System.out.println(student.getAccounts());    }}</code></pre><p>最终的结果可以看出就是使用了延迟加载</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206195359858.png" alt="image-20200206195359858" style="zoom:80%;"><p>其实单表查询和一对多的查询，<strong>本质上都是在用的时候调用对方配置文件中的一个配置实现查询功能</strong></p><h1 id="mybatis的缓存"><a href="#mybatis的缓存" class="headerlink" title="mybatis的缓存"></a>mybatis的缓存</h1><h2 id="1-什么是缓存"><a href="#1-什么是缓存" class="headerlink" title="1. 什么是缓存"></a>1. 什么是缓存</h2><p>存在于内存中的临时数据，在下次使用的时候不再去数据库查询，加快查询速度。</p><h2 id="2-为什么使用缓存"><a href="#2-为什么使用缓存" class="headerlink" title="2. 为什么使用缓存"></a>2. 为什么使用缓存</h2><p>减少与数据库的交互次数，提高执行效率。</p><h2 id="3-缓存使用的条件"><a href="#3-缓存使用的条件" class="headerlink" title="3. 缓存使用的条件"></a>3. 缓存使用的条件</h2><p>适用于缓存的数据：</p><ul><li>经常被查询不经常被改变</li><li>数据的正确与否对最终的结果影响不大</li></ul><p>不适用于缓存的数据：</p><ul><li>经常改变的数据</li><li>数据的正确与否对最终结果影响很大，例如商品的库存、银行的汇率等。</li></ul><h2 id="4-mybatis中的一级缓存"><a href="#4-mybatis中的一级缓存" class="headerlink" title="4. mybatis中的一级缓存"></a>4. mybatis中的一级缓存</h2><p>一级缓存：指的是mybatis中SqlSession对象的缓存，当执行查询之后，查询的结果会同时存入到SqlSession提供的一块区域中，该区域的结构是一个map。再次查询同样的数据时，mybatis会先去SqlSession中查看是否还有，如果有，就直接返回。当SqlSession对象消失的时候mybatis的一级缓存就消失了。</p><p>测试一下一级缓存，就用最简单的mybatis查询就可以了，将前面的全部删掉，整个项目框架只留下这样：</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206201310346.png" alt="image-20200206201310346" style="zoom:80%;"><p>在StudentDao的xml中只留下最朴素的通过id查找Student</p><pre><code class="xml">&lt;select id=&quot;findByID&quot; parameterType=&quot;int&quot; resultType=&quot;com.xiong.domain.Student&quot;&gt;    select * from student where id=#{i};&lt;/select&gt;</code></pre><p>然后在测试方法中连续调用两次，看两次执行得到的对象是否是同一个</p><pre><code class="java">@Testpublic void testFirstLevelCache() {    Student stu = studentDao.findByID(3);    System.out.println(stu);    Student stu1 = studentDao.findByID(3);    System.out.println(stu1);    System.out.println(stu == stu1);}</code></pre><p>最终的输出结果为：</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206201507627.png" alt="image-20200206201507627" style="zoom:80%;"><p>也就是说明了，一级缓存生效，也就是说，stu和stu1是同一个对象，而且从debug信息可以看出，只执行了一次SQL查询。但是如果SqlSession关闭，则缓存就消失了。</p><p>当然，如果将测试方法换成下面这样，也就是说查询完一次之后将sqlSession重新生成，则运行结果就不同了。</p><pre><code class="java">@Testpublic void testFirstLevelCache() {    Student stu = studentDao.findByID(3);    System.out.println(stu);    sqlSession.close();    // 重新获取SqlSession的对象    sqlSession = factory.openSession();    studentDao = sqlSession.getMapper(StudentDao.class);    Student stu1 = studentDao.findByID(3);    System.out.println(stu1);    System.out.println(stu == stu1);}</code></pre><p>运行结果如下，可以看出执行了两次SQL操作，并且两个得到的对象是不同的。</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206201808499.png" alt="image-20200206201808499" style="zoom:80%;"><p>除了通过重新生成一个sqlSession之外，还可以通过clearCache方法来清空缓存，即：</p><pre><code class="java">@Testpublic void testFirstLevelCache() {    Student stu = studentDao.findByID(3);    System.out.println(stu);    sqlSession.clearCache();    Student stu1 = studentDao.findByID(3);    System.out.println(stu1);    System.out.println(stu == stu1);}</code></pre><p>从结果可以看出，也是用了两次SQL查询，虽然并没有重新生成sqlSession对象</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206202124350.png" alt="image-20200206202124350" style="zoom:80%;"><p>如果数据库中的数据与一级缓存中的内容不同步了，那么是如何实现数据同步的呢？</p><p>可以测试一下，获取完数据，再对数据库执行一次update操作，然后看看效果。</p><p>在StudentDao中添加接口，并且在xml文件中添加SQL查询，这里就不写了，比较简单。然后将测试方法修改为下面这样：</p><pre><code class="java">@Testpublic void testClearCache() {    Student stu = studentDao.findByID(10);    System.out.println(stu);    stu.setAddress(&quot;在家啊&quot;);    stu.setName(&quot;更新&quot;);    studentDao.update(stu);    Student stu1 = studentDao.findByID(10);    System.out.println(stu1);    System.out.println(stu == stu1);}</code></pre><p>运行结果如下：发现没有从缓存中读取数据</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206203344507.png" alt="image-20200206203344507" style="zoom:80%;"><p><strong>分析：因为一级缓存是SqlSession范围的缓存，当调用SqlSession的修改、添加、删除、commit()、close()方法的时候，会清空一级缓存。</strong>也就是下面这个操作流程：</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206203610413.png" alt="image-20200206203610413" style="zoom: 67%;"><h2 id="5-mybatis中的二级缓存"><a href="#5-mybatis中的二级缓存" class="headerlink" title="5. mybatis中的二级缓存"></a>5. mybatis中的二级缓存</h2><p>指的是mybatis中SqlSessionFactory对象的缓存，由同一个SqlSessionFactory对象创建的SqlSession共享其缓存。</p><p>下面主要通过修改test方法来查看其区别：</p><pre><code class="java">public class SecondLevelCacheTest {    private InputStream in;    private SqlSessionFactory factory;    @Before // 这个注解表示在执行测试方法之前执行    public void init() throws IOException {        // 读取配置文件，生成输入字节流        in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;);        // 获取SqlSessionFactory对象        factory = new SqlSessionFactoryBuilder().build(in);    }    @After // 这个注解表示在执行完测试方法之后执行    public void destroy() throws IOException {        // 因为没有提交事务，所以会rolling back，因此需要在这里进行提交        in.close();    }    /*     * 测试缓存的同步     * */    @Test    public void testClearCache() {        SqlSession sqlSession1 = factory.openSession();        StudentDao studentDao1 = sqlSession1.getMapper(StudentDao.class);        Student stu = studentDao1.findByID(10);        System.out.println(stu);        sqlSession1.close(); // 此时一级缓存消失        SqlSession sqlSession2 = factory.openSession();        StudentDao studentDao2 = sqlSession2.getMapper(StudentDao.class);        Student stu2 = studentDao2.findByID(10);        System.out.println(stu2);        sqlSession2.close();        System.out.println(stu == stu2);    }}</code></pre><p>运行结果如下，发现并没有利用到缓存的意思，仍然是通过两次不同的查询。</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206204342778.png" alt="image-20200206204342778" style="zoom:80%;"><p>所以要使用二级缓存的步骤是：</p><ol><li><p>让mybatis框架支持二级缓存，需要在主配置文件SqlMapConfig.xml中进行配置</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206204646299.png" alt="image-20200206204646299" style="zoom:80%;"></li><li><p>让当前的映射文件支持二级缓存，需要在StudentDao.xml文件中进行配置</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206204739506.png" alt="image-20200206204739506" style="zoom:80%;"></li><li><p>让当前的操作支持二级缓存，也就是在select标签中配置</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206204801455.png" alt="image-20200206204801455" style="zoom:80%;"></li></ol><p>此时再来执行原来的方法，结果就变成下面这样，也就是只执行了一次查询</p><img src="/2020/02/06/mybatis/9_%E7%BC%93%E5%AD%98/image-20200206204840725.png" alt="image-20200206204840725" style="zoom:80%;"><p>但是最后返回得到的两个student对象是不同的，即返回了false。原因是，<strong>二级缓存中存放的是数据而不是对象</strong>。新来一个新的查询，就把这个缓存内容通过数据填充到新的对象中，从而实现了缓存。</p><p>因此在使用二级缓存时，<strong>所缓存的类一定要实现 java.io.Serializable 接口，这种就可以使用序列化方式来保存对象</strong>。  </p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> MyBatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Mybatis实战3】动态SQL与多表操作</title>
      <link href="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="基于xml配置的动态SQL语句使用"><a href="#基于xml配置的动态SQL语句使用" class="headerlink" title="基于xml配置的动态SQL语句使用"></a>基于xml配置的动态SQL语句使用</h1><p>mappers配置文件中的几个标签</p><h2 id="1-if"><a href="#1-if" class="headerlink" title="1. if"></a>1. if</h2><p>使用动态SQL语句的基础就是在xml语句里面使用相对应的标签，根据标签表示的逻辑关系对应拼接成相应的SQL语句。</p><p>例如下面这个条件查询，就是在xml判断传进来的Student对象中的name字段不为空，才在SQL语句后面拼接上查询name的语句。<strong>（注意，这里的1=1是一条永久为真的语句，并没有什么意义，但是可以避免where后面什么都不加导致语法错误）</strong></p><pre><code class="xml">&lt;!--    条件查询--&gt;&lt;select id=&quot;findStudentByCondition&quot; parameterType=&quot;com.xiong.domain.Student&quot; resultType=&quot;com.xiong.domain.Student&quot;&gt;    select * from student where 1=1    &lt;if test=&quot;name != null&quot;&gt;        &lt;!-- 注意，这里如果不是第一条，需要加上and --&gt;        and name = #{name}    &lt;/if&gt;    &lt;if test=&quot;sex != null&quot;&gt;        &lt;!-- 注意，这里如果不是第一条，需要加上and --&gt;        and sex = #{sex}    &lt;/if&gt;&lt;/select&gt;</code></pre><p>StudentDao接口</p><pre><code class="java">/* * 根据传入的参数条件查询 * student是查询的条件，有可能有某些条件，有可能什么都没有* */List&lt;Student&gt; findStudentByCondition(Student student);</code></pre><p>test类</p><pre><code class="java">@Testpublic void testCondition() {    Student student = new Student();    student.setName(&quot;蔡徐坤&quot;);    List&lt;Student&gt; students = studentDao.findStudentByCondition(student);    for (Student student1 : students) {        System.out.println(student1);    }}</code></pre><p>运行结果为：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200205223547697.png" alt="image-20200205223547697" style="zoom:80%;"><h2 id="2-where"><a href="#2-where" class="headerlink" title="2. where"></a>2. where</h2><p>上面可以看到，有两个if语句，可以使用where标签来把SQL语句中的where 1=1给去掉，也就是这样：</p><pre><code class="xml">&lt;!--    条件查询--&gt;&lt;select id=&quot;findStudentByCondition&quot; parameterType=&quot;com.xiong.domain.Student&quot; resultType=&quot;com.xiong.domain.Student&quot;&gt;    select * from student    &lt;where&gt;        &lt;if test=&quot;name != null&quot;&gt;            name = #{name}        &lt;/if&gt;        &lt;if test=&quot;sex != null&quot;&gt;            &lt;!-- 注意，这里如果不是第一条，需要加上and --&gt;            and sex = #{sex}        &lt;/if&gt;    &lt;/where&gt;&lt;/select&gt;</code></pre><p>接口类和调用方法均不变，结果是一样的。</p><h2 id="3-foreach"><a href="#3-foreach" class="headerlink" title="3. foreach"></a>3. foreach</h2><p>需要通过QueryVo来实现，首先在QueryVo中添加一个Ids的方法和相应的getter、setter方法</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200205225659964.png" alt="image-20200205225659964" style="zoom:80%;"><p>xml文件：通过where标签和if标签生成动态的SQL语句</p><pre><code class="xml">&lt;!-- 根据QueryVo中的Id集合实现查询用户列表 --&gt;&lt;select id=&quot;findStudentInIds&quot;         parameterType=&quot;com.xiong.domain.QueryVo&quot;         resultType=&quot;com.xiong.domain.Student&quot;&gt;    select * from student    &lt;where&gt;        &lt;if test=&quot;ids != null and ids.size() &gt; 0&quot;&gt;            &lt;!-- collection表示一个集合，                open表示开始之前加上的内容，                close表示结束的时候加上的内容，                item表示，                separator表示分隔符 --&gt;            &lt;foreach collection=&quot;ids&quot; open=&quot;and id in (&quot; close=&quot;)&quot; item=&quot;id&quot; separator=&quot;,&quot;&gt;                #{id}            &lt;/foreach&gt;        &lt;/if&gt;    &lt;/where&gt;&lt;/select&gt;</code></pre><p>StudentDao接口中添加一个方法</p><pre><code class="java">/* * 根据vo中的id集合查询用户信息* */List&lt;Student&gt; findStudentInIds(QueryVo vo);</code></pre><p>在调用的时候只需要往这个接口中传入一个参数就可以了</p><pre><code class="java">/* * 测试条件查询，使用foreach标签* */@Testpublic void testFindInIds() {    QueryVo vo = new QueryVo();    List&lt;Integer&gt; list = new ArrayList&lt;&gt;();    list = Arrays.asList(1,2,3);    vo.setIds(list);    List&lt;Student&gt; students = studentDao.findStudentInIds(vo);    for (Student student1 : students) {        System.out.println(student1);    }}</code></pre><p>运行结果如下</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200205225342092.png" alt="image-20200205225342092" style="zoom:80%;"><h2 id="4-sql"><a href="#4-sql" class="headerlink" title="4. sql"></a>4. sql</h2><p>前面写了很多比如 <code>select * from student</code> 语句，可以<strong>通过sql标签来抽取重复的SQL语句</strong></p><pre><code class="xml">&lt;sql id=&quot;defaultStudent&quot;&gt;    select * from student&lt;/sql&gt;</code></pre><p>在使用的时候，只需要将其include进来就可以了，如下所示：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200205230344575.png" alt="image-20200205230344575" style="zoom:80%;"><p>经过测试，结果是正常的</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200205230404681.png" alt="image-20200205230404681" style="zoom:80%;"><h1 id="多表操作"><a href="#多表操作" class="headerlink" title="多表操作"></a>多表操作</h1><p>表的关系有以下几种：</p><ol><li><p><strong>一对多</strong></p><p>一个用户可以有多个订单，多个订单属于同一个用户，一对多同时也暗示着一个多对一。</p></li><li><p><strong>一对一</strong></p><p>一个人只能有一个身份证号，一个身份证号只能对应一个人。</p><p>一个特定的订单只能属于同一个用户，所以<strong>mybatis将多对一看作是一对一</strong>。</p></li><li><p><strong>多对多</strong></p><p>一个学生可以被多个老师教，一个老师可以教多个学生，老师和学生之间是多对多。</p></li></ol><p><strong>下面的一对一和一对多都是用这样的两个表来进行：用户表+账户表（即student表和account表）</strong></p><p>示例：用户与账户</p><ul><li>一个用户可以有多个账户</li><li>一个账户只能属于一个用户（多个账户可以属于同一个用户）</li></ul><p>步骤：</p><ol><li><p><strong>建立两张表</strong>：用户表、账户表</p><p>让用户表和账户表之间具备一对多的关系：需要使用外键在账户表中添加</p></li><li><p><strong>建立两个实体类</strong>：用户实体类和账户实体类</p><p>让用户和账户的实体类能体现出一对多的关系</p></li><li><p><strong>建立两个配置文件</strong>：用户的配置文件、账户的配置文件</p></li><li><p><strong>实现配置</strong>：</p><ul><li>查询用户时，可以同时得到用户下的所有账户信息</li><li>查询账户时，可以同时得到账户所属的用户信息</li></ul></li></ol><p>用户表使用student来表示，账户表使用account来表示</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206154456732.png" alt="image-20200206154456732" style="zoom:80%;"><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206154512421.png" alt="image-20200206154512421" style="zoom:80%;"><p>两个实体类中的Student类还是使用之前的实体类，account对应的实体类使用Account来表示，</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206154850656.png" alt="image-20200206154850656" style="zoom:80%;"><p>其中account表使用下面的SQL语句创建</p><pre><code class="mysql">DROP TABLE IF EXISTS `account`;CREATE TABLE `account` (  `ID` int(11) NOT NULL COMMENT &#39;编号&#39;,  `UID` int(11) default NULL COMMENT &#39;用户编号&#39;,  `MONEY` double default NULL COMMENT &#39;金额&#39;,  PRIMARY KEY  (`ID`),  KEY `FK_Reference_8` (`UID`),  CONSTRAINT `FK_Reference_8` FOREIGN KEY (`UID`) REFERENCES `student` (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert  into `account`(`ID`,`UID`,`MONEY`) values (1,1,1000),(2,2,1000),(3,3,2000);</code></pre><h2 id="1-一对一"><a href="#1-一对一" class="headerlink" title="1. 一对一"></a>1. 一对一</h2><h3 id="1-1-通过写Account的子类方式查询"><a href="#1-1-通过写Account的子类方式查询" class="headerlink" title="1.1 通过写Account的子类方式查询"></a>1.1 通过写Account的子类方式查询</h3><p>这种方法就是创建一个新的类，继承Account类，然后在这个类里面加上Student类中的属性或者student表中的一些或者全部属性，如下图所示。同时为其生成getter和setter方法。</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206160251683.png" alt="image-20200206160251683" style="zoom:80%;"><p>在查询的xml中只需要把resultType改一下，查询语句换一下就可以了</p><pre><code class="xml">&lt;select id=&quot;findAllAccount&quot; resultType=&quot;com.xiong.domain.StudentAccount&quot;&gt;    select a.*, s.name, s.address from account a, student s where s.id = a.uid;&lt;/select&gt;</code></pre><p>这就可以把account的所有属性以及student表中的name和address两个属性填充到结果中了。</p><p>调用的测试java方法为：</p><pre><code class="java">@Testpublic void testFindAccount() {    List&lt;StudentAccount&gt; studentAccounts = accountDao.findAllAccount();    for (StudentAccount account : studentAccounts) {        System.out.println(account);    }}</code></pre><p>运行结果如下：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206160436707.png" alt="image-20200206160436707" style="zoom:80%;"><h3 id="1-2-通过建立实体类关系的方式"><a href="#1-2-通过建立实体类关系的方式" class="headerlink" title="1.2 通过建立实体类关系的方式"></a>1.2 通过建立实体类关系的方式</h3><p>如果要通过这种方式来进行一对一查询，则需要在Account类中包含一个主表实体的对象student，并且设置相应的getter和setter方法来进行数据的获取与设置。</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206154702338.png" alt="image-20200206154702338" style="zoom:80%;"><p>查询完成后需要将数据封装成为Account类，因为Account类中又包含了另外一个Student类的对象，所以需要通过一个resultMap来进行结果的映射</p><pre><code class="xml">&lt;!--    定义封装account和student的resultmap--&gt;&lt;resultMap id=&quot;accountStudentMap&quot; type=&quot;com.xiong.domain.Account&quot;&gt;    &lt;!-- 保证account对象封装成功 --&gt;    &lt;id property=&quot;id&quot; column=&quot;aid&quot;&gt;&lt;/id&gt;    &lt;result property=&quot;uid&quot; column=&quot;uid&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;money&quot; column=&quot;money&quot;&gt;&lt;/result&gt;    &lt;!-- 一对一的关系映射，也就是配置封装Student的内容 --&gt;    &lt;association property=&quot;student&quot; column=&quot;uid&quot; javaType=&quot;com.xiong.domain.Student&quot;&gt;        &lt;id property=&quot;id&quot; column=&quot;id&quot;&gt;&lt;/id&gt;        &lt;result property=&quot;name&quot; column=&quot;name&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;sex&quot; column=&quot;sex&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;address&quot; column=&quot;address&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;math&quot; column=&quot;math&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;english&quot; column=&quot;english&quot;&gt;&lt;/result&gt;    &lt;/association&gt;&lt;/resultMap&gt;</code></pre><p>此后，就可以把查询的SQL写成如下方式：</p><pre><code class="xml">&lt;select id=&quot;findAll&quot; resultMap=&quot;accountStudentMap&quot;&gt;    select s.*, a.id aid, a.uid, a.money from account a, student s where s.id=a.uid;&lt;/select&gt;</code></pre><p>要注意，上面resultMap中的column里面所写的内容实际上是下面SQL语句中所起的别名，如果在SQL语句中没有起别名，则column需要使用和表中完全相同的列名。</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206191414640.png" alt="image-20200206191414640" style="zoom:80%;"><p>在使用java方法进行测试的时候，就还是采用最基本的方式进行测试，并且可以通过account对象调用getStudent方法来获取实体类中对应的关系：</p><pre><code class="java">@Testpublic void testFindAll() {    List&lt;Account&gt; accounts = accountDao.findAll();    for (Account account : accounts) {        System.out.println(account);        // 打印出从类中包含的主类相对应的student信息        // 实现了：查询账户，并获取账户对应的用户信息（用户就是Student类的对象）        System.out.println(account.getStudent());    }}</code></pre><p>结果如下：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206155845786.png" alt="image-20200206155845786" style="zoom:80%;"><h2 id="2-一对多"><a href="#2-一对多" class="headerlink" title="2. 一对多"></a>2. 一对多</h2><p>如果想要完成一对多的映射，需要在主表实体类中包含从表实体的集合引用</p><p>将Student类中的数据改成下面这样，并且生成对应的getter和setter方法：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206160932645.png" alt="image-20200206160932645" style="zoom:80%;"><p>xml文件中需要创建一个映射来完成结果的封装与返回，由于Student类中包含了Account类的一个集合，因此在后面需要加上一个collection的标签，在其中定义相应的返回结果。</p><pre><code class="xml">&lt;resultMap id=&quot;studentAccountMap&quot; type=&quot;com.xiong.domain.Student&quot;&gt;    &lt;id property=&quot;id&quot; column=&quot;id&quot;&gt;&lt;/id&gt;    &lt;result property=&quot;name&quot; column=&quot;name&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;sex&quot; column=&quot;sex&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;address&quot; column=&quot;address&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;math&quot; column=&quot;math&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;english&quot; column=&quot;english&quot;&gt;&lt;/result&gt;    &lt;!--配置accounts集合的映射，其中column是数据库中的列名，property是字段的名称--&gt;    &lt;collection property=&quot;accounts&quot; ofType=&quot;com.xiong.domain.Account&quot;&gt;        &lt;id property=&quot;aid&quot; column=&quot;id&quot;&gt;&lt;/id&gt;        &lt;result property=&quot;uid&quot; column=&quot;uid&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;money&quot; column=&quot;money&quot;&gt;&lt;/result&gt;    &lt;/collection&gt;&lt;/resultMap&gt;</code></pre><p>查询的xml只需要使用这个resultMap进行映射就可以了。要注意这里的SQL语句中，需要使用左外连接left outer来代替逗号，左外连接的含义就是不管右边是不是null，都总是返回左表中的所有信息。</p><pre><code class="xml">&lt;select id=&quot;findAll&quot; resultMap=&quot;studentAccountMap&quot;&gt;    &lt;!-- 使用左外连接，返回左表的所有信息 --&gt;    select * from student s left outer join account a on s.id=a.uid;&lt;/select&gt;</code></pre><p>调用的java方法也就是简单地进行调用，如下：</p><pre><code class="java">@Testpublic void testFindAll() {    // 执行查找所有方法    List&lt;Student&gt; students = studentDao.findAll();    for (Student student : students) {        System.out.println(student);        System.out.println(student.getAccounts());    }}</code></pre><p>由于只有uid为123的三个数据项中才有Account信息，因此得到的结果如下。</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206162350616.png" alt="image-20200206162350616" style="zoom:80%;"><p>如果用数据库来表示，则查询结果为：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206162454216.png" alt="image-20200206162454216" style="zoom:80%;"><p>注意：这里的例子可能不是特别好，因为一个ID就对应一个UID，但是如果这里一旦一个UID对应多个ID的话，就可以在上面运行结果展示的时候将多个Account对象放在集合里面一并返回。</p><h2 id="3-多对多"><a href="#3-多对多" class="headerlink" title="3. 多对多"></a>3. 多对多</h2><p>多对多的示例用这样的一个场景进行：用户和角色</p><ul><li>一个用户可以拥有多个角色</li><li>一个角色可以赋予多个用户</li></ul><p>因此用户和角色之间就是多对多的关系</p><p><strong>步骤：</strong></p><ol><li><p><strong>建立两张表</strong>：用户表，角色表</p><p>让用户表和角色表具有多对多的关系，需要使用中间表，中间表中包含各自主键，在中间表中是外键</p></li><li><p><strong>建立两个实体类</strong>：用户实体类，角色实体类</p><p>让用户和角色的实体类能体现出来多对多的关系，各自包含对方的一个集合引用</p></li><li><p><strong>建立两个配置文件</strong></p><p>用户配置文件和角色配置文件</p></li><li><p><strong>实现配置</strong></p><p>当查询用户时，可以同时得到用户下包含的角色信息</p><p>当查询角色时，可以同时得到拥有该角色的所有用户信息</p></li></ol><p>首先创建两个表：role和student_role</p><pre><code class="mysql">DROP TABLE IF EXISTS `role`;CREATE TABLE `role` (  `ID` int(11) NOT NULL COMMENT &#39;编号&#39;,  `ROLE_NAME` varchar(30) default NULL COMMENT &#39;角色名称&#39;,  `ROLE_DESC` varchar(60) default NULL COMMENT &#39;角色描述&#39;,  PRIMARY KEY  (`ID`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert  into `role`(`ID`,`ROLE_NAME`,`ROLE_DESC`) values (1,&#39;院长&#39;,&#39;管理整个学院&#39;),(2,&#39;总裁&#39;,&#39;管理整个公司&#39;),(3,&#39;校长&#39;,&#39;管理整个学校&#39;);DROP TABLE IF EXISTS `user_role`;CREATE TABLE `student_role` (  `UID` int(11) NOT NULL COMMENT &#39;用户编号&#39;,  `RID` int(11) NOT NULL COMMENT &#39;角色编号&#39;,  PRIMARY KEY  (`UID`,`RID`),  KEY `FK_Reference_10` (`RID`),  CONSTRAINT `FK_Reference_10` FOREIGN KEY (`RID`) REFERENCES `role` (`ID`),  CONSTRAINT `FK_Reference_9` FOREIGN KEY (`UID`) REFERENCES `student` (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert  into `student_role`(`UID`,`RID`) values (3,1),(2,1),(3,2);</code></pre><p>这里的操作需要将一对一和一对多的操作都暂时删掉</p><h3 id="3-1-角色到用户的多对多"><a href="#3-1-角色到用户的多对多" class="headerlink" title="3.1 角色到用户的多对多"></a>3.1 角色到用户的多对多</h3><p>然后重新创建一个类Role，其中包含了role数据表中的三个列，在这里java类中的名称与数据库中的列名并不相同，也就是暗示了在后面写xml文件的时候需要加上resultMap。属性添加完成后生成getter，setter，toString方法。</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206180353212.png" alt="image-20200206180353212" style="zoom:80%;"><p>在RoleDao中增加一个查询的接口，该接口将与xml配置文件进行对接。</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206180514440.png" alt="image-20200206180514440" style="zoom:80%;"><p>xml文件需要进行resultMap配置，并且将需要的SQL语句写在里面。要注意配置resultMap的时候，property表示java类中的属性名，column表示的是数据表中的属性名。</p><pre><code class="xml">&lt;resultMap id=&quot;roleMap&quot; type=&quot;com.xiong.domain.Role&quot;&gt;    &lt;id property=&quot;roleId&quot; column=&quot;rid&quot;&gt;&lt;/id&gt;    &lt;result property=&quot;roleName&quot; column=&quot;role_name&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;roleDesc&quot; column=&quot;role_desc&quot;&gt;&lt;/result&gt;    &lt;collection property=&quot;students&quot; ofType=&quot;com.xiong.domain.Student&quot;&gt;        &lt;id property=&quot;id&quot; column=&quot;id&quot;&gt;&lt;/id&gt;        &lt;result property=&quot;name&quot; column=&quot;name&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;sex&quot; column=&quot;sex&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;address&quot; column=&quot;address&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;math&quot; column=&quot;math&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;english&quot; column=&quot;english&quot;&gt;&lt;/result&gt;    &lt;/collection&gt;&lt;/resultMap&gt;</code></pre><p>查询的SQL语句如下所示，要注意，一个比较长的SQL语句可以换行，但是换行前后需要加上空格，否则以下面的SQL为例，r可能与left合在一起，就不是关键字了。</p><pre><code class="xml">&lt;select id=&quot;findAll&quot; resultMap=&quot;roleMap&quot;&gt;    select s.*, r.id as rid, r.role_name, r.role_desc from role r    left outer join student_role sr on r.id=sr.rid    left outer join student s on s.id=sr.uid;&lt;/select&gt;</code></pre><p>通过普通的java测试方法调用</p><pre><code class="java">@Testpublic void testFindAll() {    // 执行查找所有方法    List&lt;Role&gt; roles = roleDao.findAll();    for (Role role : roles) {        System.out.println(role);        System.out.println(role.getStudents());    }}</code></pre><p>可以得到结果为：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206180829229.png" alt="image-20200206180829229" style="zoom:80%;"><p>也就是role1对应了1个Student，role2对应了1个Student，role3对应了0个Student</p><h3 id="3-2-用户到角色的多对多"><a href="#3-2-用户到角色的多对多" class="headerlink" title="3.2 用户到角色的多对多"></a>3.2 用户到角色的多对多</h3><p>SQL语句中更换掉就可以了</p><pre><code class="mysql">select s.*, r.id as rid, r.role_name, r.role_desc from student sleft outer join student_role sr on s.id=sr.uidleft outer join role r on r.id=sr.rid;</code></pre><p>SQL查询的结果为：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206184418958.png" alt="image-20200206184418958" style="zoom:80%;"><p>首先需要将Student类中增加一个多对多的映射关系，即添加一个List的Role成员变量并设置getter、setter方法</p><p>然后就将SQL语句以及对应的映射配置文件放进xml文件中</p><p>其中，resultMap定义为：</p><pre><code class="xml">&lt;resultMap id=&quot;studentAccountMap&quot; type=&quot;com.xiong.domain.Student&quot;&gt;    &lt;id property=&quot;id&quot; column=&quot;id&quot;&gt;&lt;/id&gt;    &lt;result property=&quot;name&quot; column=&quot;name&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;sex&quot; column=&quot;sex&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;address&quot; column=&quot;address&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;math&quot; column=&quot;math&quot;&gt;&lt;/result&gt;    &lt;result property=&quot;english&quot; column=&quot;english&quot;&gt;&lt;/result&gt;    &lt;collection property=&quot;roles&quot; ofType=&quot;com.xiong.domain.Role&quot;&gt;        &lt;id property=&quot;roleId&quot; column=&quot;rid&quot;&gt;&lt;/id&gt;        &lt;result property=&quot;roleName&quot; column=&quot;role_name&quot;&gt;&lt;/result&gt;        &lt;result property=&quot;roleDesc&quot; column=&quot;role_desc&quot;&gt;&lt;/result&gt;    &lt;/collection&gt;&lt;/resultMap&gt;</code></pre><p>查询方法写为：</p><pre><code class="xml">&lt;select id=&quot;findAll&quot; resultMap=&quot;studentAccountMap&quot;&gt;    select s.*, r.id as rid, r.role_name, r.role_desc from student s    left outer join student_role sr on s.id=sr.uid    left outer join role r on r.id=sr.rid;&lt;/select&gt;</code></pre><p>测试的java方法为：</p><pre><code class="java">@Testpublic void testFindAll() {    // 执行查找所有方法    List&lt;Student&gt; students = studentDao.findAll();    for (Student student : students) {        System.out.println(student);        System.out.println(student.getRoles());    }}</code></pre><p>可以得到最终的运行结果：</p><img src="/2020/02/06/mybatis/8_%E5%8A%A8%E6%80%81SQL%E4%B8%8E%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C/image-20200206185050880.png" alt="image-20200206185050880" style="zoom:80%;"><p>可以看到，一个Student对象可以对应0个或多个Role信息</p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> MyBatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Mybatis实战2】CRUD操作</title>
      <link href="/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/"/>
      <url>/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="mybatis的CRUD操作"><a href="#mybatis的CRUD操作" class="headerlink" title="mybatis的CRUD操作"></a>mybatis的CRUD操作</h1><h2 id="1-C-创建记录"><a href="#1-C-创建记录" class="headerlink" title="1. C 创建记录"></a>1. C 创建记录</h2><p>StudentDao接口中添加方法：</p><pre><code class="java">void saveStudent(Student student);</code></pre><p>xml文件中增加一个SQL查询：</p><pre><code class="xml">&lt;!--    保存用户--&gt;&lt;insert id=&quot;saveStudent&quot; parameterType=&quot;com.xiong.domain.Student&quot;&gt;    &lt;!-- 配置插入操作后，获取插入数据的ID --&gt;    &lt;!--    keyProperty对应的属性名称            order 表示什么时候进行这个操作            resultType 表示返回值类型--&gt;    &lt;selectKey keyProperty=&quot;id&quot; order=&quot;AFTER&quot; resultType=&quot;int&quot; keyColumn=&quot;id&quot;&gt;        select last_insert_id();    &lt;/selectKey&gt;    insert into student(name, age, sex, address, math, english) values(#{name}, #{age}, #{sex}, #{address}, #{math}, #{english});&lt;/insert&gt;</code></pre><p>测试代码如下：</p><pre><code class="java">/* * 测试保存用户 * */@Testpublic void testSave() {    Student student = new Student();    student.setName(&quot;mybatis&quot;);    student.setAge(24);    student.setSex(&quot;男&quot;);    student.setAddress(&quot;呵呵&quot;);    student.setMath(100);    student.setEnglish(100);    // 添加了selectKey之后，会获取得到这个id的，在执行savestudent操作前后分别打印出两个结果，可以发现一开始是null，后来是12，也就是被写进去了    System.out.println(student.getId());    // 执行保存方法    studentDao.saveStudent(student);    System.out.println(student.getId());}</code></pre><img src="/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/image-20200206111318724.png" alt="image-20200206111318724" style="zoom:80%;"><h2 id="2-R-读取记录"><a href="#2-R-读取记录" class="headerlink" title="2. R 读取记录"></a>2. R 读取记录</h2><h3 id="2-1-根据id查询"><a href="#2-1-根据id查询" class="headerlink" title="2.1 根据id查询"></a>2.1 根据id查询</h3><p>这种调用方法很朴素，就是向其中传一个参数，</p><pre><code class="java">Student findByID(Integer id);</code></pre><p>xml文件定义为：</p><pre><code class="xml">&lt;select id=&quot;findByID&quot; parameterType=&quot;int&quot; resultType=&quot;com.xiong.domain.Student&quot;&gt;    &lt;!-- 注意，这里的id只是用来表示参数的，因为参数只有一个，所以随便写什么都可以 --&gt;    select * from student where id=#{id};&lt;/select&gt;</code></pre><p>调用的java方法为：</p><pre><code class="java">@Testpublic void testFind() {    Student student = studentDao.findByID(10);    System.out.println(student);}</code></pre><p>查询结果为：</p><img src="/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/image-20200206123054525.png" alt="image-20200206123054525" style="zoom:80%;"><h3 id="2-2-根据用户名模糊查询"><a href="#2-2-根据用户名模糊查询" class="headerlink" title="2.2 根据用户名模糊查询"></a>2.2 根据用户名模糊查询</h3><p>StudentDao接口中定义一个接口：</p><pre><code class="java">List&lt;Student&gt; findByName(String username);</code></pre><p>xml文件中定义的SQL查询为：</p><pre><code class="xml">&lt;!--    根据名称进行模糊查询--&gt;&lt;select id=&quot;findByName&quot; parameterType=&quot;String&quot; resultType=&quot;com.xiong.domain.Student&quot;&gt;    select * from student where name like #{name};    &lt;!--        select * from student where name like &#39;%${value}%&#39;;--&gt;&lt;/select&gt;</code></pre><p>测试的java类如下：</p><pre><code class="java">    @Test    public void testFindByName() {         List&lt;Student&gt; students = studentDao.findByName(&quot;%马%&quot;);        // 下面的这种写法在xml的SQL语句中就已经加了百分号，所以这里就不用再加百分号占位符了//        List&lt;Student&gt; students = studentDao.findByName(&quot;马&quot;);        for (Student student : students) {            System.out.println(student);        }    }</code></pre><p>上面的代码xml+调用java有两种方式，第一种方式的运行debug信息为：</p><img src="/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/image-20200206123356049.png" alt="image-20200206123356049" style="zoom:80%;"><p>第二种方式的运行debug信息为：</p><img src="/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/image-20200206123439520.png" alt="image-20200206123439520" style="zoom:80%;"><p>也就是说，第一种方式是通过向mysql占位符传参的方式，第二种方式是通过字符串拼接的方式，因此第一种方式的效果较好。</p><h3 id="2-3-使用聚合函数"><a href="#2-3-使用聚合函数" class="headerlink" title="2.3 使用聚合函数"></a>2.3 使用聚合函数</h3><p>聚合函数实际上就是一个统计的函数,，就相当于是一个普通的查询，在调用的时候可以直接拿到结果。</p><p>在StudentDao接口中定义下面的一个接口：</p><pre><code class="java">int findTotal();</code></pre><p>在xml文件中实现SQL查询：</p><pre><code class="xml">&lt;!--    获取用户的总记录行数--&gt;&lt;select id=&quot;findTotal&quot; resultType=&quot;int&quot;&gt;    select count(id) from student;&lt;/select&gt;</code></pre><p>在测试java文件中调用：</p><pre><code class="java">@Testpublic void testTotal() {    System.out.println(studentDao.findTotal());}</code></pre><h3 id="2-4-使用queryVo条件查询"><a href="#2-4-使用queryVo条件查询" class="headerlink" title="2.4 使用queryVo条件查询"></a>2.4 使用queryVo条件查询</h3><p>首先定义QueryVo类，因为条件查询也是需要一个Student类的对象作为查询条件，因此这里的queryVo相当于只是一个包装对象，把Student的对象包装在queryVo对象中，查询的时候从包装中拆解出来并使用。</p><img src="/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/image-20200206111809089.png" alt="image-20200206111809089" style="zoom:80%;"><p>根据queryVo中的查询条件来查询用户，还是通过名称来查询。只不过查询的对象被封装到一个对象：QueryVo中</p><pre><code class="java">List&lt;Student&gt; findStudentByVo(QueryVo vo);</code></pre><p>xml中的使用方式为：</p><pre><code class="xml">&lt;!--    根据QueryVo的条件查询用户--&gt;&lt;select id=&quot;findStudentByVo&quot;         parameterType=&quot;com.xiong.domain.QueryVo&quot;         resultType=&quot;com.xiong.domain.Student&quot;&gt;    select * from student where name like #{student.name};&lt;/select&gt;</code></pre><p>测试java函数：</p><pre><code class="java">@Testpublic void testFindByVo() {    QueryVo vo = new QueryVo();    Student student = new Student();    student.setName(&quot;%马%&quot;);    vo.setStudent(student);    List&lt;Student&gt; students = studentDao.findStudentByVo(vo);    for (Student student1 : students) {        System.out.println(student1);    }}</code></pre><h2 id="3-U-更新记录"><a href="#3-U-更新记录" class="headerlink" title="3. U 更新记录"></a>3. U 更新记录</h2><p>在StudentDao接口中定义一个接口：</p><pre><code class="java">void updateStudent(Student student);</code></pre><p>下xml文件中对接口进行SQL实现：</p><p>要传进来的参数就是一个Student类型的对象，根据传进来对象的id来进行更新，即 <code>where id = #{id}</code></p><pre><code class="xml">&lt;update id=&quot;updateStudent&quot; parameterType=&quot;com.xiong.domain.Student&quot;&gt;    update student set name=#{name}, age=#{age}, sex=#{sex}, address=#{address}, math=#{math}, english=#{english} where id=#{id};&lt;/update&gt;</code></pre><p>调用的java方法：</p><pre><code class="java">@Testpublic void testUpdate() {    Student student = new Student();    student.setId(10);    student.setName(&quot;Update&quot;);    student.setAge(24);    student.setSex(&quot;男&quot;);    student.setAddress(&quot;北京&quot;);    student.setMath(23);    student.setEnglish(44);    studentDao.updateStudent(student);}</code></pre><h2 id="4-D-删除记录"><a href="#4-D-删除记录" class="headerlink" title="4. D 删除记录"></a>4. D 删除记录</h2><p>StudentDao接口中添加一个接口方法</p><pre><code class="java">void deleteStudent(Integer studentId);</code></pre><p>xml文件中的实现为：</p><p>parameterType可以写int，Integer，java.lang.Integer，由于接口中只有一个参数，因此参数只是一个占位符，写id也可以，写studentId也可以</p><pre><code class="xml">&lt;delete id=&quot;deleteStudent&quot; parameterType=&quot;int&quot;&gt;    delete from student where id=#{studentId};&lt;/delete&gt;</code></pre><p>测试的java方法为：</p><pre><code class="java">@Testpublic void testDelete() {    studentDao.deleteStudent(9);}</code></pre><h1 id="OGNI表达式"><a href="#OGNI表达式" class="headerlink" title="OGNI表达式"></a>OGNI表达式</h1><p>Object Graphic Navigation Language</p><p>对象图导航语言，通过对象的取值方法来获取数据，在写法上，把get给省略了。</p><p>例如：获取用户名称：</p><ul><li>类中的写法：user.getUsername()</li><li>OGNL表达式写法：user.username</li></ul><p>为什么在mybatis中可以直接写username呢？是因为在parameterType中已经提供了属性所属的类，因此此时不需要写对象名。</p><h1 id="mybatis的参数："><a href="#mybatis的参数：" class="headerlink" title="mybatis的参数："></a>mybatis的参数：</h1><ol><li><p>parameterType（输入类型）</p></li><li><p>传递简单类型</p></li><li><p>传递pojo对象</p><p>mybatis使用OGNL表达式解析对象字段的值，#{}或者${}括号中的值为pojo属性名称</p></li><li><p>传递pojo包装对象</p><p>开发中通过pojo传递查询条件，查询条件是综合的查询条件，不仅包含用户查询条件，还包含了其他的查询条件（比如将用户购买的商品信息也作为查询条件，这时可以通过包装对象传入参数，Pojo类中包含pojo）需求是：根据用户名查询用户信息，查询条件放到QueryVo的user属性中。也就是将实体类对象包装起来做查询。</p></li></ol><h1 id="mybatis输出结果的封装"><a href="#mybatis输出结果的封装" class="headerlink" title="mybatis输出结果的封装"></a>mybatis输出结果的封装</h1><ol><li><p>resultType（输出类型）</p><ol><li><p>输出简单类型</p><p>输出简单类型必须查询出来的结果集有一条记录，最终将第一个字段的值转换为输出类型。使用session的selectOne可以查询单条记录。</p></li><li><p>输出pojo对象</p></li><li><p>输出pojo列表</p></li></ol></li></ol><p>如果<strong>实体类与数据库的列名不一致</strong>，有两种解决思路：</p><ol><li>就在SQL语句里面设置别名，相当于查询的结果与实体类的属性保持一致了，这样就可以令实体类的列名与数据库不一致。</li></ol><pre><code class="mysql">select id as userId, name as userName,....</code></pre><ol start="2"><li><p>另一种解决方式，就是配置查询结果的列名和实体类的属性名之间的对应关系。property中的是java实体类的列名，要严格区分大小写，后面的column表示的是数据库的列名。同时，resultType需要更换为resultMap，如下所示：</p><img src="/2020/02/06/mybatis/6_mybatis%E8%BF%9B%E8%A1%8CCRUD/image-20200205164943529.png" alt="image-20200205164943529" style="zoom:80%;"><p>使用第二种方式处理由于需要多余解析一个xml，因此执行效率不如第一种方式（直接在SQL语句上面起别名）。不过开发的效率会比较高，因为只需要改变一次，其他地方使用的时候只需要引用就可以了。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> MyBatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Mybatis实战1】两种环境搭建方法及示例</title>
      <link href="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
      <url>/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="使用xml搭建环境"><a href="#使用xml搭建环境" class="headerlink" title="使用xml搭建环境"></a>使用xml搭建环境</h1><h2 id="1-创建maven的工程并且导入坐标"><a href="#1-创建maven的工程并且导入坐标" class="headerlink" title="1. 创建maven的工程并且导入坐标"></a>1. <strong>创建maven的工程并且导入坐标</strong></h2><p>对mybatis和mysql进行配置（必须），剩下的log4j以及junit分别是用于日志和单元测试的选填部分，不写其实也无所谓。</p><pre><code class="xml">&lt;packaging&gt; jar &lt;/packaging&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.mybatis&lt;/groupId&gt;        &lt;artifactId&gt;mybatis&lt;/artifactId&gt;        &lt;version&gt;3.5.3&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;        &lt;version&gt;8.0.11&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--日志部分--&gt;    &lt;dependency&gt;        &lt;groupId&gt;log4j&lt;/groupId&gt;        &lt;artifactId&gt;log4j&lt;/artifactId&gt;        &lt;version&gt;1.2.12&lt;/version&gt;    &lt;/dependency&gt;    &lt;!--单元测试--&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;4.10&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><h2 id="2-创建实体类和Dao的接口"><a href="#2-创建实体类和Dao的接口" class="headerlink" title="2. 创建实体类和Dao的接口"></a>2. <strong>创建实体类和Dao的接口</strong></h2><p>这里要使用的数据库表如下所示：</p><img src="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/image-20200203084330771.png" alt="image-20200203084330771" style="zoom:80%;"><p>即数据库db1，表名为student，然后分别创建一个和数据库中表相同的java类以及一个Dao接口。</p><ul><li><p>Student类：</p><p>对于Student类，需要实现Serializable接口，创建与对应数据库表字段相同的属性，生成get和set方法并重写toString方法</p><pre><code class="java">import java.io.Serializable;public class Student implements Serializable {    private Integer id;    private String name;    private Integer age;    private String sex;    private String address;    private Integer math;    private Integer english;    // 下面省略生成的所有属性的get与set方法    ...    // 下面省略生成的重写toString方法    @Override    public String toString() {        ...    }}</code></pre></li><li><p>StudentDao接口</p><p>因为Dao是用户的持久层接口，因此</p><pre><code class="java">public interface StudentDao {    /*    * 查询所有操作    * @return    * */    List&lt;Student&gt; findAll();}</code></pre></li></ul><h2 id="3-创建主配置文件"><a href="#3-创建主配置文件" class="headerlink" title="3. 创建主配置文件"></a>3. <strong>创建主配置文件</strong></h2><p>主配置文件名为： <code>SqlMapConfig.xml</code> ，放在 <code>resources</code> 文件夹的根目录下。</p><img src="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/image-20200203084618737.png" alt="image-20200203084618737" style="zoom:80%;"><p>参考官网给出的配置文件，将连接本地数据库的相关信息填写进来就可以了。</p><blockquote><p>注意：这里的url部分，因为高版本mysql的原因，需要设置时区，所以需要在url的后面添加上?后面的内容，否则会报错。</p></blockquote><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;&lt;!--配置环境--&gt;    &lt;environments default=&quot;development&quot;&gt;&lt;!--    配置development的环境--&gt;        &lt;environment id=&quot;development&quot;&gt;&lt;!--        配置事务配型--&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;&lt;!--        配置数据源（连接池）--&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;&lt;!--            配置连接数据库的基本信息--&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/student?useUnicode=true&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;&lt;!--指定映射配置文件的位置，映射配置文件指的是每个dao独立的配置文件--&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;com/xiong/dao/StudentDao.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;</code></pre><h2 id="4-创建映射配置文件"><a href="#4-创建映射配置文件" class="headerlink" title="4. 创建映射配置文件"></a>4. <strong>创建映射配置文件</strong></h2><p>映射配置文件为：<code>StudentDao.xml</code>，这个文件需要在 <code>resources</code> 文件夹里面创建。并且与 <code>StudentDao</code> 接口的路径是相同的。</p><img src="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/image-20200203084801528.png" alt="image-20200203084801528" style="zoom:80%;"><p>注意resultType字段的内容就是前面所写的Student类</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.xiong.dao.StudentDao&quot;&gt;&lt;!--    配置查询所有--&gt;&lt;!--    这里需要写方法的名称--&gt;    &lt;select id=&quot;findAll&quot; resultType=&quot;com.xiong.domain.Student&quot;&gt;        select * from student    &lt;/select&gt;&lt;/mapper&gt;</code></pre><h2 id="5-设置log4j配置文件"><a href="#5-设置log4j配置文件" class="headerlink" title="5. 设置log4j配置文件"></a>5. <strong>设置log4j配置文件</strong></h2><p>这个配置文件放在resources的根目录下面就可以了</p><pre><code class="xml">log4j.rootLogger=debug, stdout, Rlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p - %m%nlog4j.appender.R=org.apache.log4j.RollingFileAppenderlog4j.appender.R.File=firestorm.loglog4j.appender.R.MaxFileSize=100KBlog4j.appender.R.MaxBackupIndex=1log4j.appender.R.layout=org.apache.log4j.PatternLayoutlog4j.appender.R.layout.ConversionPattern=%p %t %c - %m%nlog4j.logger.com.codefutures=DEBUG</code></pre><p>经过上面的步骤，可以看到整个项目的架构如下所示：</p><img src="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/image-20200129144020101.png" alt="image-20200129144020101" style="zoom:80%;"><h1 id="环境搭建的注意事项"><a href="#环境搭建的注意事项" class="headerlink" title="环境搭建的注意事项"></a>环境搭建的注意事项</h1><ol><li><code>StudentDao.xml</code>（映射配置文件）和 <code>StudentDao.java</code>（实体类Dao接口）的包结构必须相同，其名称是为了与之前的知识保持一致。在mybatis中，常把持久层的操作接口名称和映射文件叫做Mapper，因此StudentDao和StudentMapper是一样的；</li><li><code>StudentDao.xml</code>（映射配置文件）中的 <code>mapper</code> 标签 <code>namespace</code> 属性的取值必须是<code>StudentDao.java</code>（实体类Dao接口）的全限定类名；</li><li><code>StudentDao.xml</code>（映射配置文件）的操作配置（<code>select</code> 等），<code>id</code> 属性的取值必须是<code>StudentDao.java</code>（实体类Dao接口）的方法名。</li><li><code>StudentDao.xml</code>（映射配置文件）的操作配置中需要配置 <code>resultType</code> 属性，这个属性表示的就是封装的结果类型，如果不填写这个信息，是没有办法执行的，因为mybatis不知道结果要以什么样的形式来展示。</li></ol><img src="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/image-20200203091802833.png" alt="image-20200203091802833" style="zoom:80%;"><p>遵从上面的点之后，开发的时候就不需要再写dao的实现类。也就是写完接口，操作就结束了，之后的实现由mybatis来进行。</p><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><h2 id="1-不写Dao实现类"><a href="#1-不写Dao实现类" class="headerlink" title="1. 不写Dao实现类"></a>1. 不写Dao实现类</h2><p>创建一个测试java文件，使用mybatis的步骤为</p><ol><li><p>读取配置文件</p><pre><code class="java">InputStream in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;);</code></pre></li><li><p>创建 <code>SqlSessionFactory</code> 工厂</p><pre><code class="java">SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder();SqlSessionFactory factory = builder.build(in);</code></pre></li><li><p>使用工厂生产 <code>SqlSession</code> 对象</p><pre><code class="java">SqlSession session = factory.openSession();</code></pre></li><li><p>使用 <code>SqlSession</code> 创建Dao接口的代理对象</p><pre><code class="java">StudentDao studentDao = session.getMapper(StudentDao.class);</code></pre></li><li><p>使用代理对象执行Dao中的方法</p><pre><code class="java">List&lt;Student&gt; students = studentDao.findAll();</code></pre></li><li><p>释放资源</p><pre><code class="java">session.close();in.close();</code></pre></li></ol><p>具体代码如下：</p><pre><code class="java">public class MybatisTest {    public static void main(String[] args) throws IOException {        // 1. 读取配置文件        InputStream in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;);        // 2. 创建SqlSessionFactory工厂        //    由于SqlSessionFactory是一个接口，因此不能直接new        //    因此需要通过mybatis的一个实现类来new对象，这个实现类就叫做builder        //    然后通过builder来build出一个工厂        SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder();        SqlSessionFactory factory = builder.build(in);        // 3. 使用工厂生产SqlSession对象        SqlSession session = factory.openSession();        // 4. 使用SqlSession创建Dao接口的代理对象        //    传入的参数是一个Dao接口的字节码        StudentDao studentDao = session.getMapper(StudentDao.class);        // 5. 使用代理对象执行Dao中的方法        List&lt;Student&gt; students = studentDao.findAll();        for(Student student : students) {            System.out.println(student);        }        // 6. 释放资源        session.close();        in.close();    }}</code></pre><p><img src="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/image-20200129143049720.png" alt="image-20200129143049720"></p><h2 id="2-自己写Dao的实现类"><a href="#2-自己写Dao的实现类" class="headerlink" title="2. 自己写Dao的实现类"></a>2. 自己写Dao的实现类</h2><p>首先，创建一个StudentDao接口的实现类，在这个实现类中重写 <code>findAll()</code> 方法</p><img src="/2020/02/05/mybatis/2_%E5%9F%BA%E4%BA%8Exml%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/image-20200203095216750.png" alt="image-20200203095216750" style="zoom:80%;"><p>在3.1中，在第3步中，是通过工厂创建了一个代理来执行Dao中的方法的。如果自己写实现类的话就不需要创建代理类了，不过还是需要使用到工厂。因此，在实现类中需要添加一个工厂的对象，并且在实现类中使用这个对象来执行方法并返回结果。</p><pre><code class="java">package com.xiong.dao.impl;import com.xiong.dao.StudentDao;import com.xiong.domain.Student;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import java.util.List;public class StudentDaoImpl implements StudentDao {    private SqlSessionFactory factory;    public StudentDaoImpl(SqlSessionFactory factory) {        this.factory = factory;    }    @Override    public List&lt;Student&gt; findAll() {        // 使用工厂创建SqlSession对象        SqlSession session = factory.openSession();        // selectList()方法需要一个参数，这个参数是一个String类型的语句，需要从StudentDao.xml        // 这个配置文件中拿到语句。在语句中使用namespace来进行全限定        List&lt;Student&gt; students = session.selectList(&quot;com.xiong.dao.StudentDao.findAll&quot;);        session.close();        return students;    }}</code></pre><h1 id="案例设计模式分析"><a href="#案例设计模式分析" class="headerlink" title="案例设计模式分析"></a>案例设计模式分析</h1><h2 id="1-创建工厂（构建者模式）"><a href="#1-创建工厂（构建者模式）" class="headerlink" title="1. 创建工厂（构建者模式）"></a>1. 创建工厂（构建者模式）</h2><p>创建工厂在案例中的代码就是：</p><pre><code class="java">SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder();SqlSessionFactory factory = builder.build(in);</code></pre><p>mybatis使用了构建者模式来创建工厂，通过构建者（<code>builder</code>）来创建工厂（<code>factory</code>）。</p><h2 id="2-生产SqlSession对象（工厂模式）"><a href="#2-生产SqlSession对象（工厂模式）" class="headerlink" title="2. 生产SqlSession对象（工厂模式）"></a>2. 生产SqlSession对象（工厂模式）</h2><p>生产SqlSession对象的代码为：</p><pre><code class="java">SqlSession session = factory.openSession();</code></pre><p>mybatis使用了工厂模式来创建对象，通过工厂（<code>factory</code>）来创建对象（<code>session</code>）。使用这种模式的好处是可以解耦，能够降低类之间的依赖关系，使用工厂模式来替换new，会比较方便。</p><h2 id="3-创建Dao接口实现类（代理模式）"><a href="#3-创建Dao接口实现类（代理模式）" class="headerlink" title="3. 创建Dao接口实现类（代理模式）"></a>3. 创建Dao接口实现类（代理模式）</h2><p>创建Dao接口实现类的代码为：</p><pre><code class="java">StudentDao studentDao = session.getMapper(StudentDao.class);</code></pre><p>mybatis使用了代理模式来创建Dao接口的实现类，优点是在不修改源码的基础上，对已有方案进行增强。</p><h1 id="使用注解搭建环境"><a href="#使用注解搭建环境" class="headerlink" title="使用注解搭建环境"></a>使用注解搭建环境</h1><p>和使用xml的方法很类似，但是不需要映射配置文件了，即需要将resources文件夹中的xml配置文件连同其目录一起删掉。</p><h2 id="1-在StudentDao接口文件中添加注解"><a href="#1-在StudentDao接口文件中添加注解" class="headerlink" title="1. 在StudentDao接口文件中添加注解"></a>1. 在StudentDao接口文件中添加注解</h2><p><code>@Select(&quot;&quot;)</code> 中填写相应的SQL语句</p><pre><code class="java">package com.xiong.dao;import com.xiong.domain.Student;import org.apache.ibatis.annotations.Select;import java.util.List;/** Dao：用户的持久层接口* */public interface StudentDao {    /*    * 查询所有操作    * @return    * */    @Select(&quot;select * from student&quot;)    List&lt;Student&gt; findAll();}</code></pre><h2 id="2-修改主配置文件"><a href="#2-修改主配置文件" class="headerlink" title="2. 修改主配置文件"></a>2. 修改主配置文件</h2><p>主配置文件为 <code>SqlMapConfig.xml</code>，将该文件中更换原来mappers的内容修改为：</p><pre><code class="xml">&lt;mappers&gt;    &lt;mapper class=&quot;com.xiong.dao.StudentDao&quot;/&gt;&lt;/mappers&gt;</code></pre><p>再去执行test文件，发现结果和前面使用xml配置的结果是一样的。</p>]]></content>
      
      
      <categories>
          
          <category> SSM </category>
          
          <category> MyBatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多表查询与事务</title>
      <link href="/2020/01/29/11-MySQL/3_%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%B8%8E%E4%BA%8B%E5%8A%A1/"/>
      <url>/2020/01/29/11-MySQL/3_%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%B8%8E%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="多表查询"><a href="#多表查询" class="headerlink" title="多表查询"></a>多表查询</h1><p>查询语法：</p><pre><code class="mysql">SELECT    列名FROM    表名WHERE    ...</code></pre><p>首先，在这里使用两个表：dept和emp</p><pre><code class="mysql">CREATE TABLE dept (    id INT PRIMARY KEY AUTO_INCREMENT,    name VARCHAR(20));INSERT INTO dept (name) VALUES (&#39;市场部&#39;), (&#39;开发部&#39;), (&#39;财务部&#39;);CREATE TABLE emp (    id INT PRIMARY KEY AUTO_INCREMENT,    name VARCHAR(20),    gender CHAR(1),    salary DOUBLE,    join_date DATE,    dept_id INT,    FOREIGN KEY (dept_id) REFERENCES dept(id));INSERT INTO emp (name, gender, salary, join_date, dept_id) VALUES (&#39;孙悟空&#39;, &#39;男&#39;, 7200, &#39;2013-02-14&#39;, 1);INSERT INTO emp (name, gender, salary, join_date, dept_id) VALUES (&#39;猪八戒&#39;, &#39;男&#39;, 3500, &#39;2013-02-14&#39;, 2);INSERT INTO emp (name, gender, salary, join_date, dept_id) VALUES (&#39;唐僧&#39;, &#39;男&#39;, 9000, &#39;2013-02-14&#39;, 2);INSERT INTO emp (name, gender, salary, join_date, dept_id) VALUES (&#39;白骨精&#39;, &#39;女&#39;, 4200, &#39;2013-02-14&#39;, 3);INSERT INTO emp (name, gender, salary, join_date, dept_id) VALUES (&#39;蜘蛛精&#39;, &#39;女&#39;, 3700, &#39;2013-02-14&#39;, 1);</code></pre><p>经过初始化之后，可以得到下面的两张表：</p><ol><li><p>emp表</p><img src="/2020/01/29/11-MySQL/3_%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%B8%8E%E4%BA%8B%E5%8A%A1/image-20200126164811557.png" alt="image-20200126164811557" style="zoom:80%;"></li><li><p>dept表</p><img src="/2020/01/29/11-MySQL/3_%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%B8%8E%E4%BA%8B%E5%8A%A1/image-20200126164854157.png" alt="image-20200126164854157" style="zoom:80%;"></li></ol><h2 id="1-普通的多表查询"><a href="#1-普通的多表查询" class="headerlink" title="1. 普通的多表查询"></a>1. 普通的多表查询</h2><p>直接在查询语句中，在FROM后面写上多个表即可：</p><pre><code class="mysql">SELECT * FROM emp, dept;</code></pre><p>查询到的结果是这样的：</p><img src="/2020/01/29/11-MySQL/3_%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%B8%8E%E4%BA%8B%E5%8A%A1/image-20200126164926734.png" alt="image-20200126164926734" style="zoom:80%;"><p>也就是说，查询结果的项数量是原来两个表中项目数量的乘积，被称为<strong>笛卡尔积</strong>。因为笛卡尔积中有很多无用的数据，因此要完成多表查询，需要消除无用的数据</p><h2 id="2-内连接查询"><a href="#2-内连接查询" class="headerlink" title="2. 内连接查询"></a>2. 内连接查询</h2><h3 id="2-1-隐式内连接"><a href="#2-1-隐式内连接" class="headerlink" title="2.1 隐式内连接"></a>2.1 隐式内连接</h3><p>隐式内连接就是<strong>使用WHERE条件来消除无用的数据</strong>。</p><p>例如上面那个表格中，emp表中的dept_id实际上是与dept表中的id表示相同的含义，因此可以通过这个来消除重复</p><pre><code class="mysql">SELECT * FROM emp, dept WHERE emp.dept_id = dept.id;</code></pre><p>这样，查询到的结果都是emp表的dept_id属性与dept表的id属性相同的记录了。</p><img src="/2020/01/29/11-MySQL/3_%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%B8%8E%E4%BA%8B%E5%8A%A1/image-20200126174538939.png" alt="image-20200126174538939" style="zoom:80%;"><p>如果想要查询指定表中的指定数据，则只需要通过 <code>.</code> 运算符来指定表和列就可以了。</p><pre><code class="mysql">SELECT emp.name, emp.gender, dept.name FROM emp, dept WHERE emp.dept_id = dept.id;</code></pre><img src="/2020/01/29/11-MySQL/3_%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%E4%B8%8E%E4%BA%8B%E5%8A%A1/image-20200126174600441.png" alt="image-20200126174600441" style="zoom:80%;"><p>注意事项：（需要确定的事情）</p><ol><li>从哪些表中查询数据</li><li>查询条件是什么</li><li>查询字段是什么</li></ol><h3 id="2-2-显式内连接"><a href="#2-2-显式内连接" class="headerlink" title="2.2 显式内连接"></a>2.2 显式内连接</h3><p>语法：</p><pre><code class="mysql">SELECT 字段列表 FROM 表名1 [INNER] JOIN 表名2 ON 条件;</code></pre><p>例如下面的：</p><pre><code class="mysql">SELECT * FROM emp INNER JOIN dept ON emp.dept_id = dept.id;SELECT * FROM emp JOIN dept ON emp.dept_id = dept.id;</code></pre><p>INNER是一个可选的操作，如果不写也是可以的</p><h2 id="3-外连接查询"><a href="#3-外连接查询" class="headerlink" title="3. 外连接查询"></a>3. 外连接查询</h2><p>分为两种：</p><ol><li>左外连接</li><li>右外连接</li></ol><h3 id="3-1-左外连接"><a href="#3-1-左外连接" class="headerlink" title="3.1 左外连接"></a>3.1 左外连接</h3><p>查询的是左表中的所有数据以及其交集部分，而内连接查询的是交集部分。</p><p>语法：</p><pre><code class="mysql">SELECT 字段列表 FROM 表1 LEFT [OUTER] JOIN 表2 ON 条件;</code></pre><p>OUTER是一个可选的操作，不写也是可以的。它与显式内连接的写法非常相似，只有几个关键字不同。</p><h3 id="3-2-右外连接"><a href="#3-2-右外连接" class="headerlink" title="3.2 右外连接"></a>3.2 右外连接</h3><p>查询的时右表中的所有数据以及交集部分，使用方法与左外连接是一样的。</p><p>语法：</p><pre><code class="mysql">SELECT 字段列表 FROM 表1 RIGHT [OUTER] JOIN 表2 ON 条件;</code></pre><p>因此：左外与右外查询实际上是一种，只不过表的位置写的不一样而已。</p><h2 id="4-子查询"><a href="#4-子查询" class="headerlink" title="4. 子查询"></a>4. 子查询</h2><p>查询中嵌套查询，就称嵌套的查询叫做子查询，根据子查询的结果情况，可以分为三种，如下所示。</p><h3 id="4-1-子查询的结果是单行单列"><a href="#4-1-子查询的结果是单行单列" class="headerlink" title="4.1 子查询的结果是单行单列"></a>4.1 子查询的结果是单行单列</h3><p>子查询的结果可以作为条件，使用运算符。</p><p>例如：要查询工资最多的员工信息，如果不使用子查询，则需要分为两步：先确定最大工资，然后通过最大工资来查询，即：</p><pre><code class="mysql">SELECT MAX(salary) FROM emp;-- 得到结果为9000SELECT * FROM emp WHERE emp.salary = 9000;-- 使用上一步得到的结果9000进行查询</code></pre><p>如果使用子查询，就可以将上面的两步查询合二为一</p><pre><code class="mysql">SELECT * FROM emp WHERE emp.salary = (SELECT MAX(salary) FROM emp);</code></pre><h3 id="4-2-子查询的结果是多行单列"><a href="#4-2-子查询的结果是多行单列" class="headerlink" title="4.2 子查询的结果是多行单列"></a>4.2 子查询的结果是多行单列</h3><p>可以通过使用IN运算符来判断。</p><p>例如：要查询部门为财务部和市场部两个部门的所有成员信息，则如果使用两条语句可以写成下面这样：</p><pre><code class="mysql">SELECT id FROM dept WHERE name = &#39;财务部&#39; OR name = &#39;市场部&#39;;-- 得到的结果为id=2和id=3SELECT * FROM emp WHERE dept_id = 2 OR dept_id = 3;-- 使用上一步得到的结果2和3进行查询</code></pre><p>如果使用子查询，则可以将上面的两条查询语句合二为一，其中需要使用IN来从这个多行单列的子查询结果中获取查询条件。</p><pre><code class="mysql">SELECT * FROM emp WHERE dept_id IN (SELECT id FROM dept WHERE name = &#39;财务部&#39; OR name = &#39;市场部&#39;);</code></pre><h3 id="4-3-子查询的结果是多行多列"><a href="#4-3-子查询的结果是多行多列" class="headerlink" title="4.3 子查询的结果是多行多列"></a>4.3 子查询的结果是多行多列</h3><p>如果子查询的结果是多行多列，则可以将这个子查询的结果作为一个虚拟表，来进行表的查询。</p><p>查询员工入职日期是2011年11月11日之后的员工信息和部门信息</p><pre><code class="mysql">SELECT * FROM emp WHERE emp.join_date &gt; &#39;2011-11-11&#39;;-- 把上面的子查询结果当成一张表SELECT * FROM dept t1, (SELECT * FROM emp WHERE emp.join_date &gt; &#39;2011-11-11&#39;) t2WHERE t1.id = t2.dept_id;-- 这里就将前面子查询语句拿过来当做一张表，并将其起名为t2，就能够进行子查询结果为多行多列的查询了</code></pre><p>上面的查询也可以使用普通的内连接来查询：</p><pre><code class="mysql">SELECT * FROM tmp t1, dept t2 WHERE t1.dept_id = t2.id AND t1.join_date &gt; &#39;2011-11-11&#39;;</code></pre><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="1-事务的基本介绍"><a href="#1-事务的基本介绍" class="headerlink" title="1. 事务的基本介绍"></a>1. 事务的基本介绍</h2><p>概念：如果一个包含多个步骤的业务操作被事务管理，那么这些操作要么同时成功，要么同时失败。</p><p>例如：张三给李四转账500元</p><ol><li>查询张三账户的余额是否大于500</li><li>张三账户金额-500</li><li>李四账户金额+500</li></ol><p>如果在某第二步结束之后出现异常，则后面的操作将不会再进行，此时的影响是：张三的账户-500，但是李四的账户没有+500。</p><p>如果这三个步骤被事务管理，首先会开启事务。一旦其中一个步骤出现异常，就会回滚，如果没有出现异常，则会提交事务。这三种操作在SQL中会有三条语句：</p><ul><li>开启事务：<code>START TRANSACTION</code></li><li>回滚：<code>ROLLBACK</code></li><li>提交事务：<code>COMMIT</code></li></ul><p>使用一个实际的例子为：</p><pre><code class="mysql">START TRANSACTIONUPDATE account SET balance = balance - 500 WHERE name = &#39;张三&#39;;UPDATE account SET balance = balance + 500 WHERE name = &#39;李四&#39;;-- 如果没有问题，则提交事务COMMIT-- 如果出现问题，则回滚ROLLBACK</code></pre><p>事务提交的方式：</p><ul><li><p><strong>自动提交</strong></p><p>mysql是自动提交的，一条DML语句就会自动提交一次事务</p></li><li><p><strong>手动提交</strong></p><p>需要手动开启事务，再提交</p></li></ul><p>修改事务的默认提交方式：</p><ul><li><p>查询默认的提交方式</p><pre><code class="mysql">SELECT @@autocommit; -- 其中，1代表自动提交，0代表手动提交</code></pre></li><li><p>改变默认提交方式</p><pre><code class="mysql">SET @@autocommit = 0;</code></pre></li></ul><h2 id="2-事务的四点特征"><a href="#2-事务的四点特征" class="headerlink" title="2. 事务的四点特征"></a>2. 事务的四点特征</h2><p>事务的四大特征</p><ol><li>原子性：是不可分割的最小操作单位，要么同时成功，要么同时失败</li><li>持久性：事务提交或回滚之后，数据库会持久化保存数据</li><li>隔离性：多个事务之间相互独立</li><li>一致性：事务操作前后数据总量不变</li></ol><h2 id="3-事务的隔离级别"><a href="#3-事务的隔离级别" class="headerlink" title="3. 事务的隔离级别"></a>3. 事务的隔离级别</h2><p>概念：多个事务之间是隔离的，也就是说他们是独立的，但是多个事务操作同一批事务，则会产生一些问题，设置不同的隔离级别，就可以解决这些问题。</p><h3 id="3-1-问题"><a href="#3-1-问题" class="headerlink" title="3.1 问题"></a>3.1 问题</h3><ol><li><p><strong>脏读</strong></p><p>一个事务读取到另一个事务中没有提交的数据</p></li><li><p><strong>不可重复读（虚读）</strong></p><p>在同一个事务中，两次读取到的数据不一样</p></li><li><p><strong>幻读</strong></p><p>一个事务操作（DML）数据表中的所有记录，另一个事务添加了一条数据，则第一个事务查询不到自己的修改</p></li></ol><h3 id="3-2-隔离级别"><a href="#3-2-隔离级别" class="headerlink" title="3.2 隔离级别"></a>3.2 隔离级别</h3><ol><li><p><strong><code>READ UNCOMMITTED</code></strong></p><p>即读未提交</p><p><strong>产生的问题</strong>：脏读、不可重复读、幻读</p></li><li><p><strong><code>READ COMMITTED</code>（ORACLE的默认级别）</strong></p><p>读已提交，也就是提交之后其他事务才可以读取</p><p><strong>产生的问题</strong>：不可重复读、幻读</p></li><li><p><strong><code>REPEATABLE READ</code>（MYSQL的默认级别）</strong></p><p>可重复读，设置了这个隔离级别之后，在事务未提交或回滚时，多次读取得到的结果是相同的</p><p><strong>产生的问题</strong>：幻读</p></li><li><p><strong><code>SERIALIZABLE</code></strong></p><p>即串行化，可以解决所有的问题，如果有两个事务来操作同一个表，则必须等待一个事务操作完毕之后，另一个事务才可以开始执行。也就相当于加了一个锁，使用的效率会大大降低，不过安全性很高。</p></li></ol><p>隔离级别从小到大，其安全性越来越高，但是其效率会越来越低</p><h3 id="3-3-查询与操作"><a href="#3-3-查询与操作" class="headerlink" title="3.3 查询与操作"></a>3.3 查询与操作</h3><p>查询隔离级别：</p><pre><code class="mysql">SELECT @@tx_isolation;</code></pre><p>设置隔离级别：</p><pre><code class="mysql">SET GLOBAL TRANSACTION LEVEL 级别字符串;</code></pre><p>在设置完隔离级别之后，需要将连接断开然后重新连接，才会生效</p><h1 id><a href="#" class="headerlink" title></a></h1>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库高级知识及SQL实现</title>
      <link href="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/"/>
      <url>/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="高级"><a href="#高级" class="headerlink" title="高级"></a>高级</h1><h2 id="1-约束"><a href="#1-约束" class="headerlink" title="1. 约束"></a>1. 约束</h2><p>对表中的数据进行限定，从而保证数据的正确性、有效性、完整性。</p><p>比如说，在数据库中，某一列中必须有值，比如名字，如果这个数据不存在，则这一条数据是无效的。因此可以通过对表中的数据进行限定来保证数据的三个特性。</p><ul><li>非空约束</li><li>唯一约束</li><li>主键约束</li><li>外键约束</li></ul><h3 id="1-1-非空约束"><a href="#1-1-非空约束" class="headerlink" title="1.1 非空约束"></a>1.1 非空约束</h3><p>即 <code>NOT NULL</code>，某一列的值不能为空。</p><ul><li><p>在创建表的时候添加约束。</p><pre><code class="mysql">CREATE TABLE stu (    id INT,     name VARCHAR(20) NOT NULL);SELECT * FROM stu;</code></pre><p>往表中添加数据的时候，如果这一项中的数据为空，则会报错，例如下面：</p></li></ul><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200125141922542.png" alt="image-20200125141922542" style="zoom:80%;"><ul><li><p>创建表后添加非空约束</p><pre><code class="mysql">ALTER TABLE stu MODIFY name VARCHAR(20) NOT NULL;</code></pre></li><li><p>删除非空约束</p><pre><code class="mysql">ALTER TABLE stu MODIFY name VARCHAR(20);</code></pre></li></ul><h3 id="1-2-唯一约束"><a href="#1-2-唯一约束" class="headerlink" title="1.2 唯一约束"></a>1.2 唯一约束</h3><p>即 <code>UNIQUE</code>，被修饰的列的值是不能重复的（注：多个NULL是可以同时存在的，NULL实际上表示的是不确定，因此是不重复的）。</p><ul><li><p>创建表时添加唯一约束</p><pre><code class="mysql">CREATE TABLE stu (    id INT,    phone_number VARCHAR(20) UNIQUE -- 添加了唯一约束);SELECT * FROM stu;</code></pre></li><li><p>创建表后添加唯一约束</p><pre><code class="mysql">ALTER TABLE stu MODIFY phone_number VARCHAR(20) UNIQUE;</code></pre></li><li><p>删除唯一约束</p><pre><code class="mysql">ALTER TABLE stu DROP INDEX phone_number; -- 注意，这个与非空约束是不同的</code></pre></li></ul><h3 id="1-3-主键约束"><a href="#1-3-主键约束" class="headerlink" title="1.3 主键约束"></a>1.3 主键约束</h3><p>即 <code>PRIMARY KEY</code>，表示<strong>非空且唯一</strong>，一张表中只有一个字段可以为主键，<strong>主键就是表中记录的唯一标识。</strong></p><ul><li><p>创建表时添加主键约束</p><pre><code class="mysql">CREATE TABLE stu(    id INT PRIMARY KEY,            -- 这是主键约束    phone_number VARCHAR(20));</code></pre></li><li><p>创建表后添加主键约束</p><pre><code class="mysql">ALTER TABLE stu MODIFY id INT PRIMARY KEY;    -- 添加的时候需要表中没有重复主键</code></pre></li><li><p>删除主键约束</p><pre><code class="mysql">ALTER TABLE stu DROP PRIMARY KEY;         -- 因为主键约束只有一个，因此这里不需要指定</code></pre></li><li><p>自动增长：</p><p>如果某一列是数值类型的，使用 <code>AUTO_INCREMENT</code> 可以完成值的自动增长</p><pre><code class="mysql">CREATE TABLE stu (    id INT PRIMARY KEY AUTO_INCREMENT,    phone_number VARCHAR(20));</code></pre><p>如果设置了自动增长，可以通过 <code>INSERT INTO</code> 来添加数据</p><pre><code class="mysql">INSERT INTO stu VALUES(NULL, &#39;ABCD&#39;); -- 如果加了自动增长，则会自动添加id的值，并非将其设置为NULLINSERT INTO stu VALUES(10, &#39;QWE&#39;);INSERT INTO stu VALUES(10, &#39;RRR&#39;);-- 如果设置了自动增长，则只与上一条记录有关，因此RRR的id值为11，而不是其他的值</code></pre></li><li><p>删除自动增长</p><pre><code class="mysql">ALTER TABLE stu MODIFY id INT; -- 主键约束还存在，但是没有了自动增长</code></pre></li><li><p>添加自动增长</p><pre><code class="mysql">ALTER TABLE stu MODIFY id INT AUTO_INCREMENT;</code></pre></li></ul><p>一般而言，自动增长都和主键一同使用，但是也可以不这样使用。</p><h3 id="1-4-外键约束"><a href="#1-4-外键约束" class="headerlink" title="1.4 外键约束"></a>1.4 外键约束</h3><p>即 <code>FOREIGN KEY</code></p><p>数据有冗余，则可以使用多个表来存储，数据冗余的概念可以简单理解为同样的数据出现了多次。这样就可以通过创建多个表把重复的数据分散出去。</p><p>例如下面这个例子，emp表中包含了五个列，其中的dep_name和dep_location两个字段中的值都是重复出现的，就产生了冗余，因此，可以将一个表拆成多个。</p><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200125194959661.png" alt="image-20200125194959661" style="zoom:80%;"><p>可以将员工表与部门表拆分，将员工表和部门表进行联系即可</p><pre><code class="mysql">CREATE TABLE department (    id INT PRIMARY KEY AUTO_INCREMENT,    dep_name VARCHAR(20),    dep_location VARCHAR(20));CREATE TABLE employee (    id INT PRIMARY KEY AUTO_INCREMENT,    name VARCHAR(20),    age INT,    dep_id INT -- 注意：这里的dep_id表示部门的主键ID);-- 向部门表中添加数据：INSERT INTO department VALUES(NULL, &#39;研发部&#39;, &#39;广州&#39;), (NULL, &#39;销售部&#39;, &#39;深圳&#39;);-- 向员工表中添加员工数据：INSERT INTO employee (name, age, dep_id) VALUES (&#39;张三&#39;, 20, 1);INSERT INTO employee (name, age, dep_id) VALUES (&#39;李四&#39;, 20, 1);INSERT INTO employee (name, age, dep_id) VALUES (&#39;王五&#39;, 20, 1);INSERT INTO employee (name, age, dep_id) VALUES (&#39;赵柳&#39;, 20, 2);INSERT INTO employee (name, age, dep_id) VALUES (&#39;呵呵&#39;, 20, 2);INSERT INTO employee (name, age, dep_id) VALUES (&#39;嘻嘻&#39;, 20, 2);SELECT * FROM employee;</code></pre><p>如果想要employee表中的dep_id表来和department表中的id产生关联关系，则需要使用到外键约束</p><ul><li><p>创建表时添加外键</p><pre><code class="mysql">CREATE TABLE 表名 (    ...    CONSTRAINT 外键名称 FOREIGN KEY (外键列名称) REFERENCES 主表名称(主表的列的名称));</code></pre><ol><li>外键名称：新起的名</li><li>外键列名称：本表中列的名称</li><li>主表名称：需要关联的表的名称，可以理解为外联表名称</li><li>主表中的列名称：需要关联的表中列的名称，可以理解为外联表中列的名称</li></ol><p><strong>例子</strong></p><pre><code class="mysql">CREATE TABLE department (    id INT PRIMARY KEY AUTO_INCREMENT,    dep_name VARCHAR(20),    dep_location VARCHAR(20));CREATE TABLE employee (    id INT PRIMARY KEY AUTO_INCREMENT,    name VARCHAR(20),    age INT,    dep_id INT, -- 注意：这里的dep_id表示部门的主键ID    CONSTRAINT emp_dept_id FOREIGN KEY (dep_id) REFERENCES department(id));</code></pre><p>此时：</p><ul><li>如果在外键中对主表中的有引用，则不能够删除主表中的引用。（比如有用户属于dep_id=1，但是删除department表中id=1的行不能被删除）</li><li>外键不可以是主表中不存在的值，但是可以为NULL。（比如不能添加一个dep_id=3的用户）</li></ul></li><li><p>创建表之后添加外键</p><pre><code class="mysql">ALTER TABLE employee ADD CONSTRAINT emp_dept_id FOREIGN KEY (dep_id) REFERENCES department(id);-- 也就是在ALTER TABLE employee ADD后面，将创建表的时候的内容在加进来</code></pre></li><li><p>删除外键</p><pre><code class="mysql">ALTER TABLE employee DROP FOREIGN KEY emp_dept_id;</code></pre></li><li><p>级联操作</p><p>在主表中修改数据，同时在外联表中也生效，如果不采用级联操作，则需要执行两步：</p><p>即：先将dep_id = 1的值设置为NULL，再将它设置为5</p><pre><code class="mysql">UPDATE employee SET dep_id = NULL WHERE dep_id = 1;UPDATE employee SET dep_id = 5 WHERE dep_id = NULL;</code></pre><p>在主表中修改了一些数据之后，外联表中也自动进行修改，即为级联操作。级联操作更细致地分就是级联更新和级联删除。</p><p>但是级联删除还是有一定弊端的，如果有很多表都有关联，那么一旦删除了一个其中一个，则与之级联的表都可能会受到影响（被删除）。</p><pre><code class="mysql">ALTER TABLE employee ADD CONSTRAINT emp_dept_id FOREIGN KEY (dep_id) REFERENCES department(id) ON UPDATE CASCADE;-- 级联更新：后面的ON UPDATE CASCADE就表示设置了级联的更新-- 此后，只要修改其中一个，另一个也可以同时进行修改ALTER TABLE employee ADD CONSTRAINT emp_dept_id FOREIGN KEY (dep_id) REFERENCES department(id) ON DELETE CASCADE;-- 级联删除：后面的ON DELETE CASCADE就表示级联的删除-- 级联更新和级联删除可以同时设置，只需要在后面把这两个语句都加上就可以了</code></pre></li></ul><h2 id="2-多表关系"><a href="#2-多表关系" class="headerlink" title="2. 多表关系"></a>2. 多表关系</h2><p>多表关系有以下几种：</p><ol><li><p><strong>一对一</strong></p><p>例：人与身份证。比如一个人只有一个身份证，一个身份证只对应一个人，因此人与身份证之间的关系就是一对一的</p></li><li><p><strong>一对多（多对一）</strong></p><p>例：部门与员工。比如一个部门可能有多个员工，多个员工对应于一个部门，因此部门与员工之间的关系就是一对多或者多对一的</p></li><li><p><strong>多对多</strong></p><p>例：学生与课程。比如一个学生可以选择多个课程，一个课程可以被多个课程选择，因此课程与学生之间的关系就是多对多的</p></li></ol><h3 id="2-1-一对多"><a href="#2-1-一对多" class="headerlink" title="2.1 一对多"></a>2.1 一对多</h3><p>实现方式：在“多”的一方建立外键，指向“一”的一方的主键</p><h3 id="2-2-多对多"><a href="#2-2-多对多" class="headerlink" title="2.2 多对多"></a>2.2 多对多</h3><p>实现方式：多对多的实现方式需要一个中间表。</p><p>中间表中至少包含两个字段，这两个字段作为<strong>第三张表的外键</strong>，分别指向<strong>两张表的主键</strong>。</p><p><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200126101717803.png" alt="image-20200126101717803"></p><h3 id="2-3-一对一"><a href="#2-3-一对一" class="headerlink" title="2.3 一对一"></a>2.3 一对一</h3><p>实现方式：在任意一方添加<strong>唯一外键</strong>指向另一方的主键。注意：需要使得外键唯一，也就是添加唯一约束（<code>UNIQUE</code>）。但是一对一的关系其实是可以放在一张表中的，硬拆成多张表实际上是没有太大意义的。</p><p><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200126102246638.png" alt="image-20200126102246638"></p><h2 id="3-范式"><a href="#3-范式" class="headerlink" title="3. 范式"></a>3. 范式</h2><p>范式指的是：设计数据库时，需要遵循的一些规范。设计关系数据库的时候，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范称为不同的范式。各种范式呈现<strong>递次规范</strong>，也就是要遵循后面的范式要求，就需要先遵循前面的范式要求，并且越高的范式数据库冗余越小。</p><p>目前分为六种范式：</p><ol><li>第一范式（1NF）</li><li>第二范式（2NF）</li><li>第三范式（3NF）</li><li>巴斯-科德范式（BCNF）</li><li>第四范式（4NF）</li><li>第五范式（5NF）</li></ol><h3 id="3-1-第一范式"><a href="#3-1-第一范式" class="headerlink" title="3.1 第一范式"></a>3.1 第一范式</h3><p>每一列都是不可分割的原子数据项。</p><p>通俗理解：一个列不可以拆分成多个列，例如下面的表就不符合1NF</p><p><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200126104502927.png" alt="image-20200126104502927"></p><h3 id="3-2-第二范式"><a href="#3-2-第二范式" class="headerlink" title="3.2 第二范式"></a>3.2 第二范式</h3><p>在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）。其实2NF就是<strong>删除部分依赖</strong>，让所有的非主属性完全依赖于主码。</p><p>以下面这个表为例来说明：</p><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200126111101491.png" alt="image-20200126111101491" style="zoom: 67%;"><p>首先需要理解下面几个概念：</p><ul><li><p><strong>函数依赖</strong></p><p><code>A--&gt;B</code> ：如果通过A属性的值可以确定唯一B属性的值，则称B依赖于A。（即由A可以得到B）</p><p>例如：学号被姓名依赖、姓名依赖于学号，即 <code>学号--&gt;姓名</code></p><p>由学号和课程名称可以唯一确定分数，即 <code>(学号, 课程名称)--&gt;分数</code></p></li><li><p><strong>完全函数依赖</strong></p><p><code>A--&gt;B</code> ：如果A是一个属性组，则B属性值的确定需要依赖于A属性组中所有的属性值</p><p>例如：学号和课程名称被分数完全依赖。</p></li><li><p><strong>部分函数依赖</strong></p><p>A属性组里面的某一个属性就可以确定B属性的值，则A被B部分依赖</p><p>例如：学号和课程名称被姓名完全依赖，又因为学号就可以确定姓名了，课程名实际上并没有什么作用。 <code>(学号, 课程名称)--&gt;姓名</code></p></li><li><p><strong>传递函数依赖</strong></p><p><code>A--&gt;B   B--&gt;C</code>，如果通过A属性可以唯一确定B属性的值，通过B属性的值可以唯一确定C属性的值，则称C传递函数依赖于A。（C依赖B，B依赖A，则C传递依赖于A）</p><p>例如：学号被系名依赖，系名被系主任依赖，则可以构成传递函数依赖关系：<code>学号--&gt;系名, 系名--&gt;系主任</code></p></li><li><p><strong>码</strong></p><p>如果在一张表中，一个属性或属性组被其他所有属性所完全依赖，则称这个属性（或属性组）为该表的码</p><p>例如：通过学号+课程名称可以唯一确定姓名、系名、系主任、分数，则这个属性组就被称为码，该表中的码就是 <code>(学号, 课程名称)</code></p><ul><li><strong>主属性</strong>：码属性组中的所有属性</li><li><strong>非主属性</strong>：除了码属性组属性的其他属性</li></ul></li></ul><p>做法：通过分表来实现</p><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200126111639233.png" alt="image-20200126111639233" style="zoom:80%;"><p>来分析上面这两张表：</p><p>选课表中：学号+课程名称是码，非主属性：分数完全依赖于码，不存在部分依赖关系</p><p>学生表中：学号是码，姓名、系名、系主任完全依赖于学号，不存在部分依赖关系</p><p>不过上面的表分开之后还存在两个问题</p><ol><li><strong>数据添加问题</strong>：增加新开设的系和系主任时，数据将会不合法。比如添加一个计算机系，系主任为xx，这时候由于学号和姓名不存在，也就是没有学生在这个系里，这个数据是不合法的。</li><li><strong>数据删除的问题</strong>：如果10010号学生被删除了，也就是这个系本来有学生，但是毕业后删除这个学生会导致这个系里没有数据，那么数据就变成不合法的了。</li></ol><h3 id="3-3-第三范式"><a href="#3-3-第三范式" class="headerlink" title="3.3 第三范式"></a>3.3 第三范式</h3><p>在2NF的基础上，任何非主属性不依赖于其他非主属性（在2NF的基础上<strong>消除传递依赖</strong>）</p><p>在3.2表中，学号被系名依赖，系名被系主任依赖，这样，<strong>系主任就传递依赖于学号</strong>。</p><p><img src="/2020/01/26/11-MySQL/2_SQL%E9%AB%98%E7%BA%A7/image-20200126112813445.png" alt="image-20200126112813445"></p><p>那就再拆一次，将系名与系主任从学生表中拆出来，专门放一个系表，这样就解决了2NF中不能解决系数据添加与删除的问题了。</p><h2 id="4-数据库的备份和还原"><a href="#4-数据库的备份和还原" class="headerlink" title="4. 数据库的备份和还原"></a>4. 数据库的备份和还原</h2><ol><li><p>命令行方式：</p><p>备份：</p><pre><code>mysqldump -u用户名 -p密码 数据库名 &gt; 保存的路径</code></pre><p>还原：</p><ol><li>登录数据库</li><li>创建数据库</li><li>使用数据库</li><li>执行文件</li></ol><pre><code>mysql -u用户名 -p密码CREATE DATABASE 数据库名;USE 数据库名;source 文件路径</code></pre></li><li><p>图形界面方式</p><p>通过图形界面的指定操作进行就可以了</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL语言基础</title>
      <link href="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="1-SQL语言"><a href="#1-SQL语言" class="headerlink" title="1. SQL语言"></a>1. SQL语言</h1><p>分类：</p><ul><li>DDL：操作数据库、数据表</li><li>DQL：查询表中数据</li><li>DML：增删改表中数据</li><li>DCL：用于授权</li></ul><h2 id="1-DDL"><a href="#1-DDL" class="headerlink" title="1. DDL"></a>1. DDL</h2><p>用来定义数据库对象:数据库，表，列等。 关键字：create,drop, alter等。</p><h3 id="1-1-操作数据库"><a href="#1-1-操作数据库" class="headerlink" title="1.1 操作数据库"></a>1.1 操作数据库</h3><ol><li><p><strong>创建</strong>（Create）</p><ul><li><p>创建数据库：</p><pre><code class="mysql">CREATE DATABASE 数据库名称;</code></pre></li><li><p>创建数据库，如果不存在才创建</p><pre><code class="mysql">CREATE DATABASE IF NOT EXISTS 数据库名称;</code></pre></li><li><p>创建数据库，并指定字符集</p><pre><code class="mysql">CREATE DATABASE 数据库名称 CHARACTER SET 字符集名;</code></pre></li><li><p>综合上面的一条语句：</p><pre><code class="mysql">CREATE DATABASE IF NOT EXISTS 数据库名称 CHARACTER SET 字符集名;</code></pre></li></ul></li><li><p><strong>查询</strong>（Retrieve）</p><ul><li><p>查询所有数据库的名称</p><pre><code class="mysql">SHOW DATABASES;</code></pre></li><li><p>查询某个数据库的字符集：查询某个数据库的创建语句</p><pre><code class="mysql">SHOW CREATE DATABASE 数据库名称;</code></pre></li></ul></li><li><p><strong>修改</strong>（Update）</p><ul><li><p>修改数据库的字符集</p><pre><code class="mysql">ALTER DATABASE 数据库名称 CHARACTER SET 字符集名称;</code></pre></li></ul></li><li><p><strong>删除</strong>（Delete）</p><ul><li><p>删除数据库</p><pre><code class="mysql">DROP DATABASE 数据库名称;</code></pre></li><li><p>判断数据库是否存在，如果存在则将其删除</p><pre><code class="mysql">DROP DATABASE IF EXISTS 数据库名称;</code></pre></li></ul></li><li><p><strong>使用</strong></p><ul><li><p>查询当前正在使用的数据库名称</p><pre><code class="mysql">SELECT DATABASE();</code></pre></li><li><p>使用当前使用的数据库</p><pre><code class="mysql">USE 数据库名称;</code></pre></li></ul></li></ol><h3 id="1-2-操作数据表"><a href="#1-2-操作数据表" class="headerlink" title="1.2 操作数据表"></a>1.2 操作数据表</h3><ol><li><p><strong>创建</strong>（Create）</p><ul><li><p>语法：</p><pre><code class="sql">CREATE TABLE 表名(    列名1 数据类型1,    列名2 数据类型2,    列名3 数据类型3,    ...);-- 最后一列不需要加逗号就可以了</code></pre></li><li><p>数据类型</p><p>不同数据库的数据类型描述语言是不太相同的，以MYSQL为例，分为以下这些：</p><ol><li><p>Text类型</p><table><thead><tr><th>数据类型</th><th>描述</th></tr></thead><tbody><tr><td>CHAR(size)</td><td>保存固定长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的长度。最多 255 个字符。</td></tr><tr><td>VARCHAR(size)</td><td>保存可变长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的最大长度。最多 255 个字符。如果值的长度大于 255，则被转换为 TEXT 类型。</td></tr><tr><td>TINYTEXT</td><td>存放最大长度为 255 个字符的字符串。</td></tr><tr><td>TEXT</td><td>存放最大长度为 65,535 个字符的字符串。</td></tr><tr><td>BLOB</td><td>用于 BLOBs (Binary Large OBjects)。存放最多 65,535 字节的数据。</td></tr><tr><td>MEDIUMTEXT</td><td>存放最大长度为 16,777,215 个字符的字符串。</td></tr><tr><td>MEDIUMBLOB</td><td>用于 BLOBs (Binary Large OBjects)。存放最多 16,777,215 字节的数据。</td></tr><tr><td>LONGTEXT</td><td>存放最大长度为 4,294,967,295 个字符的字符串。</td></tr><tr><td>LONGBLOB</td><td>用于 BLOBs (Binary Large OBjects)。存放最多 4,294,967,295 字节的数据。</td></tr><tr><td>ENUM(x,y,z,etc.)</td><td>允许你输入可能值的列表。可以在 ENUM 列表中列出最大 65535 个值。如果列表中不存在插入的值，则插入空值。注释：这些值是按照你输入的顺序存储的。可以按照此格式输入可能的值：ENUM(‘X’,’Y’,’Z’)</td></tr><tr><td>SET</td><td>与 ENUM 类似，SET 最多只能包含 64 个列表项，不过 SET 可存储一个以上的值。</td></tr></tbody></table></li></ol></li></ul></li></ol><pre><code> 2. Number类型    | 数据类型        | 说明                                                         |    | --------------- | ------------------------------------------------------------ |    | TINYINT(size)   | -128 到 127 常规。0 到 255 无符号*。在括号中规定最大位数。   |    | SMALLINT(size)  | -32768 到 32767 常规。0 到 65535 无符号*。在括号中规定最大位数。 |    | MEDIUMINT(size) | -8388608 到 8388607 普通。0 to 16777215 无符号*。在括号中规定最大位数。 |    | INT(size)       | -2147483648 到 2147483647 常规。0 到 4294967295 无符号*。在括号中规定最大位数。 |    | BIGINT(size)    | -9223372036854775808 到 9223372036854775807 常规。0 到 18446744073709551615 无符号*。在括号中规定最大位数。 |    | FLOAT(size,d)   | 带有浮动小数点的小数字。在括号中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 |    | DOUBLE(size,d)  | 带有浮动小数点的大数字。在括号中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 |    | DECIMAL(size,d) | 作为字符串存储的 DOUBLE 类型，允许固定的小数点。             | 3. Date类型    | 数据类型    | 说明                                                         |    | ----------- | ------------------------------------------------------------ |    | DATE()      | 日期。格式：YYYY-MM-DD，支持的范围是从 &#39;1000-01-01&#39; 到 &#39;9999-12-31&#39; |    | DATETIME()  | *日期和时间的组合。格式：YYYY-MM-DD HH:MM:SS，支持的范围是从 &#39;1000-01-01 00:00:00&#39; 到 &#39;9999-12-31 23:59:59&#39; |    | TIMESTAMP() | *时间戳。TIMESTAMP 值使用 Unix 纪元(&#39;1970-01-01 00:00:00&#39; UTC) 至今的描述来存储。格式：YYYY-MM-DD HH:MM:SS，支持的范围是从 &#39;1970-01-01 00:00:01&#39; UTC 到 &#39;2038-01-09 03:14:07&#39; UTC |    | TIME()      | 时间。格式：HH:MM:SS 注释：支持的范围是从 &#39;-838:59:59&#39; 到 &#39;838:59:59&#39; |    | YEAR()      | 2 位或 4 位格式的年。4 位格式所允许的值：1901 到 2155。2 位格式所允许的值：70 到 69，表示从 1970 到 2069。 | - 例子：   ```mysql   CREATE TABLE player  (       -- player_id int(11) NOT NULL AUTO_INCREMENT,       player_name varchar(255) NOT NULL,       create_time date,       player_score double(5,3)   );   ```   数据类型中 有下面这些关键字，可以解释如下：   - `int(11)`：代表整数类型，显示长度为 11 位，括号中的参数 11 代表的是最大有效显示长度，与类型包含的数值范围大小无关。   - `varchar(255)`：代表的是最大长度为 255 的可变字符串类型。   - `date`：如果不设置或者设置为null，则默认使用当前的时间。   - `double(5,3)`：表示double类型数据一共5位，小数3位。   - `NOT NULL`：表明整个字段不能是空值，是一种数据约束。   - `AUTO_INCREMENT`：代表主键自动增长。</code></pre><ol start="2"><li><p><strong>查询</strong>（Retrieve）</p><ul><li><p>查询某个数据库中所有表的名称</p><pre><code class="mysql">SHOW TABLES;</code></pre></li><li><p>查询表结构，也就是查看表中的详情</p><pre><code class="sql">DESC 表名;</code></pre></li></ul></li><li><p><strong>修改</strong>（Update）</p><ul><li><p>修改表名</p><pre><code class="mysql">ALTER TABLE 旧表名 RENAME TO 新表名;</code></pre></li><li><p>修改表的字符集</p><pre><code class="mysql">ALTER TABLE 表名 CHARACTER SET UTF8;</code></pre></li><li><p>添加列</p><pre><code class="mysql">ALTER TABLE 表名 ADD 列名 数据类型;</code></pre></li><li><p>修改列的名称和类型</p><pre><code class="mysql">ALTER TABLE 表名 CHANGE 旧列名 新列名 新列类型; -- 列名称和数据类型同时修改ALTER TABLE 表名 MODIFY 旧列名 新列类型; -- 只修改列的数据类型，不修改列名称</code></pre></li></ul></li><li><p><strong>删除</strong>（Delete）</p><ul><li><p>删除列</p><pre><code class="mysql">ALTER TABLE 表名 DROP 列名;</code></pre></li></ul></li></ol><h2 id="2-DML"><a href="#2-DML" class="headerlink" title="2. DML"></a>2. DML</h2><h3 id="2-1-添加数据"><a href="#2-1-添加数据" class="headerlink" title="2.1 添加数据"></a>2.1 添加数据</h3><pre><code class="mysql">INSERT INTO 表名(列名1, 列名2, ...列名n) VALUES(值1, 值2, ...值n);/*1. 列名与值需要一一对应2. 如果没有指定列名，则默认表示所有列，并且需要在VALUES里面把所有列的值写进去3. 如果不给值，则写为NULL4. 除了数字类型之外，其他类型需要使用引号来引起来，并且单双引号都可以*/</code></pre><h3 id="2-2-删除数据"><a href="#2-2-删除数据" class="headerlink" title="2.2 删除数据"></a>2.2 删除数据</h3><pre><code class="mysql">DELETE FROM 表名 [WHERE 条件]; -- 当条件满足时，就从指定表中删除 其中[]表示里面内容是可选项DELETE FROM 表名; -- 这种方式不管有多少条记录，就会执行多少次删除操作TRUNCATE TABLE 表名; -- 删除表，并且建立一个一模一样的空表，与上面不同在于会创建空表，并且只会执行两次语句，也就是drop 和 create，因此效率会更高</code></pre><h3 id="2-3-修改数据"><a href="#2-3-修改数据" class="headerlink" title="2.3 修改数据"></a>2.3 修改数据</h3><pre><code class="mysql">UPDATE 表名 SET 列名1 = 值1, 列名2 = 值2, ... [WHERE 条件];-- 删除满足指定条件的项的数据-- 注意：如果不加任何条件，则会将表中所有记录全部都修改掉，因此是非常危险的</code></pre><h2 id="3-DQL"><a href="#3-DQL" class="headerlink" title="3. DQL"></a>3. DQL</h2><p>用来查询数据库中表的记录(数据)。 关键字:select, where等</p><h3 id="3-1-查询语法"><a href="#3-1-查询语法" class="headerlink" title="3.1 查询语法"></a>3.1 查询语法</h3><pre><code class="mysql">SELECT         -- 字段列表FROM         -- 表名列表WHERE        -- 条件列表GROUP BY    -- 分组字段HAVING        -- 分组之后的条件ORDER BY    -- 排序LIMIT        -- 分页-- 所谓列表就是可以写多个</code></pre><h3 id="3-2-基础查询"><a href="#3-2-基础查询" class="headerlink" title="3.2 基础查询"></a>3.2 基础查询</h3><p>下面的查询内容都基于一个数据库，该数据库的定义如下：</p><pre><code class="mysql">CREATE TABLE student (    id int, -- 编号    name varchar(20), -- 姓名    age int, -- 年龄    sex varchar(5), -- 性别    address varchar(100), -- 地址    math int, -- 数学    english int -- 英语);INSERT INTO student(id,NAME,age,sex,address,math,english) VALUES (1,&#39;马云&#39;,55,&#39;男&#39;,&#39;杭州&#39;,66,78),(2,&#39;马化腾&#39;,45,&#39;女&#39;,&#39;深圳&#39;,98,87),(3,&#39;马景涛&#39;,55,&#39;男&#39;,&#39;香港&#39;,56,77),(4,&#39;柳岩&#39;,20,&#39;女&#39;,&#39;湖南&#39;,76,65),(5,&#39;柳青&#39;,20,&#39;男&#39;,&#39;湖南&#39;,86,NULL),(6,&#39;刘德华&#39;,57,&#39;男&#39;,&#39;香港&#39;,99,99),(7,&#39;马德&#39;,22,&#39;女&#39;,&#39;香港&#39;,99,99),(8,&#39;德玛西亚&#39;,18,&#39;男&#39;,&#39;南京&#39;,56,65);</code></pre><ol><li><p><strong>多个字段的查询</strong></p><p>注意：如果查询所有字段，则可以使用 <code>*</code> 来代替字段的列表。</p><pre><code class="mysql">SELECT    name,    ageFROM    student;</code></pre></li><li><p><strong>去除重复</strong></p><p>去除重复仅需要在SELECT后面加上DISTINCT。注意，如果去重，需要两条查询出来的记录完全一样（而不是原始记录一样）</p><pre><code class="mysql">SELECTDISTINCT    name,    ageFROM    student;</code></pre></li><li><p><strong>计算列</strong></p><p>相当于直接定义出一个新列，可以对其进行操作，但是，如果两列中其中之一为NULL，则结果就为NULL</p><pre><code class="mysql">SELECT    name,    math,    english,    math + englishFROM    student;</code></pre><p>结果如下：</p><img src="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/image-20200120164721429.png" alt="image-20200120164721429" style="zoom:80%;"><p>但是，正常使用的时候，如果english为NULL，想要将其按照0来处理，则需要使用一个IFNULL来操作，比如下面：</p><pre><code class="mysql">SELECT    name,    math,    english,    math + IFNULL(english, 0)FROM    student;</code></pre><img src="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/image-20200120164942272.png" alt="image-20200120164942272" style="zoom:80%;"><p>就成了想要的形式了。</p></li><li><p><strong>起别名</strong></p><p>上面那个，因为math + ifnull(english, 0)太长了，而且不便于理解，因此可以给他起一个别名，用AS就可以了。甚至说AS也可以不用，只需要加空格就行了。</p><pre><code class="mysql">SELECT    name 姓名,    math 数学,    english 英语,    math + IFNULL(english, 0) AS 总分FROM    student;</code></pre><img src="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/image-20200120165307118.png" alt="image-20200120165307118" style="zoom:80%;"></li></ol><h3 id="3-3-条件查询"><a href="#3-3-条件查询" class="headerlink" title="3.3 条件查询"></a>3.3 条件查询</h3><ul><li><p>where子句后跟条件</p></li><li><p>运算符</p><ul><li><p><code>&gt; &lt; &lt;= &gt;= = != &lt;&gt;</code>，其中<code>&lt;&gt;</code>表示不等于，在mysql中可以使用==，但是没有!=这个运算符</p><pre><code class="mysql">SELECT * FROM student WHERE age &gt; 20;        -- 大于SELECT * FROM student WHERE age &lt; 20;        -- 小于SELECT * FROM student WHERE age = 20;        -- 等于，注意等于是一个等号，不是两个SELECT * FROM student WHERE age != 20;        -- 不等于SELECT * FROM student WHERE age &lt;&gt; 20;        -- 不等于</code></pre></li><li><p>区间条件</p><p>“<strong>与</strong>” 关系</p><pre><code class="mysql">SELECT * FROM student WHERE age &gt;= 20 &amp;&amp; age &lt;= 30;SELECT * FROM student WHERE age &gt;= 20 AND age &lt;= 30;SELECT * FROM student WHERE age BETWEEN 20 AND 30;        -- 包含左右区间</code></pre><p>“<strong>或</strong>” 关系</p><pre><code class="mysql">SELECT * FROM student WHERE age = 20 || age = 23;SELECT * FROM student WHERE age = 20 OR age = 23 OR age = 17;SELECT * FROM student WHERE age IN (17, 20, 23);</code></pre><p>“<strong>NULL</strong>” 关系</p><pre><code class="mysql">SELECT * FROM student WHERE english IS NULL;    -- 查询为空的记录，注意不能使用=或者!=SELECT * FROM student WHERE english IS NOT NULL;    -- 查询不为空的记录</code></pre></li></ul></li></ul><h3 id="3-4-模糊查询"><a href="#3-4-模糊查询" class="headerlink" title="3.4 模糊查询"></a>3.4 模糊查询</h3><p>模糊查询其实也是条件查询的一种，查询的结果并不需要与查询条件完全相同，需要理解的是占位符：</p><ul><li><code>_</code>：匹配1个任意字符</li><li><code>%</code>：匹配0个或多个任意字符</li></ul><pre><code class="mysql">SELECT * FROM student WHERE name LIKE &#39;马%&#39;;        -- 查询第一个字是马的人SELECT * FROM student WHERE name LIKE &#39;_化%&#39;;    -- 查询第二个字是化的人SELECT * FROM student WHERE name LIKE &#39;___&#39;;     -- 查询name是三个字的人SELECT * FROM student WHERE name LIKE &#39;%腾%&#39;;    -- 查询包含腾的人，因为%可以匹配任意个字符</code></pre><img src="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/image-20200125131308376.png" alt="image-20200125131308376" style="zoom:80%;"><h3 id="3-5-排序查询"><a href="#3-5-排序查询" class="headerlink" title="3.5 排序查询"></a>3.5 排序查询</h3><ul><li><p>语法：</p><pre><code class="mysql">ORDER BY 排序字段1 排序方式1, 排序字段2 排序方式2, ...; -- 注意，如果有多个排序条件，只有前面字段排序结果相同的时候，后面的排序字段才会被判断</code></pre><p>排序方式：</p><ol><li><code>ASC</code>：升序，默认排序方式，如果不指定则为升序</li><li><code>DESC</code>：降序</li></ol><pre><code class="mysql">SELECT * FROM student ORDER BY math ;        -- 如果不写排序方式，则默认为从小到大SELECT * FROM student ORDER BY math DESC;    -- 按照降序排列</code></pre></li><li><p>例子</p><p>按照数学成绩排名，如果数学成绩一样，则按照英语成绩排名</p><pre><code class="mysql">SELECT * FROM student ORDER BY math ASC, english ASC;</code></pre><img src="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/image-20200125132813440.png" alt="image-20200125132813440" style="zoom:80%;"></li></ul><h3 id="3-6-聚合函数"><a href="#3-6-聚合函数" class="headerlink" title="3.6 聚合函数"></a>3.6 聚合函数</h3><p>将一列数据作为一个整体，进行<strong>纵向计算</strong>，类似于求成绩的平均分等操作。</p><ul><li><p>语法</p><p><code>COUNT</code>：计算个数</p><p><code>MAX</code>：计算最大值</p><p><code>MIN</code>：计算最小值</p><p><code>SUM</code>：求和</p><p><code>AVG</code>：计算平均值</p><p><strong>注意</strong>：具体函数的计算会排除NULL，即如果遇到NULL的数据将不会统计。</p><pre><code class="mysql">SELECT COUNT(name) FROM student; -- 输出为8，也就表示name中有8条记录-- 如果需要统计NULL，有两种方法：SELECT COUNT(IFNULL(english, 0)) FROM student; -- 将NULL转为0-- 选择不包含空的列进行计算，一般为主键-- 还有一种方式，不太常用SELECT COUNT(*) FROM student; -- 使用*表示只要有一个列不为空，就都统计上，但是一般不使用-- 注意以下的这几种操作都会排除NULL的记录，只统计不为NULL的数据SELECT MAX(math) FROM student;SELECT MIN(math) FROM student;SELECT SUM(math) FROM student;SELECT AVG(math) FROM student;</code></pre></li></ul><h3 id="3-7-分组查询"><a href="#3-7-分组查询" class="headerlink" title="3.7 分组查询"></a>3.7 分组查询</h3><p>也就是将整个表分成多个组，来统计具有相同特征的某一类数据，将他们当做一个整体。</p><ul><li><p>语法</p><p>使用<code>GROUP BY</code>关键字来操作</p><p><strong>注意</strong>：</p><ol><li><p>分组之后，查询的字段为：分组字段、聚合函数。</p><p>不可以写其他的字段。比如下面图中，红圈中的内容是分组字段，紫圈中的内容是聚合函数。</p><img src="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/image-20200125134358383.png" alt="image-20200125134358383" style="zoom:80%;"></li><li><p><code>WHERE</code> 与 <code>HAVING</code> 的区别：</p><p><code>WHERE</code>：在分组之前限定，如果不满足条件，则不参与分组，并且 <code>WHERE</code> 后面不能跟聚合函数</p><p><code>HAVING</code>：在分组之后进行限定，如果不满足结果，则不会被查询出来，<code>HAVING</code> 后面可以跟聚合函数</p></li></ol></li><li><p>例子</p><p>按照性别进行分组，分别查询男女的平均分</p></li></ul><pre><code class="mysql">SELECT sex, AVG(math) FROM student GROUP BY sex;    -- 查询男、女的平均分SELECT sex, AVG(math), COUNT(id) FROM student GROUP BY sex; -- 包含主键SELECT sex, AVG(math), COUNT(id) FROM student WHERE math &gt; 70 GROUP BY sex;-- 低于70分的不参与分组SELECT sex, AVG(math), COUNT(id) 人数 FROM student WHERE math &gt; 70 GROUP BY sex HAVING COUNT(id) &gt; 2;-- 低于70分的不参与分组，且分组之后的人数要大于2个人，并且将COUNT(id)改成人数</code></pre><h3 id="3-8-分页查询"><a href="#3-8-分页查询" class="headerlink" title="3.8 分页查询"></a>3.8 分页查询</h3><ul><li><p>语法：</p><pre><code class="mysql">LIMIT 开始的索引, 每页查询的条数;</code></pre><ol><li><p>从客户端查询的方式一般都是页码和页大小，因此需要计算索引。</p><p>计算公式：<code>索引 = (当前的页码 - 1) * 每页显示的条数;</code></p></li><li><p>如果没有那么多数据，则有多少就显示多少</p></li></ol></li><li><p>例子：</p><pre><code class="mysql"> SELECT * FROM student ORDER BY math ASC, english ASC LIMIT 0, 5; -- 表示从第0条开始，往后数5条</code></pre><p>limit只能在mysql中使用（即limit是一个mysql的“方言”），在其他的数据库中不能使用，需要使用其他的关键词才可以进行分页查询操作</p></li></ul><h2 id="4-DCL"><a href="#4-DCL" class="headerlink" title="4. DCL"></a>4. DCL</h2><h3 id="4-1-管理用户"><a href="#4-1-管理用户" class="headerlink" title="4.1 管理用户"></a>4.1 管理用户</h3><ol><li><p><strong>添加用户</strong></p><p>语法：</p><pre><code class="mysql">CREATE USER &#39;用户名&#39;@&#39;主机名&#39; IDENTIFIED BY &#39;密码&#39;;-- 这里的主机名如果是localhost表示只能在本机使用，如果是%通配符，则表示可以在任意电脑上使用CREATE USER &#39;zhangsan&#39;@&#39;%&#39; IDENTIFIED BY &#39;root&#39;;</code></pre><img src="/2020/01/23/11-MySQL/1_SQL%E8%AF%AD%E8%A8%80%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/image-20200126222210956.png" alt="image-20200126222210956" style="zoom:80%;"></li><li><p><strong>删除用户</strong></p><p>语法：</p><pre><code class="mysql">DROP USER &#39;用户名&#39;@&#39;主机名&#39;;</code></pre></li><li><p><strong>修改用户密码</strong></p><p>修改一般用户的密码：</p><pre><code class="mysql">UPDATE USER SET PASSWORD = PASSWORD(&#39;新密码&#39;) WHERE USER = &#39;用户名&#39;;SET PASSWORD FOR &#39;用户名&#39;@&#39;主机名&#39; = PASSWORD(&#39;新密码&#39;);-- 下面的这个是DCL特有的方式</code></pre><p>修改root用户的密码：</p><p>如果忘记了root用户的密码，</p><ul><li><p>先停掉mysql服务，在cmd中执行：</p><pre><code>net stop mysql # 需要管理员权限</code></pre></li><li><p>使用无验证方式启动mysql服务</p><pre><code>mysqld --skip-grant-tables</code></pre><p>然后打开一个新的cmd窗口，直接输入mysql就可以启动了</p></li><li><p>使用mysql语句修改密码</p><pre><code class="mysql">USE mysql;UPDATE USER SET PASSWORD = PASSWORD(&#39;新密码&#39;) WHERE USER = &#39;root&#39;;</code></pre></li><li><p>关闭mysqld进程</p></li><li><p>启动mysql服务</p></li><li><p>使用新密码登录</p></li></ul></li><li><p><strong>查询用户</strong></p><ul><li><p>切换到mysql数据库</p><pre><code class="mysql">USE mysql;</code></pre></li><li><p>查询user表</p><pre><code class="mysql">SELECT * FROM USER;</code></pre></li></ul></li></ol><h3 id="4-2-管理权限"><a href="#4-2-管理权限" class="headerlink" title="4.2 管理权限"></a>4.2 管理权限</h3><p>之前在查询用户的时候，每个用户后面都有很多的权限，比如下图中所示的内容，因此，并不是每一个用户都有所有的权限，这些权限是可以授予或撤销的。</p><ol><li><p><strong>查询权限</strong></p><pre><code class="mysql">SHOW GRANTS FOR &#39;用户名&#39;@&#39;主机名&#39;;</code></pre></li><li><p><strong>授予权限</strong></p><pre><code class="mysql">GRANT 权限列表 ON 数据库名.表名 TO &#39;用户名&#39;@&#39;主机名&#39;;-- 例如：给李四查询的权限GRANT SELECT ON db3.account TO &#39;lisi&#39;@&#39;%&#39;;</code></pre><p>只有授权过的表才可以被看到，如果没有进行授权，则甚至都无法使用SHOW展示出来，更不必说其他的操作。</p><p>授予某个用户在所有数据库的所有表上的所有权限</p><pre><code class="mysql">GRANT ALL *.* TO &#39;用户名&#39;@&#39;主机名&#39;;-- 所有权限的通配符为ALL-- 所有库和表的通配符为*</code></pre></li><li><p><strong>撤销权限</strong></p><pre><code class="mysql">REVOKE 权限列表 ON 数据库名.表名 FROM &#39;用户名&#39;@&#39;主机名&#39;;-- 例如，撤销李四在db3的account表上面的更新权限REVOKE UPDATE ON db3.account FROM &#39;lisi&#39;@&#39;%&#39;;</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java使用protobuf</title>
      <link href="/2020/01/16/10-java%E7%BD%91%E7%BB%9C/2_protobuf/"/>
      <url>/2020/01/16/10-java%E7%BD%91%E7%BB%9C/2_protobuf/</url>
      
        <content type="html"><![CDATA[<h1 id="protobuf"><a href="#protobuf" class="headerlink" title="protobuf"></a>protobuf</h1><h2 id="1-定义与概念"><a href="#1-定义与概念" class="headerlink" title="1. 定义与概念"></a>1. 定义与概念</h2><p>文档中给出的定义为：protobuf是一种用于序列化结构化数据的灵活，高效，自动化的机制。</p><p>您只需要定义数据结构一次，然后可以使用生成的特殊源代码轻松地使用各种语言在各种数据流中写入和读取结构化数据。 您甚至可以更新数据结构，而不会破坏已针对“旧”格式编译的已部署程序。</p><p>通过在.proto文件中定义protobuf的消息类型，指定要序列化的信息的结构。 每个protobuf消息都是一个小的逻辑信息记录，其中包含一系列名称/值对。 这是.proto文件的一个非常基本的示例，该文件定义了一条包含有关Person的信息的消息：</p><pre><code class="protobuf">message Person {    required string name = 1;    required int32 id = 2;    optional string email = 3;    enum PhoneType {        MOBILE = 0;        HOME = 1;        WORK = 2;    }    message PhoneNumber {        required string number = 1;        optional PhoneType type = 2 [default = HOME];    }    repeated PhoneNumber phone = 4;}</code></pre><p>每个消息类型都有一个或多个唯一编号的字段，每个字段都有一个名称和一个值类型，其中值类型可以是数字（int或float），bool，string ，byte，其他protobuf消息类型。</p><p>定义消息后，就可以在.proto文件上为应用程序的语言运行protobuf编译器，以生成数据访问类。 这些为每个字段提供了简单的访问器（例如<code>name()</code>和<code>set_name()</code>），以及将整个结构序列化为原始字节或从原始字节中解析出整个结构的方法，例如使用C++可以通过下面的方式来使用：</p><pre><code class="c++">Person person;person.set_name(&quot;John Doe&quot;);person.set_id(1234);person.set_email(&quot;jdoe@example.com&quot;);fstream output(&quot;myfile&quot;, ios::out | ios::binary);person.SerializeToOstream(&amp;output);</code></pre><h2 id="2-对比xml"><a href="#2-对比xml" class="headerlink" title="2. 对比xml"></a>2. 对比xml</h2><p>protobuf相比于xml，它的优势如下：</p><ul><li>更简单</li><li>小3到10倍</li><li>快20到100倍</li><li>不那么模棱两可</li><li>生成易于通过编程使用的数据访问类</li></ul><h3 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h3><p>例如，如果要定义一个Person类，如果使用xml，则需要这样写：</p><pre><code class="xml">&lt;person&gt;    &lt;name&gt;John Doe&lt;/name&gt;    &lt;email&gt;jdoe@example.com&lt;/email&gt;&lt;/person&gt;</code></pre><p>如果是protobuf，则可以写成这样：</p><pre><code class="protobuf">person {    name: &quot;John Doe&quot;    email: &quot;jdoe@example.com&quot;}</code></pre><h3 id="2-2-二进制大小"><a href="#2-2-二进制大小" class="headerlink" title="2.2 二进制大小"></a>2.2 二进制大小</h3><p>当上面的内容被编写为二进制格式时，其占用的空间大小为：</p><ul><li>protobuf：28字节，解析时间为100-200ns</li><li>xml：69字节，解析时间为5000-10000ns</li></ul><h3 id="2-3-使用便捷性"><a href="#2-3-使用便捷性" class="headerlink" title="2.3 使用便捷性"></a>2.3 使用便捷性</h3><ul><li><p>protobuf：</p><pre><code class="c++">cout &lt;&lt; &quot;Name: &quot;      &lt;&lt; person.name()     &lt;&lt; endl;cout &lt;&lt; &quot;E-mail: &quot;      &lt;&lt; person.email()      &lt;&lt; endl;</code></pre></li><li><p>xml：</p><pre><code class="c++">cout &lt;&lt; &quot;Name: &quot;     &lt;&lt; person.getElementsByTagName(&quot;name&quot;)-&gt;item(0)-&gt;innerText()     &lt;&lt; endl;cout &lt;&lt; &quot;E-mail: &quot;     &lt;&lt; person.getElementsByTagName(&quot;email&quot;)-&gt;item(0)-&gt;innerText()     &lt;&lt; endl;</code></pre></li></ul><h3 id="2-4-局限性"><a href="#2-4-局限性" class="headerlink" title="2.4 局限性"></a>2.4 局限性</h3><p>但是，protobuf并不总是比XML更好的解决方案</p><ul><li>protobuf不是用标记（例如HTML）为基于文本的文档建模的好方法，不能轻易地使结构与文本交错。 </li><li>另外，XML是人类可读和可编辑的。 protobuf（至少以其本机格式）不是。 </li><li>XML在某种程度上也是<strong>自描述</strong>的。 仅当您具有消息定义（.proto文件）时，protobuf才有意义。</li></ul><h2 id="3-在maven中配置"><a href="#3-在maven中配置" class="headerlink" title="3. 在maven中配置"></a>3. 在maven中配置</h2><p>要在maven中使用protobuf，则需要做的有以下几件事情：</p><ul><li><p>在pom文件中添加配置</p><pre><code class="xml">&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt;        &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt;        &lt;version&gt;3.2.0&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt;    &lt;defaultGoal&gt;package&lt;/defaultGoal&gt;    &lt;extensions&gt;        &lt;extension&gt;            &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt;            &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt;            &lt;version&gt;1.5.0.Final&lt;/version&gt;        &lt;/extension&gt;    &lt;/extensions&gt;    &lt;plugins&gt;        &lt;!-- protobuf 编译组件 --&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt;            &lt;version&gt;0.5.1&lt;/version&gt;            &lt;extensions&gt;true&lt;/extensions&gt;            &lt;configuration&gt;                &lt;protoSourceRoot&gt;${project.basedir}/src/main/proto&lt;/protoSourceRoot&gt;                &lt;protocArtifact&gt;com.google.protobuf:protoc:3.2.0:exe:${os.detected.classifier}&lt;/protocArtifact&gt;            &lt;/configuration&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;goals&gt;                        &lt;goal&gt;compile&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;        &lt;!-- 编译jar包的jdk版本 --&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;            &lt;version&gt;3.1&lt;/version&gt;            &lt;configuration&gt;                &lt;source&gt;${java.version}&lt;/source&gt;                &lt;target&gt;${java.version}&lt;/target&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;</code></pre></li></ul><ul><li><p>在idea中添加插件，在商店中搜索protobuf support即可</p><img src="/2020/01/16/10-java%E7%BD%91%E7%BB%9C/2_protobuf/image-20200115172522009.png" alt="image-20200115172522009" style="zoom:80%;"></li><li><p>更改识别后缀名，可以在编辑proto文件的时候能够高亮显示。</p><img src="/2020/01/16/10-java%E7%BD%91%E7%BB%9C/2_protobuf/image-20200115172452881.png" alt="image-20200115172452881" style="zoom:80%;"></li></ul><p>以上三步配置完成之后，就可以在maven中看到下面这些操作了！</p><img src="/2020/01/16/10-java%E7%BD%91%E7%BB%9C/2_protobuf/image-20200115172714689.png" alt="image-20200115172714689" style="zoom:80%;"><p>写完proto文件后，可以通过这一个操作来编译proto文件，并生成java。此后就可以正常使用了！！</p><h2 id="4-语法"><a href="#4-语法" class="headerlink" title="4. 语法"></a>4. 语法</h2><h3 id="4-1-指定版本与包"><a href="#4-1-指定版本与包" class="headerlink" title="4.1 指定版本与包"></a>4.1 指定版本与包</h3><p>在proto文件的第一行添加下面一条语句表示使用protobuf3版本，如果没有本行语句，则默认使用protobuf2。</p><p>同时，使用package可以指定包名，类似于namespace，解决不同消息的命名冲突问题。</p><pre><code class="protobuf">syntax = &quot;proto3&quot;;package test; //声明了一个包名，用来防止不同的消息类型命名冲突，类似于 namespace </code></pre><h3 id="4-2-消息内容"><a href="#4-2-消息内容" class="headerlink" title="4.2 消息内容"></a>4.2 消息内容</h3><p>消息由至少一个字段组合而成，类似于C语言中的结构，使用message关键字作为开头，每个字段都有一定的格式。</p><p><strong>字段格式</strong>：</p><p><strong>限定修饰符① | 数据类型② | 字段名称③ | = | 标识号④ | [默认值⑤]</strong></p><p>例如下面的一个消息定义</p><pre><code class="protobuf">message SearchRequest {    required string query = 1 [default = &quot;空&quot;];    repeated int32 page_number = 2;    optional int32 result_per_page = 3;    string requestID;}</code></pre><p>字段中有以下三个要素：</p><ul><li><p><strong>① 限定修饰符</strong></p><p><strong>在protobuf3中，限定修饰符只有两种：不写或者为repeated</strong>，但是在protobuf2中，限定修饰符有以下四种</p><ul><li><p>空：被修饰的字段有0个或者1个这种字段（不能超过1个）</p></li><li><p>repeated：被修饰的字段可以重复任意多次（包括0次）。重复值的顺序会被保留。</p></li><li><p>required：表示是一个必须字段，必须相对于发送方，在发送消息之前必须设置该字段的值，对于接收方，必须能够识别该字段的意思。发送之前没有设置required字段或者无法识别required字段都会引发编解码异常，导致消息被丢弃。</p></li><li><p>optional：表示是一个可选字段，可选对于发送方，在发送消息时，可以有选择性的设置或者不设置该字段的值。对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则忽略该字段，消息中的其它字段正常处理。</p><blockquote><p>因为optional字段的特性，很多接口在升级版本中都把后来添加的字段都统一的设置为optional字段，这样老的版本无需升级程序也可以正常的与新的软件进行通信，只不过新的字段无法识别而已，因为并不是每个节点都需要新的功能，因此可以做到按需升级和平滑过渡。</p></blockquote></li></ul></li><li><p><strong>② 数据类型</strong></p><p>例如query的字段类型就是string，page_number的字段类型是int32，result_per_page的字段类型是int32。</p><p>关于具体的数据类型在4.3中详细列出</p></li><li><p><strong>④ 标识号</strong></p><p><strong>每个字段</strong>都有唯一的一个数字标识符。这些标识符是用来在消息的二进制格式中识别各个字段的，一旦开始使用就不能够再改变。</p><blockquote><p>注：[1,15]之内的标识号在编码的时候会占用1个字节。[16,2047]之内的标识号则占用2个字节。</p><p>所以应该为那些频繁出现的消息元素保留 [1,15]之内的标识号。</p><p>切记：要为将来有可能添加的、频繁出现的标识号预留一些标识号。 </p></blockquote></li><li><p><strong>⑤ 默认值</strong></p><p>只有proto2中使用默认值，在proto3中的默认值是不可以使用的。</p></li></ul><h3 id="4-3-数据类型"><a href="#4-3-数据类型" class="headerlink" title="4.3 数据类型"></a>4.3 数据类型</h3><ul><li><p>基础类型：</p><table><thead><tr><th align="center">proto</th><th align="center">java</th><th align="center">C++</th><th>备注</th></tr></thead><tbody><tr><td align="center">double</td><td align="center">double</td><td align="center">double</td><td></td></tr><tr><td align="center">float</td><td align="center">float</td><td align="center">float</td><td></td></tr><tr><td align="center">int32</td><td align="center">int</td><td align="center">int32</td><td>使用可变长编码方式。编码负数时不够高效——如果你的字段可能含有负数，那么请使用sint32。</td></tr><tr><td align="center">int64</td><td align="center">long</td><td align="center">int64</td><td>使用可变长编码方式。编码负数时不够高效——如果你的字段可能含有负数，那么请使用sint64。</td></tr><tr><td align="center">unit32</td><td align="center">int[1]</td><td align="center">unit32</td><td>总是4个字节。如果数值总是比总是比228大的话，这个类型会比uint32高效。</td></tr><tr><td align="center">unit64</td><td align="center">long[1]</td><td align="center">unit64</td><td>总是8个字节。如果数值总是比总是比256大的话，这个类型会比uint64高效。</td></tr><tr><td align="center">sint32</td><td align="center">int</td><td align="center">int32</td><td>使用可变长编码方式。有符号的整型值。编码时比通常的int32高效。</td></tr><tr><td align="center">sint64</td><td align="center">long</td><td align="center">int64</td><td>使用可变长编码方式。有符号的整型值。编码时比通常的int64高效。</td></tr><tr><td align="center">fixed32</td><td align="center">int[1]</td><td align="center">unit32</td><td></td></tr><tr><td align="center">fixed64</td><td align="center">long[1]</td><td align="center">unit64</td><td>总是8个字节。如果数值总是比总是比256大的话，这个类型会比uint64高效。</td></tr><tr><td align="center">sfixed32</td><td align="center">int</td><td align="center">int32</td><td>总是4个字节。</td></tr><tr><td align="center">sfixed64</td><td align="center">long</td><td align="center">int64</td><td>总是8个字节。</td></tr><tr><td align="center">bool</td><td align="center">boolean</td><td align="center">bool</td><td></td></tr><tr><td align="center">string</td><td align="center">String</td><td align="center">string</td><td>一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本。</td></tr><tr><td align="center">bytes</td><td align="center">ByteString</td><td align="center">string</td><td>可能包含任意顺序的字节数据</td></tr></tbody></table></li><li><p>特殊字段</p><table><thead><tr><th>英文</th><th>中文</th><th>备注</th></tr></thead><tbody><tr><td>enum</td><td>枚举(数字从零开始) 作用是为字段指定某”预定义值序列”</td><td>enum Type {MAN = 0;WOMAN = 1; OTHER= 3;}</td></tr><tr><td>message</td><td>消息体</td><td>message User{}</td></tr><tr><td>repeated</td><td>数组/集合</td><td>repeated User users = 1</td></tr><tr><td>import</td><td>导入定义</td><td>import “protos/other_protos.proto”</td></tr><tr><td>//</td><td>注释</td><td>//用于注释</td></tr><tr><td>extend</td><td>扩展</td><td>extend User {}</td></tr><tr><td>package</td><td>包名</td><td>相当于命名空间，用来防止不同消息类型的明明冲突</td></tr></tbody></table></li></ul><h3 id="4-4-service"><a href="#4-4-service" class="headerlink" title="4.4 service"></a>4.4 service</h3><ul><li><p>定义服务</p><p>如果想要将消息类型用在RPC(远程方法调用)系统中，可以在.proto文件中定义一个RPC服务接口，protocol buffer编译器将会根据所选择的不同语言生成服务接口代码及存根。如，想要定义一个RPC服务并具有一个方法，该方法能够接收 SearchRequest并返回一个SearchResponse，此时可以在.proto文件中进行如下定义：</p><pre><code class="protobuf">service SearchService {  rpc Search (SearchRequest) returns (SearchResponse);}</code></pre></li></ul><h3 id="4-5-option"><a href="#4-5-option" class="headerlink" title="4.5 option"></a>4.5 option</h3><p>在proto文件开始的时候使用option来定义的值表示一些可选项，有以下这些：</p><ul><li><p><code>option java_multiple_files = true;</code></p></li><li><p><code>option java_package = &quot;test.package1&quot;;</code></p><p>表明生成java类所在的包。如果在.proto文件中没有明确的声明java_package，就采用默认的包名。 </p><p>例如 <code>option java_package = &quot;com.example.foo&quot;;</code>后面proto编译生成的java类就属于这个包。</p><blockquote><p>java_package指定生成的类应该以什么样的java包名存在。如果没有明确指定，它只是与包声明中给出的包名相匹配，但是这些名称通常不是合适的Java包名(因为它们通常不以域名开头)。java_outer_classname选项定义了应该包含该文件中所有类的类名。如果没有明确给出java_outer_classname，它将通过将文件名转换为camel大小写来生成。例如，默认情况下，“my_proto.proto”将使用“MyProto”作为外部类名。</p></blockquote></li><li><p><code>option java_outer_classname = &quot;TestClass1&quot;;</code></p><p>是文件级别的选项，表明<strong>想要生成Java类的名称</strong>。如果在.proto文件中没有明确的java_outer_classname定义，生成的class名称将会根据.proto文件的名称采用驼峰式的命名方式进行生成。如（foo_bar.proto生成的java类名为FooBar.java）,如果不生成java代码，则该选项不起任何作用。</p></li></ul><p>前面提到的java_package和java_outer_classname和生成的java文件之间的关系如下：箭头指向的java文件就是通过proto文件生成的java类</p><p><img src="/2020/01/16/10-java%E7%BD%91%E7%BB%9C/2_protobuf/image-20200116103419529.png" alt="image-20200116103419529"></p><h2 id="5-使用"><a href="#5-使用" class="headerlink" title="5. 使用"></a>5. 使用</h2><p>在编译生成java类之后，在需要使用的地方直接将其import进来就可以了。</p><p>下面是一个例子：</p><h3 id="5-1-proto文件定义"><a href="#5-1-proto文件定义" class="headerlink" title="5.1 proto文件定义"></a>5.1 proto文件定义</h3><pre><code class="protobuf">syntax = &quot;proto3&quot;;     // 指定protobuf的版本为3package tutorial;      // 指定命名空间为tutorialoption java_package = &quot;com.example.tutorial&quot;;        // 生成的java类的package名字option java_outer_classname = &quot;AddressBookProtos&quot;;    // 生成的java类名称message Person {    string name = 1;    int32 id = 2;    string email = 3;    enum PhoneType {        MOBILE = 0;        HOME = 1;        WORK = 2;    }    message PhoneNumber {        string number = 1;        PhoneType type = 2;    }    repeated PhoneNumber phones = 4;}message AddressBook {    repeated Person people = 1;}</code></pre><p>通过这个proto文件生成的java类实际上是一个标准的javabean风格的类，可以访问其中的各个字段，并且可以对各个字段进行读写操作。</p><h3 id="5-2-访问message中的各个字段"><a href="#5-2-访问message中的各个字段" class="headerlink" title="5.2 访问message中的各个字段"></a>5.2 访问message中的各个字段</h3><p>对于Person类，会生成以下这些方法来对message中的各个字段进行访问：</p><pre><code class="java">// string name = 1;public boolean hasName();public String getName();// int32 id = 2;public boolean hasId();public int getId();// string email = 3;public boolean hasEmail();public String getEmail();// repeated .tutorial.Person.PhoneNumber phones = 4;public List&lt;PhoneNumber&gt; getPhonesList();public int getPhonesCount();public PhoneNumber getPhones(int index);</code></pre><h3 id="5-3-Builder"><a href="#5-3-Builder" class="headerlink" title="5.3 Builder"></a>5.3 Builder</h3><h4 id="5-3-1-读取、设置字段"><a href="#5-3-1-读取、设置字段" class="headerlink" title="5.3.1 读取、设置字段"></a>5.3.1 读取、设置字段</h4><p>builder中可以对各个字段进行判断有无、读取、设置，并且可以使用clear进行清除。</p><pre><code class="java">// required string name = 1;public boolean hasName();public java.lang.String getName();public Builder setName(String value);public Builder clearName();// required int32 id = 2;public boolean hasId();public int getId();public Builder setId(int value);public Builder clearId();// optional string email = 3;public boolean hasEmail();public String getEmail();public Builder setEmail(String value);public Builder clearEmail();// repeated .tutorial.Person.PhoneNumber phones = 4;public List&lt;PhoneNumber&gt; getPhonesList();public int getPhonesCount();public PhoneNumber getPhones(int index);public Builder setPhones(int index, PhoneNumber value);public Builder addPhones(PhoneNumber value);public Builder addAllPhones(Iterable&lt;PhoneNumber&gt; value);public Builder clearPhones();</code></pre><h4 id="5-3-2-标准化方法"><a href="#5-3-2-标准化方法" class="headerlink" title="5.3.2 标准化方法"></a>5.3.2 标准化方法</h4><p>Builder中还有一些处理标准化的方法，如下所示：</p><pre><code class="java">isInitialized();             // 检查是否所有必填字段都已设置。toString();                    // 返回字符串消息。mergeFrom(Message other);     // (仅Builder) 将其他的内容合并到此消息中，                           //覆盖单个标量字段，合并复合字段，并连接重复的字段。clear();                    // (仅Builder) 将所有字段清除回空状态。</code></pre><h4 id="5-3-3-解析与序列化"><a href="#5-3-3-解析与序列化" class="headerlink" title="5.3.3 解析与序列化"></a>5.3.3 解析与序列化</h4><pre><code class="java">byte[] toByteArray();    //序列化消息并返回包含原始字节的字节数组。static Person parseFrom(byte[] data);    //解析给定字节数组中的消息。void writeTo(OutputStream output);    //序列化消息并将其写入输出流。static Person parseFrom(InputStream input);    //读取并解析来自输入流的消息。</code></pre><h3 id="5-4-创建实例"><a href="#5-4-创建实例" class="headerlink" title="5.4 创建实例"></a>5.4 创建实例</h3><pre><code class="java">Person john =    Person.newBuilder()        .setId(1234)        .setName(&quot;John&quot;)        .setEmail(&quot;jdoe@example.com&quot;)        .addPhones( // 注意，对于repeated的类型，需要使用add而不是set            Person.PhoneNumber.newBuilder()                .setNumber(&quot;555-4321&quot;)                .setType(Person.PhoneType.HOME)        )        .build();</code></pre><h3 id="5-5-实际使用"><a href="#5-5-实际使用" class="headerlink" title="5.5 实际使用"></a>5.5 实际使用</h3><h4 id="5-5-1-生成消息"><a href="#5-5-1-生成消息" class="headerlink" title="5.5.1 生成消息"></a>5.5.1 生成消息</h4><p>下面这些代码的作用就是将输入的内容转换为protobuf类型的消息类型，并且将其写入文件，文件名为argv[0]。</p><pre><code class="java">package com.example.tutorial;import com.example.tutorial.AddressBookProtos.Person;import com.example.tutorial.AddressBookProtos.AddressBook;import com.example.tutorial.AddressBookProtos.Person;import java.io.BufferedReader;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.InputStreamReader;import java.io.IOException;import java.io.PrintStream;public class HelloWorld {    // This function fills in a Person message based on user input.    static Person PromptForAddress(BufferedReader stdin,                                   PrintStream stdout) throws IOException {        // 创建一个Person消息的Builder        Person.Builder person = Person.newBuilder();        // 通过builder对消息的各个字段进行填充        stdout.print(&quot;Enter person ID: &quot;);        person.setId(Integer.valueOf(stdin.readLine()));        stdout.print(&quot;Enter name: &quot;);        person.setName(stdin.readLine());        stdout.print(&quot;Enter email address (blank for none): &quot;);        String email = stdin.readLine();        if (email.length() &gt; 0) {            person.setEmail(email);        }        while (true) {            stdout.print(&quot;Enter a phone number (or leave blank to finish): &quot;);            String number = stdin.readLine();            if (number.length() == 0) {                break;            }            Person.PhoneNumber.Builder phoneNumber =                    Person.PhoneNumber.newBuilder().setNumber(number);            stdout.print(&quot;Is this a mobile, home, or work phone? &quot;);            String type = stdin.readLine();            if (type.equals(&quot;mobile&quot;)) {                phoneNumber.setType(Person.PhoneType.MOBILE);            } else if (type.equals(&quot;home&quot;)) {                phoneNumber.setType(Person.PhoneType.HOME);            } else if (type.equals(&quot;work&quot;)) {                phoneNumber.setType(Person.PhoneType.WORK);            } else {                stdout.println(&quot;Unknown phone type.  Using default.&quot;);            }            person.addPhones(phoneNumber);        }        // 最终通过build方法将builder生成一个实际的对象。        return person.build();    }    // Main function:  Reads the entire address book from a file,    //   adds one person based on user input, then writes it back out to the same    //   file.    public static void main(String[] args) throws Exception {        if (args.length != 1) {            System.err.println(&quot;Usage:  AddPerson ADDRESS_BOOK_FILE&quot;);            System.exit(-1);        }        AddressBook.Builder addressBook = AddressBook.newBuilder();        // Read the existing address book.        try {            addressBook.mergeFrom(new FileInputStream(args[0]));        } catch (FileNotFoundException e) {            System.out.println(args[0] + &quot;: File not found.  Creating a new file.&quot;);        }        // Add an address.        addressBook.addPeople(                PromptForAddress(new BufferedReader(new InputStreamReader(System.in)),                        System.out));        // Write the new address book back to disk.        FileOutputStream output = new FileOutputStream(args[0]);        addressBook.build().writeTo(output);        output.close();    }}</code></pre><h4 id="5-5-2-读取消息"><a href="#5-5-2-读取消息" class="headerlink" title="5.5.2 读取消息"></a>5.5.2 读取消息</h4><p>上面一节生成的相关消息是写在指定的文件中的，如果想要读取刚才写的数据，则需要使用下面的方法从文件中进行读取。</p><pre><code class="java">import com.example.tutorial.AddressBookProtos.AddressBook;import com.example.tutorial.AddressBookProtos.Person;import java.io.FileInputStream;import java.io.IOException;import java.io.PrintStream;class ListPeople {  // Iterates though all people in the AddressBook and prints info about them.  static void Print(AddressBook addressBook) {    for (Person person: addressBook.getPeopleList()) {      System.out.println(&quot;Person ID: &quot; + person.getId());      System.out.println(&quot;  Name: &quot; + person.getName());      if (person.hasEmail()) {        System.out.println(&quot;  E-mail address: &quot; + person.getEmail());      }      for (Person.PhoneNumber phoneNumber : person.getPhonesList()) {        switch (phoneNumber.getType()) {          case MOBILE:            System.out.print(&quot;  Mobile phone #: &quot;);            break;          case HOME:            System.out.print(&quot;  Home phone #: &quot;);            break;          case WORK:            System.out.print(&quot;  Work phone #: &quot;);            break;        }        System.out.println(phoneNumber.getNumber());      }    }  }  // Main function:  Reads the entire address book from a file and prints all  //   the information inside.  public static void main(String[] args) throws Exception {    if (args.length != 1) {      System.err.println(&quot;Usage:  ListPeople ADDRESS_BOOK_FILE&quot;);      System.exit(-1);    }    // Read the existing address book.    AddressBook addressBook =      AddressBook.parseFrom(new FileInputStream(args[0]));    Print(addressBook);  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> protobuf </category>
          
      </categories>
      
      
        <tags>
            
            <tag> protobuf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java实现简单的HTTP</title>
      <link href="/2020/01/15/10-java%E7%BD%91%E7%BB%9C/1_HTTP/"/>
      <url>/2020/01/15/10-java%E7%BD%91%E7%BB%9C/1_HTTP/</url>
      
        <content type="html"><![CDATA[<h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><h2 id="1-server端"><a href="#1-server端" class="headerlink" title="1. server端"></a>1. server端</h2><pre><code class="java">import com.sun.net.httpserver.HttpExchange;import com.sun.net.httpserver.HttpHandler;import com.sun.net.httpserver.HttpServer;</code></pre><p>一个简单的Http Server端需要导入以上三个包，而且大概也只需要这三个就可以完成基本的操作。其中HttpExchange用来定义或控制一个Http交互中的请求与响应内容。</p><h3 id="1-1-HttpExchange"><a href="#1-1-HttpExchange" class="headerlink" title="1.1 HttpExchange"></a>1.1 HttpExchange</h3><p>文档中的介绍如下：</p><blockquote><p>此类封装了在一个交换中，可以用在一个交换中的请求与响应两个阶段，其作用如下：</p><ul><li>请求阶段：解析接收到的HTTP请求，检查来自客户端的请求</li><li>响应阶段：要生成的响应，构建和发送响应</li></ul></blockquote><p>主要的方法：</p><ul><li><p>请求阶段：</p><ol><li><p><a href="https://docs.oracle.com/javase/7/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/HttpExchange.html#getRequestMethod()" target="_blank" rel="noopener"><code>getRequestMethod()</code></a> ：确定命令</p><pre><code class="java">HttpExchange exchange;String method = exchange.getRequestMethod();</code></pre></li><li><p><a href="https://docs.oracle.com/javase/7/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/HttpExchange.html#getRequestHeaders()" target="_blank" rel="noopener"><code>getRequestHeaders()</code></a> ：检查请求标头（如果需要）</p></li><li><p><a href="https://docs.oracle.com/javase/7/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/HttpExchange.html#getRequestBody()" target="_blank" rel="noopener"><code>getRequestBody()</code></a> ：返回一个 <a href="https://docs.oracle.com/javase/7/docs/api/java/io/InputStream.html?is-external=true" target="_blank" rel="noopener"><code>InputStream</code></a> 用于读取请求正文。 读取请求正文后，流关闭。</p><pre><code class="java">HttpExchange exchange;String bodyStr = new String(exchange.getRequestBody().readAllBytes());bodyStr = URLDecoder.decode(bodyStr, &quot;UTF-8&quot;);</code></pre></li></ol></li></ul><ul><li><p>响应阶段：</p><ol><li><p><a href="https://docs.oracle.com/javase/7/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/HttpExchange.html#getResponseHeaders()" target="_blank" rel="noopener"><code>getResponseHeaders()</code></a> ：设置任何响应头，内容长度除外</p></li><li><p>[<code>sendResponseHeaders(int,long)</code>](<a href="https://docs.oracle.com/javase/7/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/HttpExchange.html#sendResponseHeaders" target="_blank" rel="noopener">https://docs.oracle.com/javase/7/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/HttpExchange.html#sendResponseHeaders</a>(int, long)) ：发送响应头。 必须在下一步之前调用。</p><pre><code class="java">exchange.sendResponseHeaders(200, 0);</code></pre></li><li><p><a href="https://docs.oracle.com/javase/7/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/HttpExchange.html#getResponseBody()" target="_blank" rel="noopener"><code>getResponseBody()</code></a> 获得一个 <a href="https://docs.oracle.com/javase/7/docs/api/java/io/OutputStream.html?is-external=true" target="_blank" rel="noopener"><code>OutputStream</code></a> ，发送响应正文。 写入响应主体后，必须关闭流以终止交换。</p><pre><code class="java">exchange.getResponseBody().write(&quot;success&quot;.getBytes());exchange.close();</code></pre></li></ol></li></ul><h3 id="1-2-HttpHandler"><a href="#1-2-HttpHandler" class="headerlink" title="1.2 HttpHandler"></a>1.2 HttpHandler</h3><p>文档中的描述是：</p><blockquote><p>被调用以处理HTTP交换的处理程序。 每个HTTP交换均由这些处理程序之一处理。</p></blockquote><p>也就是说，每个HTTP Exchange 交互过程都需要在这个接口的实现中处理。</p><p>在java中创建一个类，并且这个类用来实现HttpHandler接口，并且重写handler方法：</p><pre><code class="java">class 类名 implements HttpHandler {    @Override    public void handle(HttpExchange exchange) throws IOException {    }}</code></pre><p>因此，下面是一个例子，其中重写了HttpHandler接口，实现出来了两个类，这两个类分别用来处理不同的Http请求。</p><pre><code class="java">class FormHttpHandler implements HttpHandler {    @Override    public void handle(HttpExchange exchange) throws IOException {        System.out.println(&quot;from方法：&quot; + exchange.getRequestMethod());//get        String paramStr = exchange.getRequestURI().getQuery();        System.out.println(&quot;get参数：&quot; + TestHttpServer.getParams(paramStr));        exchange.sendResponseHeaders(200, 0);        String body = &quot;get Message!!!&quot;;        exchange.getResponseBody().write(body.getBytes());        exchange.close();    }}class InfoHttpHandler implements HttpHandler {    @Override    public void handle(HttpExchange exchange) throws IOException {        System.out.println(&quot;info方法：&quot; + exchange.getRequestMethod());//post        String bodyStr = new String(exchange.getRequestBody().readAllBytes());        bodyStr = URLDecoder.decode(bodyStr, &quot;UTF-8&quot;);        System.out.println(&quot;post收到：&quot; + TestHttpServer.getParams(bodyStr));        exchange.sendResponseHeaders(200, 0);        exchange.getResponseBody().write(&quot;success&quot;.getBytes());        exchange.close();    }}</code></pre><h3 id="1-3-HttpServer"><a href="#1-3-HttpServer" class="headerlink" title="1.3 HttpServer"></a>1.3 HttpServer</h3><p>对于HttpServer的使用，需要进行以下两个步骤：</p><ul><li><p><strong>建立一个HttpServer对象</strong></p><p>此类实现一个简单的HTTP服务器。 HttpServer绑定到IP地址和端口号，并侦听此地址上来自客户端的传入TCP连接。 子类HttpsServer实现了一个处理HTTPS请求的服务器。</p><pre><code class="java">HttpServer server = HttpServer.create(new InetSocketAddress(8080), 0);</code></pre><blockquote><p>上面<code>cteate</code>函数的第二个参数为<code>socket backlogs</code>，这个参数表示系统将在内部排队的<strong>最大传入TCP连接数</strong>。 </p><p>连接在等待HttpServer接受时排队。当达到限制时，基础的TCP实现可能会拒绝（或可能忽略）其他连接，因此需要合理地设置该值。</p></blockquote></li><li><p><strong>关联HttpHandler对象</strong></p><p><strong>服务器必须与一个或多个HttpHandler对象关联才能处理请求</strong>。每个此类HttpHandler都注册有一个根URI路径，该路径表示应用程序或服务在此服务器上的位置。 处理程序到HttpServer的映射由HttpContext对象封装。 </p><ul><li>HttpContext是通过调用 <code>createContext(String，HttpHandler)</code> 创建的。</li><li>找不到任何处理程序的任何请求都会被404响应拒绝。</li></ul><p>通过提供Executor对象，可以在此对象外部进行线程管理。 如果未提供，则使用默认实现。例如下面这个例子，就是来对特定的URI需要进行的不同操作进行绑定。</p><pre><code class="java">server.createContext(&quot;/form&quot;, new FormHttpHandler());server.createContext(&quot;/info&quot;, new InfoHttpHandler());</code></pre><p>也就是说，经过上面的绑定操作之后，如果server收到了URI为 <code>/form</code> 的请求，将会使用 <code>FormHttpHandler</code> 类中重写的 <code>handle</code> 方法进行处理。</p><p>该函数的使用原理如下：</p><blockquote><p><strong>建立关联</strong></p><p>收到HTTP请求时，将请求URI映射到HttpContext路径。通过查找其路径是请求URI路径的最长匹配前缀的上下文，可以找到适当的HttpContext（和处理程序）。比较字符串时会<strong>区分大小写</strong>，并且不会与任何编码形式进行转换。 例如。 给定配置了以下HttpContext的HttpServer。</p><table><thead><tr><th>context</th><th>context type</th></tr></thead><tbody><tr><td>ctx1</td><td>“/“</td></tr><tr><td>ctx2</td><td>“/apps/“</td></tr><tr><td>ctx3</td><td>“/apps/foo/“</td></tr></tbody></table><p>然后，假如收到了下面的请求的URI，则与之匹配的context分别如下：</p><table><thead><tr><th>请求的URI</th><th>context</th></tr></thead><tbody><tr><td><code>http://foo.com/apps/foo/bar</code></td><td>ctx3</td></tr><tr><td><code>http://foo.com/apps/Foo/bar</code></td><td>无匹配，错误</td></tr><tr><td><code>http://foo.com/apps/app1</code></td><td>ctx2</td></tr><tr><td><code>http://foo.com/foo</code></td><td>ctx1</td></tr></tbody></table></blockquote></li><li><p>启动HttpServer</p><p>这一步没啥好说的，就是调用start()方法来启动HttpServer</p><pre><code class="java">server.start();</code></pre></li></ul><h3 id="1-4-所有代码"><a href="#1-4-所有代码" class="headerlink" title="1.4 所有代码"></a>1.4 所有代码</h3><pre><code class="java">import java.io.IOException;import java.net.InetSocketAddress;import java.net.URLDecoder;import java.util.Map;import java.util.stream.Collectors;import java.util.stream.Stream;import com.sun.net.httpserver.HttpExchange;import com.sun.net.httpserver.HttpHandler;import com.sun.net.httpserver.HttpServer;class FormHttpHandler implements HttpHandler {    @Override    public void handle(HttpExchange exchange) throws IOException {        System.out.println(&quot;from方法：&quot; + exchange.getRequestMethod());//get        String paramStr = exchange.getRequestURI().getQuery();        System.out.println(&quot;get参数：&quot; + TestHttpServer.getParams(paramStr));        exchange.sendResponseHeaders(200, 0);        String body = &quot;get Message!!!&quot;;        exchange.getResponseBody().write(body.getBytes());        exchange.close();    }}class InfoHttpHandler implements HttpHandler {    @Override    public void handle(HttpExchange exchange) throws IOException {        System.out.println(&quot;info方法：&quot; + exchange.getRequestMethod());//post        String bodyStr = new String(exchange.getRequestBody().readAllBytes());        bodyStr = URLDecoder.decode(bodyStr, &quot;UTF-8&quot;);        System.out.println(&quot;post收到：&quot; + TestHttpServer.getParams(bodyStr));        exchange.sendResponseHeaders(200, 0);        exchange.getResponseBody().write(&quot;success&quot;.getBytes());        exchange.close();    }}public class TestHttpServer {    public static Map&lt;String, String&gt; getParams(String paramStr){        if(paramStr != null) {            return Stream.of(paramStr.split(&quot;&amp;&quot;))                    .filter(s -&gt; s.split(&quot;=&quot;).length == 2 &amp;&amp; s.split(&quot;=&quot;)[0].length() &gt; 0 &amp;&amp; s.split(&quot;=&quot;)[1].length() &gt; 0)                    .collect(Collectors.toMap(x -&gt; x.toString().split(&quot;=&quot;)[0], y -&gt; y.toString().split(&quot;=&quot;)[1]));        }        return null;    }    public static void main(String[] args) {        try {            HttpServer server = HttpServer.create(new InetSocketAddress(8080), 0);            server.createContext(&quot;/form&quot;, new FormHttpHandler());            server.createContext(&quot;/info&quot;, new InfoHttpHandler());            server.start();        } catch (IOException e) {            e.printStackTrace();        }    }}</code></pre><h2 id="2-client端"><a href="#2-client端" class="headerlink" title="2. client端"></a>2. client端</h2><h3 id="2-1-类变量"><a href="#2-1-类变量" class="headerlink" title="2.1 类变量"></a>2.1 类变量</h3><p>首先定义了下面这些类变量</p><pre><code class="java">// utf-8字符编码public static final String CHARSET_UTF_8 = &quot;utf-8&quot;;// HTTP内容类型。public static final String CONTENT_TYPE_TEXT_HTML = &quot;text/xml&quot;;// HTTP内容类型。相当于form表单的形式，提交数据public static final String CONTENT_TYPE_FORM_URL = &quot;application/x-www-form-urlencoded&quot;;// HTTP内容类型。相当于form表单的形式，提交数据public static final String CONTENT_TYPE_JSON_URL = &quot;application/json;charset=utf-8&quot;;// 连接管理器private static PoolingHttpClientConnectionManager pool;// 请求配置private static RequestConfig requestConfig;</code></pre><h3 id="2-2-初始化"><a href="#2-2-初始化" class="headerlink" title="2.2 初始化"></a>2.2 初始化</h3><p>这里主要就是进行一些必要的初始化，写在静态代码块中，一旦类被使用，这部分代码将被执行，其操作的各种变量均为静态变量，因为HTTP client初始化的内容对于所有类都是共享的，不需要将这些内容设置为类变量，同时用起来会非常方便。</p><pre><code class="java">static {    try {        //System.out.println(&quot;初始化HttpClientTest~~~开始&quot;);        SSLContextBuilder builder = new SSLContextBuilder();        builder.loadTrustMaterial(null, new TrustSelfSignedStrategy());        SSLConnectionSocketFactory sslsf =             new SSLConnectionSocketFactory(builder.build());        // 配置同时支持 HTTP 和 HTPPS        Registry&lt;ConnectionSocketFactory&gt; socketFactoryRegistry =             RegistryBuilder.&lt;ConnectionSocketFactory&gt; create()            .register(&quot;http&quot;, PlainConnectionSocketFactory.getSocketFactory())            .register(&quot;https&quot;, sslsf)            .build();        // 初始化连接管理器        pool = new PoolingHttpClientConnectionManager(socketFactoryRegistry);        // 将最大连接数增加到200，实际项目最好从配置文件中读取这个值        pool.setMaxTotal(200);        // 设置最大路由        pool.setDefaultMaxPerRoute(2);        // 根据默认超时限制初始化requestConfig        int socketTimeout = 10000;        int connectTimeout = 10000;        int connectionRequestTimeout = 10000;        requestConfig = RequestConfig.custom()            .setConnectionRequestTimeout(connectionRequestTimeout)            .setSocketTimeout(socketTimeout)            .setConnectTimeout(connectTimeout)            .build();        //System.out.println(&quot;初始化HttpClientTest~~~结束&quot;);    } catch (NoSuchAlgorithmException e) {        e.printStackTrace();    } catch (KeyStoreException e) {        e.printStackTrace();    } catch (KeyManagementException e) {        e.printStackTrace();    }    // 设置请求超时时间    requestConfig = RequestConfig.custom()        .setSocketTimeout(50000)        .setConnectTimeout(50000)        .setConnectionRequestTimeout(50000)        .build();}</code></pre><h3 id="2-3-创建HTTP实例"><a href="#2-3-创建HTTP实例" class="headerlink" title="2.3 创建HTTP实例"></a>2.3 创建HTTP实例</h3><pre><code class="java">public static CloseableHttpClient getHttpClient() {    CloseableHttpClient httpClient = HttpClients.custom()        // 设置连接池管理        .setConnectionManager(pool)        // 设置请求配置        .setDefaultRequestConfig(requestConfig)        // 设置重试次数        .setRetryHandler(new DefaultHttpRequestRetryHandler(0, false))        .build();    return httpClient;}</code></pre><h3 id="2-4-发送POST请求"><a href="#2-4-发送POST请求" class="headerlink" title="2.4 发送POST请求"></a>2.4 发送POST请求</h3><h4 id="2-4-0-包装POST请求"><a href="#2-4-0-包装POST请求" class="headerlink" title="2.4.0 包装POST请求"></a>2.4.0 包装POST请求</h4><p>首先，如果需要发送一个POST请求，需要new一个HttpPost的对象，然后将这个对象作为参数分别传递给2.4.1~2.4.5这些函数中进行实际的发送与交互处理。</p><pre><code class="java">public static String sendHttpPost(String httpUrl) {    // 创建httpPost    HttpPost httpPost = new HttpPost(httpUrl);    return 下面某个函数(httpPost, ...参数);}</code></pre><p>其实，2.4.3~2.4.5都是依赖于2.4.2进行的，都是将文件、参数等附加参数全部都转换成String类型的param，然后发给2.4.2中的函数里进行统一发送的。</p><h4 id="2-4-1-不带参数"><a href="#2-4-1-不带参数" class="headerlink" title="2.4.1 不带参数"></a>2.4.1 不带参数</h4><pre><code class="java">private static String sendHttpPost(HttpPost httpPost) {    CloseableHttpClient httpClient = null;    CloseableHttpResponse response = null;    // 响应内容    String responseContent = null;    try {        // 创建默认的httpClient实例.        httpClient = getHttpClient();        // 配置请求信息        httpPost.setConfig(requestConfig);        // 执行请求        response = httpClient.execute(httpPost);        // 得到响应实例        HttpEntity entity = response.getEntity();        // 可以获得响应头        // Header[] headers = response.getHeaders(HttpHeaders.CONTENT_TYPE);        // for (Header header : headers) {        // System.out.println(header.getName());        // }        // 得到响应类型        // System.out.println(ContentType.getOrDefault(response.getEntity()).getMimeType());        // 判断响应状态        if (response.getStatusLine().getStatusCode() &gt;= 300) {            throw new Exception(                &quot;HTTP Request is not success, Response code is &quot; +                 response.getStatusLine().getStatusCode());        }        if (HttpStatus.SC_OK == response.getStatusLine().getStatusCode()) {            responseContent = EntityUtils.toString(entity, CHARSET_UTF_8);            EntityUtils.consume(entity);        }    } catch (Exception e) {        e.printStackTrace();    } finally {        try {            // 释放资源            if (response != null) {                response.close();            }        } catch (IOException e) {            e.printStackTrace();        }    }    return responseContent;}</code></pre><h4 id="2-4-2-带参数"><a href="#2-4-2-带参数" class="headerlink" title="2.4.2 带参数"></a>2.4.2 带参数</h4><pre><code class="java">public static String sendHttpPost(String httpUrl, String params) {    HttpPost httpPost = new HttpPost(httpUrl);// 创建httpPost    try {        // 设置参数        if (params != null &amp;&amp; params.trim().length() &gt; 0) {            StringEntity stringEntity = new StringEntity(params, &quot;UTF-8&quot;);            stringEntity.setContentType(CONTENT_TYPE_FORM_URL);            httpPost.setEntity(stringEntity);        }    } catch (Exception e) {        e.printStackTrace();    }    return sendHttpPost(httpPost);}public static String sendHttpPost(String httpUrl, Map&lt;String, String&gt; maps) {    String parem = convertStringParameter(maps);    return sendHttpPost(httpUrl, parem);}</code></pre><p>其中，进行参数转换的convertStringParameter(maps)函数的定义如下：</p><pre><code class="java">/** * 将map集合的键值对转化成：key1=value1&amp;key2=value2 的形式 * * @param parameterMap 需要转化的键值对集合 * @return 字符串 */public static String convertStringParameter(Map parameterMap) {    StringBuffer parameterBuffer = new StringBuffer();    if (parameterMap != null) {        Iterator iterator = parameterMap.keySet().iterator();        String key = null;        String value = null;        while (iterator.hasNext()) {            key = (String) iterator.next();            if (parameterMap.get(key) != null) {                value = (String) parameterMap.get(key);            } else {                value = &quot;&quot;;            }            parameterBuffer.append(key).append(&quot;=&quot;).append(value);            if (iterator.hasNext()) {                parameterBuffer.append(&quot;&amp;&quot;);            }        }    }    return parameterBuffer.toString();}</code></pre><h4 id="2-4-3-带参数和文件"><a href="#2-4-3-带参数和文件" class="headerlink" title="2.4.3 带参数和文件"></a>2.4.3 带参数和文件</h4><pre><code class="java">public static String sendHttpPost(String httpUrl,                                   Map&lt;String, String&gt; maps,                                   List&lt;File&gt; fileLists) {    HttpPost httpPost = new HttpPost(httpUrl);// 创建httpPost    MultipartEntityBuilder meBuilder = MultipartEntityBuilder.create();    if (maps != null) {        for (String key : maps.keySet()) {            meBuilder.addPart(key,                               new StringBody(                                  maps.get(key),                                   ContentType.TEXT_PLAIN                              ));        }    }    if (fileLists != null) {        for (File file : fileLists) {            FileBody fileBody = new FileBody(file);            meBuilder.addPart(&quot;files&quot;, fileBody);        }    }    HttpEntity reqEntity = meBuilder.build();    httpPost.setEntity(reqEntity);    return sendHttpPost(httpPost);}</code></pre><h4 id="2-4-4-发送json"><a href="#2-4-4-发送json" class="headerlink" title="2.4.4 发送json"></a>2.4.4 发送json</h4><pre><code class="java">public static String sendHttpPostJson(String httpUrl, String paramsJson) {    HttpPost httpPost = new HttpPost(httpUrl);// 创建httpPost    try {        // 设置参数        if (paramsJson != null &amp;&amp; paramsJson.trim().length() &gt; 0) {            StringEntity stringEntity = new StringEntity(paramsJson, &quot;UTF-8&quot;);            stringEntity.setContentType(CONTENT_TYPE_JSON_URL);            httpPost.setEntity(stringEntity);        }    } catch (Exception e) {        e.printStackTrace();    }    return sendHttpPost(httpPost);}</code></pre><h4 id="2-4-5-发送xml"><a href="#2-4-5-发送xml" class="headerlink" title="2.4.5 发送xml"></a>2.4.5 发送xml</h4><pre><code class="java">public static String sendHttpPostXml(String httpUrl, String paramsXml) {    HttpPost httpPost = new HttpPost(httpUrl);// 创建httpPost    try {        // 设置参数        if (paramsXml != null &amp;&amp; paramsXml.trim().length() &gt; 0) {            StringEntity stringEntity = new StringEntity(paramsXml, &quot;UTF-8&quot;);            stringEntity.setContentType(CONTENT_TYPE_TEXT_HTML);            httpPost.setEntity(stringEntity);        }    } catch (Exception e) {        e.printStackTrace();    }    return sendHttpPost(httpPost);}</code></pre><h3 id="2-5-发送GET请求"><a href="#2-5-发送GET请求" class="headerlink" title="2.5 发送GET请求"></a>2.5 发送GET请求</h3><h4 id="2-5-0-包装GET请求"><a href="#2-5-0-包装GET请求" class="headerlink" title="2.5.0 包装GET请求"></a>2.5.0 包装GET请求</h4><pre><code class="java">public static String sendHttpGet(String httpUrl) {    // 创建get请求    HttpGet httpGet = new HttpGet(httpUrl);    return sendHttpGet(httpGet);}</code></pre><h4 id="2-5-1-发送GET请求"><a href="#2-5-1-发送GET请求" class="headerlink" title="2.5.1 发送GET请求"></a>2.5.1 发送GET请求</h4><pre><code class="java">private static String sendHttpGet(HttpGet httpGet) {    CloseableHttpClient httpClient = null;    CloseableHttpResponse response = null;    // 响应内容    String responseContent = null;    try {        // 创建默认的httpClient实例.        httpClient = getHttpClient();        // 配置请求信息        httpGet.setConfig(requestConfig);        // 执行请求        response = httpClient.execute(httpGet);        // 得到响应实例        HttpEntity entity = response.getEntity();        // 可以获得响应头        // Header[] headers = response.getHeaders(HttpHeaders.CONTENT_TYPE);        // for (Header header : headers) {        // System.out.println(header.getName());        // }        // 得到响应类型        // System.out.println(ContentType.getOrDefault(response.getEntity()).getMimeType());        // 判断响应状态        if (response.getStatusLine().getStatusCode() &gt;= 300) {            throw new Exception(                &quot;HTTP Request is not success, Response code is &quot; +                 response.getStatusLine().getStatusCode());        }        if (HttpStatus.SC_OK == response.getStatusLine().getStatusCode()) {            responseContent = EntityUtils.toString(entity, CHARSET_UTF_8);            EntityUtils.consume(entity);        }    } catch (Exception e) {        e.printStackTrace();    } finally {        try {            // 释放资源            if (response != null) {                response.close();            }        } catch (IOException e) {            e.printStackTrace();        }    }    return responseContent;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> HTTP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【hadoop 1】hadoop环境搭建</title>
      <link href="/2020/01/06/hadoop/1_hadoop/"/>
      <url>/2020/01/06/hadoop/1_hadoop/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h1 id="1-环境搭建步骤"><a href="#1-环境搭建步骤" class="headerlink" title="1. 环境搭建步骤"></a>1. 环境搭建步骤</h1><p>首先需要使用root用户登录，登录完成后执行以下几步：</p><h2 id="1-1-关防火墙"><a href="#1-1-关防火墙" class="headerlink" title="1.1 关防火墙"></a>1.1 关防火墙</h2><pre><code class="bash">service iptables stopchkconfig iptables off#检查防火墙是否被关闭：service iptables statuschkconfig --list iptables</code></pre><h2 id="1-2-创建一个一般用户，并更改密码"><a href="#1-2-创建一个一般用户，并更改密码" class="headerlink" title="1.2 创建一个一般用户，并更改密码"></a>1.2 创建一个一般用户，并更改密码</h2><pre><code class="bash">useradd hadoopUserpasswd hadoopUser</code></pre><p><img src="/2020/01/06/hadoop/1_hadoop/1576724242576.png" alt="1576724242576"></p><h2 id="1-3-在opt目录下创建software、module文件夹，并改变所有权"><a href="#1-3-在opt目录下创建software、module文件夹，并改变所有权" class="headerlink" title="1.3 在opt目录下创建software、module文件夹，并改变所有权"></a>1.3 在opt目录下创建software、module文件夹，并改变所有权</h2><pre><code class="bash">mkdir /opt/software /opt/module  chown hadoopUser:hadoopUser /opt/software /opt/module # 注意这里的冒号前后是用户和组，写一样的就行了</code></pre><p><img src="/2020/01/06/hadoop/1_hadoop/1576724592490.png" alt="1576724592490"></p><h2 id="1-4-增加可以使用sudo命令的用户"><a href="#1-4-增加可以使用sudo命令的用户" class="headerlink" title="1.4 增加可以使用sudo命令的用户"></a>1.4 增加可以使用sudo命令的用户</h2><pre><code class="bash">vim /etc/sudoers</code></pre><p><img src="/2020/01/06/hadoop/1_hadoop/1576724850790.png" alt="1576724850790"></p><p>然后再下面这个位置增加和用户相关的信息：</p><pre><code class="bash">hadoopUser  ALL=(ALL)  NOPASSWD: ALL</code></pre><img src="/2020/01/06/hadoop/1_hadoop/1576724883308.png" alt="1576724883308" style="zoom:80%;"><p>为了验证这个是否正确，可以将用户切换至hadoopUser然后执行一条sudo命令，如果没有报错，则表示该用户可以正常使用sudo命令</p><p><img src="/2020/01/06/hadoop/1_hadoop/1576725007365.png" alt="1576725007365"></p><h2 id="1-5-更改hosts"><a href="#1-5-更改hosts" class="headerlink" title="1.5 更改hosts"></a>1.5 更改hosts</h2><p>使用下面这条命令打开hosts文件并进行修改（注意，需要在root用户下进行修改，否则将不能保存修改）</p><pre><code class="bash">vim /etc/hosts</code></pre><p>修改之前需要先查询以下本机的IP地址，也就是使用ifconfig来看到</p><img src="/2020/01/06/hadoop/1_hadoop/1576725437482.png" alt="1576725437482" style="zoom:80%;"><p>在文件后面追加以下内容：</p><img src="/2020/01/06/hadoop/1_hadoop/1576725778264.png" alt="1576725778264" style="zoom:80%;"><p>注意修改的IP地址需要和自己的IP地址一样</p><blockquote><p>小提示：这里使用vim的指令：</p><ul><li>yy表示复制一整行</li><li>dd表示删除一整行</li><li>p表示粘贴</li></ul><p>因此可以通过yy+p来快速进行写入</p></blockquote><h2 id="1-6-改静态IP"><a href="#1-6-改静态IP" class="headerlink" title="1.6 改静态IP"></a>1.6 改静态IP</h2><pre><code class="bash">vim /etc/sysconfig/network-scripts/ifcfg-eth0</code></pre><p><img src="/2020/01/06/hadoop/1_hadoop/1576725953241.png" alt="1576725953241"></p><p>然后将文件中的内容写如下所示：</p><pre><code class="bash">DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;IPADDR=&quot;192.168.57.134&quot;PREFIX=&quot;24&quot;GATEWAY=&quot;192.168.57.2&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot;DNS1=&quot;192.168.57.2&quot;NAME=&quot;eth0&quot;</code></pre><img src="/2020/01/06/hadoop/1_hadoop/1576726190849.png" alt="1576726190849" style="zoom:80%;"><p>如果与下面有不一样的则全部都删掉，改成和这个一样的就可以了。其中网关设置，需要在VMware里面查看：编辑-虚拟网关编辑器，然后按照下面的方式查看，并且设置成网关IP，DNS地址设置和网关地址相同就可以了。</p><img src="/2020/01/06/hadoop/1_hadoop/1576726353181.png" alt="1576726353181" style="zoom:80%;"><h2 id="1-7-改主机名"><a href="#1-7-改主机名" class="headerlink" title="1.7 改主机名"></a>1.7 改主机名</h2><pre><code class="bash">vim /etc/sysconfig/network</code></pre><p><img src="/2020/01/06/hadoop/1_hadoop/1576726500824.png" alt="1576726500824"></p><p>在这个文件中，将HOSTNAME换成指定的主机名就行了。</p><p><strong>注意：这里需要将hosts、network、ifconfig中看到的主机名与IP地址对应且相同！</strong></p><img src="/2020/01/06/hadoop/1_hadoop/1576726659036.png" alt="1576726659036" style="zoom:67%;"><h2 id="1-8-拍快照并克隆"><a href="#1-8-拍快照并克隆" class="headerlink" title="1.8 拍快照并克隆"></a>1.8 拍快照并克隆</h2><p>上面的操作完成之后，就已经完成了机器的配置，需要进行拍快照复制主机了。将当前的虚拟机关闭，并且拍摄一张快照configureOK，然后从configureOK处克隆快照。</p><img src="/2020/01/06/hadoop/1_hadoop/1576726951757.png" alt="1576726951757" style="zoom:80%;"><p>克隆完毕之后，打开这个克隆出来的新虚拟机，发现在登录界面就提示以下的错误：</p><img src="/2020/01/06/hadoop/1_hadoop/1576727252057.png" alt="1576727252057" style="zoom:67%;"><p>因为之前设置的ifcfg里面的网卡名称叫做eth0，只有一个网卡，并且被之前的虚拟机占用了。也就是说eth0这个网卡需要重新配置。并且，主机名、静态IP也需要重新指定。</p><h2 id="1-9-修改新虚拟机的配置"><a href="#1-9-修改新虚拟机的配置" class="headerlink" title="1.9 修改新虚拟机的配置"></a>1.9 修改新虚拟机的配置</h2><p>使用下面的命令来对文件进行修改，主要就是：</p><ol><li>删除网卡eth0（这是之前虚拟机的网卡）</li><li>修改静态IP地址</li><li>修改本机的主机名</li></ol><p>前面三个步骤依次对以下三个文件进行相关的修改，主要也就是把IP地址和主机名给换掉。</p><pre><code class="bash">sudo vim /etc/udev/rules.d/70-persistent-net.rulessudo vim /etc/sysconfig/network-scripts/ifcfg-eth0sudo vim /etc/sysconfig/network</code></pre><p><strong>注意：要使用sudo，否则无法写该文件。</strong></p><img src="/2020/01/06/hadoop/1_hadoop/1576737848284.png" alt="1576737848284" style="zoom:80%;"><p>改完之后重启，发现之前报的错已经没了</p><img src="/2020/01/06/hadoop/1_hadoop/1576738175883.png" alt="1576738175883" style="zoom:80%;"><h1 id="4-快照"><a href="#4-快照" class="headerlink" title="4. 快照"></a>4. 快照</h1><p>类似于游戏存档，虚拟机的游戏存档就是快照</p><img src="/2020/01/06/hadoop/1_hadoop/1576738462471.png" alt="1576738462471" style="zoom:80%;"><p>例如，之前存过一次快照，现在查看快照管理就能看到现在这个样子。</p><p>注意：拍快照需要关机，因为关机之后只会保存硬盘状态，否则还需要保存内存状态，这样存储开销就非常大了。</p><p><img src="/2020/01/06/hadoop/1_hadoop/1576738600987.png" alt="1576738600987"></p><p>此外，上图中，hadoop001中的图标表示这个虚拟机是一个独立的虚拟机，hadoop002是需要依赖于其他虚拟机的虚拟机。有一个前提状态hadoop001在支撑着hadoop002，hadoop002既包含001的状态，又包含002的状态，002是讲001的某个状态封装成一个只读模式，后面对它做的修改就是<strong>叠加在上面的状态</strong>。</p><p>如果进行完整拷贝来说，就会将原来的状态复制过来，生成一个独立的新虚拟机，</p><h1 id="5-安装java与hadoop"><a href="#5-安装java与hadoop" class="headerlink" title="5. 安装java与hadoop"></a>5. 安装java与hadoop</h1><h2 id="5-1-拷贝并解压tar包"><a href="#5-1-拷贝并解压tar包" class="headerlink" title="5.1 拷贝并解压tar包"></a>5.1 拷贝并解压tar包</h2><p>往里面传文件的时候直接将文件拖动到xshell里面就可以了，<strong>如果上传不过去，可以在虚拟机里面安装一个软件<code>sudo yum install lrzsz</code>。</strong></p><p>使用下面的命令将考进去的tar包解压</p><pre><code class="bash">tar -zxvf jdk-8u1... -C /opt/module/</code></pre><p>其中的参数含义为：</p><ul><li>z：gzip的压缩编码</li><li>x：解压</li><li>v：解压过程中显示详细信息</li><li>f：指定解压文件</li><li>-C：指定解压目录</li></ul><p>将这两个tar包都放到module文件夹下</p><h2 id="5-2-配置环境变量"><a href="#5-2-配置环境变量" class="headerlink" title="5.2 配置环境变量"></a>5.2 配置环境变量</h2><p>配置环境变量：</p><pre><code class="bash">sudo vim /etc/profile</code></pre><p>使用sudo对profile文件进行编辑，在最后一行加上以下两句话。</p><pre><code class="bash">export JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin</code></pre><p>然后用source执行该配置文件</p><pre><code class="bash">source /etc/profile</code></pre><p>此后，再进行echo $JAVA_HOME的时候，就能够打印出刚才配置出来的结果了。然后可以查看java的版本，应该是能够看到的</p><p><img src="/2020/01/06/hadoop/1_hadoop/1576742129797.png" alt="1576742129797"></p><p>对于hadoop也是一样的，只不过需要注意要加一个sbin。</p><pre><code class="bash">export HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin</code></pre><p>然后查询hadoop的版本就可以得到下面的输出</p><p><img src="/2020/01/06/hadoop/1_hadoop/1576743205123.png" alt="1576743205123"></p><p>下面看一下hadoop文件夹下的内容</p><p><img src="/2020/01/06/hadoop/1_hadoop/1576743374308.png" alt="1576743374308"></p><ul><li>bin：可执行文件</li><li>etc：配置文件</li><li>include：头文件</li><li>lib：库</li><li>libexec：</li><li>sbin：shellbin，可执行脚本</li><li>share：所有的jar包都放在该目录下</li></ul><h2 id="5-3-配置hadoop"><a href="#5-3-配置hadoop" class="headerlink" title="5.3 配置hadoop"></a>5.3 配置hadoop</h2><p>按照官网上的知道配置就可以了</p><p> <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html</a> </p><p><strong>配置hadoop</strong></p><p>这里需要修改 <code>etc/hadoop/hadoop-env.sh</code> ，把里面的java目录换成正确的就可以了。</p><pre><code class="bash">export JAVA_HOME=/opt/module/jdk1.8.0_144</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hyperledger Fabric系统框架笔记</title>
      <link href="/2019/11/24/blockchain/09/"/>
      <url>/2019/11/24/blockchain/09/</url>
      
        <content type="html"><![CDATA[<h1 id="fabric网络框架"><a href="#fabric网络框架" class="headerlink" title="fabric网络框架"></a>fabric网络框架</h1><p>@[toc]</p><p>区块链网络是一种技术基础架构，可为应用程序提供账本和智能合约（链码）服务。 首先，智能合约用于生成交易，随后将交易分配到网络中的每个对等节点，在该对等节点中，它们一成不变地记录在账本副本中。 应用程序的用户可能是使用客户端应用程序或区块链网络管理员的最终用户。</p><p>在大多数情况下，多个组织会作为一个联盟聚集在一起以形成网络，并且<strong>它们的权限由最初配置网络时联盟所规定的一组策略确定</strong>。当然这个策略也是可以被修改的。</p><p>下面将按构造一个网络的顺序来讲述fabric的结构</p><h2 id="1-创建网络"><a href="#1-创建网络" class="headerlink" title="1. 创建网络"></a>1. 创建网络</h2><p><img src="/2019/11/24/blockchain/09/network.diagram.2.png" alt="network.creation"></p><p>上图中，各个元素的含义：</p><ul><li><p>N：网络</p></li><li><p>O4：排序服务（ordering service），这里由单个节点组成，但是也可以由多个节点组成。在网络中，它是最早被定义的东西，因此可以<strong>被视为初始的管理节点</strong>。</p></li><li><p>NC4：网络配置（network configuration），其中包含了描述<strong>网络管理功能</strong>的初始集合的策略。一开始的时候由于R4是网络中唯一的组织，因此NC4一开始只能授权给他。</p></li><li><p>R4：组织（organization）</p></li><li><p>CA4：证书颁发机构（certification authority），用于向R4组织的管理员和网络节点分配身份。</p></li></ul><h3 id="1-1-CA"><a href="#1-1-CA" class="headerlink" title="1.1 CA"></a>1.1 CA</h3><p>CA4是用于为管理员和网络节点解决认证问题的，<strong>使用X.509来为属于组织R4的成员提供身份认证。</strong>由CA颁发的证书还可以用于签署交易，以<strong>表明组织认可交易结果</strong>——这是将交易写到账本中的前提。</p><p>首先，区块链网络中的各个成员<strong>用证书（certificates）来彼此证明其属于特定的组织中</strong>，因此<strong>不同的组织使用不同的CA</strong>。</p><p>证书到组织成员的映射是通过<strong>成员服务提供者（MSP）</strong>的结构来提供的，网络配置NC4使用一个MSP来识别CA4颁发的证书的属性，CA4将证书持有者与组织R4关联起来。然后，NC4可以<strong>在策略中</strong>使用这个MSP名称来授予来自R4的成员对网络资源的特殊权限。这种策略的一个功能是识别R4中可以向网络添加新成员组织的管理员。</p><p>X.509证书用于客户端应用程序交易提出（transaction proposals）和智能合约交易响应，以便对交易进行数字签名。</p><h2 id="2-向网络中添加管理员"><a href="#2-向网络中添加管理员" class="headerlink" title="2. 向网络中添加管理员"></a>2. 向网络中添加管理员</h2><p>最初将NC4配置为网络中仅允许R4用户进行管理。本章将添加允许组织R1用户管理网络。 </p><p><img src="/2019/11/24/blockchain/09/network.diagram.2.1.png" alt="network.admins"></p><p><strong>组织R4更新网络配置来让组织R1也成为管理员。此后R1和R4将在网络配置中具有相同的权限。</strong>CA1同时也被添加了，它被用于认证组织R1中的成员的身份。</p><p>虽然排序服务O4运行在R4的基础设施上，但是只要R1能够获得网络访问，它对R4就能够共享管理权限。即<strong>R1或R4可以更新网络配置NC4</strong>，使R2组织成为网络操作的子集。通过这种方式，即使R4正在运行排序服务，并且R1对其拥有完全的管理权限，R2创建新联盟的权限也是有限的。</p><p><strong>排序服务通常是多节点的</strong>，可以将其配置为<strong>在不同的组织中具有不同的排序服务节点</strong>。例如，我们可以在R4中运行O4并将其连接到R1中的排序节点O2。这样，我们就有了一个多站点（sites）、多组织的管理结构。</p><h2 id="3-定义一个联盟"><a href="#3-定义一个联盟" class="headerlink" title="3. 定义一个联盟"></a>3. 定义一个联盟</h2><p> <img src="/2019/11/24/blockchain/09/network.diagram.3.png" alt="network.consortium"> </p><p>我们需要做的第一件事是<strong>定义一个联盟</strong>。这个词的字面意思是“有着共同命运的一群人”。</p><p>网络管理员定义了一个联盟X1，该联盟包含两个成员，组织R1和R2。 <strong>该联盟定义存储在网络配置NC4中，并将在网络开发的下一阶段使用。 CA1和CA2是这些组织的各自的证书颁发机构。</strong></p><p>由于NC4的配置方式，只有R1或R4可以创建新的联盟。这里新联盟X1将R1和R2定义为其组成组织。</p><p><strong>一个联盟可以有任意数量的组织成员</strong>。</p><p>联盟为什么重要？ 我们可以看到，一个联盟定义了<strong>网络中彼此共享交易需求的组织集合</strong>。</p><h2 id="4-为一个联盟创建一个通道"><a href="#4-为一个联盟创建一个通道" class="headerlink" title="4. 为一个联盟创建一个通道"></a>4. 为一个联盟创建一个通道</h2><p>通道是主要的<strong>通信机制</strong>，联盟的成员可以通过该机制相互通信。在一个网络中网络中可以有多个通道。</p><p><img src="/2019/11/24/blockchain/09/network.diagram.4.png" alt="network.channel"> </p><ul><li>CC1：通道配置（channel configuration），这个配置与NC4具有相同的权限。</li></ul><p>联盟X1为R1和R2创建了通道C1。<strong>通道由完全独立于网络配置NC4的通道配置CC1控制。CC1由对C1拥有同等权利的R1和R2管理。R4在CC1中没有任何权利，因此，通道C1仅用于R1和R2之间的交易处理。</strong></p><p>客户端应用程序和对等节点等组件的连接也是通过通道完成的。</p><p>因为当初添加权限的时候，R1与R4的权限是相同的，因此R1也是可以创建通道的！所以在上图中，通道C1可能是由组织R1创建的，也可能是组织R4创建的。</p><p><strong>通道C1的通道配置CC1与网络配置NC4应当是完全独立的</strong>。CC1包含用于控制R1和R2在通道C1上的权限的策略，<strong>R3和R4在此通道上没有权限</strong>。如果R3和R4是由通道配置CC1中通过适当的策略被R1或R2添加到C1中的，则R3和R4只能与C1交互。特别要注意的是，<strong>R4不能将自己添加到通道C1中，它必须并且只能由R1或R2授权。</strong></p><blockquote><p>从后文中可以知道，NC4是一个用于网络配置的配置文件，它可以生成新的联盟或新的通道，但是<strong>在新的通道或联盟中， R1和R4不一定有成为通道管理员的权限</strong>。</p></blockquote><p>一旦创建了一个通道，只有<strong>在通道配置中明确指定的组织才能对其进行控制</strong>。也就是说，从此时开始对网络配置NC4的任何更新都不会直接影响通道配置CC1；例如，<strong>如果联盟X1更改，它将不会影响通道C1的成员</strong>。 通道之所以有用，是因为<strong>它们允许构成通道的组织之间进行私密通信</strong>。通道中的数据与网络的其余部分（包括其他通道）完全隔离。</p><p>还有一个<strong>特殊的系统通道，供排序服务使用</strong>。它的行为与常规通道完全相同，因此有时会称为<strong>应用程序通道</strong>。</p><h2 id="5-对等节点与账本"><a href="#5-对等节点与账本" class="headerlink" title="5. 对等节点与账本"></a>5. 对等节点与账本</h2><p><img src="/2019/11/24/blockchain/09/network.diagram.5.png" alt="network.peersledger"> </p><ul><li>P1：对等节点，是<strong>托管区块链账本副本的网络组件</strong>。在本例中，P1上存放账本L1的副本，P1与O4可以通过通道C1相互通信。P1在网络中的目的纯粹是为了托管账本L1的副本，以供其他人访问。</li><li>L1：账本</li></ul><p>因此，可以认为<strong>L1物理上托管在P1上，但逻辑上托管在通道C1上。</strong></p><p>P1配置的关键部分是CA1发出的X.509身份，该身份<strong>将P1与组织R1相关联</strong>。<strong>一旦P1启动，它就可以使用排序服务O4加入通道C1。</strong>O4收到此加入请求后，会使用通道配置CC1来确定P1在 此通道上的权限。 例如，CC1确定P1是否可以向账本L1读取和/或写入信息。</p><h2 id="6-应用与智能合约链码"><a href="#6-应用与智能合约链码" class="headerlink" title="6. 应用与智能合约链码"></a>6. 应用与智能合约链码</h2><p>现在，通道C1上有一个账本，我们可以开始<strong>连接客户端应用程序</strong>，以使用账本的主要对象（对等节点）提供的某些服务！</p><p><img src="/2019/11/24/blockchain/09/network.diagram.6.png" alt="network.appsmartcontract"> </p><ul><li>A1：客户端应用程序，它与组织有一一对应的关系，在本例中，A1属于组织R1，同时它与P1、O4一样，也是连接在通道C1上的。因此，尽管A1位于区块链网络之外，但是仍然可以通过通道C1来访问账本L1。</li><li>S5：智能合约，被安装在P1上，组织R1中的客户端应用程序<strong>A1可以而且必须通过智能合约S5才能访问账本L1</strong>。</li></ul><p><strong>智能合约用于生成交易，随后可以将交易分配到网络中的每个节点。</strong>智能合约上需要执行以下两个操作</p><ol><li>必须已安装在对等节点上（物理安装）</li><li>在通道上定义（逻辑安装）</li></ol><p><strong>智能合约和链码的关系：</strong></p><ul><li><p><strong>智能合约</strong>：定义了控制全局状态中包含的业务对象生命周期的交易逻辑。</p></li><li><p><strong>链码</strong>：需要将智能合约进行打包，然后才能将其部署到区块链网络上的。</p></li></ul><p>其实这两个关系是很接近的，从某种意义上来说，将智能合约成为链码也无可厚非。</p><h3 id="6-1-安装链码"><a href="#6-1-安装链码" class="headerlink" title="6.1 安装链码"></a>6.1 安装链码</h3><p>一旦R1将智能合约打包成链码并将其安装到它对应的P1上，P1就完全了解S5。即，<strong>P1可以看到S5的实现逻辑</strong>（访问L1的程序代码）。 </p><p><strong>当某个组织在一个通道中有多个对等节点时，它可以在指定的对等节点上安装智能合约。不需要在每个对等节点上都安装智能合约。</strong></p><h3 id="6-2-定义链码"><a href="#6-2-定义链码" class="headerlink" title="6.2 定义链码"></a>6.2 定义链码</h3><p>在将chaincode定义提交给通道并用于与通道账本交互之前，<strong>需要有足够多的组织批准chaincode定义</strong>(默认情况下是大多数组织)。由于通道只有一个成员，因此<strong>R1的管理员可以将S5的链码定义提交给通道C1</strong>。 提交定义后，现在可以由客户端应用程序A1调用S5！</p><p>请注意，尽管通道上的每个组件现在都<strong>可以访问S5</strong>，但它们<strong>无法看到其程序逻辑</strong>。 <strong>对于已安装它的那些节点，它仍然是私有的</strong>（这里指的是对于P1是公开的，但是对于通道上的其他组件而言，则是私密的）； 在我们的示例中，这意味着P1。从概念上讲，这意味着<strong>定义并提交给通道上各个组件的是智能合约的接口，而不是智能合约的实现。</strong> </p><ul><li><p>安装到peer上：将智能合约其物理托管在对等节点上</p></li><li><p>定义到通道上：将智能合约在逻辑上托管到通道上</p></li></ul><h3 id="6-3-背书策略"><a href="#6-3-背书策略" class="headerlink" title="6.3 背书策略"></a>6.3 背书策略</h3><p>链码定义中提供的最重要的信息是<strong>背书策略</strong>。 它描述了<strong>交易必须经过哪些组织批准，其他组织才能将写到他们的账本上</strong>。 在本例中，<strong>只有R1或R2认可交易，才可以将交易接受到账本L1上</strong>。</p><p>将链码定义提交给通道会将背书策略放置在通道账本上。 它使通道的任何成员都可以访问它。</p><h3 id="6-4-调用智能合约"><a href="#6-4-调用智能合约" class="headerlink" title="6.4 调用智能合约"></a>6.4 调用智能合约</h3><p>将智能合约安装在对等节点上并在通道上定义后，即可由客户端应用程序调用。<strong>客户端应用程序通过向智能合约认可策略指定的组织所拥有的对等节点发送交易提案来完成此任务。</strong>交易提案<strong>用作智能合约的输入</strong>，智能合约使用它来生成认可的交易响应，<strong>该响应由对等节点返回到客户端应用程序</strong>。</p><p>这些交易响应与交易提案打包在一起，形成一个完全认可的交易，并可以广播到整个网络。</p><p>目前，组织R1正在完全参与网络。A1通过智能合约S5访问账本L1，以生成将由组织R1认可的交易，因此由于它们符合认可策略而被接受到分类帐中。</p><h2 id="7-网络完成"><a href="#7-网络完成" class="headerlink" title="7. 网络完成"></a>7. 网络完成</h2><p><img src="/2019/11/24/blockchain/09/network.diagram.7.png" alt="network.grow"> </p><p>上图中的信息如下：</p><ul><li>R2添加了对等节点P2，该对等节点<strong>托管账本L1和链码S5的副本</strong>。</li><li>R2中的管理员必须批准R2与R1具有相同的链码定义。 </li><li>P2也与应用程序A2一样加入了通道C1。</li><li><strong>A2和P2使用来自CA2的证书进行认证。</strong></li></ul><p>所有这些意味着应用程序A1和A2都可以使用对等节点P1或P2在C1上调用S5。</p><p>现在，组织R1和R2可以进行交易。 具体来说，<strong>应用程序A1和A2可以使用智能合约S5和账本L1在通道C1上生成交易</strong>。</p><h3 id="7-1-生成并接受交易"><a href="#7-1-生成并接受交易" class="headerlink" title="7.1 生成并接受交易"></a>7.1 生成并接受交易</h3><p>与始终承载账本副本的对等节点相反，存在两种不同类型的对等节点。</p><ul><li>拥有智能合约的节点：这种节点可以帮助生成交易（can help generate tx）。因为安装了智能合约的对等节点才能够参与交易背书的过程。</li><li>没有智能合约的节点。虽然没有存放智能合约，但是<strong>它可以通过连接到通道，而感知到智能合约的接口</strong>。在大型网络中，其实是有很多节点都不存放智能合约副本的。</li></ul><p>不管节点中是否存了智能合约，<strong>所有对等节点都可以验证并随后接受或拒绝将交易添加到其账本L1的副本上</strong>。</p><h3 id="7-2-对等节点的类型"><a href="#7-2-对等节点的类型" class="headerlink" title="7.2 对等节点的类型"></a>7.2 对等节点的类型</h3><p>在Hyperledger Fabric中，<strong>尽管所有对等体都相同，但是它们可以根据网络的配置方式承担多个角色</strong>。</p><ul><li><p><strong>committing peer（提交节点）</strong>： 通道中的<strong>每个对等节点都是提交节点</strong>。它接收生成的交易区块，随后将这些交易进行验证，然后根据验证结果决定同意/拒绝将它们添加到对等节点的账本副本。</p></li><li><p><strong>endorsing peer（背书节点）</strong>：如果安装了智能合约，则该节点就是背书节点。但是，实际上要成为背书节点，客户端应用程序必须使用节点上的智能合约来生成数字签名的事务响应。背书节点一词是对此事实的明确引用。</p><p>智能合约的背书策略<strong>可确定组织</strong>，<strong>先对生成的交易进行数字签名，然后才能将其接受到提交的对等节点的账本副本中</strong>。</p></li><li><p><strong>leader peer（主节点）</strong>：当组织在一个通道中有多个节点时，主节点负责<strong>将交易从排序节点分发到组织中其他提交节点</strong>。同伴可以选择参与静态或动态的leader选择。</p><p>因此，从leader的角度考虑两组同伴是有帮助的-那些具有静态leader选举和动态leader选举。对于静态集，<strong>可以将零个或多个对等节点配置为leader</strong>。对于动态集，将由该集<strong>选出一个对等节点作为leader</strong>。此外，在动态集中，如果leader节点挂掉，则其余对等节点将重新选举领导者。</p><p>这意味着组织<strong>可以让一个或多个主节点连接到排序服务节点</strong>。这可以帮助提高处理大量事务的大型网络的弹性和可伸缩性。</p></li><li><p><strong>anchor peer（锚节点）</strong>：如果<strong>对等节点需要与另一个组织中的对等节点进行通信</strong>，则可以使用该组织的通道配置中定义的锚节点之一。一个组织可以为其定义零个或多个锚节点，并且锚节点可以<strong>跨组织通信</strong>场景。</p></li></ul><p>注意，<strong>一个对等体可以同时是一个提交节点，背书节点，主节点和锚节点</strong>！（其中，锚节点是可选的）</p><blockquote><p>这里描述的不是特别清楚，不过可以猜测他说的应该指的是一个组织中应该至少有一个leader、一个背书节点、一个提交节点。</p></blockquote><h3 id="7-3-添加组织或节点到通道中"><a href="#7-3-添加组织或节点到通道中" class="headerlink" title="7.3 添加组织或节点到通道中"></a>7.3 添加组织或节点到通道中</h3><p><strong>当R2加入通道时，组织必须将智能合约S5安装到其对等节点P2上</strong>。这很明显–如果应用程序A1或A2希望在对等节点P2上使用S5来生成事务，则必须首先存在它；安装是发生这种情况的机制。此时，对等节点P2具有智能合约和账本的物理副本；像P1一样，它可以在其账本L1的副本上生成并接受交易。</p><p>为了使用智能合约S5，<strong>R2必须与R1有的相同的链码定义。由于链码定义已由组织R1提交给通道，因此，只要组织批准链码定义并安装链码软件包，R2就可以使用链码</strong>。提交事务只需发生一次。新组织批准通道其他成员同意的链码参数后，便可以使用链码。<strong>由于链码定义的批准是在组织级别进行的，因此R2可以批准链码定义一次，并将安装了链码包的多个对等方加入到通道中。</strong>但是，如果R2想要更改链码定义，则R1和R2都需要为其组织批准新的定义，然后其中一个组织需要将该定义提交给通道。</p><p>通道C1连接了两个客户端应用程序，两个对等节点和一个排序服务。由于只有一个通道，<strong>因此只有一个逻辑账本可以与这些组件进行交互</strong>。对等节点P1和P2中存储的账本是账本L1的副本。智能合约S5的副本通常将使用相同的编程语言完全相同地实现，但如果不同，则它们在语义上必须等效。</p><p>我们可以看到，将对等体（节点）添加到网络可以帮助支持增加的吞吐量，稳定性和弹性。例如，<strong>网络中更多的对等点将允许更多的应用程序连接到它</strong>；如果计划内或计划外的停机，组织中的多个对等方将提供额外的弹性。</p><p>网络可以达到的规模没有理论上的限制。此外，单个组织内的对等方有效地发现并彼此通信的技术机制（gossip协议）将容纳大量对等节点，以支持此类拓扑。</p><p>使用网络和通道策略可以使大型网络得到良好管理。<strong>组织可以自由地将对等节点添加到网络，只要它们符合网络约定的策略即可。</strong>网络和通道策略在自治和控制之间建立了平衡，这是分散网络的特征。</p><h2 id="8-简化视图"><a href="#8-简化视图" class="headerlink" title="8. 简化视图"></a>8. 简化视图</h2><p>用<strong>连接点</strong>替换通道线来简化网络图，显示为蓝色圆圈，其中写的是通道号。</p><p><img src="/2019/11/24/blockchain/09/network.diagram.8.png" alt="network.vocabulary"> </p><p>该图显示了如下的结构：</p><ul><li>客户端应用程序A1和A2可以使用通道C1与对等端P1和P2以及排序服务节点O4进行通信。 </li><li>对等节点P1和P2可以使用通道C1的通信服务。 </li><li>排序服务服务O4可以利用通道C1的通信服务。 </li><li>通道配置CC1适用于通道C1。</li></ul><h2 id="9-添加另一个联盟"><a href="#9-添加另一个联盟" class="headerlink" title="9. 添加另一个联盟"></a>9. 添加另一个联盟</h2><p><img src="/2019/11/24/blockchain/09/network.diagram.9.png" alt="network.consortium2"> </p><p>组织R1或R4的网络管理员添加了新的联盟定义X2（包括组织R2和R3）。 这将用于为X2定义一个新通道。</p><p>此时的网络中有两个联盟：R1和R2组成的联盟X1以及R2和R3组成的联盟X2。</p><p>只有<strong>网络配置（NC4）专门定义的组织（R1, R4）</strong>才能够创建新的通道。它将可以在网络级别管理资源的组织与可以在通道级别管理资源的组织分开。</p><h2 id="10-添加新通道"><a href="#10-添加新通道" class="headerlink" title="10. 添加新通道"></a>10. 添加新通道</h2><p><img src="/2019/11/24/blockchain/09/network.diagram.10.png" alt="network.channel2"> </p><ul><li>联盟X2为R2和R3创建了一个新的通道C2。 </li><li>通道C2具有完全独立于网络配置NC4和通道配置CC1的通道配置CC2。</li><li>通道C2由R2和R3管理，它们具有CC2中策略定义的对C2相同的权限。</li><li>R1和R4在CC2中均未定义任何权限。</li></ul><p><strong>X2为C2通道中的节点提供了私密交流</strong>。通道配置CC2现在包含管理通道资源的策略，并<strong>通过通道C2向组织R2和R3分配管理权限</strong>。它仅由R2和R3管理，而R1和R4在通道C2中没有权限。例如，随后可以更新通道配置CC2以添加组织来支持网络增长，但这只能由R2或R3完成。</p><p>请注意，<strong>通道配置CC1和CC2彼此完全独立，并与网络配置NC4完全独立</strong>。 再次，我们看到了Hyperledger Fabric网络的去中心化性质； 创建通道C2后，组织R2和R3会独立于其他网络元素来管理它。 <strong>通道策略始终保持彼此独立，并且只能由有权在通道中这样做的组织进行更改</strong>。</p><h3 id="10-1-网络与通道配置"><a href="#10-1-网络与通道配置" class="headerlink" title="10.1 网络与通道配置"></a>10.1 网络与通道配置</h3><p>在整个示例网络中，我们看到了<strong>网络和通道配置封装了网络成员同意的策略</strong>，这些策略为控制对网络资源的访问提供了共享的参考。网络和通道配置还包含有关网络和通道组成的事实，例如联盟名称及其组织。</p><ul><li>当首先使用排序服务节点O4形成网络时，其行为由网络配置NC4控制。</li><li>NC4的初始配置仅包含允许组织R4管理网络资源的策略。</li><li>随后将NC4更新为还允许R1管理网络资源。进行此更改后，组织R1或R4中连接到O4的任何管理员都将具有网络管理权限，因为这是NC4网络配置中允许的策略。</li><li>在内部，排序服务中的每个节点都会记录网络配置中的每个通道，以便在网络级别上记录每个创建的通道。</li></ul><p>这意味着尽管排序服务节点O4创建了联盟X1和X2以及通道C1和C2，但网络的智能（the intelligence of the network）包含在O4遵循的网络配置NC4中。<strong>只要O4表现良好，并且在处理网络资源时正确执行NC4中定义的策略，我们的网络就会按照所有组织的同意行事。</strong>在许多方面，NC4比O4更重要，因为它最终控制了网络访问。</p><p>相同的原则适用于有关节点的通道配置。在我们的网络中，当对等节点P1和P2与客户端应用程序A1或A2交互时，它们每个都使用在通道配置CC1中定义的策略来控制对通道C1资源的访问。</p><p>例如，如果A1要访问对等节点P1或P2上的智能合约链码S5，则<strong>每个对等节点都使用其CC1副本确定A1可以执行的操作</strong>。例如，可以根据CC1中定义的策略允许A1从分类账L1读取或写入数据。再次，我们可以看到，尽管对等方和应用程序是网络中的关键角色，<strong>但它们在通道中的行为更多地由通道配置策略决定。</strong></p><p>每个网络中只有一个网络配置，同样，一个通道也只有一个通道配置。访问网络或通道的每个组件都必须对授予不同组织的权限有共同的了解。</p><p>即使从逻辑上讲只有一个配置，但实际上它被构成网络或通道的每个节点复制并保持一致。例如，在我们的网络中，<strong>对等节点P1和P2都具有通道配置CC1的副本，而到网络完全完成时，对等节点P2和P3都将具有通道配置CC2的副本。</strong>类似地，排序服务节点O4具有网络配置的副本，但是<strong>如果有多个排序节点，则每个排序服务节点将具有其自己的网络配置副本</strong>。</p><p>使用用于用户交易（但用于配置交易）的相同区块链技术，可以<strong>使网络和通道配置保持一致</strong>。要更改网络或通道配置，管理员必须提交配置事务以更改网络或通道配置。必须<strong>由适当策略中确定负责配置更改的组织签名。这项策略称为mod_policy</strong>，我们将在后面讨论。</p><p>的确，<strong>排序服务节点运行着一个微型区块链</strong>，通过我们前面提到的系统通道连接。使用系统通道排序服务节点可以分发网络配置事务。这些事务用于在每个排序服务节点上合作维护网络配置的一致副本。以类似的方式，应用程序通道中的对等节点可以分发通道配置事务。同样，这些事务用于在每个对等节点上维护通道配置的一致副本。</p><p>这种逻辑上的个体间的平衡，通过物理上的分布，是超级账本结构中常见的模式。例如，<strong>逻辑上单一的对象（如网络配置）实际上是在一组排序服务节点之间进行物理复制的</strong>。我们还会<strong>在通道配置，账本以及某种程度上将智能合约安装在多个位置</strong>，但它们的接口逻辑上存在于通道级别的情况下看到它。</p><h2 id="11-添加另一个对等体（peer）"><a href="#11-添加另一个对等体（peer）" class="headerlink" title="11. 添加另一个对等体（peer）"></a>11. 添加另一个对等体（peer）</h2><p>现在，组织R3可以完全参与通道C2了，让我们将其基础结构组件添加到通道中。 我们不会一次添加一个组件，而是一次添加一个对等方，其分类帐的本地副本，智能合约和客户端应用程序！</p><p><img src="/2019/11/24/blockchain/09/network.diagram.11.png" alt="network.peer2"> </p><ul><li>客户端应用程序A1和A2可以使用通道C1与P1、P2、O4进行通信。</li><li>客户端应用程序A3可以使用通道C2与P3、O4进行通信。</li><li>排序服务O4可以利用通道C1和C2的通信服务。</li><li>通道配置CC1适用于通道C1，CC2适用于通道C2。</li></ul><p>由于对等节点P3连接到通道C2，因此它对使用通道C1的那些对等节点具有不同的账本L2。账本L2有效地限定在通道C2上。<strong>因此，通道提供了私密性，可以用于隐私保护</strong>、</p><blockquote><p>每个通道都有不同的账本</p></blockquote><p>以类似的方式，安装在对等节点P3上（物理）并在通道C2上定义（逻辑）的智能合约S6用于提供对分类帐L2的受控访问。应用程序A3可以<strong>使用通道C2调用由智能合约S6提供的服务</strong>，以生成可以接受到网络中账本L2的每个副本上的交易。</p><h2 id="12-将一个peer加入多个通道"><a href="#12-将一个peer加入多个通道" class="headerlink" title="12. 将一个peer加入多个通道"></a>12. 将一个peer加入多个通道</h2><p><img src="/2019/11/24/blockchain/09/network.diagram.12.png" alt="network.multichannel"> </p><ul><li>客户端应用程序A1可以使用通道C1与P1、P2、O4进行通信。</li><li>客户端应用程序A2可以使用通道C1与对等端P1和P2进行通信，并使用通道C2与P2、P3、O4进行通信。</li><li>客户端应用程序A3可以使用通道C2与对等端P3和P2以及排序服务O4进行通信。</li><li>排序服务O4可以利用通道C1和C2的通信服务。</li><li>通道配置CC1适用于通道C1</li><li>通道配置CC2适用于通道C2。</li></ul><p>我们可以看到R2是网络中唯一一个连接两个通道的组织，它能够与通道C1上的组织R1进行交易，同时它还可以与其他通道C2上的组织R3进行交易。</p><p>请注意，对等节点P2为通道C1安装了智能合约S5，并为通道C2安装了智能合约S6。<strong>对等节点P2通过不同账本的不同智能合约同时是两个通道的正式成员。</strong></p><p>这是一个非常强大的概念-渠道既提供了组织分离的机制，又提供了组织之间协作的机制。一直以来，此基础结构是由一组独立的组织提供并在它们之间共享的。</p><p>同样重要的是要注意，对等节点P2的行为受其进行交易的通道的控制非常不同。</p><ul><li><p>通道配置CC1中的策略规定了P2在通道C1中的行为</p></li><li><p>通道配置CC2中的策略规定了P2在通道C2中的行为</p><p>R2和R1同意了通道C1的规则，而R2和R3同意了通道C2的规则。<strong>这些规则是在各自的通道策略中捕获的-通道中的每个组件都可以并且必须使用它们来强制执行正确的行为，这已经达成共识。</strong></p></li></ul><p><strong>客户端应用程序A2现在能够在通道C1和C2上进行交易。同样，它也将由适当通道配置中的策略控制</strong>。</p><h3 id="12-1-排序服务"><a href="#12-1-排序服务" class="headerlink" title="12.1 排序服务"></a>12.1 排序服务</h3><p><strong>排序服务本身也可以完全分散</strong>！ 因为排序服务可能<strong>由不同组织拥有的许多单个节点组成</strong>。</p><p>下面是一个更现实的排序服务节点配置：</p><p><img src="/2019/11/24/blockchain/09/1574412510685.png" alt="1574412510685"> </p><p>图中所示的就是一个<strong>多组织的排序服务</strong>。排序服务节点包括了节点O1和O4。 O1由组织R1提供，节点O4由组织R4提供。网络配置NC4为组织R1和R4的参与者定义了网络资源权限。</p><p>网络配置策略<strong>NC4允许R1和R4在网络资源上享有同等的权利</strong>。 来自R1和R4的客户端应用程序和对等节点可以通过<strong>连接到节点O1或节点O4来管理网络资源</strong>，因为这两个节点的行为方式相同，如网络配置NC4中的策略所定义。 实际上，<strong>来自特定组织的参与者往往会使用其上级组织提供的基础架构，但是并非总是如此</strong>。</p><h3 id="12-2-去中心化交易分布"><a href="#12-2-去中心化交易分布" class="headerlink" title="12.2 去中心化交易分布"></a>12.2 去中心化交易分布</h3><p><strong>排序服务不仅是网络的管理点，而且还是交易的分发点。</strong>排序服务是一个组件，它<strong>从应用程序中收集已认可的交易并将其排序到交易块中，然后将其分发到通道中的每个对等节点</strong>。在这些提交对等方的每个对等方，记录交易（有效或无效），并适当更新其本地账本副本。</p><p>请注意，根据排序服务节点O4的角色不同，其作用也是不同的。</p><ul><li>在<strong>通道级别</strong>，O4的作用是在通道C1内收集交易并分配区块。它根据通道配置CC1中定义的策略执行此操作。</li><li>在<strong>网络级别</strong>，O4的作用是根据网络配置NC4中定义的策略为网络资源提供管理点。</li></ul><p>再次注意，这些作用分别由通道和网络配置中的不同策略定义的。也就是说，<strong>策略既定义了联盟的每个成员，又用于控制联盟的每个成员的行为。</strong></p><p>我们可以看到，<strong>排序服务是完全去中心化的组件</strong>。</p><h3 id="12-3-改变策略"><a href="#12-3-改变策略" class="headerlink" title="12.3 改变策略"></a>12.3 改变策略</h3><p>Hyperledger Fabric允许<strong>网络和通道管理员自行管理策略更改</strong>！也就是说会经常发生变化。例如：</p><ul><li>新组织可以加入通道</li><li>现有组织的权限可以增加或减少</li></ul><p>让我们举两个简单的例子，说明我们如何使用mod_policy来进行管理策略的更改！</p><p>最初建立网络时，仅组织R4被允许管理网络。实际上，这是通过<strong>使R4成为网络配置NC4中定义的唯一拥有网络资源许可的组织来实现的</strong>。此外，NC4的mod_policy仅允许R4更改此配置。</p><ol><li><p>然后，<strong>新增允许组织R1来管理网络</strong>。做法是：<strong>R4将R1添加到用于通道创建和联盟创建的策略中</strong>。由于此更改，R1能够定义联盟X1和X2，并创建通道C1和C2。R1对网络配置中的通道和联盟策略具有同等的管理权限。</p></li><li><p><strong>R4可以将R1添加到mod_policy中，此后R1也能够管理网络策略的更改</strong>。这意味着R1原则上与R4具有相同的权限。</p></li></ol><p>第二个比第一个强大得多，因为<strong>R1现在可以完全控制网络配置NC4</strong>！R4可以配置mod_policy，使得修改需要经过自己（或者mod_policy中的所有组织）批准。</p><p>mod_policy使基本配置可以优雅地演变为复杂的配置。<strong>在所有相关组织的同意下，这种改变一直存在。</strong> mod_policy的行为类似于网络或通道配置中的其他所有策略；<strong>它定义了一组允许更改mod_policy本身的组织。</strong></p><h2 id="13-完整的网络"><a href="#13-完整的网络" class="headerlink" title="13. 完整的网络"></a>13. 完整的网络</h2><p><img src="/2019/11/24/blockchain/09/network.diagram.14.png" alt="network.finalnetwork2"> </p><p>在此图中，我们看到Fabric区块链网络<strong>由两个应用程序通道和一个排序通道组成</strong>。</p><ul><li>组织R1和R4负责排序通道</li><li>组织R1和R2负责蓝色应用程序通道</li><li>组织R2和R3负责红色应用程序通道。</li><li>客户端应用程序A1是组织R1的成员，CA1是该组织的证书颁发机构。</li><li>组织R2的<strong>P2可以使用蓝色和红色应用程序通道的通信设施</strong>。</li><li>每个应用程序通道都有自己的通道配置（这里是CC1和CC2）。</li><li>系统通道的通道配置是网络配置NC4的一部分。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> Fabric </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>闪电网络（四）比特币闪电网络：The Bitcoin Lightning Network</title>
      <link href="/2019/11/21/blockchain/08/"/>
      <url>/2019/11/21/blockchain/08/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><p>PS：这篇文章的英语表述特别native，而且全篇59页，写的非常详细，是一片不可多得的佳作。由于原文内容非常长，所以这里将原文拆成4个部分，分别为：</p><ul><li>（一）微支付通道</li><li>（二）双向支付通道：Bidirectional Payment Channels + RSMC</li><li>（三）哈希时间锁合约：Hashed Timelock Contract (HTLC) </li><li>（四）比特币闪电网络：The Bitcoin Lightning Network</li></ul><p><strong>本文为本系列的第四篇，文中的标题序号均按照原论文中顺序进行编号</strong></p><h2 id="8-The-Bitcoin-Lightning-Network"><a href="#8-The-Bitcoin-Lightning-Network" class="headerlink" title="8. The Bitcoin Lightning Network"></a>8. The Bitcoin Lightning Network</h2><p>By having a micropayment channel with contracts encumbered by hashlocks and timelocks, it is possible to clear transactions over a multi-hop payment network using a series of decrementing timelocks without additional central clearinghouses.</p><p> 通过使用带有hashlocks和timelocks合约的微支付通道，可以<strong>使用一系列不断减少的timelocks在多跳支付网络上清除交易</strong>，而不需要额外的中央清算所（clearinghouses）。 </p><p>Traditionally, financial markets clear transactions by transferring the obligation for delivery at a central point and settle by transferring ownership through this central hub. Bank wire and fund transfer systems (such as ACH and the Visa card network), or equities clearinghouses (such as the DTCC) operate in this manner.</p><p>传统上，金融市场通过在中心点转移交付义务来结算交易，并通过该中心枢纽转移所有权来进行结算。 银行电汇和资金转帐系统（例如ACH和Visa卡网络）或股票票据交换所（例如DTCC）以这种方式运行。</p><p>As Bitcoin enables programmatic money, it is possible to create transactions without contacting a central clearinghouse. Transactions can execute off-chain with no third party which collects all funds before disbursing it only transactions with uncooperative channel counterparties become automatically adjudicated on the blockchain.  </p><p>由于比特币启用程序化资金，因此<strong>无需联系中央票据交换所就可以创建交易</strong>。 交易可以在没有第三方的情况下进行链下执行，而第三方不会收集所有资金，只有在与不合作的通道交易方进行交易时才自动裁定区块链上的交易。</p><p>The obligation to deliver funds to an end-recipient is achieved through a process of chained delegation. Each participant along the path assumes the obligation to deliver to a particular recipient. Each participant passes on this obligation to the next participant in the path. The obligation of each subsequent participant along the path, defined in their respective HTLCs, has a shorter time to completion compared to the prior participant. This way each participant is sure that they will be able to claim funds when the obligation is sent along the path.</p><p>通过<strong>链式授权的过程</strong>来实现向最终接收者提供资金的义务。 沿途的每个参与者都承担着向特定收件人交付的义务。 <strong>每个参与者都将这一义务传递给路径中的下一个参与者</strong>。 与先前参与者相比，每个后续参与者在其各自的HTLC中定义的沿路径的义务具有较短的完成时间。 这样，每个参与者都可以确保在沿路径发送义务时能够索取资金。</p><p>Bitcoin Transaction Scripting, a form of what some call an implementation of “Smart Contracts”[19], enables systems without trusted custodial clearinghouses or escrow services.</p><p>比特币交易脚本（一种称为“智能合约” [19]的实现形式）使系统无需受信任的保管清算所或托管服务。</p><h3 id="8-1-递减时间锁"><a href="#8-1-递减时间锁" class="headerlink" title="8.1 递减时间锁"></a>8.1 递减时间锁</h3><p>Decrementing Timelocks</p><p>Presume Alice wishes to send 0.001 BTC to Dave. She locates a route through Bob and Carol. The transfer path would be Alice to Bob to Carol to Dave</p><p>假设Alice希望向Dave发送0.001 BTC。 她找到了一条通过Bob和Carol的路线。 传输路径将是Alice到Bob到Carol到Dave</p><p><img src="/2019/11/21/blockchain/08/1574342962451.png" alt="1574342962451"></p><p>Figure 15: Payment over the Lightning Network using HTLCs.</p><p>图15：使用HTLC通过闪电网络付款。</p><p>When Alice sends payment to Dave through Bob and Carol, she requests from Dave hash(R) to use for this payment. Alice then counts the amount of hops until the recipient and uses that as the HTLC expiry. In this case, she sets the HTLC expiry at 3 days. Bob then creates an HTLC with Carol with an expiry of 2 days, and Carol does the same with Dave with an expiry of 1 day. Dave is now free to disclose R to Carol, and both parties will likely agree to immediate settlement via novation with a replacement Commitment Transaction. This then occurs step-by-step back to Alice. Note that this occurs off-chain, and nothing is broadcast to the blockchain when all parties are cooperative.</p><p>当Alice通过Bob和Carol向Dave发送付款时，她向Dave请求使用该付款。 然后，<strong>Alice计算从他开始到接收者的hop数，并将其视为HTLC的<code>Timeout</code></strong>。 在这种情况下，她将HTLC设置为3天。 然后，Bob与Carol创建了一个HTLC，有效期为2天，而Carol为Dave创建了HTLC，其有效期为1天。 Dave现在可以自由地将R透露给Carol，并且双方都可能同意通过换新的<code>Commitment Tx</code>立即进行结算。 然后这一步一步地回到Alice。 请注意，<strong>这发生在链下，并且当各方合作时，不会向区块链广播任何内容</strong>。</p><p><img src="/2019/11/21/blockchain/08/1574342973867.png" alt="1574342973867"></p><p>Figure 16: Settlement of HTLC, Alice’s funds get sent to Dave.</p><p>图16：HTLC的结算，Alice的资金被发送给了Dave。</p><p>Decrementing timelocks are used so that all parties along the path know that the disclosure of R will allow the disclosing party to pull funds, since they will at worst be pulling funds after the date whereby they must receive R. If Dave does not produce R within 1 day to Carol, then Carol will be able to close out the HTLC. If Dave broadcasts R after 1 day, then he will not be able to pull funds from Carol. Carol’s responsibility to Bob occurs on day 2, so Carol will never be responsible for payment to Dave without an ability to pull funds from Bob provided that she updates her transaction with Dave via transmission to the blockchain or via novation.</p><p>使用<strong>递减的时间锁</strong>，以便<strong>沿途的所有各方都知道R的公开将允许披露方提取资金</strong>，因为最坏的情况是他们将在必须收到R的日期之后提取资金。 Carol 在1天后，便可以关闭HTLC。 如果Dave在1天后播放R，那么他将无法从Carol提取资金。 Carol对Bob的责任发生在第2天，因此如果没有通过Bob提取资金的能力，只要Carol通过传输到区块链或通过更新与Dave进行交易来更新，则Carol将永远不负责支付给Dave。</p><p>In the event that R gets disclosed to the participants halfway through expiry along the path (e.g. day 2), then it is possible for some parties along the path to be enriched. The sender will be able to know R, so due to Pay to Contract, the payment will have been fulfilled even though the receiver did not receive the funds. Therefore, the receiver must never disclose R unless they have received an HTLC from their channel counterparty; they are guaranteed to receive payment from one of their channel counterparties upon disclosure of the preimage.</p><p>如果R在沿路径到期（例如第2天）的中途向参与者披露，则沿该路径的某些参与方有可能变得更加丰富。 <strong>发送者将能够知道R，因此由于按合同付款，即使接收者未收到资金，付款也已完成。</strong> 因此，<strong>除非接收者已经从其信道对方接收到HTLC，否则它绝不能透露R</strong>； 他们保证在公开原像后会从其通道交易方之一收到付款。</p><p>In the event a party outright disconnects, the counterparty will be responsible for broadcasting the current Commitment Transaction state in the channel to the blockchain. Only the failed non-responsive channel state gets closed out on the blockchain, all other channels should continue to update their Commitment Transactions via novation inside the channel. Therefore, counterparty risk for transaction fees are only exposed to direct channel counterparties. If a node along the path decides to become unresponsive, the participants not directly connected to that node suffer only decreased timevalue of their funds by not conducting early settlement before the HTLC close.</p><p><strong>如果一方直接断开连接，则交易对手将负责在通道中向区块链广播当前的<code>Commitment Tx</code>状态。</strong> 只有失败的无响应通道状态在区块链上被关闭，所有其他通道应继续通过通道内的更新来更新其<code>Commitment Tx</code>。 因此，交易费用的交易对手风险仅暴露于直接通道交易对手。 如果沿路径的某个节点决定不响应，则不直接连接到该节点的参与者通过在HTLC关闭之前不进行早期结算，只会遭受其资金时间价值下降的困扰。</p><p><img src="/2019/11/21/blockchain/08/1574342985884.png" alt="1574342985884"></p><p>Figure 17: Only the non-responsive channels get broadcast on the blockchain, all others are settled off-chain via novation.</p><p>图17：只有无响应的通道才在区块链上广播，所有其他通道都通过创新在链下解决。</p><h3 id="8-2-支付金额"><a href="#8-2-支付金额" class="headerlink" title="8.2 支付金额"></a>8.2 支付金额</h3><p>Payment Amount</p><p>It is preferable to use a small payment per HTLC. One should not use an extremely high payment, in case the payment does not fully route to its destination. If the payment does not reach its destination and one of the participants along the path is uncooperative, it is possible that the sender must wait until the expiry before receiving a refund. Delivery may be lossy, similar to packets on the internet, but the network cannot outright steal funds in transit. Since transactions don’t hit the blockchain with cooperative channel counterparties, it is recommended to use as small of a payment as possible. A tradeoff exists between locking up transaction fees on each hop versus the desire to use as small a transaction amount as possible (the latter of which may incur higher total fees). Smaller transfers with more intermediaries imply a higher percentage paid as Lightning Network fees to the intermediaries.  </p><p>每个HTLC最好使用少量付款。 如果付款未完全汇到其目的地，则不应使用极高的付款。 <strong>如果付款没有到达目的地，并且路径上的参与者之一不合作，则发件人可能必须等到到期后才能收到退款</strong>。 传递可能是有损的，类似于Internet上的数据包，但网络无法彻底窃取传输中的资金。 由于交易不会通过合作通道交易对手进入区块链，因此建议使用尽可能少的付款方式。 在锁定每一跳的交易费用与使用尽可能小的交易金额（后者可能会产生更高的总费用）的愿望之间存在权衡。 与更多中介机构的较小转移意味着闪电网络向中介机构支付的百分比更高。</p><h3 id="8-3-Clearing-Failure-and-Rerouting"><a href="#8-3-Clearing-Failure-and-Rerouting" class="headerlink" title="8.3 Clearing Failure and Rerouting"></a>8.3 Clearing Failure and Rerouting</h3><p>If a transaction fails to reach its final destination, the receiver should send an equal payment to the sender with the same hash, but not disclose R. This will net out the disclosure of the hash for the sender, but may not for the receiver. The receiver, who generated the hash, should discard R and never broadcast it. If one channel along the path cannot be contacted, then the channels may elect to wait until the path expires, which all participants will likely close out the HTLC as unsettled without any payment with a new Commitment Transaction.</p><p>如果交易未能到达其最终目的地，则接收方应使用相同的散列向发送方发送同等付款，但不披露R。这将消除对发送方的散列披露，但对于接收方而言则不然。 产生散列的接收者应该丢弃R，并且永远不要广播它。 如果无法联系沿路径的一个通道，则这些通道可以选择等待直到路径到期为止，所有参与者都可能会因为尚未结算而关闭HTLC，而无需通过新的<code>Commitment Tx</code>付款。</p><p><img src="/2019/11/21/blockchain/08/1574246226758.png" alt="1574246226758"></p><p>Figure 18: Dave creates a path back to Alice after Alice fails to send funds to Dave, because Carol is uncooperative. The input R from hash(R) is never brodcast by Dave, because Carol did not complete her actions. If R was broadcast, Alice will break-even. Dave, who controls R should never broadcast R because he may not receive funds from Carol, he should let the contracts expire. Alice and Bob have the option to net out and close the contract early, as well, in this diagram.</p><p>图18：由于Carol不合作，<strong>在Alice未能向Dave汇款后，Dave创建了一条返回Alice的路径</strong>。 Dave从不对hash（R）的输入R广播，因为Carol没有完成她的动作。 如果播放R，Alice将收支平衡。 控制R的Dave永远不要广播R，因为他可能不会从Carol那里收到资金，他应该让合同到期。 在此图中，Alice和Bob也可以选择提前清算并关闭合约。</p><p>If the refund route is the same as the payment route, and there are no half-signed contracts whereby one party may be able to steal funds, it is possible to outright cancel the transaction by replacing it with a new Commitment Transaction starting with the most recent node who participated in the HTLC.</p><p>如果退款途径与付款途径相同，并且没有一方可以窃取资金的半签合同，则可以通过以最高 最近参加HTLC的节点。</p><p>It is also possible to clear out a channel by creating an alternate route path in which payment will occur in the opposite direction (netting out to zero) and/or creating an entirely alternate route for the payment path. This will create a time-value of money for disclosing inputs to hashes on the Lightning Network. Participants may specialize in high connectivity between nodes and offering to offload contract hashlocks from other nodes for a fee. These participants will agree to payments which net out to zero (plus fees), but are loaning bitcoins for a set time period. Most likely, these entities with low demand for channel resources will be end-users who are already connected to multiple well-connected nodes. When an end-user connects to a node, the node may ask the client to lock up their funds for several days to another channel the client has established for a fee. This can be achieved by having the new transactions require a new hash(Y) from input Y in addition to the existing hash which may be generated by any participant, but must disclose Y only after a full circle is established. The new participant has the same responsibility as well as the same timelocks as the old participant being replaced. It is also possible that the one new participant replaces multiple hops.</p><p>还可以通过创建一条备用路由路径来清理通道，在该路径中，支付将沿相反的方向发生（净额为零）和/或为支付路径创建一条完全备用的路径。这将创建一个货币时间值，用于将输入信息公开给闪电网络上的哈希。参与者可能会专门研究节点之间的高连接性，并愿意从其他节点上卸载合约哈希锁（收费）。这些参与者将同意支付净额为零（加上费用）的付款，但是在设定的时间段内借入比特币。这些对通道资源需求低的实体很可能是已经连接到多个连接良好的节点的最终用户。当最终用户连接到某个节点时，该节点可能会要求客户将其资金锁定到客户已建立的另一收费通道的几天。这可以通过让新交易除了可以由任何参与者生成的现有哈希值之外，还需要输入Y的新哈希值（Y）来实现，但必须在建立完整圆圈后才公开Y。<strong>新的参与者与被替换的老参与者具有相同的责任和相同的时间锁定</strong>。一个新的参与者也有可能替换多个跃点。</p><p><img src="/2019/11/21/blockchain/08/1574246295380.png" alt="1574246295380"></p><p>Figure 19: Erin is connected to both Bob and Dave. If Bob wishes to free up his channel with Carol, since that channel is active and very profitable, Bob can offload the payment to Dave via Erin. Since Erin has extra bitcoin available, she will be able to collect some fee for offloading the channel between Bob and Carol as well as between Carol and Dave. The channels between Bob and Carol as well as Carol and Dave are undone and no longer have the HTLC, nor has payment occurred on that path. Payment will occur on the path involving Erin. This is achieved by creating a new payment from Dave to Carol to Bob contingent upon Erin constructing an HTLC. The payment in dashed lines (red) are netted out to zero and settled via a new Commitment Contract.</p><p>图19：Erin连接到Bob和Dave。 <strong>如果Bob希望与Carol释放通道，因为该通道活跃并且非常有利可图，Bob可以通过Erin将付款转给Dave。</strong> 由于Erin有额外的可用比特币，因此她可以收取卸载Bob和Carol之间以及Carol和Dave之间的通道的费用。 Bob和Carol之间的通道以及Carol和Dave之间的通道都已撤消，不再具有HTLC，在该路径上也没有发生付款。 付款将在涉及Erin的道路上进行。 这是通过根据Erin构建HTLC的方式从Dave到Carol到Bob的新付款来实现的。 虚线（红色）中的付款净额清零，并通过新的承诺合同进行结算。</p><h3 id="8-4-支付路径"><a href="#8-4-支付路径" class="headerlink" title="8.4 支付路径"></a>8.4 支付路径</h3><p>Payment Routing</p><p>It is theoretically possible to build a route map implicitly from observing 2-of-2 multisigs on the blockchain to build a routing table. Note, however, this is not feasible with pay-to-script-hash transaction outputs, which can be resolved out-of-band from the bitcoin protocol via a third party routing service. Building a routing table will become necessary for large operators (e.g. BGP, Cjdns). Eventually, with optimizations, the network will look a lot like the correspondent banking network, or Tier-1 ISPs. Similar to how packets still reach their destination on your home network connection, not all participants need to have a full routing table. The core Tier-1 routes can be online all the time - while nodes at the edges, such as average users, would be connected intermittently. </p><p>从理论上讲，有可能通过观察区块链上的2之2多重信号隐式地构建路由图，以构建路由表。 但是请注意，这对于按脚本哈希支付交易输出是不可行的，可以通过第三方路由服务从比特币协议进行带外解析。 对于大型运营商（例如BGP，Cjdns），建立路由表将变得非常必要。 最终，通过优化，该网络将看起来非常类似于代理银行网络或Tier-1 ISP。 与数据包仍通过家庭网络连接到达目的地的方式类似，并非所有参与者都需要具有完整的路由表。 第一层的核心路由可以一直保持在线状态，而边缘节点（例如普通用户）将断续连接。</p><p>Node discovery can occur along the edges by pre-selecting and offering partial routes to well-known nodes.  </p><p>通过预选并提供通往知名节点的部分路由，可以沿边缘进行节点发现。</p><h3 id="8-5-Fees"><a href="#8-5-Fees" class="headerlink" title="8.5 Fees"></a>8.5 Fees</h3><p>Lightning Network fees, which differ from blockchain fees, are paid directly between participants within the channel. The fees pay for the time-value of money for consuming the channel for a determined maximum period of time, and for counterparty risk of non-communication. </p><p>与区块链费用不同的闪电网络费用直接在通道内的参与者之间支付。 费用用于支付在确定的最大时间段内占用通道的金钱时间价值，以及交易对方未进行通信的风险。</p><p>Counterparty risk for fees only exist with one’s direct channel counterparty. If a node two hops away decides to disconnect and their transaction gets broadcast on the blockchain, one’s direct counterparties should not broadcast on the blockchain, but continue to update via novation with a new Commitment Transaction. See the Decrementing Timelocks entry in the HTLC section for more information about counterparty risk. </p><p>交易对手的费用风险仅存在于直接通道交易对手中。 如果两跳远的节点决定断开连接，并且其交易在区块链上进行广播，则直接交易对手不应在区块链上进行广播，而应通过新的<code>Commitment Tx</code>继续更新。 有关交易对手风险的更多信息，请参见HTLC部分中的递减时间锁定条目。</p><p>The time-value of fees pays for consuming time (e.g. 3 days) and is conceptually equivalent to a gold lease rate without custodial risk; it is the time-value for using up the access to money for a very short duration. Since certain paths may become very profitable in one direction, it is possible for fees to be negative to encourage the channel to be available for those profitable paths.</p><p>费用的时间价值是消耗时间（例如3天）的费用，在概念上等同于没有保管风险的黄金租赁率； 这是在很短的时间内用尽金钱的时间价值。 由于某些路径可能会在一个方向上变得非常有利可图，因此收费可能为负数，以鼓励该通道可用于那些有利可图的路径。</p><h2 id="9-风险"><a href="#9-风险" class="headerlink" title="9. 风险"></a>9. 风险</h2><p>The primary risks relate to timelock expiration. Additionally, for core nodes and possibly some merchants to be able to route funds, the keys must be held online for lower latency. However, end-users and nodes are able to keep their private keys firewalled off in cold storage. </p><p>主要风险与时间锁到期有关。 另外，为了使核心节点以及可能的某些商人能够路由资金，必须将密钥保持在线以降低延迟。 但是，最终用户和节点能够将其私钥保留在冷存储中。</p><h3 id="9-1-不当的时间锁"><a href="#9-1-不当的时间锁" class="headerlink" title="9.1 不当的时间锁"></a>9.1 不当的时间锁</h3><p>Improper Timelocks</p><p>Participants must choose timelocks with sufficient amounts of time. If insufficient time is given, it is possible that timelocked transactions believed to be invalid will become valid, enabling coin theft by the counterparty. There is a trade-off between longer timelocks and the time-value of money. When writing wallet and Lightning Network application software, it is necessary to ensure that sufficient time is given and users are able to have their transactions enter into the blockchain when interacting with non-cooperative or malicious channel counterparties.</p><p>参与者必须选择有足够时间的时间锁。 <strong>如果给定的时间不足，则被认为无效的时间锁定交易可能会变为有效，从而使交易对手盗窃硬币。 在较长的时间锁定和金钱的时间价值之间需要权衡</strong>。 在编写钱包和Lightning Network应用程序软件时，有必要确保有足够的时间，并且在与非合作或恶意通道交易对手进行交互时，用户能够使其交易进入区块链。</p><h3 id="9-2-Forced-Expiration-Spam"><a href="#9-2-Forced-Expiration-Spam" class="headerlink" title="9.2 Forced Expiration Spam"></a>9.2 Forced Expiration Spam</h3><p>Forced expiration of many transactions may be the greatest systemic risk when using the Lightning Network. If a malicious participant creates many channels and forces them all to expire at once, these may overwhelm block data capacity, forcing expiration and broadcast to the blockchain. The result would be mass spam on the bitcoin network. The spam may delay transactions to the point where other locktimed transactions become valid.</p><p>使用闪电网络时，<strong>许多交易的强制到期可能是最大的系统风险</strong>。 如果恶意参与者创建了许多通道并强迫所有通道立即失效，则这些通道可能会使块数据容量不堪重负，从而迫使其失效并广播到区块链。 结果将是比特币网络上的大量垃圾邮件。 垃圾邮件可能会将交易延迟到其他锁定时间的交易变为有效的程度。</p><p>This may be mitigated by permitting one transaction replacement on all pending transactions. Anti-spam can be used by permitting only one transaction replacement of a higher sequence number by the inverse of an even or odd number. For example, if an odd sequence number was broadcast, permit a replacement to a higher even number only once. Transactions would use the sequence number in an orderly way to replace other transactions. This mitigates the risk assuming honest miners. This attack is extremely high risk, as incorrect broadcast of Commitment Transactions entail a full penalty of all funds in the channel.</p><p>可以通过允许所有未决交易替换一次交易来缓解这种情况。 通过仅允许一个交易用偶数或奇数的倒数替换较高序号，可以使用反垃圾邮件。 例如，如果广播了奇数序号，则只允许一次替换为更高的偶数。 交易将有序地使用序号来替换其他交易。 这减轻了假设诚实矿工的风险。 此攻击的风险极高，因为<code>Commitment Tx</code>的不正确广播会导致通道中所有资金的全部损失。</p><p>Additionally, one may attempt to steal HTLC transactions by forcing a timeout transaction to go through when it should not. This can be easily mitigated by having each transfer inside the channel be lower than the total transaction fees used. Since transactions are extremely cheap and do not hit the blockchain with cooperative channel counterparties, large transfers of value can be split into many small transfers. This attempt can only work if the blocks are completely full for a long time. While it is possible to mitigate it using a longer HTLC timeout duration, variable block sizes may become common, which may need mitigations.</p><p>此外，可能会通过迫使超时交易在不应该进行的超时交易中进行尝试来窃取HTLC交易。 通过使通道内的每次传输都低于所使用的总交易费用，可以轻松地缓解这种情况。 由于交易非常便宜，并且不会与合作通道交易对手打中区块链，因此大笔价值转移可以分为许多小额转移。 仅当块长时间完全充满时，此尝试才能起作用。 尽管可以使用更长的HTLC超时持续时间来缓解它，但可变块大小可能变得很常见，这可能需要缓解。</p><p>If this type of transaction becomes the dominant form of transactions which are included on the blockchain, it may become necessary to increase the block size and run a variable blocksize structure and timestop flags as described in the section below. This can create sufficient penalties and disincentives to be highly unprofitable and unsuccessful for attackers, as attackers lose all their funds from broadcasting the wrong transaction, to the point where it will never occur.</p><p>如果这种类型的交易成为区块链中包含的主要交易形式，则可能有必要增加块大小并运行可变的块大小结构和时间停止标志，如以下部分所述。 由于攻击者由于广播错误的交易而损失了所有资金，甚至可能永远不会发生，因此这可能会导致足够的惩罚和惩罚措施，使攻击者极不获利且无法成功。</p><h3 id="9-3-碰撞导致财产窃取"><a href="#9-3-碰撞导致财产窃取" class="headerlink" title="9.3 碰撞导致财产窃取"></a>9.3 碰撞导致财产窃取</h3><p>Coin Theft via Cracking</p><p>As parties must be online and using private keys to sign, there is a possibility that, if the computer where the private keys are stored is compromised, coins will be stolen by the attacker. While there may be methods to mitigate the threat for the sender and the receiver, the intermediary nodes must be online and will likely be processing the transaction automatically. For this reason, the intermediary nodes will be at risk and should not be holding a substantial amount of money in this “hot wallet.” Intermediary nodes which have better security will likely be able to out-compete others in the long run and be able to conduct greater transaction volume due to lower fees. Historically, one of the largest component of fees and interest in the financial system are from various forms of counterparty risk in Bitcoin it is possible that the largest component in fees will be derived from security risk premiums.</p><p>由于各方必须在线并且使用私钥进行签名，因此，如果存储私钥的计算机受到威胁，攻击者可能会窃取硬币。 尽管可能存在减轻发送方和接收方威胁的方法，但中间节点必须处于联机状态，并且很可能会自动处理交易。 因此，中间节点将处于危险之中，不应在此“热钱包”中持有大量资金。 从长远来看，具有更高安全性的中间节点将有可能超过其他节点，并且由于费用较低而能够进行更大的交易量。 从历史上看，金融系统中费用和利息的最大组成部分之一来自比特币中各种形式的交易对手风险，费用中最大的部分可能来自安全风险溢价。</p><p>A Funding Transaction may have multiple outputs with multiple Commitment Transactions, with the Funding Transaction key and some Commitment Transactions keys stored offline. It is possible to create an equivalent of a “Checking Account” and “Savings Account” by moving funds between outputs from a Funding Transaction, with the “Savings Account” stored offline and requiring additional signatures from security services.</p><p>资金交易可以具有多个输出和多个<code>Commitment Tx</code>，其中资金交易密钥和一些<code>Commitment Tx</code>密钥离线存储。 可以通过在资金交易的输出之间移动资金来创建等价于“支票帐户”和“储蓄帐户”，而“储蓄帐户”是离线存储的，并且需要安全服务的附加签名。</p><h3 id="9-4-数据丢失"><a href="#9-4-数据丢失" class="headerlink" title="9.4 数据丢失"></a>9.4 数据丢失</h3><p>Data Loss</p><p>When one party loses data, it is possible for the counterparty to steal funds. This can be mitigated by having a third party data storage service where encrypted data gets sent to this third party service which the party cannot decrypt. Additionally, one should choose channel counterparties who are responsible and willing to provide the current state, with some periodic tests of honesty  </p><p>当一方丢失数据时，对方可能会窃取资金。 可以通过拥有第三方数据存储服务来缓解这种情况，其中加密数据被发送到该第三方不能解密的第三方服务。 此外，应该选择负责并愿意提供当前状态的通道交易对手，并定期进行一些诚实测试。</p><h3 id="9-5-忘记及时广播交易"><a href="#9-5-忘记及时广播交易" class="headerlink" title="9.5 忘记及时广播交易"></a>9.5 忘记及时广播交易</h3><p>Forgetting to Broadcast the Transaction in Time</p><p>If one does not broadcast a transaction at the correct time, the counterparty may steal funds. This can be mitigated by having a designated third party to send funds. An output fee can be added to create an incentive for this third party to watch the network. Further, this can also be mitigated by implementing OP CHECKSEQUENCEVERIFY.  </p><p>如果未在正确的时间广播交易，则对方可能会窃取资金。 可以通过指定第三方汇款来缓解这种情况。 可以增加输出费用，以激励该第三方观看网络。 此外，这也可以通过实现OP CHECKSEQUENCEVERIFY来缓解。</p><h3 id="9-6-无法制作必要的软分叉"><a href="#9-6-无法制作必要的软分叉" class="headerlink" title="9.6 无法制作必要的软分叉"></a>9.6 无法制作必要的软分叉</h3><p>Inability to Make Necessary Soft-Forks</p><p>Changes are necessary to bitcoin, such as the malleability soft-fork. Additionally, if this system becomes popular, it will be necessary for the system to securely transact with many users and some kind of structure like a blockheight timestop will be desirable. This system assumes such changes to enable Lightning Network to exist entirely, as well as soft-forks ensuring the security is robust against attackers will occur. While the system may continue to operate with only some time lock and malleability soft-forks, there will be necessary soft-forks regarding systemic risks. Without proper community foresight, an inability to establish a timestop or similar function will allow systemic attacks to take place and may not be recognized as imperative until an attack actually occurs.</p><p>比特币必须进行更改，例如可延展性软叉。 另外，如果该系统变得流行，则该系统必须与许多用户安全地进行交易，并且诸如块高限时器之类的某种结构将是期望的。 该系统假设进行了此类更改，以使Lightning Network能够完全存在，并采用了软分叉来确保对攻击者的鲁棒性。 尽管系统可能仅在一定时间锁定和延展性软叉的情况下继续运行，但对于系统性风险仍将存在必要的软叉。 如果没有适当的社区先见之明，则无法建立时间停止或类似功能将导致系统性攻击，并且可能直到真正发生攻击时才被认为是当务之急。</p><h3 id="9-7-勾结矿工攻击"><a href="#9-7-勾结矿工攻击" class="headerlink" title="9.7 勾结矿工攻击"></a>9.7 勾结矿工攻击</h3><p>Colluding Miner Attacks</p><p>Miners may elect to refuse to enter in particular transactions (e.g. Breach Remedy transactions) in order to assist in timeout coin theft. An attacker can pay off all miners to refuse to include certain transactions in their mempool and blocks. The miners can identify their own blocks in an attempt to prove their behavior to the paying attacker. </p><p>矿工可以选择拒绝参加特定交易（例如违约救济交易），以协助超时盗窃硬币。 攻击者可以还清所有矿工的款项，以拒绝将某些交易包括在其内存池和区块中。 矿工可以识别自己的区块，以向付费攻击者证明自己的行为。</p><p>This can be mitigated by encouraging miners to avoid identifying their own blocks. Further, it should be expected that this kind of payment to miners is malicious activity and the contract is unenforcible. Miners may then take payment and surreptitiously mine a block without identifying the block to the attacker. Since the attacker is paying for this, they will quickly run out of money by losing the fee to the miner, as well as losing all their money in the channel. This attack is unlikely and fairly unattractive as it is far too difficult and requires a high degree of collusion with extreme risk. </p><p>可以通过鼓励矿工避免识别自己的区块来缓解这种情况。 此外，应该预料到，这种对矿工的付款是恶意活动，合同是不可执行的。 然后，矿工可以付款并秘密开采一个区块，而不会向攻击者识别该区块。 由于攻击者为此付出了代价，因此他们会很快损失掉矿工的费用，并在通道中损失所有金钱，从而很快耗尽金钱。 这种攻击是不太可能的，并且没有吸引力，因为它太困难了，需要高度勾结并具有极大的风险。</p><p>The risk model of this attack occurirng is similar to that of miners colluding to do reorg attacks: Extremely unlikely with many uncoordinated miners.</p><p>发生这种攻击的风险模型类似于串谋进行重组攻击的矿工的模型：对于许多不协调的矿工来说，这种可能性极小。</p><h2 id="10-区块大小增长与共识"><a href="#10-区块大小增长与共识" class="headerlink" title="10. 区块大小增长与共识"></a>10. 区块大小增长与共识</h2><p>Block Size Increases and Consensus</p><p>If we presume that a decentralized payment network exists and one user will make 3 blockchain transactions per year on average, Bitcoin will be able  to support over 35 million users with 1MB blocks in ideal circumstances (assuming 2000 transactions/MB, or 500 bytes/Tx). This is quite limited, and an increase of the block size may be necessary to support everyone in the world using Bitcoin. A simple increase of the block size would be a hard fork, meaning all nodes will need to update their wallets if they wish to participate in the network with the larger blocks.</p><p>如果我们假设存在去中心化支付网络，并且一个用户平均每年进行3次区块链交易，那么在理想情况下，比特币将能够以1MB的块数支持超过3500万用户（假设2000个交易/ MB或500字节/ Tx ）。 这是非常有限的，为了支持世界上每个使用比特币的人，可能需要增加区块大小。 块大小的简单增加将是硬分叉，这意味着如果所有节点都希望使用更大的块参与网络，则需要更新其钱包。</p><p>While it may appear as though this system will mitigate the block size increases in the short term, if it achieves global scale, it will necessitate a block size increase in the long term. Creating a credible tool to help prevent blockchain spam designed to encourage transactions to timeout becomes imperative.</p><p>尽管该系统看起来似乎将在短期内缓解块大小的增加，但如果要达到全局规模，则从长远来看将有必要增加块大小。 创建一个可靠的工具来帮助防止旨在鼓励交易超时的区块链垃圾邮件变得势在必行。</p><p>To mitigate timelock spam vulnerabilities, non-miner and miners’ consensus rules may also differ if the miners’ consensus rules are more restrictive. Non-miners may accept blocks over 1MB, while miners may have different soft-caps on block sizes. If a block size is above that cap, then that is viewed as an invalid block by other miners, but not by non-miners. The miners will only build the chain on blocks which are valid according to the agreed-upon soft-cap. This permits miners to agree on raising the block size limit without requiring frequent hard-forks from clients, so long as the amount raised by miners does not go over the clients’ hard limit. This mitigates the risk of mass expiry of transactions at once. All transactions which are not redeemed via Exercise Settlement (ES) may have a very high fee attached, and miners may use a consensus rule whereby those transactions are exempted from the soft-cap, making it very likely the correct transactions will enter the blockchain.</p><p>为了缓解时间锁定的垃圾邮件漏洞，如果矿工的共识规则更具限制性，则非矿工和矿工的共识规则也可能会有所不同。 非矿工可以接受超过1MB的块，而矿工可能对块大小具有不同的软上限。 如果区块大小超过该上限，则其他矿工将其视为无效块，而非非矿工则视为无效块。 矿工将只在根据商定的软上限有效的区块上建立链。 只要矿工筹集的资金不超过客户的硬性限制，这便允许矿工同意提高区块大小限制而无需客户频繁进行分叉。 这降低了一次交易大量到期的风险。 所有未通过演习和解（ES）赎回的交易可能会收取很高的费用，矿工可能会使用共识规则，即免于软上限，从而使正确的交易很有可能进入区块链。</p><p>When transactions are viewed as circuits and contracts instead of transaction packets, the consensus risks can be measured by the amount of time available to cover the UTXO set controlled by hostile parties. In effect, the upper bound of the UTXO size is determined by transaction fees and the standard minimum transaction output value. If the bitcoin miners have a deterministic mempool which prioritizes transactions respecting a “weak” local time order of transactions, it could become extremely unprofitable and unlikely for an attack to succeed. Any transaction spam time attack by broadcasting the incorrect Commitment Transaction is extremely high risk for the attacker, as it requires an immense amount of bitcoin and all funds committed in those transactions will be lost if the attacker fails.</p><p>当将交易视为电路和合同而不是交易数据包时，共识风险可以通过覆盖敌对方控制的UTXO集的可用时间来衡量。 实际上，UTXO大小的上限由交易费用和标准最小交易输出值确定。 如果比特币矿工拥有确定性的内存池，该内存池优先考虑“弱”本地交易时间顺序的交易，则它可能变得极其无利可图，并且攻击成功的可能性很小。 通过广播不正确的<code>Commitment Tx</code>而进行的任何垃圾邮件时间攻击，对于攻击者来说都是极高的风险，因为它需要大量的比特币，并且如果攻击者失败，在这些交易中投入的所有资金都将丢失。</p><h2 id="11-Use-Cases"><a href="#11-Use-Cases" class="headerlink" title="11. Use Cases"></a>11. Use Cases</h2><p>In addition to helping bitcoin scale, there are many uses for transactions on the Lightning Network:</p><p>除了帮助扩大比特币规模外，Lightning Network上的交易还有很多用途：</p><ul><li><p>Instant Transactions. Using Lightning, Bitcoin transactions are now nearly instant with any party. It is possible to pay for a cup of coffee with direct non-revocable payment in milliseconds to seconds.</p><p>即时交易。 使用闪电，比特币交易现在几乎可以与任何一方进行。 您可以在毫秒到秒之间直接支付不可撤销的费用来支付一杯咖啡的费用。</p></li><li><p>Exchange Arbitrage. There is presently incentive to hold funds on exchanges to be ready for large market moves due to 3-6 block confirmation times. It is possible for the exchange to participate in this network and for clients to move their funds on and off the exchange for orders nearly instantly. If the exchange does not have deep market depth and commits to only permitting limit orders close to the top of the order book, then the risk of coin theft becomes much lower. The exchange, in effect, would no longer have any need for a cold storage wallet. This may substantially reduce thefts and the need for trusted third party custodians. </p><p>外汇套利。 由于存在3到6个区块的确认时间，目前有激励将资金保留在交易所上，以准备进行大规模的市场交易。 交易所可以参与该网络，客户可以几乎立即将其资金用于交易所的内外交易。 如果交易所没有很深的市场深度，并承诺只允许限价订单接近订单簿的顶部，那么硬币被盗的风险就会大大降低。 实际上，该交换将不再需要冷藏钱包。 这可以大大减少盗窃和对可信第三方保管人的需求。</p></li><li><p>Micropayments. Bitcoin blockchain fees are far too high to accept micropayments, especially with the smallest of values. With this system, near-instant micropayments using Bitcoin without a 3rd party custodian would be possible. It would enable, for example, paying per-megabyte for internet service or per-article to read a newspaper.</p><p>小额付款。 比特币区块链费用太高，无法接受小额付款，尤其是价值最小的小额付款。 有了这个系统，就可以在没有第三者保管人的情况下使用比特币进行近乎即时的小额支付。 例如，它将使每兆字节的互联网服务费用或每篇文章的阅读费用增加。</p></li><li><p>Financial Smart Contracts and Escrow. Financial contracts are especially time-sensitive and have higher demands on blockchain computation. By moving the overwhelming majority of trustless transactions off-chain, it is possible to have highly complex transaction contract terms without ever hitting the blockchain.</p><p>金融智能合约和托管。 金融合同对时间特别敏感，并且对区块链计算有更高的要求。 通过将绝大多数的无信任交易移出链下，可以在不触及区块链的情况下拥有高度复杂的交易合同条款。</p></li><li><p>Cross-Chain Payments. So long as there are similar hash-functions across chains, it’s possible for transactions to be routed over multiple chains with different consensus rules. The sender does not have to trust or even know about the other chains – even the destination chain. Simiarly, the receiver does not have to know anything about the sender’s chain or any other chain. All the receiver cares about is a conditional payment upon knowledge of a secret on their chain.  Payment can be routed by participants in both chains in the hop. E.g. Alice is on Bitcoin, Bob is on both Bitcoin and X-Coin and Carol is on a hypothetical X-Coin, Alice can pay Carol without understanding the X-Coin consensus rules.</p><p>跨链支付。 只要跨链具有类似的哈希函数，就可以通过具有不同共识规则的多条链对交易进行路由。 发送者不必信任甚至不了解其他链，甚至不必知道目的地链。 同样，接收者不必了解发送者链或任何其他链。 接收者所关心的只是根据对链上秘密的了解有条件地付款。 跃点中两个链中的参与者都可以路由付款。 例如。 Alice使用比特币，Bob使用比特币和X-Coin，而Carol使用假设的X-Coin，Alice可以在不了解X-Coin共识规则的情况下向Carol付款。</p></li></ul><h2 id="12-Conclusion"><a href="#12-Conclusion" class="headerlink" title="12 Conclusion"></a>12 Conclusion</h2><p>Creating a network of micropayment channels enables bitcoin scalability, micropayments down to the satoshi, and near-instant transactions. These channels represent real Bitcoin transactions, using the Bitcoin scripting opcodes to enable the transfer of funds without risk of counterparty theft, especially with long-term miner risk mitigations.</p><p>创建小额支付通道网络可实现比特币的可扩展性，小巧的小额支付以及近乎即时的交易。 这些通道代表了真实的比特币交易，使用比特币脚本操作码来实现资金转移，而没有交易对手被盗的风险，尤其是在长期减轻矿工风险的情况下。</p><p>If all transactions using Bitcoin were on the blockchain, to enable 7 billion people to make two transactions per day, it would require 24GB blocks every ten minutes at best (presuming 250 bytes per transaction and 144 blocks per day). Conducting all global payment transactions on the blockchain today implies miners will need to do an incredible amount of computation, severely limiting bitcoin scalability and full nodes to a few centralized processors.</p><p>如果所有使用比特币的交易都在区块链上，要使70亿人每天能够进行两次交易，则每十分钟最多需要24GB块（假设每笔交易250个字节，每天144个块）。 今天，在区块链上进行所有全球支付交易意味着，矿工将需要进行大量的计算，从而将比特币的可扩展性和完整的节点严格限制在少数中央处理器中。</p><p>If all transactions using Bitcoin were conducted inside a network of micropayment channels, to enable 7 billion people to make two channels per year with unlimited transactions inside the channel, it would require 133 MB blocks (presuming 500 bytes per transaction and 52560 blocks per year). Current generation desktop computers will be able to run a full node with old blocks pruned out on 2TB of storage.</p><p>如果所有使用比特币的交易都是在小额支付通道网络内进行的，则要使70亿人每年创建两个通道，且通道内无限制交易，则将需要133 MB块（假设每笔交易500字节，每年52560块） 。 当前一代的台式计算机将能够运行完整节点，并在2TB的存储空间上删除旧块。</p><p>With a network of instantly confirmed micropayment channels whose payments are encumbered by timelocks and hashlock outputs, Bitcoin can scale to billions of users without custodial risk or blockchain centralization when transactions are conducted securely off-chain using bitcoin scripting, with enforcement of non-cooperation by broadcasting signed multisignature transactions on the blockchain.</p><p>通过即时确认的小额支付通道网络，其支付受到时间锁和哈希锁输出的阻碍，当使用比特币脚本安全地在链外进行交易并强制执行不合作时，比特币可以扩展到数十亿用户，而无托管风险或区块链集中化 在区块链上广播已签名的多重签名交易。</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>闪电网络（三）哈希时间锁合约：Hashed Timelock Contract (HTLC)</title>
      <link href="/2019/11/20/blockchain/07/"/>
      <url>/2019/11/20/blockchain/07/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><p>PS：这篇文章的英语表述特别native，而且全篇59页，写的非常详细，是一片不可多得的佳作。由于原文内容非常长，所以这里将原文拆成4个部分，分别为：</p><ul><li>（一）微支付通道</li><li>（二）双向支付通道：Bidirectional Payment Channels + RSMC</li><li>（三）哈希时间锁合约：Hashed Timelock Contract (HTLC) </li><li>（四）比特币闪电网络：The Bitcoin Lightning Network</li></ul><p><strong>本文为本系列的第三篇，文中的标题序号均按照原论文中顺序进行编号</strong></p><h2 id="4-Hashed-Timelock-Contract-HTLC"><a href="#4-Hashed-Timelock-Contract-HTLC" class="headerlink" title="4. Hashed Timelock Contract (HTLC)"></a>4. Hashed Timelock Contract (HTLC)</h2><p>A bidirectional payment channel only permits secure transfer of funds inside a channel. To be able to construct secure transfers using a network of channels across multiple hops to the final destination requires an additional construction, a Hashed Timelock Contract (HTLC). </p><p>双向支付通道仅允许在<strong>一个</strong>通道内安全转移资金。为了能够使用跨多跳的信道网络构造到最终目的地的安全传输，需要进行额外的构造，即哈希时间锁定合约（HTLC）。也就是说，在（二）中讲到的那种双向支付通道需要被扩展，而HTLC就是这个强化版。</p><p>The purpose of an HTLC is to allow for global state across multiple nodes via hashes. This global state is ensured by time commitments and time-based unencumbering of resources via disclosure of preimages. Transactional “locking” occurs globally via commitments, at any point in time a single participant is responsible for disclosing to the next participant whether they have knowledge of the preimage R. This construction does not require custodial trust in one’s channel counterparty, nor any other participant in the network.</p><p>HTLC的目的是能够使得<strong>通过散列跨越多个节点的全局状态</strong>成立。<strong>这种全局状态由commitment的时间和基于时间的资源无阻碍(通过公开预映像)来保证。</strong>交易性“锁定”是通过<code>Commitment</code> 在全局范围内发生的，在任何时间点，单个参与者负责<strong>向下一个参与者公开他们是否了解原像R</strong>。这种构造不需要对通道对手方的托管信任，也不需要对网络中的任何其他参与者的托管信任。 </p><blockquote><p>这里的描述看的云里雾里的，其实可以这样理解，借助架构之道与术公众号的一张图</p><p><img src="/2019/11/20/blockchain/07/1574255741292.png" alt="1574255741292"></p><p>其实就是Alice和Eric想要建立一个通道，二者之间的通道由多跳组成（A、B、C、D、E），因此就是一个<strong>多跳的信道网络</strong>。HTLC就是应用于这种场景的一种算法。</p></blockquote><p>In order to achieve this, an HTLC must be able to create certain transactions which are only valid after a certain date, using nLockTime, as well as information disclosure to one’s channel counterparty. Additionally, this data must be revocable, as one must be able to undo an HTLC.</p><p>为了实现这一目标，HTLC必须能够<strong>使用nLockTime创建某些交易</strong>，这些交易<strong>仅在特定日期后才有效</strong>，并且<strong>必须向通道的另一方披露信息</strong>。 此外，此数据必须是可撤消的，即必须能够撤消HTLC。</p><p>An HTLC is also a channel contract with one’s counterparty which is enforcible via the blockchain. The counterparties in a channel agree to the following terms for a Hashed Timelock Contract:</p><p>HTLC也是与交易对手的通道合约，可以通过区块链强制执行。 通道中的交易对手同意以下有关HTLC的条款：</p><ol><li><p>If Bob can produce to Alice an unknown 20-byte random input data R from a known hash H, within three days, then Alice will settle the contract by paying Bob 0.1 BTC.</p><p>如果Bob可以在三天内从已知哈希H向Alice生成未知的20字节随机输入数据R，则Alice将通过向Bob支付0.1 BTC来结算合约。</p></li><li><p>If three days have elapsed, then the above clause is null and void and the clearing process is invalidated, both parties must not attempt to settle and claim payment after three days.</p><p>如果超过了三天，则以上条款无效，并且结算流程无效，双方不得在三天后尝试结算并要求付款。</p></li><li><p>Either party may (and should) pay out according to the terms of this contract in any method of the participants choosing and close out this contract early so long as both participants in this contract agree.</p><p>只要本合约双方当事人同意，任何一方都可以(也应该)按照本合同的条款以任何方式并提前终止本合约。</p></li><li><p>Violation of the above terms will incur a maximum penalty of the funds locked up in this contract, to be paid to the non-violating counterparty as a fidelity bond.</p><p>违反上述条款将对本合约中锁定的资金处以最高罚金，并将其作为忠诚保证金支付给非违约交易对手。</p></li></ol><p>For clarity of examples, we use days for HTLCs and block height for RSMCs. In reality, the HTLC should also be defined as a block height (e.g. 3 days is equivalent to 432 blocks)</p><p>为了使示例更清晰，我们使用days表示HTLCs，使用block height表示RSMCs。实际上，HTLC也应该被定义为一个block height（区块高度）(例如3天等于432个块)</p><p>In effect, one desires to construct a payment which is contingent upon knowledge of R by the recipient within a certain timeframe. After this timeframe, the funds are refunded back to the sender.</p><p>实际上，人们希望构建一种付款方式，<strong>该付款方式取决于接收者在特定时间范围内对R的了解</strong>。 在此时间段之后，资金将退还给发送者。</p><p>Similar to RSMCs, these contract terms are programatically enforced on the Bitoin blockchain and do not require trust in the counterparty to adhere to the contract terms, as all violations are penalized via unilaterally enforced fidelity bonds, which are constructed using penalty transactions spending from commitment states. If Bob knows R within three days, then he can redeem the funds by broadcasting a transaction; Alice is unable to withhold the funds in any way, because the script returns as valid when the transaction is spent on the Bitcoin blockchain.</p><p>与RSMC相似，这些合约条款在Bitoin区块链上以编程方式执行，并且不需要信任对方以遵守合约条款，因为所有违规行为均通过单方面强制执行的忠实保证金进行处罚，该保证金使用<code>Commitment</code> 状态的罚金交易支出构建 。 如果Bob在三天内知道了R，那么他可以通过广播一个交易来赎回资金； Alice无法以任何方式扣留资金，因为当交易花费在比特币区块链上时，脚本将返回为有效。</p><p>An HTLC is an additional output in a Commitment Transaction with a unique output script:</p><p>HTLC是<code>Commitment Tx</code>中的附加输出，具有唯一的输出脚本：</p><pre><code>OP_IF OP_HASH160 &lt;Hash160 (R)&gt; OP_EQUALVERIFY    2 &lt;Alice2&gt; &lt;Bob2&gt; OP_CHECKMULTISIGOP_ELSE    2 &lt;Alice1&gt; &lt;Bob1&gt; OP_CHECKMULTISIGOP_ENDIF</code></pre><p>Conceptually, this script has two possible paths spending from a single HTLC output. The first path (defined in the OP IF) sends funds to Bob if Bob can produce R. The second path is redeemed using a 3-day timelocked refund to Alice. The 3-day timelock is enforced using nLockTime from the spending transaction.</p><p>从概念上讲，此脚本从单个HTLC输出中花费具有两种可能（也就是成功和失败两种情况）</p><ul><li>如果Bob可以产生R，则第一条路径（在OP IF中定义）会将资金发送给Bob。</li><li>3天定期退款给Alice。 使用支出交易中的nLockTime强制执行3天时间锁定。</li></ul><h3 id="4-1-不可撤销的HTLC"><a href="#4-1-不可撤销的HTLC" class="headerlink" title="4.1 不可撤销的HTLC"></a>4.1 不可撤销的HTLC</h3><p>Non-revocable HTLC Construction</p><p><img src="/2019/11/20/blockchain/07/1574237935284.png" alt="1574237935284"></p><p>Figure 11: This is a non-functional naive implementation of an HTLC. Only the HTLC path from the Commitment Transaction is displayed. Note that there are two possible spends from an HTLC output. If Bob can produce the preimage R within 3 days and he can redeem path 1. After three days, Alice is able to broadcast path 2. When 3 days have elapsed either is valid. This model, however, doesn’t work with multiple Commitment Transactions.</p><p>图11：这是HTLC的非功能性的简单实现。 仅显示<code>Commitment Tx</code>中的HTLC路径。请注意，HTLC输出有两种可能的支出：</p><ul><li>如果Bob可以在3天内产生原像R，并且可以赎回path 1，并得到这0.1个btc。</li><li>三天后，Alice可以广播path 2。</li></ul><p>三天后，上面两种情况肯定有一种会生效。但是，<strong>此模型不适用于多个<code>Commitment Tx</code>。</strong></p><p>If R is produced within 3 days, then Bob can redeem the funds by broadcasting the “Delivery” transaction. A requirement for the “Delivery” transaction to be valid requires R to be included with the transaction. If R is not included, then the “Delivery” transaction is invalid. However, if 3 days have elapsed, the funds can be sent back to Alice by broadcasting transaction “Timeout”. When 3 days have elapsed and R has been disclosed, either transaction may be valid.</p><p>如果在<strong>3天内产生了R，那么Bob可以通过广播<code>Delivery Tx</code>来赎回资金</strong>。让<code>Delivery Tx</code>有效的条件是R包含在该交易中。 如果不包括R，则<code>Delivery Tx</code>无效。 但是，<strong>如果3天过去了，Alice可以通过广播 <code>Timeout Tx</code> 将资金发送回Alice。</strong> 当3天过去且R已被披露时，任何一项交易都可能有效。</p><p>It is within both parties individual responsibility to ensure that they can get their transaction into the blockchain in order to ensure the balances are correct. For Bob, in order to receive the funds, he must either broadcast the “Delivery” transaction on the Bitcoin blockchain, or otherwise settle with Alice (while cancelling the HTLC). For Alice, she must broadcast the “Timeout” 3 days from now to receive the refund, or cancel the HTLC entirely with Bob.</p><p>双方都有各自的责任，以确保他们可以将其交易进入区块链，以确保余额正确。 对于Bob来说，为了接收资金，他<strong>必须要么在比特币区块链上广播<code>Delivery Tx</code>，要么以其他方式与Alice达成和解</strong>（即取消HTLC）。 对于Alice，<strong>她必须在3天后播出<code>Timeout Tx</code>，以获取退款，或者与Bob一起彻底取消HTLC。</strong></p><p>Yet this kind of simplistic construction has similar problems as an incorrect bidirectional payment channel construction. When an old Commitment Transaction gets broadcast, either party may attempt to steal funds as both paths may be valid after the fact. For example, if R gets disclosed 1 year later, and an incorrect Commitment Transaction gets broadcast, both paths are valid and are redeemable by either party; the contract is not yet enforcible on the blockchain. Closing out the HTLC is absolutely necessary, because in order for Alice to get her refund, she must terminate the contract and receive her refund. Otherwise, when Bob discovers R after 3 days have elapsed, he may be able to steal the funds which should be going to Alice. With uncooperative counterparties it’s not possible to terminate an HTLC without broadcasting it to the bitcoin blockchain as the uncooperative party is unwilling to create a new Commitment Transaction.</p><p>然而，这种简单的构造具有与不正确的双向支付通道构造类似的问题。 当旧的<code>Commitment Tx</code>被广播时，<strong>任何一方都可能会尝试窃取资金，因为事后两条路径都可能是有效的</strong>。 例如，如果Bob在一年后才披露R，并且错误的<code>Commitment Tx</code>被广播，那么这两个路径都是有效的，并且任何一方都可以赎回。 该合约尚未在区块链上强制执行。 关闭HTLC是绝对必要的，因为要使Alice获得退款，她必须在获得退款的同时彻底关掉HTLC。 否则，当Bob在三天后发现R时，他是可以窃取应归给Alice的资金的。 对于不合作的交易对手，由于不合作的一方不愿创建新的<code>Commitment Tx</code>，因此无法在不将HTLC广播到比特币区块链的情况下终止HTLC。</p><blockquote><p>总的来说是这样的：</p><p>正常情况下，如果Bob在规定的期限内找到了这个R，他需要广播一个<code>Delivery Tx</code>，如果没找到需要和Alice一起将这个HTLC关掉。对于Alicce而言，如果规定的期限内没有认找到这个R（或者叫披露），则她需要广播一个<code>Timeout Tx</code>，这时她就可以拿回她的钱了。</p><p>异常是这样的：Alice想取回它的钱。Bob没有在规定的时间内找到这个R，但也想拿钱，那么他们两个就都能够作弊。对于Alice而言，如果她在广播一个<code>Timeout Tx</code>之后没有关闭掉对应的HTLC，则Bob可能在非时限之内提交<code>Delivery Tx</code>，这样，双方都拿到了钱，这就是出错了的。</p></blockquote><h3 id="4-2-离线可撤销的HTLC"><a href="#4-2-离线可撤销的HTLC" class="headerlink" title="4.2 离线可撤销的HTLC"></a>4.2 离线可撤销的HTLC</h3><p>Off-chain Revocable HTLC</p><p>To be able to terminate this contract off-chain without a broadcast to the Bitcoin blockchain requires embedding RSMCs in the output, which will have a similar construction to the bidirectional channel.</p><p>为了能够在不向比特币区块链进行广播的情况下<strong>在链下终止HTLC合约</strong>，需要在输出中嵌入RSMC，其结构与双向通道类似。</p><p><img src="/2019/11/20/blockchain/07/1574239927526.png" alt="1574239927526"></p><p>Figure 12: If Alice broadcasts C2a, then the left half will execute. If Bob broadcasts C2b, then the right half will execute. Either party may broadcast their Commitment transaction at any time. HTLC Timeout is only valid after 3 days. HTLC Executions can only be broadcast if the preimage to the hash R is known. Prior Commitments (and their dependent transactions) are not displayed for brevity.</p><p>图12：上图中的这么多情况可以总结一下：</p><ul><li>如果Alice广播C2a，则左半部分将执行。 </li><li>如果Bob广播C2b，则将执行右半部分。 </li><li>任何一方都可以<strong>随时广播其对应的<code>Commitment Tx</code></strong>（C2a / C2b）。</li><li>HTLC <code>Timeout</code>（HT1a / HT1b）仅在3天后广播才是合法的。 </li><li>仅当已知哈希R的原像时，才可以广播HTLC Execution（HED1a / HED1b）。 </li></ul><p>为简洁起见，不会显示先前的<code>Commitment</code> （及其相关交易）。</p><p><strong>下面是对上面这张图的一个详细举例</strong></p><p>Presume Alice and Bob wish to update their balance in the channel at Commitment 1 with a balance of 0.5 to Alice and 0.5 to Bob.</p><p>假定Alice和Bob希望在<code>Commitment</code> 1的通道中更新其余额，Alice的余额为0.5，Bob的余额为0.5。</p><p>Alice wishes to send 0.1 to Bob contingent upon knowledge of R within 3 days, after 3 days she wants her money back if Bob does not produce R. </p><p>Alice希望在3天内根据对R的信息将0.1发送给Bob，如果3天内Bob不产生R，她就需要把钱再转回给自己。</p><p>The new Commitment Transaction will have a full refund of the current balance to Alice and Bob (Outputs 0 and 1), with output 2 being the HTLC, which describes the funds in transit. As 0.1 will be encumbered in an HTLC, Alice’s balance is reduced to 0.4 and Bob’s remains the same at 0.5.</p><p>新的<code>Commitment Tx</code>将把当前余额全额退还给Alice和Bob（在图中表示为<code>output 0</code>和<code>output 1</code>），<code>output 2</code>是HTLC，它描述了<strong>在途资金</strong>。 由于HTLC将负担0.1，Alice的余额减少到0.4，Bob的余额保持在0.5。</p><p>This new Commitment Transaction (C2a/C2b) will have an HTLC output with two possible spends. Each spend is different depending on each counterparty’s version of the Commitment Transaction. Similar to the bidirectional payment channel, when one party broadcasts their Commitment, payments to the counterparty will be assumed to be valid and not invalidated. This can occur because when one broadcasts a Commitment Transaction, one is attesting this is the most recent Commitment Transaction. If it is the most recent, then one is also attesting that the HTLC exists and was not invalidated before, so potential payments to one’s counterparty should be valid.</p><p>这项新的<code>Commitment Tx</code>（C2a / C2b）将具有两个可能花费的HTLC输出（也就是<code>output 2</code>会有两个分支）。 每个输出都不同，具体取决于对方的<code>Commitment Tx</code>版本。 与双向付款通道类似，<strong>当一方广播其<code>Commitment Tx</code>时，将假定对交易对手的付款有效。</strong> 之所以会发生这种情况，是因为当一个人广播<code>Commitment Tx</code>时，正在证明这是最新的<code>Commitment Tx</code>。 如果是最新的，则还可以证明HTLC存在并且之前没有失效，因此向交易对手的潜在付款应该是有效的。</p><blockquote><p>（因为先提出commitment Tx的那个人是可能作恶的，而没有提出的那个人没有作恶的动机，所以这里默认认为被动方不会作恶。）</p></blockquote><p>Note that HTLC transaction names (beginning with the letter H) will begin with the number 1, whose values do not correlate with Commitment Transactions. This is simply the first HTLC transaction. HTLC transactions may persist between Commitment Transactions. Each HTLC has 4 keys per side of the transaction (C2a and C2b) for a total of 8 keys per counterparty.</p><p>注意，HTLC交易名称(以字母H开头)将以数字1开头，<strong>其值与<code>Commitment Tx</code>无关。这只是第一个HTLC交易。</strong>HTLC交易可能在<code>Commitment Txs</code>之间持续存在。每个HTLC在交易的每一端都有4个密钥(C2a和C2b)，每个交易对总共有8个密钥。（下面就说了是哪8个，也就是A和B每一边各有4个） </p><p>The HTLC output in the Commitment Transaction has two sets of keys per counterparty in the output.</p><p><strong><code>Commitment Tx</code>中的HTLC输出在output中为每个对手方提供两组密钥。</strong> 下面是对于Alice或者Bob的不同<code>Commitment Tx</code>所做的不同操作。</p><ul><li><p>For Alice’s Commitment Transaction (C2a), the HTLC output script requires multisig(PAlice2; PBob2) encumbered by disclosure of R, as well as multisig(PAlice1; PBob1) with no encumbering.</p><p>对于Alice的<code>Commitment Tx</code>(C2a)，HTLC输出脚本需要通过公开R来阻碍的multisig（PAlice2; PBob2）以及没有阻碍的multisig（PAlice1; PBob1）。</p></li><li><p>For Bob’s Commitment Transaction (C2b), the HTLC output script requires multisig(PAlice6; PBob6) encumbered by disclosure of R, as well as multisig(PAlice5; PBob5) with no encumbering.</p><p>对于Bob的<code>Commitment Tx</code>(C2b)，HTLC输出脚本需要通过公开R来阻碍的multisig（PAlice6; PBob6）以及没有阻碍的multisig（PAlice5; PBob5）。</p></li></ul><p>The HTLC output states are different depending upon which Commitment Transaction is broadcast.</p><p>根据广播的<code>Commitment Tx</code>，HTLC输出状态是不同的。</p><h4 id="4-2-1-发送方广播Commitment-Tx时的HTLC"><a href="#4-2-1-发送方广播Commitment-Tx时的HTLC" class="headerlink" title="4.2.1 发送方广播Commitment Tx时的HTLC"></a>4.2.1 发送方广播Commitment Tx时的HTLC</h4><p><img src="/2019/11/20/blockchain/07/1574239927526.png" alt="1574239927526"></p><p>For the sender (Alice), the “Delivery” transaction is sent as an HTLC Execution Delivery transaction (HED1a), which is not encumbered in an RSMC. It assumes that this HTLC has never been terminated off-chain, as Alice is attesting that the broadcasted Commitment Transaction is the most recent. If Bob can produce the preimage R, he will be able to redeem funds from the HTLC after the Commitment Transaction is broadcast on the blockchain. This transaction consumes multisig(PAlice2; PBob2) if Alice broadcasts her Commitment C2a. Only Bob can broadcast HED1a since only Alice gave her signature for HED1a to Bob.</p><p><strong>对于发送人（Alice），<code>Delivery Tx</code>是作为HTLC执行传递交易（HED1a）发送的</strong>，该交易不受RSMC的约束。 假设该HTLC从未在链下终止，因为Alice证明广播的<code>Commitment Tx</code>是最新的。 如果Bob可以产生原像R，那么他将能够在区块链上广播<code>Commitment Tx</code>后从HTLC赎回资金。 如果Alice广播其<code>Commitment</code> C2a，则此交易将消耗multisig（PAlice2; PBob2）。 因为只有Alice将自己的HED1a签名交给了Bob，Bob才可以广播HED1a。</p><p>However, if 3 days have elapsed since forming the HTLC, then Alice will be able broadcast a “Timeout” transaction, the HTLC Timeout transaction (HT1a). This transaction is an RSMC. It consumes the output multisig(PAlice1; PBob1) without requiring disclosure of R if Alice broadcasts C2a. This transaction cannot enter into the blockchain until 3 days have elapsed. The output for this transaction is an RSMC with multisig(PAlice3; PBob3) with relative maturity of 1000 blocks, and multisig(PAlice4; PBob4) with no requirement for confirmation maturity. Only Alice can broadcast HT1a since only Bob gave his signature for HT1a to Alice.</p><p>但是，如果自形成HTLC以来已经过去了3天，那么Alice将能够广播<code>Timeout Tx</code>，即HTLC超时事务（HT1a）。 该交易是一个RSMC。 如果Alice广播C2a，它将消耗输出multisig（PAlice1; PBob1），而无需公开R。 直到3天后，该交易才能进入区块链。 此事务的输出是具有相对成熟度为1000块的multisig（PAlice3; PBob3）的RSMC，以及不需要确认成熟度的multisig（PAlice4; PBob4）。 因为只有Bob将自己的HT1a签名交给了Alice，所以只有Alice可以广播HT1a。</p><p>After HT1a enters into the blockchain and 1000 block confirmations occur, an HTLC Timeout Revocable Delivery transaction (HTRD1a) may be broadcast by Alice which consumes multisig(PAlice3; PBob3). Only Alice can broadcast HTRD1a 1000 blocks after HT1a is broadcast since only Bob gave his signature for HTRD1a to Alice. This transaction can be revocable when another transaction supersedes HTRD1a using multisig(PAlice4; PBob4) which does not have any block maturity requirements.</p><p><strong>在HT1a进入区块链并进行1000次块确认后，Alice可以广播HTLC <code>Timeout</code> 可撤销 <code>Delivery Tx</code> （HTRD1a）</strong>，该交易需要用到multisig（PAlice3; PBob3）。也就是说Alice想要广播HTRD1a，需要满足的条件是：<strong>Bob需要把HTRD1a的签名交给Alice，即Bob也认可了这条消息</strong>。 当另一笔交易使用multisig（PAlice4; PBob4）取代HTRD1a，而该笔交易没有任何区块成熟度要求时，该笔交易可以撤消。</p><h4 id="4-2-2-接收方广播Commitment-Tx时的HTLC"><a href="#4-2-2-接收方广播Commitment-Tx时的HTLC" class="headerlink" title="4.2.2 接收方广播Commitment Tx时的HTLC"></a>4.2.2 接收方广播Commitment Tx时的HTLC</h4><p>HTLC when the Receiver Broadcasts the Commitment Transaction</p><p>For the potential receiver (Bob), the “Timeout” of receipt is refunded as an HTLC Timeout Delivery transaction (HTD1b). This transaction directly refunds the funds to the original sender (Alice) and is not encumbered in an RSMC. It assumes that this HTLC has never been terminated off-chain, as Bob is attesting that the broadcasted Commitment Transaction (C2b) is the most recent. If 3 days have elapsed, Alice can broadcast HTD1b and take the refund. This transaction consumes multisig(PAlice5; PAlice5) if Bob broadcasts C2b. Only Alice can broadcast HTD1b since Bob gave his signature for HTD1b to Alice.</p><p>对于潜在的接收者（Bob），<strong>收据的“ <code>Timeout</code> ”将作为HTLC <code>Timeout</code>  <code>Delivery Tx</code> （HTD1b）退还。 该交易将资金直接退还给原始发送人（Alice），并且不受RSMC的约束。</strong>它假定该HTLC从未在链下终止，因为Bob证明广播的<code>Commitment Tx</code>（C2b）是最新的。 如果3天过去了，Alice可以播放HTD1b并获得退款。 如果Bob广播C2b，此交易将消耗multisig（PAlice5; PAlice5）。 Bob将自己的HTD1b签名交给Alice之后，只有Alice才能广播HTD1b。</p><p>However, if HTD1b is not broadcast (3 days have not elapsed) and Bob knows the preimage R, then Bob will be able to broadcast the HTLC Execution transaction (HE1b) if he can produce R. This transaction is an RSMC. It consumes the output multisig(PAlice6; PBob6) and requires disclosure of R if Bob broadcasts C2b. The output for this transaction is an RSMC with multisig(PAlice7; PBob7) with relative maturity of 1000 blocks, and multisig(PAlice8; PBob8) which does not have any block maturity requirements. Only Bob can broadcast HE1b since only Alice gave her signature for HE1b to Bob.</p><p>但是，如果未广播HTD1b（尚未过去3天）并且Bob知道原映像R，则<strong>Bob可以广播HTLC执行交易（HE1b）</strong>。该交易是RSMC。 它消耗输出multisig（PAlice6; PBob6），并且如果Bob广播C2b，则要求公开R。 <strong>此交易的输出是具有相对成熟度为1000块的multisig（PAlice7; PBob7）和没有任何成熟度要求的multisig（PAlice8; PBob8）的RSMC。</strong> 因为只有当Alice将她的HE1b签名交给了Bob之后，Bob才可以广播HE1b。</p><p>After HE1b enters into the blockchain and 1000 block confirmations occur, an HTLC Execution Revocable Delivery transaction (HERD1b) may be broadcast by Bob which consumes multisig(PAlice7; PBob7). Only Bob can broadcast HERD1b 1000 blocks after HE1b is broadcast since only Alice gave her signature for HERD1b to Bob. This transaction can be revocable when another transaction supersedes HERD1b using multisig(PAlice8; PBob8) which does not have any block maturity requirements.</p><p>HE1b进入区块链并进行1000次块确认后，Bob可能会广播HTLC执行可撤销传递交易（HERD1b），它消耗了multisig（PAlice7; PBob7）。 广播HE1b之后，且经过了1000个块之后，只有，因为Alice将她的HERD1b签名提供给了Bob，Bob才可以在广播HERD1b。 当另一笔交易使用multisig（PAlice8; PBob8）取代HERD1b时，该笔交易是可撤销的，multisig（PAlice8; PBob8）没有任何块成熟度要求。</p><h3 id="4-3-HTLC-off-line终止"><a href="#4-3-HTLC-off-line终止" class="headerlink" title="4.3 HTLC off-line终止"></a>4.3 HTLC off-line终止</h3><p>After an HTLC is constructed, to terminate an HTLC off-chain requires both parties to agree on the state of the channel. If the recipient can prove knowledge of R to the counterparty, the recipient is proving that they are able to immediately close out the channel on the Bitcoin blockchain and receive the funds. At this point, if both parties wish to keep the channel open, they should terminate the HTLC off-chain and create a new Commitment Transaction reflecting the new balance.</p><p>在构建HTLC之后，要终止HTLC链外要求双方都同意通道状态。 如果接收者可以向交易对手证明R，则接收者证明他们能够<strong>立即关闭比特币区块链上的通道并接收资金</strong>。 此时，<strong>如果双方都希望保持通道畅通，则应终止HTLC链下交易并创建一个反映新余额的新<code>Commitment Tx</code></strong>。</p><p><img src="/2019/11/20/blockchain/07/1574240246235.png" alt="1574240246235"></p><p>Figure 13: Since Bob proved to Alice he knows R by telling Alice R, Alice is willing to update the balance with a new Commitment Transaction. The payout will be the same whether C2 or C3 is broadcast at this time.</p><p>图13：由于Bob通过告诉Alice R向Alice证明了他对R的了解，所以Alice愿意通过新的Commitment Transaction更新余额。 不论此时广播C2还是C3，支出都是相同的。</p><p>Similarly, if the recipient is not able to prove knowledge of R by disclosing R, both parties should agree to terminate the HTLC and create a new Commitment Transaction with the balance in the HTLC refunded to the sender.</p><p>同样，如果接收者无法通过公开R来证明R的知识，则双方都应同意终止HTLC并创建新的<code>Commitment Tx</code>，并将HTLC中的余额退还给发送者。</p><p>If the counterparties cannot come to an agreement or become otherwise unresponsive, they should close out the channel by broadcasting the necessary channel transactions on the Bitcoin blockchain.</p><p>如果交易对手无法达成协议或以其他方式无响应，则他们应通过在比特币区块链上广播必要的通道交易来关闭通道。</p><p>However, if they are cooperative, they can do so by first generating a new Commitment Transaction with the new balances, then invalidate the prior Commitment by exchanging Breach Remedy transactions (BR2a/BR2b). Additionally, if they are terminating a particular HTLC, they should also exchange some of their own private keys used in the HTLC transactions.</p><p>但是，如果他们是合作的，则可以通过<strong>首先使用新的余额生成一个新的<code>Commitment Tx</code>，然后通过交换违约救济交易（BR2a / BR2b）使先前的<code>Commitment</code> 无效</strong>。 此外，如果它们要终止特定的HTLC，则它们还应该交换在HTLC交易中使用的一些自己的私钥。</p><p>For example, Alice wishes to terminate the HTLC, Alice will disclose KAlice1 and KAlice4 to Bob. Correspondingly if Bob wishes to terminate the HTLC, Bob will disclose KBob6 and KBob8 to Alice. After the private keys are disclosed to the counterparty, if Alice broadcasts C2a, Bob will be able to take all the funds from the HTLC immediately. If Bob broadcasts C2b, Alice will be able to take all funds from the HTLC immediately. Note that when an HTLC is terminated, the older Commitment Transaction must be revoked as well.</p><p>例如，Alice希望终止HTLC，Alice将向Bob公开KAlice1和KAlice4。 相应地，如果Bob希望终止HTLC，Bob将向Alice披露KBob6和KBob8。 在向交易对手披露私钥后，如果Alice广播C2a，则Bob将能够立即从HTLC中提取所有资金。 如果Bob广播C2b，Alice将能够立即从HTLC中提取所有资金。 请注意，当HTLC终止时，旧的<code>Commitment Tx</code>也必须被撤销。</p><p><img src="/2019/11/20/blockchain/07/1574240572272.png" alt="1574240572272"></p><p>Figure 14: A fully revoked Commitment Transaction and terminated HTLC. If either party broadcasts Commitment 2, they will lose all their money to the counterparty. Other commitments (e.g. if Commitment 3 is the current Commitment) are not displayed for brevity.</p><p>图14：完全撤销的<code>Commitment Tx</code>和终止的HTLC。 如果任何一方广播<code>Commitment</code> 2，他们将把所有钱都输给对方。 为了简洁起见，其他<code>Commitment</code> （例如，如果<code>Commitment</code> 3是当前<code>Commitment</code> ）则不会显示。</p><p>Since both parties are able to prove the current state to each other, they can come to agreement on the current balance inside the channel. Since they may broadcast the current state on the blockchain, they are able to come to agreement on netting out and terminating the HTLC with a new Commitment Transaction.</p><p>由于双方都可以相互证明当前状态，因此他们可以就通道内部的当前余额达成协议。 由于他们可以在区块链上广播当前状态，因此他们能够就通过新的<code>Commitment Tx</code>净额结算和终止HTLC达成协议。</p><h3 id="4-4-HTLC-建立与关闭次序"><a href="#4-4-HTLC-建立与关闭次序" class="headerlink" title="4.4 HTLC 建立与关闭次序"></a>4.4 HTLC 建立与关闭次序</h3><p>To create a new HTLC, it is the same process as creating a new Commitment Transaction, except the signatures for the HTLC are exchanged before the new Commitment Transaction’s signatures.</p><p>创建新的HTLC的过程与创建新的<code>Commitment Tx</code>的过程相同，只是在新的<code>Commitment Tx</code>的签名之前交换HTLC的签名。</p><p>To close out an HTLC, the process is as follows (from C2 to C3):</p><p>要关闭HTLC，过程如下（从C2到C3）：</p><ol><li><p>Alice signs and sends her signature for RD3b and C3b. At this point Bob can elect to broadcast C3b or C2b (with the HTLC) with the same payout. Bob is willing after receiving C3b to close out C2b.</p><p>Alice在RD3b和C3b上签名并发送她的签名。 此时，Bob可以选择以相同的付款方式广播C3b或C2b（使用HTLC）。 Bob在收到C3b之后愿意关闭C2b。</p></li><li><p>Bob signs and sends his signature for RD3a and C3a, as well as his private keys used for Commitment 2 and the HTLC being terminated; he sends Alice KBobRSMC2, KBob5, and KBob8. At this point Bob should only broadcast C3b and should not broadcast C2b as he will lose all his money if he does so. Bob has fully revoked C2b and the HTLC. Alice is willing after receiving C3a to close out C2b.</p><p>Bob签名并发送RD3a和C3a的签名，以及用于<code>Commitment</code> 2和HTLC终止的私钥； 他发送了Alice KBobRSMC2，KBob5和KBob8。 此时，Bob应该只广播C3b，而不应该广播C2b，因为如果这样做，他将失去所有金钱。 Bob已完全撤销了C2b和HTLC。 Alice在收到C3a之后愿意关闭C2b。</p></li><li><p>Alice signs and sends her signature for RD3b and C3b, as well as her private keys used for Commitment 2 and the HTLC being terminated; she sends Bob KAliceRSMC2, KBob1, and KBob4. At this point neither party should broadcast Commitment 2, if they do so, their funds will be going to the counterparty. The old Commitment and old HTLC are now revoked and fully terminated. Only the new Commitment 3 remains, which does not have an HTLC.  </p><p>Alice签署并发送她对RD3b和C3b的签名，以及她用于<code>Commitment</code> 2和HTLC终止的私钥； 她发送了Bob KAliceRSMC2，KBob1和KBob4。 此时，任何一方都不应广播<code>Commitment</code> 2，如果这样做，则其资金将流向交易对手。 旧的<code>Commitment Tx</code>和旧的HTLC现在被撤销并完全终止。 仅保留新的<code>Commitment</code> 3，它没有HTLC。</p></li></ol><p>When the HTLC has been closed, the funds are updated so that the present balance in the channel is what would occur had the HTLC contract been completed and broadcast on the blockchain. Instead, both parties elect to do off-chain novation and update their payments inside the channel.</p><p>关闭HTLC后，将更新资金，以便通道中的当前余额是HTLC合约完成并在区块链上广播时将发生的情况。 相反，双方都选择进行链外更新并在通道内更新其付款。</p><p>It is absolutely necessary for both parties to complete off-chain novation within their designated time window. For the receiver (Bob), he must know R and update his balance with Alice within 3 days (or whatever time was selected), else Alice will be able to redeem it within 3 days. For Alice, very soon after her timeout becomes valid, she must novate or broadcast the HTLC Timeout transaction. She must also novate or broadcast the HTLC Timeout Revocable Delivery transaction as soon as it becomes valid. If the counterparty is unwilling to novate or is stalling, then one must broadcast the current channel state, including HTLC transactions) onto the Bitcoin blockchain.</p><p>双方绝对有必要在其指定的时间范围内完成链下创新。 对于接收者（Bob），他必须知道R并在3天内（或选择的任何时间）与Alice更新其余额，否则Alice将能够在3天内赎回该余额。 对于Alice， <code>Timeout</code> 生效后不久，她必须更新或广播HTLC <code>Timeout Tx</code> 。 她还必须在HTLC <code>Timeout</code> 可撤销 <code>Delivery Tx</code> 生效后立即进行更新或广播。 如果交易对手不愿更新或停滞不前，则必须将当前频道状态（包括HTLC交易）广播到比特币区块链上。</p><p>The amount of time flexibility with these offers to novate are dependent upon one’s contingent dependencies on the hashlock R. If one establishes a contract that the HTLC must be resolved within 1 day, then if the transaction times out Alice must resolve it by day 4 (3 days plus 1), else Alice risks losing funds.</p><p>这些要约更新的时间灵活性<strong>取决于一个人对哈希锁R的或有依赖性。如果一个人建立了必须在1天之内解决HTLC的合约，那么如果交易 <code>Timeout</code> ，Alice必须在第4天解决（ 3天加1），否则Alice可能会亏损。</strong></p><h2 id="5-密钥存储"><a href="#5-密钥存储" class="headerlink" title="5. 密钥存储"></a>5. 密钥存储</h2><p>Keys are generated using BIP 0032 Hierarchical Deterministic Wallets[17]. Keys are pre-generated by both parties. Keys are generated in a merkle tree and are very deep within the tree. For instance, Alice pre-generates one million keys, each key being a child of the previous key. Alice allocates which keys to use according to some deterministic manner. For example, she starts with the child deepest in the tree to generate many sub-keys for day 1. This key is used as a master key for all keys generated on day 1. She gives Bob the address she wishes to use for the next transaction, and discloses the private key to Bob when it becomes invalidated. When Alice discloses to Bob all private keys derived from the day 1 master key and does not wish to continue using that master key, she can disclose the day 1 master key to Bob. At this point, Bob does not need to store all the keys derived from the day 1 master key. Bob does the same for Alice and gives her his day 1 key.</p><p>密钥是使用BIP 0032分层确定性钱包[17]生成的。 密钥由双方预先生成。 密钥在merkle树中生成，并且在树的深处。 例如，<strong>Alice预先生成一百万个密钥，每个密钥都是前一个密钥的子代</strong>。 Alice根据确定性的方式分配要使用的密钥。 例如，她从树上最深的孩子开始，为第1天生成许多子密钥。此密钥用作第1天生成的所有密钥的主密钥。她为Bob提供了她希望用于下一个地址的地址。 交易，并在无效时向Bob公开私钥。 当Alice向Bob透露从第一天主密钥派生的所有私钥并且不希望继续使用该主密钥时，她可以向Bob透露第一天主密钥。 此时，Bob不需要存储从第一天主密钥派生的所有密钥。 Bob（Bob）为Alice（Alice）做同样的事情，并给了他第一天的钥匙。</p><p>When all Day 2 private keys have been exchanged, for example by day 5, Alice discloses her Day 2 key. Bob is able to generate the Day 1 key from the Day 2 key, as the Day 1 key is a child of the Day 2 key as well.</p><p>当第二天的所有私钥都已交换时，例如到第五天时，Alice就会公开第二天的私钥。 Bob能够从Day 2密钥生成Day 1密钥，因为Day 1密钥也是Day 2密钥的子代。</p><p>If a counterparty broadcasts the wrong Commitment Transaction, which private key to use in a transaction to recover funds can either be brute forced, or if both parties agree, they can use the sequence id number when creating the transaction to identify which sets of keys are used.</p><p>如果交易对手广播了错误的“<code>Commitment Tx</code>”，则交易中用于收回资金的私钥可能被强行使用，或者如果双方都同意，则他们可以在创建交易时使用序列ID号来识别哪些密钥集是 用过的。</p><p>This enables participants in a channel to have prior output states (transactions) invalidated by both parties without using much data at all. By disclosing private keys pre-arranged in a merkle-tree, it is possible to invalidate millions of old transactions with only a few kilobytes of data per channel. Core channels in the Lightning Network can conduct billions of transactions without a need for significant storage costs.</p><p><strong>这使通道中的参与者可以在没有使用大量数据的情况下，由双方使先前的输出状态（交易）无效。 通过公开在merkle树中预先安排的私钥，可以使每个通道只有几千字节的数据而使数百万个旧交易无效。 闪电网络中的核心通道可以进行数十亿笔交易，而无需大量的存储成本。</strong></p><h2 id="6-双向通道的区块链交易费"><a href="#6-双向通道的区块链交易费" class="headerlink" title="6. 双向通道的区块链交易费"></a>6. 双向通道的区块链交易费</h2><p>It is possible for each participant to generate different versions of transactions to ascribe blame as to who broadcast the transaction on the blockchain. By having knowledge of who broadcast a transaction and the ability to ascribe blame, a third party service can be used to hold fees in a 2-of-3 multisig escrow. If one wishes to broadcast the transaction chain instead of agreeing to do a Funding Close or replacement with a new Commitment Transaction, one would communicate with the third party and broadcast the chain to the blockchain. If the counterparty refuses the notice from the third party to cooperate, the penalty is rewarded to the non-cooperative party. In most instances, participants may be indifferent to the transaction fees in the event of an uncooperative counterparty.</p><p>每个参与者都有可能生成不同版本的交易，以<strong>归咎于谁在区块链上广播了交易</strong>。 通过了解谁在广播交易以及归咎于责任的能力，可以使用第三方服务以2-of-3的多重代管托管费用。 如果有人希望广播<code>Tx</code>链而不是同意进行资金结清或用新的<code>Commitment Tx</code>代替，则可以与第三方进行通信并将链广播到区块链上。 如果交易对方拒绝了第三方的合作通知，则罚款将奖励给非合作方。 在大多数情况下，如果交易对手不合作，参与者可能对交易费用无动于衷。</p><p>One should pick counterparties in the channel who will be cooperative, but is not an absolute necessity for the system to function. Note that this does not require trust among the rest of the network, and is only relevant for the comparatively minor transaction fees. The less trusted party may just be the one responsible for transaction fees.</p><p>人们应该在通道中选择愿意合作的对手方，但这并不是该系统运行的绝对必要条件。注意，这并不需要网络其余部分之间的信任，并且只与相对较小的交易费用相关。较不受信任的一方可能只是负责交易费用的一方。</p><p>The Lightning Network fees will likely be significantly lower than blockchain transaction fees. The fees are largely derived from the time-value of locking up funds for a particular route, as well as paying for the chance of channel close on the blockchain. These should be significantly lower than on-chain transactions, as many transactions on a Lightning Network channel can be settled into one single blockchain transaction. With a sufficiently robust and interconnected network, the fees should asymptotically approach negligibility for many types of transactions. With cheap fees and fast transactions, it will be possible to build scalable micropayments, even amongst high-frequency systems such as Internet of Things applications or per-unit micro-billing.</p><p>闪电网络的费用可能会大大低于区块链交易费用。<strong>这些费用主要来自锁定特定线路资金的时间价值</strong>，以及支付区块链频道关闭的机会。这些交易应该比链上交易低得多，因为在一个Lightning网络通道上的许多交易可以被安排到一个单独的区块链交易中。有了一个足够健全和相互连接的网络，收费应该渐进地接近许多交易类型的可忽略性。有了低廉的费用和快速的交易，就有可能构建可扩展的微支付，即使是在物联网应用程序或单位微账单等高频系统之间。</p><h2 id="7-为合约付款"><a href="#7-为合约付款" class="headerlink" title="7. 为合约付款"></a>7. 为合约付款</h2><p>It is possible construct a cryptographically provable “Delivery Versus Payment” contract, or pay-to-contract[18], as proof of payment. This proof can be established as knowledge of the input R from hash(R) as payment of a certain value. By embedding a clause into the contract between the buyer and seller stating that knowing R is proof of funds sent, the recipient of funds has no incentive to disclose R unless they have certainty that they will receive payment. When the funds eventually get pulled from the buyer by their counterparty in their micropayment channel, R is disclosed as part of that pull of funds. One can design paper legal documents that specify that knowledge or disclosure of R implies fulfillment of payment. The sender can then arrange a cryptographically signed contract with knowledge of inputs for hashes treated as fulfillment of the paper contract before payment occurs.  </p><p>可以构造一个加密的可证明的“交付对付款”合约，或付款对合约[18]，作为付款的证明。这个证明可以建立为从哈希(R)中输入R的知识，即支付一定的值。通过在买卖双方之间的合约中嵌入一个条款，说明知道R是资金被发送的证据，资金的接收者没有动机去披露R，除非他们确信他们将收到款项。当资金最终从买方的小额支付通道的交易对手那里撤出时，R将作为资金撤出的一部分被披露。一个人可以设计出书面的法律文件，规定知道或披露R意味着支付的履行。然后，发送方可以安排一个密码签署的合约，该合约具有散列的输入知识，在付款之前将其视为纸质合约的履行。</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>闪电网络（二）双向支付通道：Bidirectional Payment Channels + RSMC</title>
      <link href="/2019/11/20/blockchain/05/"/>
      <url>/2019/11/20/blockchain/05/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><p>PS：这篇文章的英语表述特别native，而且全篇59页，写的非常详细，是一片不可多得的佳作。由于原文内容非常长，所以这里将原文拆成4个部分，分别为：</p><ul><li>（一）微支付通道</li><li>（二）双向支付通道：Bidirectional Payment Channels + RSMC</li><li>（三）哈希时间锁合约：Hashed Timelock Contract (HTLC) </li><li>（四）比特币闪电网络：The Bitcoin Lightning Network</li></ul><p>前面关于综述的部分我就直接用自己的理解简述了，至于后面具体的操作流程则采用段落翻译与理解结合的方式，以便于对照原文理解。</p><p><strong>本文为本系列的第二篇，文中的标题序号均按照原论文中顺序进行编号</strong></p><p>这一部分的目的就是生成一个双向的支付通道，其大致的思路就是两个人同时交一部分押金，然后这两个人之间可以进行任意多次交易，只需要在想要结束通道的时候将两人的余额广播到区块链网络上就可以了，可以采用不设置第三方的方式（RSMC）来自动执行。</p><p>这里，关闭通道有两种方式</p><ul><li>一种是基于RSMC的方式，经过区块链一定时间的区块确认之后默认生效，一方中途退出，另外一方可以立即拿回钱，而不是等到nLockTime到期才能拿回钱，同时，应该对主动退出方实行惩罚。</li><li>另一种是交易双方合作共同关闭通道。</li></ul><p>不过其中的细节还是相当复杂的，需要好好品味，而且论文中有些语句描述非常模棱两可（可能是英语不太好吧），导致理解起来比较困难。</p><p>RSMC用下面这个公众号里写的方式来理解反而更容易，<a href="https://mp.weixin.qq.com/s?__biz=MzU3NjU3NjYxMA==&mid=2247483800&idx=1&sn=9e7cf1690dc0853ec563361ef695d85e&chksm=fd108c95ca67058301ac938bc8da1361dd1ab8001b5b910475ddbefb1ca991a7ca532e190a2b&mpshare=1&scene=23&srcid=&sharer_sharetime=1574219943426&sharer_shareid=e0275a8c90beb99c1f6a71d4254cec74#rd" target="_blank" rel="noopener">第14课 闪电网络(Lightning Network) 之 RSMC</a></p><h2 id="3-双向支付通道"><a href="#3-双向支付通道" class="headerlink" title="3. 双向支付通道"></a>3. 双向支付通道</h2><p>Bidirectional Payment Channels</p><p>Micropayment channels permit a simple deferral of a transaction state to be broadcast at a later time. The contracts are enforced by creating a responsibility for one party to broadcast transactions before or after certain dates. If the blockchain is a decentralized timestamping system, it is possible to use clocks as a component of decentralized consensus[5] to determine data validity, as well as present states as a method to order events[6].</p><p>微支付通道允许<strong>将交易状态的简单延迟到以后广播</strong>。  这些合约的执行方式是，让一方有责任在特定日期之前或之后广播交易。如果区块链是分散式时间戳系统，则可以<strong>使用时钟作为分散式共识[5]的组件来确定数据有效性</strong>，也可以使用当前状态作为对事件[6]进行排序的方法。</p><p>By creating timeframes where certain states can be broadcast and later invalidated, it is possible to create complex contracts using bitcoin transaction scripts. There has been prior work for Hub-and-Spoke Micropayment Channels (and trusted payment channel networkslooking at building a hub-and-spoke network today. However, Lightning Network’s bidirectional micropayment channel requires the malleability softfork described in Appendix A to enable near-infinite scalability while mitigating risks of intermediate node default.  </p><p>通过创建时间框架，某些状态可以被广播，然后在一段时间之后失效，就有可能使用比特币交易脚本创建复杂的合约。之前已经有了<strong>中心辐射型</strong>（Hub-and-Spoke）微支付通道的工作(以及可信的支付通道网络，目前正在考虑构建中心辐射型网络)。然而，Lightning Network的双向微支付通道需要附录A中描述的软分叉的延展性，以支持近乎无限的可伸缩性，同时降低中间节点默认的风险。</p><p>By chaining together multiple micropayment channels, it is possible to create a network of transaction paths. Paths can be routed using a BGPlike system, and the sender may designate a particular path to the recipient. The output scripts are encumbered by a hash, which is generated by the recipient. By disclosing the input to that hash, the recipient’s counterparty will be able to pull funds along the route.</p><p>通过将多个小额付款通道链接在一起，可以<strong>创建交易路径网络</strong>。 可以使用类似BGP的系统进行路由，发送方可以<strong>为接收方指定特定的路径</strong>。输出脚本由接收方生成的散列阻碍。通过公开该散列的输入，接收方的交易对手将能够沿着这条路径提取资金。</p><h3 id="3-1-使用通道的流程"><a href="#3-1-使用通道的流程" class="headerlink" title="3.1 使用通道的流程"></a>3.1 使用通道的流程</h3><h4 id="3-1-1-创建未签名的Funding-Tx"><a href="#3-1-1-创建未签名的Funding-Tx" class="headerlink" title="3.1.1 创建未签名的Funding Tx"></a>3.1.1 创建未签名的Funding Tx</h4><p>An initial channel Funding Transaction is created whereby one or both channel counterparties fund the inputs of this transaction. Both parties create the inputs and outputs for this transaction but do not sign the transaction.</p><p>创建初始通道<code>Funding Tx</code> 是<strong>通过一个或两个通道交易对手方为该交易的投入提供资金而创建的</strong>。双方为该事务创建输入和输出，但不对该事务签名。（对比上面的那个例子，这里的<code>Funding Tx</code>指的就是饭店和水果店老板各自交的100块钱押金）</p><p>下文中的2-of-2的意思应该是从2个人得到输入，然后输出也是这两个人，即from 2 to 2</p><p>The output for this Funding Transaction is a single 2-of-2 multisignature script with both participants in this channel, henceforth named Alice and Bob. Both participants do not exchange signatures for the Funding Transaction until they have created spends from this 2-of-2 output refunding the original amount back to its respective funders. The purpose of not signing the transaction allows for one to spend from a transaction which does not yet exist. If Alice and Bob exchange the signatures from the Funding Transaction without being able to broadcast spends from the Funding Transaction, the funds may be locked up forever if Alice and Bob do not cooperate (or other coin loss may occur through hostage scenarios whereby one pays for the cooperation from the counterparty).</p><p>此资金交易的输出是一个单一的2-of-2多重签名脚本，此通道中的两个参与者都使用这个脚本，将参与者称为Alice和Bob。 双方都不会为这个<code>Funding Tx</code>进行交换签名，直到他们<strong>从2-of-2的输出中创建了支出，并将原始金额退还给了各自的出资者</strong>。 不签名的目的是允许人们<strong>从尚不存在的交易中支出</strong>。 如果Alice和Bob为<code>Founding TX</code>交换了签名，而又无法广播<code>Founding TX</code>的支出，资金可能会永远被锁定 (或其他硬币损失可能发生在人质场景,一个从交易对手支付合作)。 </p><p>Alice and Bob both exchange inputs to fund the Funding Transaction (to know which inputs are used to determine the total value of the channel), and exchange one key to use to sign with later. This key is used for the 2-of-2 output for the Funding Transaction; both signatures are needed to spend from the Funding Transaction, in other words, both Alice and Bob need to agree to spend from the Funding Transaction.</p><p>Alice和Bob都把一些资金放进<code>Funding Tx</code>（以了解哪些输入用于确定通道的总价值），并<strong>交换一个密钥以供日后使用</strong>。 此密钥用于<strong>从<code>Funding Tx</code>进行2-of-2输出</strong>； <strong>从<code>Funding Tx</code>中进行消费需要同时拥有这两个签名，也就是说，Alice和Bob需要同时同意从<code>Funding Tx</code>中支出。</strong></p><h4 id="3-1-2-从未签名的Tx中消费"><a href="#3-1-2-从未签名的Tx中消费" class="headerlink" title="3.1.2 从未签名的Tx中消费"></a>3.1.2 从未签名的Tx中消费</h4><p>The Lightning Network uses a SIGHASH NOINPUT transaction to spend from this 2-of-2 Funding Transaction output, as it is necessary to spend from a transaction for which the signatures are not yet exchanged. SIGHASH NOINPUT, implemented using a soft-fork, ensures transactions can be spent from before it is signed by all parties, as transactions would need to be signed to get a transaction ID without new sighash flags. Without SIGHASH NOINPUT, Bitcoin transactions cannot be spent from before they may be broadcast |it’s as if one could not draft a contract without paying the other party first. SIGHASH NOINPUT resolves this problem. See Appendix A for more information and implementation.</p><p>闪电网络使用SIGHASH NOINPUT交易从2-of-2<code>Funding Tx</code>的资金中支出， 因为必须从尚未交换签名的事务中支出。  使用<strong>软分叉实现的SIGHASH NOINPUT确保交易在所有参与者签名之前就可以被花费</strong>， 因为事务需要在没有新的SIGHASH标志的情况下进行签名才能获得事务ID。如果没有SIGHASH NOINPUT，则不能在广播之前就花费比特币交易|就像是一个人如果不先付钱给另一方就无法起草合同。 SIGHASH NOINPUT解决了此问题。 有关更多信息和实现，请参见附录A。</p><blockquote><p>下面提到的父母和孩子的意思应该指的是：parent意思是<code>Funding Tx</code>这个大头，相当于所有的交易的原始资金都来自这里，因此称之为parent，而child则表示从这个TX中派生出来的交易，资金的源头头来自这里，因此称为child</p></blockquote><p>Without SIGHASH NOINPUT, it is not possible to generate a spend from a transaction without exchanging signatures, since spending the Funding Transaction requires a transaction ID as part of the signature in the child’s input. A component of the Transaction ID is the parent’s (Funding Transaction’s) signature, so both parties need to exchange their signatures of the parent transaction before the child can be spent. Since one or both parties must know the parent’s signatures to spend from it, that means one or both parties are able to broadcast the parent (Funding Transaction) before the child even exists. SIGHASH NOINPUT gets around this by permitting the child to spend without signing the input. With SIGHASH NOINPUT, the order of operations are to:</p><p>如果没有SIGHASH NOINPUT，则<strong>不能在不交换签名的情况下从某个交易中产生支出</strong>，因为花费<code>Funding Tx</code>时需要交易ID作为孩子输入中签名的一部分。 交易ID的一个组成部分是父母（<code>Funding Tx</code>）的签名，因此双方都需要交换父母交易的签名，然后才能花掉孩子。 由于一方或双方必须知道父母的签字才能从中花费，因此，一方或双方都可以在孩子还没有出生之前就广播父母（<code>Funding Tx</code>）。 SIGHASH NOINPUT通过允许孩子在不签名输入的情况下进行消费来解决此问题。 使用SIGHASH NOINPUT，操作顺序为：</p><ol><li><p><strong>Create the parent (Funding Transaction)</strong></p><p>创建父母（<code>Funding Tx</code>），这里就相当于饭店和水果店老板交的那一共200块钱</p></li><li><p><strong>Create the children (Commitment Transactions and all spends from the commitment transactions)</strong></p><p>创建孩子（<code>commitment Tx</code>和所有从<code>commitment Tx</code>花费的交易），这里相当于两人私下自己记账的交易</p></li><li><p><strong>Sign the children</strong></p><p>相当于为<code>commitment Tx</code>进行签名sign</p></li><li><p><strong>Exchange the signatures for the children</strong></p><p>二者对签名后的<code>commitment Tx</code>进行交换</p></li><li><p><strong>Sign the parent</strong></p><p>对父母进行签名，相当于是打上了<code>Funding Tx</code>的签名，这个签名所需要的密钥是在第一步就生成并交换的，只是二者始终没有用到这个密钥。</p></li><li><p><strong>Exchange the signatures for the parent</strong></p><p>将前一步签名后的内容进行交换</p></li><li><p><strong>Broadcast the parent on the blockchain</strong></p><p>在网络上将前面交换后的parent进行广播，相当于往链上写了</p></li></ol><p>One is not able to broadcast the parent (Step 7) until Step 6 is complete. Both parties have not given their signature to spend from the Funding Transaction until step 6. Further, if one party fails during Step 6, the parent can either be spent to become the parent transaction or the inputs to the parent transaction can be double-spent (so that this entire transaction path is invalidated).</p><p>3-7步是一系列的签名操作。在步骤6完成之前，无法广播parent（步骤7）。 双方直到第6步都没有提供<code>Funding Tx</code>的签名。此外，如果一方在第6步中失败，则parent可以被消费并成为parent交易，或者双倍花费parent交易的输入 （以使整个交易路径无效）。（这里的double spent应该指的是一方违约另一方收到了双倍的funding）</p><h4 id="3-1-3-Commitment-Tx-不强制的构造"><a href="#3-1-3-Commitment-Tx-不强制的构造" class="headerlink" title="3.1.3 Commitment Tx: 不强制的构造"></a>3.1.3 Commitment Tx: 不强制的构造</h4><p>Commitment Transactions: Unenforcible Construction</p><p>After the unsigned (and unbroadcasted) Funding Transaction has been created, both parties sign and exchange an initial Commitment Transaction. These Commitment Transactions spends from the 2-of-2 output of the Funding Transaction (parent). However, only the Funding Transaction is broadcast on the blockchain.</p><p>创建未签名（且未广播）的<code>Funding Tx</code>后，双方签署并交换初始的<code>Commitment Tx</code>。 这些<code>Commitment Tx</code>的支出是来自<code>Funding Tx</code>（parent）2-of-2的输出。 但是，只有<code>Funding Tx</code>会在区块链上广播。</p><p>Since the Funding Transaction has already entered into the blockchain, and the output is a 2-of-2 multisignature transaction which requires the agreement of both parties to spend from, Commitment Transactions are used to express the present balance. If only one 2-of-2 signed Commitment Transaction is exchanged between both parties, then both parties will be sure that they are able to get their money back after the Funding Transaction enters the blockchain. Both parties do not broadcast the Commitment Transactions onto the blockchain until they want to close out the current balance in the channel. They do so by broadcasting the present Commitment Transaction.</p><p>由于<code>Funding Tx</code>已经进入区块链，并且输出是2的2多重签名交易，需要双方同时同意才能从中进行支出，因此使用<code>Commitment Tx</code>来表示当前余额。 如果双方之间仅交换了2-of-2的已sign的<code>Commitment Tx</code>，那么双方将确保在<code>Funding Tx</code>进入区块链后能够取回资金。</p><p><strong>！！！！！双方只有在想要关闭当前通道的时候，才将<code>Commitment Tx</code>广播到区块链上！！！！！</strong>。 他们<strong>通过广播当前的<code>Commitment Tx</code>来做到这一点</strong>。</p><p>Commitment Transactions pay out the respective current balances to each party. A naive (broken) implementation would construct an unbroadcasted transaction whereby there is a 2-of-2 spend from a single transaction which have two outputs that return all current balances to both channel counterparties. This will return all funds to the original party when creating an initial Commitment Transaction.</p><p><strong><code>Commitment Tx</code>向每一方支付各自的当前余额</strong>。 简单的（不完整的）实现将构造一个未广播的交易，从而从单个交易中获得2-of-2的支出，该支出有两个输出，<strong>将所有当前余额返还给两个通道的交易对手</strong>。 创建初始<code>Commitment Tx</code>时，这会将所有资金退还给原始方。</p><p><img src="/2019/11/20/blockchain/05/1574146669477.png" alt="1574146669477"></p><p>Figure 1: A naive broken funding transaction is described in this diagram. The Funding Transaction (F), designated in green, is broadcast on the blockchain after all other transactions are signed. All other transactions spending from the funding transactions are not yet broadcast, in case the counterparties wish to update their balance. Only the Funding Transaction is broadcast on the blockchain at this time.</p><p>图1：此图中描述了一个简单的原始资金交易。 在签署所有其他交易后，绿色的<code>Funding Tx</code>（F）在区块链上广播。 <strong>如果交易对手希望更新其余额，则尚未广播所有来自<code>Funding Tx</code>的其他交易支出</strong>。 此时，只有<code>Funding Tx</code>会在区块链上广播。</p><p>For instance, if Alice and Bob agree to create a Funding Transaction with a single 2-of-2 output worth 1.0 BTC (with 0.5 BTC contribution from each), they create a Commitment Transaction where there are two 0.5 BTC outputs for Alice and Bob. The Commitment Transactions are signed first and keys are exchanged so either is able to broadcast the Commitment Transaction at any time contingent upon the Funding Transaction entering into the blockchain. At this point, the Funding Transaction signatures can safely be exchanged, as either party is able to redeem their funds by broadcasting the Commitment Transaction.</p><p>例如，如果Alice和Bob同意创建一个总金额为1.0 BTC的2-of-2输出（双方都贡献了0.5 BTC）的<code>Funding Tx</code>，则他们创建一个<code>Commitment Tx</code>，其中Alice和Bob各有0.5 BTC输出。首先<strong>对<code>Commitment Tx</code>进行签名并交换密钥</strong>，以便<strong>在<code>Funding Tx</code>进入区块链的任何时候都可以广播<code>Commitment Tx</code></strong>。 此时，可以安全地交换<code>Funding Tx</code>签名，因为<strong>任何一方都可以通过广播<code>Commitment Tx</code>来赎回其资金</strong>。</p><p>This construction breaks, however, when one wishes to update the present balance. In order to update the balance, they must update their Commitment Transaction output values (the Funding Transaction has already entered into the blockchain and cannot be changed).</p><p>但是，当人们希望更新当前余额时，这种结构就会中断。 为了更新余额，他们必须更新其<code>Commitment Tx</code>输出值<strong>（<code>Funding Tx</code>已进入区块链，并且无法更改）</strong>。</p><p>When both parties agree to a new Commitment Transaction and exchange signatures for the new Commitment Transaction, either Commitment Transactions can be broadcast. As the output from the Funding Transaction can only be redeemed once, only one of those transactions will be valid. For instance, if Alice and Bob agree that the balance of the channel is now 0.4 to Alice and 0.6 to Bob, and a new Commitment Transaction is created to reflect that, either Commitment Transaction can be broadcast. In effect, one would be unable to restrict which Commitment Transaction is broadcast, since both parties have signed and exchanged the signatures for either balance to be broadcast.  </p><p>当双方同意新的<code>Commitment Tx</code>并交换新的<code>Commitment Tx</code>的签名时，可以通过广播任一<code>Commitment Tx</code>来使得更新的余额生效。 <strong>由于<code>Funding Tx</code>的输出只能兑换一次，因此其中只有一项<code>Commitment Tx</code>交易有效。</strong> 例如，如果爱丽丝（Alice）和鲍勃（Bob）同意通道的余额现在对爱丽丝（Alice）为0.4，对鲍勃（Bob）为0.6，并且创建了一个新的<code>Commitment Tx</code>以反映这一点，则可以广播任意一个<code>Commitment Tx</code>（个人理解这里的广播任意一个指的是<code>Commitment Tx</code>有两个，一个是生成funding tx的时候的，一个是俩人私下转账之后签署的一个<code>Commitment Tx</code>）。 实际上，由于双方已经签名并交换了要广播的任何余额的签名，因此将无法限制广播哪个<code>Commitment Tx</code>。</p><p><img src="/2019/11/20/blockchain/05/1574146958565.png" alt="1574146958565"></p><p>Figure 2: Either of the Commitment Transactions can be broadcast any any time by either party, only one will successfully spend from the single Funding Transaction. This cannot work because one party will not want to broadcast the most recent transaction.</p><p>图2：<strong>任何一方都可以在任何时间广播<code>Commitment Tx</code>中的任何一项，只有一个人可以从单个<code>Funding Tx</code>中成功支出。 由于一方不愿广播最近的交易，因此这是行不通的。</strong>（这里就引入了后面一直在提出要解决的问题，也就是为什么）</p><p>Since either party may broadcast the Commitment Transaction at any time, the result would be after the new Commitment Transaction is generated, the one who receives less funds has significant incentive to broadcast the transaction which has greater values for themselves in the Commitment Transaction outputs. As a result, the channel would be immediately closed and funds stolen. Therefore, one cannot create payment channels under this model.</p><p>由于任何一方都可以随时广播<code>Commitment Tx</code>，因此结果将是在生成新的<code>Commitment Tx</code>之后，<strong>获得较少资金的一方就有很大的动机去广播该交易（比较早的，对自己有利的那一个），从而在<code>Commitment Tx</code>输出中为自己带来更大的价值</strong>。 结果，该通道将立即关闭并且资金被盗。 因此，无法在此模型下创建支付通道。</p><h4 id="3-1-4-Commitment-Tx-违约惩罚"><a href="#3-1-4-Commitment-Tx-违约惩罚" class="headerlink" title="3.1.4 Commitment Tx: 违约惩罚"></a>3.1.4 Commitment Tx: 违约惩罚</h4><p>Since any signed Commitment Transaction may be broadcast on the blockchain, and only one can be successfully broadcast, it is necessary to prevent old Commitment Transactions from being broadcast. It is not possible to revoke tens of thousands of transactions in Bitcoin, so an alternate method is necessary. Instead of active revocation enforced by the blockchain, it’s necessary to construct the channel itself in similar manner to a Fidelity Bond, whereby both parties make commitments, and violations of these commitments are enforced by penalties. If one party violates their agreement, then they will lose all the money in the channel.</p><p>由于任何已签名的<code>Commitment Tx</code>都可以在区块链上广播，并且只能成功广播一次，因此有必要防止旧的<code>Commitment Tx</code>被广播。 不可能撤销比特币中成千上万的交易，因此有必要使用另一种方法。 代替由区块链强制撤销活动，有必要以类似于保真债券的方式构造通道本身，<strong>由双方共同做出承诺，违反这些承诺的行为将受到处罚</strong>。 如果一方违反了他们的协议，那么他们将损失通道中的所有资金。</p><p>For this payment channel, the contract terms are that both parties commit to broadcasting only the most recent transaction. Any broadcast of older transactions will cause a violation of the contract, and all funds are given to the other party as a penalty.</p><p>对于此付款通道，合同条款是双方承诺<strong>仅广播最近的交易</strong>。 <strong>任何较早交易的广播都将违反合同，所有资金均将作为违约金给予对方。</strong></p><p>This can only be enforced if one is able to ascribe blame for broadcasting an old transaction. In order to do so, one must be able to uniquely identify who broadcast an older transaction. This can be done if each counterparty has a uniquely identifiable Commitment Transaction. Both parties must sign the inputs to the Commitment Transaction which the other party is responsible for broadcasting. Since one has a version of the Commitment Transaction that is signed by the other party, one can only broadcast one’s own version of the Commitment Transaction.</p><p>只有在能够归咎于广播旧交易的情况下才可以强制执行此操作。 为此，必须能够唯一地标识谁广播了较旧的交易。 如果每个交易对手都有一个唯一可识别的<code>Commitment Tx</code>，就可以做到这一点。 双方必须签署由另一方负责广播的<code>Commitment Tx</code>的输入。 由于一个人拥有由另一方签署的<code>Commitment Tx</code>版本，因此一个人<strong>只能广播自己的版本的<code>Commitment Tx</code>（为了追究责任用）</strong>。</p><p>For the Lightning Network, all spends from the Funding Transaction output, Commitment Transactions, have two half-signed transactions. One Commitment Transaction in which Alice signs and gives to Bob (C1b), and another which Bob signs and gives to Alice (C1a). These two Commitment Transactions spend from the same output (Funding Transaction), and have different contents; only one can be broadcast on the blockchain, as both pairs of Commitment Transactions spend from the same Funding Transaction. Either party may broadcast their received Commitment Transaction by signing their version and including the counterparty’s signature. For example, Bob can broadcast Commitment C1b, since he has already received the signature for C1b from Alice |he includes Alice’s signature and signs C1b himself. The transaction will be a valid spend from the Funding Transaction’s 2-of-2 output requiring both Alice and Bob’s signature.</p><p>对于闪电网络，<code>Funding Tx</code>输出（<code>Commitment Tx</code>）中的所有支出都有两个半签名交易。 一个<code>Commitment Tx</code>，其中Alice签署并赠予Bob（C1b），另一项Bob签署并赠予Alice（C1a）。 这两个<code>Commitment Tx</code>从同一输出中支出（<code>Funding Tx</code>），并且具有不同的内容； 由于两对<code>Commitment Tx</code>都从同一笔<code>Funding Tx</code>中支出，因此只能在区块链上进行广播。 任何一方都可以通过签署其版本并包括交易对手的签名来广播其收到的<code>Commitment Tx</code>。 例如，鲍勃可以广播承诺C1b，因为他已经从爱丽丝那里收到了C1b的签名|他包括爱丽丝的签名和他自己的C1b签名。 该交易将是<code>Funding Tx</code>的2-of-2输出（需要Alice和Bob签名）的有效支出。</p><p><img src="/2019/11/20/blockchain/05/1574147424719.png" alt="1574147424719"></p><p>Figure 3: Purple boxes are unbroadcasted transactions which only Alice can broadcast. Blue boxes are unbroadcasted transaction which only Bob can broadcast. Alice can only broadcast Commitment 1a, Bob can only broadcast Commitment 1b. Only one Commitment Transaction can be spent from the Funding Transaction output. Blame is ascribed, but either one can still be spent with no penalty.</p><p>图3：紫色框是未广播的交易，<strong>只有爱丽丝可以广播</strong>。 蓝框是未广播的交易，<strong>只有鲍勃可以广播</strong>。 爱丽丝只能广播Commitment 1a，鲍勃只能广播Commitment 1b。 <code>Funding Tx</code>输出中只能花费一项<code>Commitment Tx</code>。 归咎于罪魁祸首，但任何一方仍然可以不受惩罚。</p><p>However, even with this construction, one has only merely allocated blame. It is not yet possible to enforce this contract on the Bitcoin blockchain. Bob still trusts Alice not to broadcast an old Commitment Transaction. At this time, he is only able to prove that Alice has done so via a half-signed transaction proof.</p><p>然而，即使有了这样的解释，人们也只能责怪（blame）。目前还不可能在比特币区块链上执行该合同。Bob仍然相信Alice不会广播旧的<code>Commitment Tx</code>。此时，他只能通过一个半签名的事务证明来证明Alice已经这样做了。</p><h3 id="3-2-创建带合同撤销的通道"><a href="#3-2-创建带合同撤销的通道" class="headerlink" title="3.2 创建带合同撤销的通道"></a>3.2 创建带合同撤销的通道</h3><p>To be able to actually enforce the terms of the contract, it’s necessary to construct a Commitment Transaction (along with its spends) where one is able to revoke a transaction. This revocation is achievable by using data about when a transaction enters into a blockchain and using the maturity of the transaction to determine validation paths.</p><p>为了能够实际执行合约，有必要构建一个能<strong>够撤消（revoke）交易的<code>Commitment Tx</code></strong>（连同支出）。 通过使用有关交易何时进入区块链的数据并使用交易的成熟度来确定验证路径，可以实现这种撤销。</p><h3 id="3-3-基于Sequence成熟度的合约（RSMC）"><a href="#3-3-基于Sequence成熟度的合约（RSMC）" class="headerlink" title="3.3 基于Sequence成熟度的合约（RSMC）"></a>3.3 基于Sequence成熟度的合约（RSMC）</h3><p>Sequence Maturity，通俗点讲，就是等到Sequence Number满足条件了，进行履约。</p><p>所以翻译成中文就是：<strong>可撤销的、基于Sequence成熟度的合约。</strong></p><p>Mark Freidenbach has proposed that Sequence Numbers can be enforcible via a relative block maturity of the parent transaction via a soft-fork[12]. This would allow some basic ability to ensure some form of relative block confirmation time lock on the spending script. In addition, an additional opcode, OP CHECKSEQUENCEVERIFY[13] (a.k.a. OP RELATIVECHECKLOCKTIMEVERIFY)[14], would permit further abilities, including allowing a stop-gap solution before a more permanent solution for resolving transaction malleability. A future version of this paper will include proposed solutions.</p><p>Mark Freidenbach提出，可以通过软分叉通过父事务的相对块成熟度来<strong>强制执行序列号</strong>。 这将提供一些基本功能，以确保在支出脚本上锁定某种形式的相对块确认时间。 另外，附加的操作码OP CHECKSEQUENCEVERIFY [13]（又称OP RELATIVECHECKLOCKTIMEVERIFYY）[14]将允许进一步的功能，包括在解决交易延展性的更永久性解决方案之前允许采用权宜之计。 本文的未来版本将包括建议的解决方案。</p><p>To summarize, Bitcoin was released with a sequence number which was only enforced in the mempool of unconfirmed transactions. The original behavior permitted transaction replacement by replacing transactions in the mempool with newer transactions if they have a higher sequence number. Due to transaction replacement rules, it is not enforced due to denial of service attack risks. It appears as though the intended purpose of the sequence number is to replace unbroadcasted transactions. However, this higher sequence number replacement behavior is unenforcible. One cannot be assured that old versions of transactions were replaced in the mempool and a block contains the most recent version of the transaction. A way to enforce transaction versions off-chain is via time commitments.</p><p>总而言之，比特币的发布序列号仅在<strong>未确认交易的内存池中</strong>强制执行。 原始行为允许在内存池中通过较新的交易替换较早的交易（根据序号判断先后）。 根据交易替换规则，由于拒绝服务攻击风险，这一规则并未强制执行。似乎序列号原本的目的是<strong>替换未广播的事务</strong>。 但是，这种更高的序号替换行为是<strong>不可强制的（unenforcible）</strong>。 不能保证在内存池中已替换了旧版本的事务，并且一个块中包含该事务的最新版本。 强制执行链下交易版本的方法是通过时间承诺。</p><p>A Revocable Transaction spends from a unique output where the transaction has a unique type of output script. This parent’s output has two redemption paths where the first can be redeemed immediately, and the second can only be redeemed if the child has a minimum number of confirmations between transactions. This is achieved by making the sequence number of the child transaction require a minimum number of confirmations from the parent. In essence, this new sequence number behavior will only permit a spend from this output to be valid if the number of blocks between the output and the redeeming transaction is above a specified block height.</p><p><code>Revocable Transaction</code>（可撤销交易）从唯一输出中支出，其中该交易具有唯一类型的输出脚本。 此父级的输出有两个赎回路径(redemption paths)，其中第一个可以立即赎回，而第二个<strong>需要经过一个最少确认次数之后</strong>才能赎回。 这是通过使子事务的序列号<strong>要求最小数量的父级确认来实现的</strong>。实际上，这种新的序列号行为只允许在输出和赎回事务之间经过的区块数量超过指定块高度（这里的指定高度也就是后面所说的nSequence）时，此输出中的开销才有效（经过确认后才有效）。</p><p>A transaction can be revoked with this sequence number behavior by creating a restriction with some defined number of blocks defined in the sequence number, which will result in the spend being only valid after the parent has entered into the blockchain for some defined number of blocks. This creates a structure whereby the parent transaction with this output becomes a bonded deposit, attesting that there is no revocation. A time period exists which anyone on the blockchain can refute this attestation by broadcasting a spend immediately after the transaction is broadcast.</p><p>通过创建具有在序列号中定义的一些定义数量的块的限制，可以使用这种序列号行为撤销交易，这将导致支出仅在父级进入区块链中的某些定义数量的块之后才有效。 这创建了一个结构，由此具有此输出的父交易成为保证金，证明没有撤销。 存在一个时间段，区块链上的任何人都可以在广播交易后立即广播支出来反驳此证明。</p><p>If one wishes to permit revocable transactions with a 1000-confirmation delay, the output transaction construction would remain a 2-of-2 multisig:</p><p>如果希望允许1000确认延迟的<code>Revocable Transaction</code>，则输出交易构造将保持2-of-2的多重信号：</p><p><code>2 &lt;Alice1&gt; &lt;Bob1&gt; 2 OP CHECKMULTISIG</code></p><p>However, the child spending transaction would contain a nSequence value of 1000. Since this transaction requires the signature of both counterparties to be valid, both parties include the nSequence number of 1000 as part of the signature. Both parties may, at their discretion, agree to create another transaction which supersedes that transaction without any nSequence number.</p><p>但是，<strong>child交易将包含一个值为1000的nSequence</strong>。由于此交易需要双方的签名才有效，所以双方都<strong>将值为1000的nSequence作为签名的一部分</strong>。双方可以自行决定创建另一个没有任何nSequence的交易</p><p>This construction, a Revocable Sequence Maturity Contract (RSMC), creates two paths, with very specific contract terms.</p><p>这种可撤销序列成熟度合同（RSMC）的构造创建了两条具有非常详细的合同条款的路径。</p><p>The contract terms are:  </p><ol><li><p>All parties pay into a contract with an output enforcing this contract</p><p>所有各方都<strong>向合同中支付一定数额的款项</strong>，以执行本合同</p></li><li><p>Both parties may agree to send funds to some contract, with some waiting period (1000 confirmations in our example script). This is the revocable output balance.</p><p>双方会同意将资金发送到某个合同，但有一些等待期(在我们的示例脚本中有1000个区块确认之后)。这是<strong>可撤销的输出平衡</strong>。</p></li><li><p>One or both parties may elect to not broadcast (enforce) the payouts until some future date; either party may redeem the funds after the waiting period at any time.</p><p>一方或双方可以选择<strong>在将来的某个日期之前不广播（强制执行）付款</strong>； 双方均可在<strong>等待期过后随时赎回</strong>资金。</p></li><li><p>If neither party has broadcast this transaction (redeemed the funds), they may revoke the above payouts if and only if both parties agree to do so by placing in a new payout term in a superseding transaction payout. The new transaction payout can be immediately redeemed after the contract is disclosed to the world (broadcast on the blockchain).</p><p>如果任何一方都没有广播此交易（赎回资金），则当且仅当双方同意通过<strong>在取代的交易支出中放置新的支出期限来撤销上述支出</strong>时，他们才可以撤消上述支出。 合同向全世界披露后（在区块链上广播），可以立即赎回新的交易支出。</p></li><li><p>In the event that the contract is disclosed and the new payout structure is not redeemed, the prior revoked payout terms may be redeemed by either party (so it is the responsibility of either party to enforce the new terms).</p><p>如果<strong>披露了合同且未兑现新的支出结构</strong>，则任何一方都可以赎回先前撤销的支出条款（因此，执行新条款是任何一方的责任）。</p></li></ol><p>The pre-signed child transaction can be redeemed after the parent transaction has entered into the blockchain with 1000 confirmations, due to the child’s nSequence number on the input spending the parent.</p><p>由于子项在父项上花费的输入的nSequence编号，在parent交易进入区块链并进行1000个确认后，可以赎回预签名的子项交易。</p><p>In order to revoke this signed child transaction, both parties just agree to create another child transaction with the default field of the nSequence number of MAX INT, which has special behavior permitting spending at any time.</p><p>为了撤销此已签名的子交易，双方仅同意<strong>创建另一个子交易</strong>，其默认字段为MAX INT的nSequence编号，<strong>该子交易具有特殊的行为，允许随时进行支出</strong>。</p><p>This new signed spend supersedes the revocable spend so long as the new signed spend enters into the blockchain within 1000 confirmations of the parent transaction entering into the blockchain. In effect, if Alice and Bob agree to <strong>monitor the blockchain for incorrect broadcast of Commitment Transactions</strong>, the moment the transaction gets broadcast, they are able to spend using the <strong>superseding transaction</strong> immediately. In order to broadcast the revocable spend (deprecated transaction), which spends from the same output as the superseding transaction, they must wait 1000 confirmations. So long as both parties watch the blockchain, the revocable spend will never enter into the transaction if either party prefers the superseding transaction.</p><p>只要新签署的支出在<strong>父交易进入区块链的1000次确认内</strong>进入区块链，<strong>就会取代可撤销的支出</strong>。 实际上，如果Alice和Bob同意监视区块链中<code>Commitment Tx</code>的不正确广播，则在交易（哪个交易？错误的吗）被广播的那一刻，他们能够立即<strong>使用替代交易进行消费</strong>。为了广播可撤消的支出（弃用的交易，deprecated transaction），该支出来自与替代交易<code>superseding transaction</code>相同的输出，他们必须等待1000次确认。 只要双方都关注区块链，如果任何一方更倾向于替代交易<code>superseding transaction</code>，可撤销的支出将永远不会进入交易。</p><p>Using this construction, anyone could create a transaction, not broadcast the transaction, and then later create incentives to not ever broadcast that transaction in the future via penalties. This permits participants on the Bitcoin network to defer many transactions from ever hitting the blockchain.</p><p>使用这种结构，任何人都可以创建一个事务，而不是传播该事务，然后<strong>通过惩罚来鼓励以后不要传播该事务</strong>。这使得比特币网络上的参与者可以推迟许多交易，以免触及区块链。</p><h4 id="3-3-1-区块链的timestop机制"><a href="#3-3-1-区块链的timestop机制" class="headerlink" title="3.3.1 区块链的timestop机制"></a>3.3.1 区块链的timestop机制</h4><blockquote><p>第一次读的时候，感觉这部分非常费解，为什么忽然说了句这个，其实就是为了后面做了一个铺垫而已，而且后面其实也不太难理解，如果理解不动可以直接跳过。</p></blockquote><p>To mitigate a flood of transactions by a malicious attacker requires a credible threat that the attack will fail. Greg Maxwell proposed using a timestop to mitigate a malicious flood on the blockchain:</p><p>Greg Maxwell建议使用时间停止(timestop)来缓解区块链上的恶意洪水攻击：</p><blockquote><p>There are many ways to address this [flood risk] which haven’t been adequately explored yet |for example, the clock can stop when blocks are full; turning the security risk into more hold-up delay in the event of a dos attack.[15]</p><p>解决此[洪水风险]的方法有很多，但尚未进行充分的探索，例如，当区块已满时，时钟可能会停止； 在发生dos攻击时，将安全风险转化为更多的延迟。[15]</p></blockquote><p>This can be mitigated by allowing the miner to specify whether the current (fee paid) mempool is presently being flooded with transactions. They can enter a “1” value into the last bit in the version number of the block header. If the last bit in the block header contains a “1”, then that block will not count towards the relative height maturity for the nSequence value and the block is designated as a congested block. There is an uncongested block height (which is always lower than the normal block height). This block height is used for the nSequence value, which only counts block maturity (confirmations).</p><p>这可以通过允许矿工指定当前（付费）内存池当前是否充满交易来缓解。 他们可以在区块头的版本号的最后一位输入“ 1”值。 如果区块头中的最后一位包含“ 1”，则该块将不计入nSequence值的相对高度成熟度，并将该块指定为拥塞块（congested block）。 存在未阻塞的块高度（始终低于正常块高度）。 该块高度用于nSequence值，该值仅计算块成熟度（确认）。</p><p>A miner can elect to define the block as a congested block or not. The default code could automatically set the congested block flag as “1” if the mempool is above some size and the average fee for that set size is above some value. However, a miner has full discretion to change the rules on what automatically sets as a congested block, or can select to permanently set the congestion flag to be permanently on or off. It’s expected that most honest miners would use the default behavior defined in their miner and not organize a 51% attack.</p><p>矿工可以选择是否将该块定义为拥塞块（congested）。 如果内存池超过某个大小，并且该设置大小的平均费用超过某个值，则默认代码可以<strong>自动将拥塞块标志设置为“1”</strong>。 但是，矿工有完全的自由裁量权来更改关于自动设置为拥堵区块的规则，或者可以选择将拥堵标志永久设置为永久打开或关闭。 预计大多数诚实的矿工将使用其矿工中定义的默认行为，而不组织51％的攻击。</p><p>For example, if a parent transaction output is spent by a child with a nSequence value of 10, one must wait 10 confirmations before the transaction becomes valid. However, if the timestop flag has been set, the counting of confirmations stops, even with new blocks. If 6 confirmations have elapsed (4 more are necessary for the transaction to be valid), and the timestop block has been set on the 7th block, that block does not count towards the nSequence requirement of 10 confirmations; the child is still at 6 blocks for the relative confirmation value. Functionally, this will be stored as some kind of auxiliary timestop block height which is used only for tracking the timestop value. When the timestop bit is set, all transactions using an nSequence value will stop counting until the timestop bit has been unset. This gives sufficient time and block-space for transactions at the current auxiliary timestop block height to enter into the blockchain, which can prevent systemic attackers from successfully attacking the system.</p><p>例如，如果<strong>父交易输出由nSequence值为10的子项花费，则必须等待10次确认才能使交易生效</strong>。但是，<strong>如果设置了时间停止标志，则即使使用新的块，确认计数也将停止。</strong>如果经过了6个确认（要使交易有效，还需要4个确认），并且在第7个块上设置了timestop块，则该块不计入10个确认的nSequence要求；相对确认值，child仍处于6个区块。从功能上讲，它将存储为某种辅助时间停止块高度，仅用于跟踪timestop值。设置时间停止位后，所有使用nSequence值的事务都将停止计数，直到未设置时间停止位为止。这为在当前辅助时间停止块高度处的交易提供了足够的时间和块空间，以进入区块链，从而可能阻止系统攻击者成功攻击系统。</p><p>However, this requires some kind of flag in the block to designate whether it is a timestop block. For full SPV compatibility (Simple Payment Verification; lightweight clients), it is desirable for this to be within the 80-byte block header instead of in the coinbase. There are two places which may be a good place to put in this flag in the block header: in the block time and in the block version. The block time may not be safe due to the last bits being used as an entropy source for some ASIC miners, therefore a bit may need to be consumed for timestop flags. Another option would be to hardcode timestop activation as a hard consensus rule (e.g. via block size), however this may make things less flexible. By setting sane defaults for timestop rules, these rules can be changed without consensus soft-forks.</p><p>但是，这需要在区块中使用某种标志来指定是否为时间停止块。 为了完全兼容SPV（简单付款验证；轻量级客户端），希望此字段位于80字节的区块头中，而不是在coinbase中。 在区块头中将此标志放在两个位置可能是个好地方：区块时间和区块版本。 由于最后的位被用作某些ASIC矿工的熵源，因此区块时间可能不安全，因此可能需要将某个位用于时间停止标志。 另一个选择是将时间停止激活硬编码为硬共识规则（例如，通过区块大小），但这可能会使事情变得不太灵活。 通过为时间停止规则设置合理的默认值，可以更改这些规则而无需达成共识。</p><p>If the block version is used as a flag, the contextual information must match the Chain ID used in some merge-mined coins.</p><p>如果将块版本用作标记，则上下文信息必须与某些合并开采的硬币中使用的链ID匹配。</p><h4 id="3-3-2-可撤销的-Commitment-Tx"><a href="#3-3-2-可撤销的-Commitment-Tx" class="headerlink" title="3.3.2 可撤销的 Commitment Tx"></a>3.3.2 可撤销的 Commitment Tx</h4><p>By combining the ascribing of blame as well as the revocable transaction, one is able to determine when a party is not abiding by the terms of the contract, and enforce penalties without trusting the counterparty.</p><p>通过将违约惩罚与可撤销交易<code>revocable transaction</code>相结合，人们可以确定当事方<strong>何时不遵守合同条款</strong>，并在不需要信任交易对手的情况下执行处罚。</p><p><img src="/2019/11/20/blockchain/05/1574155643874.png" alt="1574155643874"></p><p>Figure 4: The Funding Transaction F, designated in green, is broadcast on the blockchain after all other transactions are signed. All transactions which only Alice can broadcast are in purple. All transactions which only Bob can broadcast is are blue. Only the Funding Transaction is broadcast on the blockchain at this time.</p><p>图4：在其他所有交易均已签名后，以绿色指定的<code>Funding Tx</code> F在区块链上广播。 只有Alice可以广播的所有交易为紫色。 只有Bob可以广播的所有交易为蓝色。 此时，<strong>只有<code>Funding Tx</code>会在区块链上广播</strong>。</p><p>The intent of creating a new Commitment Transaction is to invalidate all old Commitment Transactions when updating the new balance with a new Commitment Transaction. Invalidation of old transactions can happen by making an output be a Revocable Sequence Maturity Contract (RSMC). To invalidate a transaction, a superseding transaction will be signed and exchanged by both parties that gives all funds to the counterparty in the event an older transaction is incorrectly broadcast. The incorrect broadcast is identified by creating two different Commitment Transactions with the same final balance outputs, however the payment to oneself is encumbered by an RSMC.  </p><p>创建新的<code>Commitment Tx</code>的目的是在<strong>用新的<code>Commitment Tx</code>更新新余额时使所有旧的<code>Commitment Tx</code>无效</strong>。 通过使输出成为可撤销序列成熟度合同（RSMC），可以发生旧事务的无效化。 为使交易无效，当较旧的交易被错误地广播时，双方将签署并交换取代交易，该交易将所有资金提供给交易对手。 <strong>通过创建两个具有相同最终余额输出的不同的<code>Commitment Tx</code>来识别不正确的广播</strong>，但是，RSMC会负担对自己的付款。</p><p>In effect, there are two Commitment Transactions from a single Funding Transaction 2-of-2 outputs. Of these two Commitment Transactions, only one can enter into the blockchain. Each party within a channel has one version of this contract. So if this is the first Commitment Transaction pair, Alice’s Commitment Transaction is defined as C1a, and Bob’s Commitment Transaction is defined as C1b. By broadcasting a Commitment Transaction, one is requesting for the channel to close out and end. The first two outputs for the Commitment Transaction include a Delivery Transaction (payout) of the present unallocated balance to the channel counterparties. If Alice broadcasts C1a, one of the output is spendable by D1a, which sends funds to Bob. For Bob, C1b is spendable by D1b, which sends funds to Alice. The Delivery Transaction (D1a/D1b) is immediately redeemable and is not encumbered in any way in the event the Commitment Transaction is broadcast.</p><p>实际上，单个<code>Founding Tx</code>的2-of-2输出有两个<code>Commitment Tx</code>。 <strong>在这两个<code>Commitment Tx</code>中，只有一个可以进入区块链</strong>。通道中的<strong>每一方都有此合同的一个版本</strong>。 因此，如果这是第一对<code>Commitment Tx</code>，则将Alice的<code>Commitment Tx</code>定义为C1a，将Bob的<code>Commitment Tx</code>定义为C1b。 通过广播<code>Commitment Tx</code>，可以请求关闭并结束该通道。 <code>Commitment Tx</code>的前两个输出包括当前<strong>未分配余额到交易对手的<code>Delivery Tx</code></strong>（交付支付）。 如果Alice广播C1a，则输出之一可由D1a花费，D1a将资金发送给Bob。 对于Bob来说，C1b可由D1b支出，后者将资金发送给Alice。 如果广播<code>Commitment Tx</code>，则可以立即兑换<code>Delivery Tx</code>（D1a / D1b），并且不以任何方式承担任何责任。</p><p>For each party’s Commitment Transaction, they are attesting that they are broadcasting the most recent Commitment Transaction which they own. Since they are attesting that this is the current balance, the balance paid to the counterparty is assumed to be true, since one has no direct benefit by paying some funds to the counterparty as a penalty.</p><p>对于每一方的<code>Commitment Tx</code>，他们都在证明自己正在广播自己拥有的最新的<code>Commitment Tx</code>。 由于他们证明这是当前余额，因此假设支付给对手方的余额是真实的，因为通过向对手方支付一些资金作为罚款没有直接好处。</p><p>The balance paid to the person who broadcast the Commitment Transaction, however, is unverified. The participants on the blockchain have no idea if the Commitment Transaction is the most recent or not. If they do not broadcast their most recent version, they will be penalized by taking all the funds in the channel and giving it to the counterparty. Since their own funds are encumbered in their own RSMC, they will only be able to claim their funds after some set number of confirmations after the Commitment Transaction has been included in a block (in our example, 1000 confirmations). If they do broadcast their most recent Commitment Transaction, there should be no revocation transaction superseding the revocable transaction, so they will be able to receive their funds after some set amount of time (1000 confirmations).</p><p>但是，支付给广播<code>Commitment Tx</code>的人的余额尚未验证。 区块链上的参与者不知道<code>Commitment Tx</code>是否是最新的。 如果他们不广播其最新版本，则将占用该频道中的所有资金并将其交给交易对手，将受到处罚。 由于他们自己的资金由自己的RSMC负担，因此他们只能在将<code>Commitment Tx</code>包含在一个区块中后（在我们的示例中为1000个确认），经过一定数量的确认后才能申领资金。 如果他们确实广播了最近的<code>Commitment Tx</code>，则不应有撤销交易取代可撤消交易，因此他们将能够在一定的时间（1000次确认）之后接收其资金。</p><p>By knowing who broadcast the Commitment Transaction and encumbering one’s own payouts to be locked up for a predefined period of time, both parties will be able to revoke the Commitment Transaction in the future.</p><p>通过知道谁广播了<code>Commitment Tx</code>，并阻碍了自己的付款被锁定了预定的时间，双方将来都可以撤消<code>Commitment Tx</code>。</p><h4 id="3-3-3-合作双方赎回资金的方式"><a href="#3-3-3-合作双方赎回资金的方式" class="headerlink" title="3.3.3 合作双方赎回资金的方式"></a>3.3.3 合作双方赎回资金的方式</h4><p>Redeeming Funds from the Channel: Cooperative Counterparties</p><p>Either party may redeem the funds from the channel. However, the party that broadcasts the Commitment Transaction must wait for the predefined number of confirmations described in the RSMC. The counterparty which did not broadcast the Commitment Transaction may redeem the funds immediately.</p><p>任何一方都可以从通道中赎回资金。 但是，<strong>广播<code>Commitment Tx</code>的一方必须等待RSMC中描述的预定义数量的确认。 没有广播<code>Commitment Tx</code>的交易对手可以立即赎回资金。</strong></p><p>For example, if the Funding Transaction is committed with 1 BTC (half to each counterparty) and Bob broadcasts the most recent Commitment Transaction, C1b, he must wait 1000 confirmations to receive his 0.5 BTC, while Alice can spend 0.5 BTC. For Alice, this transaction is fully closed if Alice agrees that Bob broadcast the correct Commitment Transaction (C1b).</p><p>例如，如果资金交易以1个BTC（每个交易对手的一半）进行承诺，而Bob广播了最新的<code>Commitment Tx</code>C1b，则他必须等待1000次确认才能收到他的0.5个BTC，而Alice则可以花费0.5个BTC。 对于Alice，<strong>如果Alice同意Bob广播正确的<code>Commitment Tx</code>（C1b），则此交易将完全关闭。</strong></p><p><img src="/2019/11/20/blockchain/05/1574155826861.png" alt="1574155826861"></p><p>Figure 5: When Bob broadcasts C1b, Alice can immediately redeem her portion. Bob must wait 1000 confirmations. When the block is immediately broadcast, it is in this state. Transactions in green are transactions which are committed into the blockchain.</p><p>图5：<strong>当Bob广播C1b时，Alice可以立即赎回她的部分。 Bob必须等待1000次确认。</strong> 当立即广播该块时，它处于此状态。 绿色交易是提交到区块链的交易。</p><p>After the Commitment Transaction has been in the blockchain for 1000 blocks, Bob can then broadcast the Revocable Delivery transaction. He must wait 1000 blocks to prove he has not revoked this Commitment Transaction (C1b). After 1000 blocks, the Revocable Delivery transaction will be able to be included in a block. If a party attempt to include the Revocable Delivery transaction in a block before 1000 confirmations, the transaction will be invalid up until after 1000 confirmations have passed (at which point it will become valid if the output has not yet been redeemed).</p><p>在<code>Commitment Tx</code>已在区块链中进行1000个区块之后，Bob可以在区块链网络中广播RD1b（可撤销交付交易）。<strong>他必须等待1000个区块才能证明他尚未撤消此<code>Commitment Tx</code>（C1b）</strong>。 在1000个区块之后，RD1b将可以包含在任意一个区块中。 如果一方试图在1000个确认之前将可撤销交付交易包括在一个区块中，则该交易将在1000个确认之前都是无效的（此时，如果尚未赎回输出，该交易将变为有效）。</p><p><img src="/2019/11/20/blockchain/05/1574155866394.png" alt="1574155866394"></p><p>Figure 6: Alice agrees that Bob broadcast the correct Commitment Transaction and 1000 confirmations have passed. Bob then is able to broadcast the Revocable Delivery (RD1b) transaction on the blockchain.</p><p>图6：<strong>Alice同意Bob广播正确的<code>Commitment Tx</code>，并且已经通过了1000确认。 然后，Bob能够在区块链上广播RD1b</strong></p><p>After Bob broadcasts the Revocable Delivery transaction, the channel is fully closed for both Alice and Bob, everyone has received the funds which they both agree are the current balance they each own in the channel.</p><p><strong>在Bob广播RD1b后，Alice和Bob的通道均会完全关闭，每个人都收到了他们都同意的资金，这是他们各自在该通道中拥有的当前余额。</strong></p><p>If it was instead Alice who broadcast the Commitment Transaction (C1a), she is the one who must wait 1000 confirmations instead of Bob.</p><p>如果是Alice广播<code>Commitment Tx</code>（C1a），则她是必须等待1000次确认的那个人，而不是Bob。</p><h4 id="3-3-4-创建新的-Commitment-Tx并撤销之前的"><a href="#3-3-4-创建新的-Commitment-Tx并撤销之前的" class="headerlink" title="3.3.4 创建新的 Commitment Tx并撤销之前的"></a>3.3.4 创建新的 Commitment Tx并撤销之前的</h4><p>Creating a new Commitment Transaction and Revoking Prior Commitments</p><p>While each party may close out the most recent Commitment Transaction at any time, they may also elect to create a new Commitment Transaction and invalidate the old one.</p><p>尽管各方可以<strong>随时关闭最近的<code>Commitment Tx</code></strong>，但他们也可以选择<strong>创建新的<code>Commitment Tx</code>并使旧的无效</strong>。</p><p>Suppose Alice and Bob now want to update their current balances from 0.5 BTC each refunded to 0.6 BTC for Bob and 0.4 BTC for Alice. When they both agree to do so, they generate a new pair of Commitment Transactions.</p><p>假设Alice和Bob现在希望将其当前余额从各自的0.5 BTC更新为Bob的0.6 BTC和Alice的0.4 BTC。 当他们俩都同意这样做时，就会生成一对新的<code>Commitment Tx</code>。</p><p><img src="/2019/11/20/blockchain/05/1574156002302.png" alt="1574156002302"></p><p>Figure 7: Four possible transactions can exist, a pair with the old commitments, and another pair with the new commitments. Each party inside the channel can only broadcast half of the total commitments (two each). There is no explicit enforcement preventing any particular Commitment being broadcast other than penalty spends, as they are all valid unbroadcasted spends. The Revocable Commitment still exists with the C1a/C1b pair, but are not displayed for brevity.</p><p>图7：可以存在四个可能的事务，一个与旧的承诺对，另一个与新的承诺对。 频道内的每个参与方只能广播全部承诺的一半（也就是自己的那一半）。 没有明确的执法措施可以阻止除罚款支出之外的任何特定Commitment都被广播，因为它们都是有效的未广播支出。 RD1a和RD1b在C1a / C1b对中仍然存在，但为简洁起见并未显示。</p><p>When a new pair of Commitment Transactions (C2a/C2b) is agreed upon, both parties will sign and exchange signatures for the new Commitment Transaction, then invalidate the old Commitment Transaction. This invalidation occurs by having both parties sign a Breach Remedy Transaction (BR1), which supersedes the Revocable Delivery Transaction (RD1). Each party hands to the other a half-signed revocation (BR1) from their own Revocable Delivery (RD1), which is a spend from the Commitment Transaction. The Breach Remedy Transaction will send all coins to the counterparty within the current balance of the channel. For example, if Alice and Bob both generate a new pair of Commitment Transactions (C2a/C2b) and invalidate prior commitments (C1a/C1b), and later Bob incorrectly broadcasts C1b on the blockchain, Alice can take all of Bob’s money from the channel. Alice can do this because Bob has proved to Alice via penalty that he will never broadcast C1b, since the moment he broadcasts C1b, Alice is able to take all of Bob’s money in the channel. In effect, by constructing a Breach Remedy transaction for the counterparty, one has attested that one will not be broadcasting any prior commitments. The counterparty can accept this, because they will get all the money in the channel when this agreement is violated.</p><p><strong>当达成一对新的<code>Commitment Tx</code>（C2a / C2b）时，双方将为新的<code>Commitment Tx</code>签名并交换签名，然后使旧的<code>Commitment Tx</code>无效。</strong>通过使双方签署<strong>违约救济交易</strong>（BR1）<strong>取代可撤消交付交易</strong>（RD1）来发生这种无效。双方从其自己的可撤销交付（RD1）移交给对方半签名的撤销（BR1），这是来自<code>Commitment Tx</code>的支出。<strong>违约救济交易会将所有资产发送到交易对手。</strong>例如，如果Alice和Bob都生成了一对新的<code>Commitment Tx</code>（C2a / C2b）并使先前的<code>Commitment Tx</code>（C1a / C1b）无效，并且后来Bob在区块链上错误地广播了C1b，则Alice可以从通道中获取Bob的所有资金。爱丽丝之所以能够这样做，是因为鲍勃已经通过BR1向爱丽丝证明了自己永远不会播出C1b，自从他播出C1b的那一刻起，爱丽丝就可以将鲍勃的所有钱都拿走。实际上，通过为对方构建违约救济交易，人们证明了该人不会广播任何先前的承诺。交易对手可以接受这一点，因为当违反此协议时，他们将在通道中获得所有款项。<strong>（这段说的挺啰嗦的，就是两个人签了协议，如果一人违约把早期的commitment Tx广播了，对方就能得到违约者所有的钱）</strong></p><p><img src="/2019/11/20/blockchain/05/1574156062370.png" alt="1574156062370"></p><p>Figure 8: When C2a and C2b exist, both parties exchange Breach Remedy transactions. Both parties now have explicit economic incentive to avoid broadcasting old Commitment Transactions (C1a/C1b). If either party wishes to close out the channel, they will only use C2a (Alice) or C2b (Bob). If Alice broadcasts C1a, all her money will go to Bob. If Bob broadcasts C1b, all his money will go to Alice. See previous figure for C2a/C2b outputs.</p><p>图8：当C2a和C2b存在时，双方交换违约救济交易<code>Breach Remedy transactions</code>（<strong>这个钱就是用来保证双方都不违约用的</strong>）。 双方现在都有明确的经济动机以避免广播旧的<code>Commitment Tx</code>（C1a / C1b）。 <strong>如果任何一方希望关闭通道，他们将仅使用C2a或C2b。 如果Alice广播了C1a，她所有的钱都将交给Bob。 如果Bob广播了C1b，他所有的钱都将交给Alice。（这两种操作就是违规地使用了先前的commitment Tx）</strong> 有关C2a / C2b输出，请参见上图。</p><p>Due to this fact, one will likely delete all prior Commitment Transactions when a Breach Remedy Transaction has been passed to the counterparty. If one broadcasts an incorrect (deprecated and invalidated Commitment Transaction), all the money will go to one’s counterparty. For example, if Bob broadcasts C1b, so long as Alice watches the blockchain within the predefined number of blocks (in this case, 1000 blocks), Alice will be able to take all the money in this channel by broadcasting RD1b. Even if the present balance of the Commitment state (C2a/C2b) is 0.4 BTC to Alice and 0.6 BTC to Bob, because Bob violated the terms of the contract, all the money goes to Alice as a penalty. Functionally, the Revocable Transaction acts as a proof to the blockchain that Bob has violated the terms in the channel and this is programatically adjudicated by the blockchain.</p><p>由于这一事实，当违约救济交易已传递给对方时，人们<strong>可能会删除所有先前的<code>Commitment Tx</code></strong>。 如果某人广播了错误的（弃用和无效的<code>Commitment Tx</code>），则所有款项都将流向对方。 例如，如果Bob广播C1b，只要Alice在预定义数量的块（在这种情况下为1000个块）内观看区块链，Alice将能够<strong>通过广播RD1b来占用此频道中的所有资金。</strong> 即使当前的承诺状态余额（C2a / C2b）对Alice来说是0.4 BTC，对Bob来说是0.6 BTC，由于Bob违反了合同条款，所有的钱都将作为惩罚而归给Alice。 从功能上讲，可撤销交易是对区块链的证明，证明Bob违反了频道中的条款，并且由区块链以程序方式裁定。</p><p><img src="/2019/11/20/blockchain/05/1574156119799.png" alt="1574156119799"></p><p>Figure 9: Transactions in green are committed to the blockchain. Bob incorrectly broadcasts C1b (only Bob is able to broadcast C1b/C2b). Because both agreed that the current state is the C2a/C2b Commitment pair, and have attested to each party that old commitments are invalidated via Breach Remedy Transactions, Alice is able to broadcast BR1b and take all the money in the channel, provided she does it within 1000 blocks after C1b is broadcast.</p><p>图9：绿色交易已提交给区块链 Bob错误地广播了C1b（只有Bob能够广播C1b / C2b）。 因为双方都同意当前状态为C2a / C2b承诺对，并且已经通过Breach Remedy Transactions向双方证明了旧承诺已失效，所以<strong>Alice可以在Bob广播了C1b之后的1000个块内广播BR1b并在通道中拿走所有资金</strong>（只要她这样做了） 。</p><p>However, if Alice does not broadcast BR1b within 1000 blocks, Bob may be able to steal some money, since his Revocable Delivery Transaction (RD1b) becomes valid after 1000 blocks. When an incorrect Commitment Transaction is broadcast, only the Breach Remedy Transaction can be broadcast for 1000 blocks (or whatever number of confirmations both parties agree to). <strong>After 1000 block confirmations, both the Breach Remedy (BR1b) and Revocable Delivery Transactions (RD1b) are able to be broadcast at any time.</strong> （这段有歧义，见下面的备注分析）Breach Remedy transactions only have exclusivity withinthis predefined time period, and any time after of that is functionally an expiration of the statute of limitations |according to Bitcoin blockchain consensus, the time for dispute has ended.</p><p>但是，<strong>如果Alice没有在1000个块内广播BR1b，则Bob的恶意操作就生效了，因为他的可撤销传递交易（RD1b）在1000个块后就会生效。</strong> 广播不正确的<code>Commitment Tx</code>时，仅可以广播1000块（或双方同意的任何数量的确认）违约救济交易。 在进行1000次阻止确认后，可以随时广播违规补救措施（BR1b）和可撤销交付交易（RD1b）（是不是可以被合法地广播？）。 违反补救交易仅在此预定时间段内具有排他性，并且在此之后的任何时间根据比特币区块链共识在功能上是<strong>时效性法规期满</strong>，争执时间已经结束。</p><blockquote><p>（这一段描述的感觉有问题啊，应该是说如果Bob发送了一个早期的commitment Tx，如果Alice在1000个区块之内没有提出异议，就已生效了，但是原文中间写的那句加粗的话很有歧义，或许他想表达的意思是在1000个区块之后可以发表异议，但是已经没有意义了）</p></blockquote><p>For this reason, one should periodically monitor the blockchain to see if one’s counterparty has broadcast an invalidated Commitment Transaction, or delegate a third party to do so. A third party can be delegated by only giving the Breach Remedy transaction to this third party. They can be incentivized to watch the blockchain broadcast such a transaction in the event of counterparty maliciousness by giving these third parties some fee in the output. Since the third party is only able to take action when the counterparty is acting maliciously, this third party does not have any power to force close of the channel.</p><p>因此，<strong>应定期监视区块链，以查看对方是否广播了无效的<code>Commitment Tx</code>，或委托第三方进行广播</strong>。 只能通过将违约救济交易交给该第三方来委派第三方。 如果交易对手发生恶意行为，可以通过在输出中给这些第三方一些费用来激励他们观看区块链广播此类交易。 由<strong>于第三方只能在交易对手恶意行事时采取行动，因此该第三方没有任何权力强制关闭通道。</strong></p><h4 id="3-3-5-创建可撤销交易的步骤"><a href="#3-3-5-创建可撤销交易的步骤" class="headerlink" title="3.3.5 创建可撤销交易的步骤"></a>3.3.5 创建可撤销交易的步骤</h4><p>Process for Creating Revocable Commitment Transactions</p><p>To create revocable Commitment Transactions, it requires proper construction of the channel from the beginning, and only signing transactions which may be broadcast at any time in the future, while ensuring that one will not lose out due to uncooperative or malicious counterparties. This requires determining which public key to use for new commitments, as using SIGHASH NOINPUT requires using unique keys for each Commitment Transaction RSMC (and HTLC) output. We use P to designate pubkeys and K to designate the corresponding private key used to sign.</p><p>要创建可撤消的<code>Commitment Tx</code>，需要从一开始就适当地构建通道，并且<strong>只签署可以在将来的任何时间广播的交易</strong>，同时确保交易不会因合作伙伴或恶意交易对手而失败。 这需要确定用于<strong>新承诺的公共密钥</strong>，因为使<strong>用SIGHASH NOINPUT要求为每个承诺事务RSMC（和HTLC）输出使用唯一的密钥。</strong> 我们使用P来指定公钥，使用K来指定用于签名的对应私钥。</p><p>When generating the first Commitment Transaction, Alice and Bob agree to create a multisig output from a Funding Transaction with a single multisig(PAliceF ; PBobF ) output, funded with 0.5 BTC from Alice and Bob for a total of 1 BTC. This output is a Pay to Script Hash[16] transaction, which requires both Alice and Bob to both agree to spend from the Funding Transaction. They do not yet make the Funding Transaction (F) spendable. Additionally, PAliceF and PBobF are only used for the Funding Transaction, they are not used for anything else.</p><p>在<strong>生成第一笔<code>Commitment Tx</code>时</strong>，Alice和Bob同意<strong>从<code>Funding Tx</code>中创建一个multisig（PAliceF; PBobF）输出的multisig输出</strong>，并从Alice和Bob获得0.5 BTC的资金，总计1 BTC。 此输出是按脚本哈希付款[16]的交易，该交易要求Alice和Bob都同意从<code>Funding Tx</code>中支出。 他们尚未使<code>Funding Tx</code>（F）变为可用。 此外，<strong>PAliceF和PBobF仅用于注资交易，不用于其他任何用途。</strong></p><p>Since the Delivery transaction is just a P2PKH output (bitcoin addresses beginning with 1) or P2SH transaction (commonly recognized as addresses beginning with the 3) which the counterparties designate beforehand, this can be generated as an output of PAliceD and PBobD. For simplicity, these output addresses will remain the same throughout the channel, since its funds are fully controlled by its designated recipient after the Commitment Transaction enters the blockchain. If desired, but not necessary, both parties may update and change PAliceD and PBobD for future Commitment Transactions.</p><p>由于交付交易（Delivery transaction）只是交易对手事先指定的P2PKH输出（比特币地址以1开头）或P2SH交易（通常以3开头的地址），因此可以将其生成为PAliceD和PBobD的输出。 为简单起见，这些输出地址在整个通道中将保持不变，<strong>因为<code>Commitment Tx</code>进入区块链后，其资金完全由其指定的接收者控制</strong>。 如果需要，但不是必需的，双方可以为将来的<code>Commitment Tx</code>更新和更改PAliceD和PBobD。</p><p>Both parties exchange pubkeys they intend to use for the RSMC (and HTLC described in future sections) for the Commitment Transaction. Each set of Commitment Transactions use their own public keys and are not ever reused. Both parties may already know all future pubkeys by using a BIP 0032[17] HD Wallet construction by exchanging Master Public Keys during channel construction. If they wish to generate a new Commitment Transaction pair C2a/C2b, they use multisig(PAliceRSMC2, PBobRSMC2) for the RSMC output.</p><p>双方交换了他们打算用于RSMC（以及以后部分中描述的HTLC）以进行<code>Commitment Tx</code>的公钥。每组<code>Commitment Tx</code>使用其自己的公钥，并且永远不会重复使用。 双方可能已经通过使用BIP 0032 [17] HD钱包构造（通过在通道构建过程中交换主公钥）来了解所有将来的公钥。 <strong>如果他们希望生成新的<code>Commitment Tx</code>对C2a / C2b，则可以将multisig（PAliceRSMC2，PBobRSMC2）用于RSMC输出。</strong></p><p>After both parties know the output values from the Commitment Transactions, both parties create the pair of Commitment Transactions, e.g. C2a/C2b, but do not exchange signatures for the Commitment Transactions. They both sign the Revocable Delivery transaction (RD2a/RD2b) and exchange the signatures. Bob signs RD1a and gives it to Alice (using KBobRSMC2), while Alice signs RD1b and gives it to Bob (using KAliceRSMC2).</p><ul><li>双方都知道了<code>Commitment Tx</code>的输出值后，双方就创建了一对<code>Commitment Tx</code>，例如 C2a / C2b，但不交换<code>Commitment Tx</code>的签名。 </li><li>他们都签署了可撤销交付交易（RD2a / RD2b）并交换了签名。 </li><li>Bob签名RD1a并将其提供给Alice（使用KBobRSMC2），而Alice签名RD1b并将其提供给Bob（使用KAliceRSMC2）。</li></ul><p>When both parties have the Revocable Delivery transaction, they exchange signatures for the Commitment Transactions. Bob signs C1a using KBobF and gives it to Alice, and Alice signs C1b using KAliceF and gives it to Bob.</p><p><strong>交换签名的步骤：当双方都有可撤销交付交易时，他们交换<code>Commitment Tx</code>的签名。 Bob使用KBobF签名C1a并将其提供给Alice，Alice使用KAliceF签名C1b并将其提供给Bob。</strong></p><p>At this point, the prior Commitment Transaction as well as the new Commitment Transaction can be broadcast; both C1a/C1b and C2a/C2b are valid. (Note that Commitments older than the prior Commitment are invalidated via penalties.) In order to invalidate C1a and C1b, both parties exchange Breach Remedy Transaction (BR1a/BR1b) signatures for the prior commitment C1a/C1b. Alice sends BR1a to Bob using KAliceRSMC1, and Bob sends BR1b to Alice using KBobRSMC1. When both Breach Remedy signatures have been exchanged, the channel state is now at the current Commitment C2a/C2b and the balances are now committed.</p><p>此时，可以广播先前的<code>Commitment Tx</code>以及新的<code>Commitment Tx</code>。 C1a / C1b和C2a / C2b均有效。 （请注意，早于先前承诺的承诺将通过罚款而无效。）<strong>为了使C1a和C1b失效，双方将先前承诺C1a / C1b的违约救济交易（BR1a / BR1b）签名交换。</strong> Alice使用KAliceRSMC1将BR1a发送给Bob，Bob使用KBobRSMC1将BR1b发送给Alice。 交换了两个违反补救措施的签名后，通道状态现在处于当前的承诺C2a / C2b，并且余额已经提交。</p><p>However, instead of disclosing the BR1a/BR1b signatures, it’s also possible to just disclose the private keys to the counterparty. This is more effective as described later in the key storage section. One can disclose the private keys used in one’s own Commitment Transaction. For example, if Bob wishes to invalidate C1b, he sends his private keys used in C1b to Alice (he does NOT disclose his keys used in C1a, as that would permit coin theft). Similarly, Alice discloses all her private key outputs in C1a to Bob to invalidate C1a.</p><p>但是，除了公开BR1a / BR1b签名之外，还可以<strong>只向交易对手公开私钥</strong>。 如稍后在密钥存储部分中所述，这更有效。 人们可以披露自己的承诺交易中使用的私钥。 例如，<strong>如果Bob希望使C1b失效，则将他在C1b中使用的私钥发送给Alice（他不会透露在C1a中使用的私钥，因为这会导致硬币被盗）。 同样，Alice将自己在C1a中的所有私钥输出透露给Bob，以使C1a无效。</strong></p><p>If Bob incorrectly broadcasts C1b, then because Alice has all the private keys used in the outputs of C1b, she can take the money. However, only Bob is able to broadcast C1b. To prevent this coin theft risk, Bob should destroy all old Commitment Transactions.</p><p>如果Bob错误地广播了C1b，则由于Alice拥有C1b输出中使用的所有私钥，因此她可以拿钱。 但是，只有Bob能够广播C1b。 <strong>为防止这种硬币被盗的风险，Bob应销毁所有旧的<code>Commitment Tx</code>。</strong></p><h3 id="3-4-合作关闭一个通道"><a href="#3-4-合作关闭一个通道" class="headerlink" title="3.4 合作关闭一个通道"></a>3.4 合作关闭一个通道</h3><p>Cooperatively Closing Out a Channel</p><p>Both parties are able to send as many payments to their counterparty as they wish, as long as they have funds available in the channel, knowing that in the event of disagreements they can broadcast to the blockchain the current state at any time.</p><p>只要双方在通道中有可用资金，双方都可以向他们的交易对手发送尽可能多的付款，<strong>并且知道在发生分歧时，他们可以随时向区块链广播当前状态。</strong></p><p>In the vast majority of cases, all the outputs from the Funding Transaction will never be broadcast on the blockchain. They are just there in case the other party is non-cooperative, much like how a contract is rarely enforced in the courts. A proven ability for the contract to be enforced in a deterministic manner is sufficient incentive for both parties to act honestly.</p><p>在绝大多数情况下，<code>Funding Tx</code>的所有输出将永远不会在区块链上广播。 他们只是在另一方不合作的情况下出现，就像法院很少执行合同一样。 事实证明，以确定性方式执行合同的能力足以激励双方诚实行事。</p><p>When either party wishes to close out a channel cooperatively, they will be able to do so by contacting the other party and spending from the Funding Transaction with an output of the most current Commitment Transaction directly with no script encumbering conditions. No further payments may occur in the channel.</p><p>当<strong>任何一方希望合作关闭通道时，他们都可以通过与另一方联系并直接从<code>Funding Tx</code>中支出最新的<code>Commitment Tx</code>的输出而没有脚本负担的情况来做到这一点</strong>。 该通道中不会再有其他付款。</p><p><img src="/2019/11/20/blockchain/05/1574156584731.png" alt="1574156584731"></p><p>Figure 10: If both counterparties are cooperative, they take the balances in the current Commitment Transaction and spend from the Funding Transaction with a Exercise Settlement Transaction (ES). If the most recent Commitment Transaction gets broadcast instead, the payout (less fees) will be the same.</p><p>图10：如果两个交易对手是合作伙伴，则他们会在当前的<code>Commitment Tx</code>中获得余额，并通过执行结算交易（ES）从<code>Funding Tx</code>中支出。 如果改为广播最近的<code>Commitment Tx</code>，则支出（扣除费用）将相同。</p><p>The purpose of closing out cooperatively is to reduce the number of transactions that occur on the blockchain and both parties will be able to receive their funds immediately (instead of one party waiting for the Revocation Delivery transaction to become valid). </p><p><strong>合作关闭的目的是减少在区块链上发生的交易数量，并且双方都将能够立即收到其资金（而不是一方等待吊销交付交易生效）。</strong></p><p>Channels may remain in perpetuity until they decide to cooperatively close out the transaction, or when one party does not cooperate with another and the channel gets closed out and enforced on the blockchain.</p><p><strong>通道可能会永久保留，直到他们决定合作结束交易，或者当一方不与另一方合作且通道被封锁并在区块链上强制执行时。</strong></p><h3 id="3-5-双向通道的实现与总结"><a href="#3-5-双向通道的实现与总结" class="headerlink" title="3.5 双向通道的实现与总结"></a>3.5 双向通道的实现与总结</h3><p>Bidirectional Channel Implications and Summary</p><p>By ensuring channels can update only with the consent of both parties, it is possible to construct channels which perpetually exist in the blockchain. Both parties can update the balance inside the channel with whatever output balances they wish, so long as it’s equal or less than the total funds committed inside the Funding Transaction; balances can move in both directions. If one party becomes malicious, either party may immediately close out the channel and broadcast the most current state to the blockchain. By using a fidelity bond construction (Revocable Delivery Transactions), if a party violates the terms of the channel, the funds will be sent to the counterparty, provided the proof of violation (Breach Remedy Transaction) is entered into the blockchain in a timely manner. If both parties are cooperative, the channel can remain open indefinitely, possibly for many years.</p><p>通过确保通道<strong>只能在双方同意的情况下进行更新</strong>，才有可能构建永久存在于区块链中的通道。 双<strong>方都可以使用自己希望的任何输出余额来更新通道内的余额，只要该余额等于或小于<code>Funding Tx</code>中承诺的总资金即可；</strong> 天平可以双向移动。 如果一方变得恶意，则任何一方都可以立即关闭该通道并将最新状态广播到区块链。 通过使用保真债券结构（可撤销交付交易），<strong>如果一方违反通道条款，只要及时将违反证明（违约救济交易）输入到区块链中，资金将被发送到交易对手 。 如果双方合作，通道可以无限期保持开放状态，可能会持续很多年。</strong></p><p>This type of construction is only possible because adjudication occurs programatically over the blockchain as part of the Bitcoin consensus, so one does not need to trust the other party. As a result, one’s channel counterparty does not possess full custody or control of the funds.</p><p>这种类型的构造仅是可能的，因为作为比特币共识的一部分，裁决程序性地在区块链上进行，因此一个人不需要信任另一方。 结果，通道交易对手无法完全托管或控制资金。</p><h2 id="RSMC"><a href="#RSMC" class="headerlink" title="RSMC"></a>RSMC</h2><p>以下内容来自<a href="https://mp.weixin.qq.com/s?__biz=MzU3NjU3NjYxMA==&mid=2247483800&idx=1&sn=9e7cf1690dc0853ec563361ef695d85e&chksm=fd108c95ca67058301ac938bc8da1361dd1ab8001b5b910475ddbefb1ca991a7ca532e190a2b&mpshare=1&scene=23&srcid=&sharer_sharetime=1574219943426&sharer_shareid=e0275a8c90beb99c1f6a71d4254cec74#rd" target="_blank" rel="noopener">第14课 闪电网络(Lightning Network) 之 RSMC</a>,文章写得很好。</p><p><strong>Step1</strong>: 同微支付通道1样，生成1个保证金交易(Funding Transaction）。不过和微支付通道的区别是，这里是双向支付。所以双方，各拿1笔钱出来，打入这个公共账户。如图：</p><p><img src="/2019/11/20/blockchain/05/640.webp" alt="img"></p><p><strong>Step2</strong>:  同微支付通道类似，为这笔钱生成退款交易（Refund Transaction）。双方可以各自拿回自己的0.5比特币。</p><p><strong>备注：和微支付通道一样，实际过程是，双方完成了Step2之后，才会把Step1的交易广播出去。以防钱被死锁在公共账号里面！！！</strong></p><p>重点来了：Alice生成的退款交易是C1a + RD1a，Bob生成的退款交易是C1b+RD1b，2者是对称的。 </p><p>假入Alice要拿回钱，它就广播C1a + RD1a；</p><p>假入Bob要拿回钱，它就广播C1b + RD1b。</p><p>为什么这么处理呢？</p><p>我们看一下：假设Alice想主动中断交易，也就是它把C1a + RD1a 广播到了区块链网络上，那结果是什么呢？？</p><p>我们会看到C1a里面，会把Bob的0.5比特币立即返还给Bob，而Alice的0.5比特币被打到了1个新的公共账号： Alice2 &amp; Bob里面！！！</p><p>Alice要拿回自己的0.5比特币，要等到RD1a被兑现。而RD1a有个seq = 1000属性，也就是要等到C1a所在的块，后面被追加了1000个块之后，RD1a这个交易才会被进入区块链里面，Alice才能拿到自己的钱！！</p><p><strong>一句话：如果Alice主动中断交易（把C1a + RD1a广播到了区块链上），Bob立马拿回自己的钱，Alice则要等到Sequence Maturity之后，才能拿回钱（Alice被轻微惩罚了）。反之亦然！！</strong></p><p><img src="/2019/11/20/blockchain/05/640.webp" alt="img"></p><p><strong>Step3: Alice与Bob开始交易</strong></p><p>假设Alice要付给Bob 0.1 比特币，那么公共账号里面的资金分配，就从0.5/0.5，变成了0.4/0.6。</p><p>过程如下：</p><p>Alice生成了C2a与RD2a，C1a与RD1a废除；</p><p>同样，Bob生成了C2b与RD2b,  C1b和RD1b废除。</p><p><img src="/2019/11/20/blockchain/05/640.webp" alt="img"></p><p><strong>重点：</strong></p><p>在双方达成了C2a/RD2a, C2b/RD2b之后，如何让C1a, RD1a, C1b, RD1b 废除呢？ 换句话说，如何保证Alice不反悔（不让Alice把C1a与Rd1a广播到区块链上去？）同样，如何保证Bob不反悔（不让Bob把C1b与Rd1b广播到区块链上去？）</p><p>这需要引入惩罚机制！！</p><p>在Alice生成C2a/RD2a之前，他要把自己在C1a里面的私钥 Alice2发给Bob；同样，Bob把自己的C1b里面的私钥Bob2发给Alice。</p><p>这样，各自会生成一个惩罚交易：</p><p>如下图所示：Alice把秘钥Alice2给了Bob，Bob会为C1a生成1个惩罚交易BR1a，攥在自己手里，以防Alice反悔。</p><p>假设Alice反悔，也就是把C1a + RD1a广播出去了，Bob就把BR1a广播出去！！ BR1a由于没有Sequence，肯定会先于RD1a执行，所以结果是RD1a不会被执行，BR1a执行了。造成的结果是，Alice拿不回钱，Bob会把Alice的0.5 比特币全转账到自己账户里面，这就是对Alice的惩罚。</p><p>反之亦然，会为C1b生成BR1b。</p><p>一句话：BR1a是Bob攒在手里的Alice的把柄，BR1b是Alice攥在手里的Bob的把柄，任何1方都不敢把旧的交易广播出去。也就是一旦达成了C2a/RD2a + C2b/RD2b，1就废除了。</p><p><img src="/2019/11/20/blockchain/05/640.webp" alt="img"></p><p>Step4: 同微支付通道一样，双方最终完成了交易，把Step3里面，最后1次更新，广播到网络上，各自得到自己的钱。最后1次的，sequence = 0，双方都立即拿到自己的钱。</p><p>总结</p><p>通过上面的过程分析，我们可以看出，RSMC设计的很巧妙：</p><p>（1）通过双方各自往同1个公共账号打钱，实现了双向支付。</p><p>（2）Alice拿回钱的时候，没有直接打回到她自己的账号里面。而是打到1个新的公共账号 Alice2 &amp; Bob，然后再用一个有sequence number的 RD1a最终拿回钱。通过这点，实现了谁主动中断，谁延迟退钱。这点做的很巧妙！！！</p><p>（3）双方协商新1轮的时候，都把自己上1轮的私钥给对方，相当于把自己的把柄给了对方，这样双方都不敢反悔。</p><p>这里，又1个很巧的地方：</p><p>虽然Alice把私钥给了对方，但Alice不广播C1a，那对方的处罚交易BR1a也不会执行。</p><p>Alice广播了C1a，对方就基于广播的交易执行处罚交易BR1a；</p><p>Alice不广播C1a，对方也就没机会执行处罚交易BR1a。 </p><p>反之亦然！</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>闪电网络（一）微支付通道</title>
      <link href="/2019/11/19/blockchain/06/"/>
      <url>/2019/11/19/blockchain/06/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><p>PS：这篇文章的英语表述特别native，而且全篇59页，写的非常详细，是一片不可多得的佳作。由于原文内容非常长，所以这里将原文拆成4个部分，分别为：</p><ul><li>（一）微支付通道</li><li>（二）双向支付通道：Bidirectional Payment Channels + RSMC</li><li>（三）哈希时间锁合约：Hashed Timelock Contract (HTLC) </li><li>（四）比特币闪电网络：The Bitcoin Lightning Network</li></ul><p>前面关于综述的部分我就直接用自己的理解简述了，至于后面具体的操作流程则采用段落翻译与理解结合的方式，以便于对照原文理解。</p><p><strong>本文为本系列的第一篇</strong>，本文中主要引入几篇网上关于微支付通道的好文，提前做一个认识，后面再看论文的时候就不会那么吃力了。（QAQ我是看完论文之后才看到这些文章的，痛苦）</p><p>由于翻译的时候微支付与小支付之间的意义差别不大，而不同地方摘抄过来的写法又是不同的，所以这里不再统一写法了，意思到了就行。</p><h2 id="比特币网络的问题"><a href="#比特币网络的问题" class="headerlink" title="比特币网络的问题"></a>比特币网络的问题</h2><blockquote><p>以下部分内容摘自 <a href="https://www.8btc.com/article/92887" target="_blank" rel="noopener">https://www.8btc.com/article/92887</a> </p></blockquote><p>比特币自诞生起一直存在若干技术问题</p><ul><li>论处理能力，目前全网只有7笔每秒；</li><li>论时延，是大致10分钟出一个块；</li><li>论交易最终性，一般建议将等待6个块的确认视作交易最终化，大额交易则建议等待更多；</li><li>论容量，目前已生成40多万个区块，约60GB数据量，且眼见的未来中只见增加不见减少。</li></ul><p>在闪电网络出现前，虽然比特币社区也试图通过区块扩容、隔离见证等技术在一定程度上增加交易处理能力，但这些方式并不能导致交易处理能力出现数量级的改善。至于前面提及的其他技术难题，<strong>现存的PoW机制是万万动不得的，需要等待多个区块的确认也是不能触碰的底线</strong>，更麻烦的是：交易处理能力和区块链数据容量似乎是一对无可调和的矛盾。</p><p>思路决定出路，常规方法找不到出路，就逼得社区换一个思路考虑这个问题。代码性能调优的经验提示我们：优化编译、改进算法、调整数据结构等方式虽然很重要也很管用，但怎么能比得上“根本不执行”的强悍？既然在比特币区块链中优化性能如此艰难，为何不尽可能将交易放到链外执行？</p><p>倚天一出，谁与争锋。以比特币区块链为后盾，在链下实现真正的点对点微支付交易，区块链处理能力的瓶颈被彻底打破，时延、最终性、容量甚至隐私问题也迎刃而解，这就是比特币“闪电网络”（Lightning Network）的思路。</p><p>闪电网络提供了一个<strong>可扩展的微支付（小额支付）通道网络</strong>。交易双方若在区块链上预先设有支付通道，就可以多次、高频、双向地通过轧差方式实现瞬间确认的微支付；双方若无直接的点对点支付通道，只要网络中存在一条连通双方的、由多个支付通道构成的支付路径，闪电网络也可以利用这条支付路径实现资金在双方之间的可靠转移。</p><p>闪电网络并不试图解决单次支付的银货对付问题，其假设是单次支付的金额足够小，即使一方违约另一方的损失也非常小，风险可以承受。因此使用时必须注意“微支付”这个前提。多少资金算“微”，显然应该根据业务而定。</p><p>直接读原论文可能会有些难度，下面引用一则博客上的例子来说明，大致有一个印象之后，再通过论文的详细描述学习其中的细节。</p><blockquote><p><a href="https://blog.csdn.net/taifei/article/details/73527680" target="_blank" rel="noopener">https://blog.csdn.net/taifei/article/details/73527680</a></p><p>有两个店是好邻居，一个是饭店，一个是水果店。餐馆饭店的老板常到邻居水果店这里买些水果，而水果店老板也常来邻居餐馆饭店这里吃饭。</p><p>因为经常地相互地付钱和找零钱很麻烦，于是两家便想出了个快速结算的好主意——记账。<strong>先每人各交100元给共同信任的一个人冻结起来作为担保。</strong>然后不用每次消费都找这个人，消费时更新下最新双方余额，加时间后签名确认即可。<br>就是说开始时是：【饭100，果100】。</p><p><strong>【以上部分是3.1.1节所描述的内容】</strong></p><p>水果店的人吃了顿饭20元打折后18.8元。那么新的余额是：【饭118.8，果81.2】，加上时间后大家两方签名确认下即可，不必去找那保管各100元的那个人来记。再之后，饭店的人去水果店买了20.8元的水果，水果店便宜点不要零头了，只要20元，最新记账为：【饭98.8，果101.2】，然后加上新时间后再两方签名。这样上次签名的那个余额因时间没有现在的新而作废，以最新为准。<br>……<br>这样就可以一直快速地支付下去。</p><p><strong>【以上部分是3.1.2节所描述的内容】</strong></p><p>最后，若一方余额过小，或急需用钱，可以拿着有签名的分配账单，找到保管200元的人那里要求按此分配方案分配返回冻结的钱。假如一方拿着已经作废的之前签名的旧分配去诈骗分配，则系统无法分辨，因为系统没有强制这个时间的限制</p><p><strong>【以上部分是3.1.3节所描述的内容】</strong></p><p>那么在缓冲时间内，只要另一方拿着更新时间的双方签名作为证据，那么就可证明且会惩罚这个不诚信的人，将所有200元都给拿出证据的人。<br>另外，还有一个规则：谁先要求主张分配那冻结的200元，谁在时间上会延后才拿到分配，这样会更安全点，且能维持双方都尽量不去先主动提出取回。</p><p><strong>【以上部分是3.1.4节所描述的内容】</strong></p><p><strong>RSMC（Recoverable Sequence Maturity Contract）</strong>本质就是上面所述的类似的东西，不同是的没有存币的第三方，而是靠程序规则将币冻结锁定在比特币主链上。从而不用担心那人拿着200元跑路或者不公正的问题，因为根本就没有人。</p><p>【以上内容就是第二篇要讲的东西】</p></blockquote><p>以下内容引自<a href="https://mp.weixin.qq.com/s?__biz=MzU3NjU3NjYxMA==&mid=2247483794&idx=1&sn=ff61e571a100ce06fd4f0b1ebd43ab18&chksm=fd108c9fca6705896c7cb07295e8338149755ea23b7b946f294974c72137cb61fc22d7fdb0a5&scene=21#wechat_redirect" target="_blank" rel="noopener">第13课 微支付通道（MicroPayment Channel) – 迄今为止最透彻的讲解了</a></p><p>问题的难点</p><p>我们知道，比特币网络至所以是可靠的、值得信任的，1个很重要的原因是因为每笔交易都是公开的，每1笔交易都是on-chain，都会得到网络上每个节点的认可，所以交易的任何1方没办法反悔、抵赖。</p><p>现在你要搞链下交易，off-chain Transaction，交易只有你们俩自己知道，没有了区块链网络这个信任的第3方，怎么保证交易的1方不会反悔、抵赖？</p><p>这个问题很有意思，接下来我们看看，微支付通道是如何解决这个问题的。</p><p><strong>nLockTime</strong></p><p>在<a href="http://mp.weixin.qq.com/s?__biz=MzU3NjU3NjYxMA==&mid=2247483789&idx=1&sn=4e8fac5da279384a924e81eef353cc14&chksm=fd108c80ca670596dc5df744f5d95e0ec09e49a82b30cb400c2d97309b33ce873a8196c6e988&scene=21#wechat_redirect" target="_blank" rel="noopener">第12课 nLockTime(CLTV)与Sequence number(CSV)</a>，介绍了Transaction数据结构里面的1个关键属性。微支付通道的建立，必须依赖这个属性。下面就看一下这个过程是怎么建立的。</p><h2 id="微支付通道建立过程"><a href="#微支付通道建立过程" class="headerlink" title="微支付通道建立过程"></a>微支付通道建立过程</h2><p>考虑如下场景：A是用户，B是一个数据提供商，B需要把1个100G的大数据文件发给A，价值是100元。</p><p>为了降低风险，A不想1次性把100元给B，而是每接收到1G的数据，给B支付1元。</p><p>那就需要100次的交易。现在看一下，微支付通道如何解决这个问题：</p><p><strong>Step1:</strong></p><p>用户A发起1笔交易，把100元打到1个公共账号上面（这个公共账号同时需要A,B的公钥，也就是前面所说的多重签名）。这笔钱，需要A,B2个人同时出具私钥，才能把钱取出来。这笔交易叫做保证金交易（Funding Transaction）。</p><p><strong>Step2:</strong> </p><p>以此同时，用户A发起1笔退款交易（Refund Transaction）。这笔退款交易的输入，就是Step1里面的交易，其目的是把Step1里面的100元，再返回给用户A。这笔交易的nLockTime为一个&gt;0的值，也就是该笔交易是Hold在那的，不会立即生效。</p><p>具体怎么做呢？ 用户A先把这笔交易发给B，让B用B的死钥签名（也就是写在scriptSig里面），再返回给A，A把这个Refund Transaction 攒在手上，这笔交易其实是A的一个保底的措施，保证前面的100元不会永远拿不回来。</p><p><strong>Step3:</strong> </p><p>我们知道，在Step2的Refund Transaction里面，有2个输出：A，100元；B，0元。</p><p>现在把Step2的Refund Transaction拷贝1份，调整一下输出：A, 99元；B, 1元。也就是付给B1元。</p><p>然后A把这个交易发给B，B保留这个交易，不广播到网络上。</p><p>等A收到B的新的1G文件之后，重新调整输出，变成： A，98；B，2元。A,B重新签名，A再把这个交易发给B。</p><p>如此，不断继续下去：.</p><pre><code>A: 98，B: 2；A: 97，B: 3；...A: 1，B: 99。</code></pre><p>这些交易，称为updated Transaction(或者叫做<strong>Commitment Transaction</strong>)，<strong>只会在A,B之间传递，不会广播到网络上。</strong></p><p><strong>Step4:</strong> </p><p>等A收到最后的1个G的文件，发起1个Settlement Transaction。这里交易里面，</p><p>A：0元， B：100元。</p><p>其nLockTime = 0，B收到这个交易，广播到网络上，交易立即生效，B收到100元。</p><h2 id="微支付通道的巧妙之处"><a href="#微支付通道的巧妙之处" class="headerlink" title="微支付通道的巧妙之处"></a>微支付通道的巧妙之处</h2><ul><li><p><strong>大大缩减公网上的交易数量</strong></p><p>整个过程，我们会看到，<strong>只有Step1的Funding Transaction和Step4的Settlement Transaction会广播到网络上，1头1尾，2个交易。</strong></p></li><li><p><strong>如何避免B跑路，A的钱永远锁死在公共账号里面？</strong></p><p>在第1步里面，A把钱打到了1个公共账号上面。如果B跑了，A的钱不是永远提不出来了？实际不是这样操作的：实际是，A会等到Step2里面，拿到Refunding Transaction之后，A才会把Step1里面的Transaction发给B，同时广播到网络上面。</p><p><strong>Refunding Transaction就相当于A攒在手里的，B的把柄</strong>。A不用把这个交易广播出去，等到B跑路了，再拿出来广播到网络上。</p></li><li><p><strong>如何避免A跑路，B拿不到自己的钱？</strong></p><p>在Step3里面，每个update Transaction，都有A,B共同的签名。如果A跑路了，B就把最新的update Transaction广播到网络上，该交易被执行，B就会拿到最新的钱。</p><p><strong>update Transaction，就相当于B攒在手里的，A的把柄。</strong></p><p>update transaction有个特点，每1次update transaction的nLockTime，都是逐级减小的，所以B把最新的update transaction广播到网络上之后，肯定会被最先打包，最先执行。先前其他的update transaction就不会被执行了。</p></li><li><p><strong>如何避免B篡改交易内容，比如调大给自己的分成比例？</strong></p><p>任何1笔交易里面，都是先让B签名，再返回给A，A再签名，再发给B。</p><p>每笔交易里面都有A,B的<strong>双重签名</strong>，B改了交易内容，和A的签名就对不上了，反过来，A改了交易内容，就和B的签名对不上了。</p><p>所以A,B都不可能更改篡改交易内容！！</p></li><li><p><strong>如何防止A双花这笔钱？</strong></p><p>在Step2里面，A拿到了Refund Transaction，A把这个交易广播到网络上，拿回这100元，再花到别处呢？</p><p>做不到。因为Refund Transaction有nLockTime，处于锁定状态。并且这个nLockTime &gt; 后面的任何1笔updated Transaction的值。</p></li></ul><p><strong><em>说到这，我们就明白了，A,B如何做到在off-chain的情况下，保证双方都没办法反悔、抵赖交易：</em></strong></p><p><strong><em>A手上拿的有B的把柄，B手上拿的有A的把柄。任何1方中途中断，另我1方，把这个把柄广播到区块链网络，就可以执行合约，拿到属于自己的钱。</em></strong></p><h2 id="微支付通道的缺点"><a href="#微支付通道的缺点" class="headerlink" title="微支付通道的缺点"></a>微支付通道的缺点</h2><p>上面说的微支付通道，解决了A给B转账的，大量小额交易问题，但它也有几个缺点：</p><ul><li><p>它是单向的，只能用来A给B转账。如果反过来，需要另外再建立1个B到A的通道。</p></li><li><p>nLockTime的限制。假设B跑路了，A也要等到Refund Transaction的nLockTime到期了，才能拿回自己的钱；同样，假设A跑路了，B也要等到updated Transaction的nLockTime到期了，拿到属于自己的钱。</p></li></ul><h2 id="2-小支付通道网络可以解决可扩展性"><a href="#2-小支付通道网络可以解决可扩展性" class="headerlink" title="2. 小支付通道网络可以解决可扩展性"></a>2. 小支付通道网络可以解决可扩展性</h2><p>A Network of Micropayment Channels Can Solve Scalability</p><p>当前，小额支付和可扩展性的解决方案是将交易分担给托管人，从而使<strong>第三方托管人可以托管自己的硬币并与其他方更新余额。</strong> 信任第三方持有所有资金会产生交易对手风险和交易成本。</p><p>取而代之的是，使用这些小额付款通道的网络，借助当今现代台式机上可用的计算能力，比特币可以扩展到每天数十亿笔交易。 在给定的小额支付通道内发送许多付款，使人们能够以分散的方式向另一方发送大量资金。 这些通道不是比特币之上的独立信任网络。但它们是真正的比特币交易。</p><h3 id="2-1-小支付通道不需要信任"><a href="#2-1-小支付通道不需要信任" class="headerlink" title="2.1 小支付通道不需要信任"></a>2.1 小支付通道不需要信任</h3><blockquote><p>If a tree falls in the forest and no one is around to hear it, does it make a sound?</p></blockquote><p>就像一个古老的问题是，树木是否掉落在树林中发出声音一样，如果各方都同意树在下午2:45倒下，那么树确实在下午2:45倒下了。 同样，如果双方都同意，通道内的当前余额是Alice的0.07 BTC，Bob的0.03 BTC，那么这就是真实的余额。 但是，如果没有加密技术，就会产生一个有趣的问题：如果交易对手不同意当前的资金余额（或树木倒下的时间），那么这就是一个人反对的说法。 </p><p>如果通道中的余额为Alice的余额为0.05 BTC，Bob的余额为0.05 BTC，并且交易后的余额为Alice的余额为0.07 BTC，Bob的余额为0.03 BTC，则<strong>网络只需要知道两人交易的最终余额情况</strong>，区块链交易通过使用时间戳系统解决这个问题。</p><h3 id="2-2-通道网络"><a href="#2-2-通道网络" class="headerlink" title="2.2 通道网络"></a>2.2 通道网络</h3><p>A Network of Channels</p><p>因此，小额支付通道<strong>只会在两方之间建立关系</strong>。 要求所有人与其他人一起创建通道并不能解决可扩展性问题。 比特币的可扩展性可以<strong>使用大型的微支付通道网络</strong>来实现。</p><p>By encumbering the Bitcoin transaction outputs with a hashlock and timelock, the channel counterparty will be unable to outright steal funds and Bitcoins can be exchanged without outright counterparty theft. Further, by using staggered timeouts, it’s possible to send funds via multiple intermediaries in a network without the risk of intermediary theft of funds.</p><p>通过使用散列锁(hashlock )和时间锁(timelock)来阻碍(encumbering)比特币交易输出，通道的交易对方将无法彻底窃取资金，并且可以在没有交易对手完全盗窃的情况下交换比特币。 此外，通过使用交错超时机制，可以通过网络中的多个中介机构进行汇款，而<strong>无需担心资金被中介机构盗取</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文翻译 OmniLedger</title>
      <link href="/2019/11/15/blockchain/03/"/>
      <url>/2019/11/15/blockchain/03/</url>
      
        <content type="html"><![CDATA[<h1 id="OmniLedger-A-Secure-Scale-Out-Decentralized-Ledger-via-Sharding"><a href="#OmniLedger-A-Secure-Scale-Out-Decentralized-Ledger-via-Sharding" class="headerlink" title="OmniLedger: A Secure, Scale-Out, Decentralized Ledger via Sharding"></a>OmniLedger: A Secure, Scale-Out, Decentralized Ledger via Sharding</h1><p>@[toc]</p><p>这篇文章是今年上半年为研讨班准备的一篇论文。当时对区块链整个体系结构还是一知半解，就觉得区块链一年在网安顶会上面发的文章也都是非常有限的，能发CCS就一定有它厉害的地方，于是就拿来硬啃。不过当时对整个区块链的体系结构不太熟悉，在研讨班上果然就被老师问住了。。从一个问题开始往前追溯会遇到更多的问题，这样一环套一环，发现中间有很多地方都没搞明白。经过这半年的查漏补缺，整个知识体系也渐渐完善起来，现在再来认真的把这篇论文研究一下。</p><p>当初只是因为本科毕业实习的时候，各种机缘巧合通过炒币接触到了区块链，一开始只是调交易所的API写一些量化交易的小脚本，对于区块链的技术也仅仅停留在公链的概念上，最近由于项目的关系，需要用到大数据背景下的区块链扩容，于是很自然就想到了分片。这篇文章也算是区块链分片这一分支为数不多的经典文章，能发顶会肯定有他的原因，下面就认真分析一遍吧，顺便以这里作为切入点来完整的学习一下分片机制。</p><h2 id="0-Abstract"><a href="#0-Abstract" class="headerlink" title="0. Abstract"></a>0. Abstract</h2><p>Abstract—Designing a secure permissionless distributed ledger(blockchain) that performs on par with centralized payment processors, such as Visa, is a challenging task. Most existing distributed ledgers are unable to scale-out, i.e., to grow their total processing capacity with the number of validators; and those that do, compromise security or decentralization. </p><p>设计一个可与中心化支付系统（比如Visa)的性能对标的 安全无权限的去中心化账本（区块链）是一件极具挑战的事。目前市面上大多数的分布式账本都不能够做到横向扩展，即随着验证者数量的增加而增加其总处理能力，并且那些具有高性能的则会损害安全性或去中心性。</p><p>We present OmniLedger, a novel scale-out distributed ledger that preserves longterm security under permissionless operation. It ensures security and correctness by using a bias-resistant public-randomness protocol for choosing large, statistically representative shards that process transactions, and by introducing an efficient crossshard commit protocol that atomically handles transactions affecting multiple shards. </p><p>我们提出OmniLedger，一种新型的高性能的去中心化账本，它具有无权限性，又保留了长期的安全性。它通过一种抗预测(bias-resistant)的公共随机协议(a bias-resistant public-randomness protocol)来选择具有统计代表性的大型分片来处理交易，以及通过引入一种有效的跨分片提交协议(an efficient crossshard commit protocol)来原子性的处理影响影响多分片的交易，从而保证了安全性和正确性。</p><p>OmniLedger also optimizes performance via parallel intra-shard transaction processing, ledger pruning via collectively-signed state blocks, and low-latency “trust-butverify” validation for low-value transactions. An evaluation of our experimental prototype shows that OmniLedger’s throughput scales linearly in the number of active validators, supporting Visa-level workloads and beyond, while confirming typical transactions in under two seconds.</p><p>omniledger同时通过并行的分片内交易处理来优化性能，通过集体签名状态区块、针对低价值交易的低延迟“trust but verify”验证等方法对账本进行剪枝。我们实验原型的一个评估显示OmniLedger的吞吐量随活跃的验证者数量的增加而线性增加，可支撑Visa级别的交易量，同时可以在2秒内对一般交易进行确认。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>The scalability of distributed ledgers (DLs), in both total transaction volume and the number of independent participants involved in processing them, is a major challenge to their mainstream adoption, especially when weighted against security and decentralization challenges. </p><p>分布式账本在总交易量和参与处理的独立参与者的数量的可扩展性，是一个被主流认可的主要挑战问题，特别是在与安全性和去中心化挑战对比的时候。 </p><p>Many approaches exhibit different security and performance trade-offs [10], [11], [21], [32], [40]. Replacing the Nakamoto consensus [36] with PBFT [13], for example, can increase throughput while decreasing transaction commit latency [1], [32]. These approaches still require all validators or consensus group members to redundantly validate and process all transactions, hence the system’s total transaction processing capacity does not increase with added participants, and, in fact, gradually decreases due to increased coordination overheads.</p><p>有许多办法展示了不同的安全性和性能权衡[10],[11],[21],[32],[40]。比如，通过替换中本聪共识(Nakamoto consensus)<code>[36]</code>为PBFT共识<code>[13]</code>，可以提高吞吐量的同时降低交易延迟<code>[1][32]</code>。这些办法仍然要求所有验证者或者共识组成员冗余性的验证和处理所有交易，因此系统总的交易处理容量是无法通过增加参与者而线性增加的，反而事实上会由于协调开销增加而逐渐降低性能。</p><blockquote><p>[10] V. Buterin, J. Coleman, and M. Wampler-Doty. <code>Notes on Scalable Blockchain Protocols (verson 0.3)</code>, 2015.</p><p>[11] C. Cachin. <code>Architecture of the Hyperledger blockchain fabric.</code> In Workshop on Distributed Cryptocurrencies and Consensus Ledgers, 2016.</p><p>[21] I. Eyal, A. E. Gencer, E. G. Sirer, and R. van Renesse. <code>BitcoinNG: A Scalable Blockchain Protocol.</code> In 13th USENIX Symposium on Networked Systems Design and Implementation (NSDI 16), Santa Clara, CA, Mar. 2016. USENIX Association.</p><p>[32] E. Kokoris-Kogias, P. Jovanovic, N. Gailly, I. Khoffi, L. Gasser, and B. Ford. <code>Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing.</code> In Proceedings of the 25th USENIX Conference on Security Symposium, 2016.</p><p>[40]  J. Poon and T. Dryja. <code>The Bitcoin Lightning Network: Scalable OffChain Instant Payments,</code> Jan. 2016. </p><p>[36]  S. Nakamoto. <code>Bitcoin: A Peer-to-Peer Electronic Cash System,</code> 2008. </p><p>[13] M. Castro and B. Liskov. <code>Practical Byzantine Fault Tolerance.</code> In 3rd USENIX Symposium on Operating Systems Design and Implementation (OSDI), Feb. 1999.</p><p>[1] I. Abraham, D. Malkhi, K. Nayak, L. Ren, and A. Spiegelman. <code>Solidus: An Incentive-compatible Cryptocurrency Based on Permissionless Byzantine Consensus.</code>CoRR, abs/1612.02916, 2016.</p></blockquote><p>The proven and obvious approach to building “scale-out” databases, whose capacity scales horizontally with the number of participants, is by sharding [14], or partitioning the state into multiple shards that are handled in parallel by different subsets of participating validators. </p><p>建立可”横向扩展“数据库的成熟有效的方式是实现分片机制(Sharding)<code>[14]</code>，通过将状态切分到多个分片由不同子集的验证者进行并行处理。</p><blockquote><p>[14] J. C. Corbett, J. Dean, M. Epstein, A. Fikes, C. Frost, J. J. Furman, S. Ghemawat, A. Gubarev, C. Heiser, P. Hochschild, W. Hsieh, S. Kanthak, E. Kogan, H. Li, A. Lloyd, S. Melnik, D. Mwaura, D. Nagle, S. Quinlan, R. Rao, L. Rolig, Y. Saito, M. Szymaniak, C. Taylor, R. Wang, and D. Woodford. <code>Spanner: Google’s Globally Distributed Database</code>. ACM Trans. Comput. Syst., 31(3):8:1–8:22, Aug. 2013.</p></blockquote><p>Sharding could benefit DLs [15] by reducing the transaction processing load on each validator and by increasing the system’s total processing capacity proportionally with the number of participants. Existing proposals for sharded DLs, however, forfeit permissionless decentralization [16], introduce new security assumptions, and/or trade performance for security [34], as illustrated in Figure 1 and explored in detail in Sections II and IX.</p><p>分片可以通过减少每个验证者上的事务处理量load，并通过与参与者数量成比例地增加系统的总处理能力，来使DL受益[15]。然而现有的对实现分片式去中心化账本的建议，要么放弃无权限去中心化<code>[16]</code>，要么引入新的安全假设以安全换性能<code>[34]</code>，如图1所示(在第2和第4章详细阐述)</p><blockquote><p>[15] K. Croman, C. Decke, I. Eyal, A. E. Gencer, A. Juels, A. Kosba, A. Miller, P. Saxena, E. Shi, E. G. Sirer, D. S. an, and R. Wattenhofer. <code>On Scaling Decentralized Blockchains (A Position Paper).</code> In 3rd Workshop on Bitcoin and Blockchain Research, 2016.</p><p>[16] G. Danezis and S. Meiklejohn. <code>Centrally Banked Cryptocurrencies.</code> 23rd Annual Network &amp; Distributed System Security Symposium (NDSS), Feb. 2016.</p><p>[34] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena. <code>A Secure Sharding Protocol For Open Blockchains.</code> In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS ’16, pages 17–30, New York, NY, USA, 2016. ACM.</p></blockquote><p><img src="/2019/11/15/blockchain/03/1573868353026.png" alt="1573868353026"></p><p>We introduce OmniLedger, the first DL architecture that provides “scale-out” transaction processing capacity competitive with centralized payment-processing systems, such as Visa, without compromising security or support for permissionless decentralization. </p><p>我们引入OmniLedger，这是第一个提供了“横向扩展”交易处理能力的DL架构，可与Visa等集中式支付处理系统竞争，而不会损害安全性或对去中心性。</p><p>To achieve this goal, OmniLedger faces three key correctness and security challenges. First, OmniLedger must choose statistically representative groups of validators periodically via permissionless Sybil-attackresistant foundations such as proof-of-work [36], [38], [32] or proof-of-stake [31], [25]. </p><p>为了达成这一目标，omniledger面临着三个正确性和安全性的挑战。</p><p>第一：omniledger必须通过可抵御无权限女巫攻击的PoW<code>[36][38][32]</code>或PoS<code>[31][25]</code>机制来周期性地选择具有统计性代表的验证者分组。 </p><blockquote><p>POW:</p><p>[36]  S. Nakamoto. <code>Bitcoin: A Peer-to-Peer Electronic Cash System,</code> 2008. </p><p>[38] R. Pass and E. Shi. <code>Hybrid Consensus: Efficient Consensus in the Permissionless Model.</code> Cryptology ePrint Archive, Report 2016/917, 2016.</p><p>[32] E. Kokoris-Kogias, P. Jovanovic, N. Gailly, I. Khoffi, L. Gasser, and B. Ford. <code>Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing.</code> In Proceedings of the 25th USENIX Conference on Security Symposium, 2016.</p><p>POS:</p><p>[31] A. Kiayias, A. Russell, B. David, and R. Oliynykov. <code>Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol.</code>Cryptology ePrint Archive, Report 2016/889, 2016</p><p>[25] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich. <code>Algorand: Scaling Byzantine Agreements for Cryptocurrencies.</code>Cryptology ePrint Archive, Report 2017/454, 2017</p></blockquote><p>Second, OmniLedger must ensure a negligible probability that any shard is compromised across the (long-term) system lifetime via periodically (re)forming shards (subsets of validators to record state and process transactions), that are both sufficiently large and bias-resistant. </p><p>第二，omniledger必须可以通过周期性（重新）重构分片（验证器的子集来记录状态和流程交易），使得任何分片在长时间受损的概率可以忽略不计，这些碎片既足够大又可以抵抗预测。</p><p>Third, OmniLedger must correctly and atomically handle cross-shard transactions, or transactions that affect the ledger state held by two or more distinct shards</p><p>第三，omniledger必须能够正确地，原子性地处理跨分片或涉及到多个独立分片的交易。</p><p>To choose representative validators via proof-of-work, OmniLedger builds on ByzCoin [32] and Hybrid Consensus [38], using a sliding window of recent proof-of-work block miners as its validator set. To support the more power-efficient alternative of apportioning consensus group membership based on directly invested stake rather than work, </p><p>为了通过工作量证明来选择具有代表性验证者，OmniLedger建立在ByzCoin [32]和Hybrid Consensus [38]的基础上，<strong>使用最近PoW区块矿工的滑动窗口作为其验证者集</strong> 。 为了支持更节能的替代方法，即直接基于PoS来分配共识组成员。</p><blockquote><p>[32] E. Kokoris-Kogias, P. Jovanovic, N. Gailly, I. Khoffi, L. Gasser, and B. Ford. <code>Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing.</code> In Proceedings of the 25th USENIX Conference on Security Symposium, 2016.</p><p>[38] R. Pass and E. Shi. <code>Hybrid Consensus: Efficient Consensus in the Permissionless Model.</code> Cryptology ePrint Archive, Report 2016/917, 2016.</p></blockquote><p>OmniLedger builds on Ouroboros [31] and Algorand [25], running a public randomness or cryptographic sortition protocol within a prior validator group to pick a subsequent validator group from the current stakeholder distribution defined in the ledger. To ensure that this sampling of representative validators is both scalable and strongly bias-resistant, OmniLedger uses RandHound [44], a protocol that serves this purpose under standard t-of-n threshold assumptions.</p><p>OmniLedger建立在<strong>Ouroboros</strong> <code>[31]</code> 和 <strong>Algorand</strong> <code>[25]</code>之上，采用在一个先前的验证者分组中运行一个公共随机协议或加密抽签协议从账本的当前持币人分布中提取一个后续的验证者分组。为保证代表性验证者的抽取是可扩展和强抗预测性的，OmniLedger采用<strong>RandHound</strong><code>[44]</code>协议，这是一种为这种目的在标准<code>t-n</code>阀值假设下服务的协议。</p><blockquote><p>[31] A. Kiayias, A. Russell, B. David, and R. Oliynykov. <code>Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol.</code>Cryptology ePrint Archive, Report 2016/889, 2016</p><p>[25] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich. <code>Algorand: Scaling Byzantine Agreements for Cryptocurrencies.</code>Cryptology ePrint Archive, Report 2017/454, 2017</p><p>[44] E. Syta, P. Jovanovic, E. Kokoris-Kogias, N. Gailly, L. Gasser, I. Khoffi, M. J. Fischer, and B. Ford. <code>Scalable Bias-Resistant Distributed Randomness.</code> In 38th IEEE Symposium on Security and Privacy, May 2017.</p></blockquote><p>Appropriate use of RandHound provides the basis by which OmniLedger addresses the second key security challenge of securely assigning validators to shards, and of periodically rotating these assignments as the set of validators evolves. OmniLedger chooses shards large enough, based on the analysis in Section VI, to ensure a negligible probability that any shard is ever compromised, even across years of operation.</p><p>适当的<strong>利用RandHound</strong>为OmniLedger解决第二个安全性挑战提供了依据，即<strong>安全地为分片分配验证者</strong>，以及当更多验证者介入时周期性地进行循环分配。基于第四章的分析，OmniLedger引入足够大的分片来保证经过几年的运行任何分片被损害的概率可以忽略不计。</p><p>Finally, to ensure that transactions either commit or abort atomically even when they affect state distributed across multiple shards (e.g., several cryptocurrency accounts), OmniLedger introduces Atomix, a two-phase client-driven “lock/unlock”protocol that ensures that clients can either fully commit a transaction across shards, or obtain “rejection proofs” to abort and unlock state affected by partially completed transactions.</p><p>最后，为保证即使影响多个分片状态的交易进行原子性的提交或取消，OmniLedger引入了<strong>Atomix</strong>，一种2阶段客户端驱动的”锁/解锁”协议，用来保证客户端可以要么在跨分片完全提交一个交易，要么获取”拒绝证据“来取消或解锁被部分完成交易影响的状态。</p><p>Besides addressing the above key security challenges, OmniLedger also introduces several performance and scalability refinements we found to be instrumental in achieving its usability goals. OmniLedger’s consensus protocol, ByzCoinX, enhances the PBFT-based consensus in ByzCoin [32] to preserve performance under Byzantine denial-of-service (DoS) attacks, by adopting a more robust group communication pattern. To help new or long-offline miners catch up to the current ledger state without having to download the entire history, OmniLedger adapts classic distributed checkpointing principles [20] to produce consistent, state blocks periodically.</p><p>除了解决上述的关键安全性问题，OmniLedger也引入了几种我们发现的有助于实现其可用性目标的性能和扩展性改进方案。OmniLedger的共识协议, <strong>ByzCoinX</strong>，增强了ByzCoin中的PBFT共识，通过接受一种更加可靠的组通信模式可使其在处于拜占庭DoS攻击时保证性能。为帮助新的或长期掉线的矿工在不需要下载整个历史数据的情况下赶上最新的账本状态，OmniLedger接纳了经典的<strong>分布式checkpoint原则( classic distributed checkpointing principles)</strong><code>[20]</code>来定期生成一致的状态区块。</p><blockquote><p>[32] E. Kokoris-Kogias, P. Jovanovic, N. Gailly, I. Khoffi, L. Gasser, and B. Ford. <code>Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing.</code> In Proceedings of the 25th USENIX Conference on Security Symposium, 2016.</p><p>[20] E. N. Elnozahy, D. B. Johnson, and W. Zwaenepoel. <code>The Performance of Consistent Checkpointing.</code> In 11th Symposium on Reliable Distributed Systems, pages 39–47. IEEE, 1992.</p></blockquote><p>Finally, to minimize transaction latency in common cases such as low-value payments, OmniLedger supports optional trust-but-verify validation in which a first small tier of validators processes the transactions quickly and then hands them over to a second larger, hence slower, tier that reverifies the correctness of the first tier transactions and ensures long-term security. This two-level approach ensures that any misbehavior within the first tier is detected within minutes, and can be strongly disincentivized through recourse such as loss of deposits. Clients can wait for both tiers to process highvalue transactions for maximum security or just wait for the first tier to process low-value transactions.</p><p>最后，为降低通常情况下的交易延迟，比如小额交易，OmniLedger支持可选的<strong>“trust-but-verify”验证方式</strong>，即在较小的第一层的验证者快速处理这些交易，然后把它们提交给更大但更慢的第二层来重新验证第一层交易的正确性以及长期的安全性。这种2层解决方案保证任何第一层的不当行为可以在数分钟内被检测，然后以损失押金的形式进行严厉地惩罚。客户可以等待两层处理完大额交易以保证最大的安全性，或者可以只等待第一层处理完小额交易。</p><p>To evaluate OmniLedger, we implemented a prototype in Go on commodity servers (12-core VMs on Deterlab). Our experimental results show that OmniLedger scales linearly in the number of validators, yielding a throughput of 6,000 transactions per second with a 10-second consensus latency (for 1800 widely-distributed hosts, of which 12.5% are malicious). Furthermore, deploying OmniLedger with two-level, trust-butverify validation provides a throughput of 2,250 tps with a four-second first-tier latency under a 25% adversary. Finally, a Bitcoin validator with a month-long stale view of the state incurs 40% of the bandwidth, due to state blocks.</p><p>为评估OmniLedger的效果，我们用Go语言实现了一个原型版本在商用服务器上运行（12核VM on Deterlab），我们的实验结果显示OmniLedger可以按照验证者数量线性横向扩展，在具有12.5%恶意节点的1800个广泛分布的的主机环境上实现了10秒共识延迟下达到了6000tps。而且，将OmniLedger以”信任但验证“的二层验证模型下部署时，在具有25% 恶意节点时实现了4秒第一层延迟的2250tps吞吐量。最后，由于区块同步，一个具有长达一个月陈旧状态视图的比特币验证者会产生40%的带宽流量。????</p><p>We introduce the first DL architecture that provides horizontal scaling without compromising either long-term security or permissionless decentralization.</p><ul><li>We introduce Atomix, a Atomic Commit protocol, to commit transactions atomically across shards.</li><li>We introduce ByzCoinX, a BFT consensus protocol that increases performance and robustness to DoS attacks.</li><li>We introduce state blocks, that are deployed along OmniLedger to minimize storage and update overhead.</li><li>We introduce two-tier trust-but-verify processing to minimize the latency of low-value transactions.</li></ul><p>引入了第一个提供水平扩展的不以损害长期安全性或无权限去中心化的去中心化架构。</p><p>引入了<strong>Atomix</strong>，一种原子提交协议，实现跨分片的原子提交交易功能。</p><p>引入了<strong>ByzCoinX</strong>，一种针对DoS攻击时增加性能和健壮性的BFT共识协议。</p><p>引入了<strong>状态区块(state blocks)</strong>，在OmniLedger上部署以减小存储空间和更新开销。</p><p>引入了<strong>trust but verify二层模型(或者叫乐观验证)</strong>来降低小额交易延迟。</p><h2 id="2-Background"><a href="#2-Background" class="headerlink" title="2. Background"></a>2. Background</h2><h3 id="2-1-ByzCoin中的可扩展拜占庭共识"><a href="#2-1-ByzCoin中的可扩展拜占庭共识" class="headerlink" title="2.1 ByzCoin中的可扩展拜占庭共识"></a>2.1 ByzCoin中的可扩展拜占庭共识</h3><p>OmniLedger builds on the Byzantine consensus scheme in ByzCoin [32], because it scales efficiently to thousands of consensus group members. To make a traditional consensus algorithm such as PBFT [13] more scalable, ByzCoin uses collective signing or CoSi [45], a scalable cryptographic primitive that implements multisignatures [42]. ByzCoin distributes blocks by using multicast trees for performance, but falls back to a less-scalable star topology for fault tolerance. Although ByzCoin’s consensus is scalable, its total processing capacity does not increase with participation i.e., it does not scale-out.</p><p>因为ByzCoin中的拜占庭共识机制能够很好地在数以千计的公式成员组中达成共识，omniledger就是基于byzcoin的共识协议。为了使传统的共识算法例如PBFT能够具有更好的扩展性，ByzCoin使用了集体签名（CoSi）[45]，一种可扩展的实现多重签名的密码原语。ByzCoin采用<strong>组播树(multicast trees)</strong>分发区块以提高性能，但是为了容错却回退使用了扩展性较差的<strong>星型拓扑</strong>。虽然ByzCoin的共识具有扩展性，但是其总体的处理容量却没有随着参与节点数量而增加，所以它是不能横向扩展的。</p><blockquote><p>[45] E. Syta, I. Tamas, D. Visher, D. I. Wolinsky, P. Jovanovic, L. Gasser, N. Gailly, I. Khoffi, and B. Ford. <code>Keeping Authorities “Honest or Bust” with Decentralized Witness Cosigning.</code> In 37th IEEE Symposium on Security and Privacy, May 2016.</p><p>[42] C. P. Schnorr. <code>Efficient signature generation by smart cards.</code> Journal of Cryptology, 4(3):161–174, 1991.</p></blockquote><h3 id="2-2-交易处理与UTXO模型"><a href="#2-2-交易处理与UTXO模型" class="headerlink" title="2.2 交易处理与UTXO模型"></a>2.2 交易处理与UTXO模型</h3><p>Distributed ledgers derive current system state from a blockchain, or a sequence of totally ordered blocks that contain transactions. OmniLedger adopts the unspent transaction output (UTXO) model to represent ledger state, due to its<br>simplicity and parallelizability. In this model, the outputs of a transaction create new UTXOs (and assign them credits), and inputs completely “spend” existing UTXOs. During bootstrapping, new (full) nodes crawl the entire distributed ledger and build a database of valid UTXOs needed to subsequently decide whether a new block can be accepted. The UTXO model was introduced by Bitcoin [36] but has been widely adopted by other distributed ledger systems</p><p>去中心化账本从区块链或一条<strong>包含交易的完全有序区块</strong>派生出了现在的系统状态。OmniLedger接受UTXO模型来代表账本状态，因为它其简单性和可并行性。在这个模型里，一个交易的输出创建新的UTXO（并授予其信用credits？），交易的输入则只能花费已存在的UTXO。在新的（全）节点启动时，会同步抓取整个分布式账本并建立合法UTXO的数据库以便用于后续验证新区块是否合法。这个UTXO模型是被比特币<code>[36]</code>引入的并且已经被其它去中心账本系统广泛认可。</p><h3 id="2-3-安全的分布式随机数生成器"><a href="#2-3-安全的分布式随机数生成器" class="headerlink" title="2.3 安全的分布式随机数生成器"></a>2.3 安全的分布式随机数生成器</h3><p>RandHound [44] is a scalable, secure multi-party computation (MPC) protocol that provides unbiasable, decentralized randomness in a Byzantine setting. RandHound assumes the existence of an externally accountable client that wants to obtain provable randomness from a large group of semitrustworthy servers. To produce randomness, RandHound splits the group of servers into smaller ones and creates a publicly verifiable commit-then-reveal protocol [43] that employs the pigeonhole principle to prove that the final random number includes the contribution of at least one honest participant, thus perfectly randomizing RandHound’s output.</p><p><strong>RandHound</strong><code>[44]</code>是一个可扩展的安全的多方计算(MPC)协议，在拜占庭环境里可提供无偏见的、去中心化的随机性。RandHound假设存在一个外部负责任的客户，他想从一大群半信任化的服务器中获取可证明的随机性。为了产生随机性，RandHound将服务器组拆分更小的组，并创建一个公开可验证的<strong>先提交后揭示</strong>(commit-then-reveal)的协议<code>[43]</code>，该协议采用<strong>鸽笼原理</strong>在包括至少一名诚实参与者贡献时来证明最终的随机数，因此完美地实现了对RandHound输出的随机化。</p><blockquote><p>[44] E. Syta, P. Jovanovic, E. Kokoris-Kogias, N. Gailly, L. Gasser, I. Khoffi, M. J. Fischer, and B. Ford. <code>Scalable Bias-Resistant Distributed Randomness.</code> In 38th IEEE Symposium on Security and Privacy, May 2017.</p><p>[43] B. Schoenmakers. <code>A simple publicly verifiable secret sharing scheme and its application to electronic voting.</code> In IACR International Cryptology Conference (CRYPTO), pages 784–784, 1999.</p></blockquote><p>Cryptographic sortition [25] is used to select a subset of validators, according to some per-validator weight function. To enable validators to prove that they belong to the selected subset, they need a public/private key pair,  Sortition is implemented using a verifiable random function (VRF) [35] that takes an input x and returns a random hash (-bit long string) and a proof π based on ski. The proof π enables anyone knowing pki to check that the hash corresponds to x.</p><p><strong>加密抽签(Cryptographic sortition)</strong><code>[25]</code>用来根据验证者权重函数对验证者选择一个子集。为了使验证者能够证明他们属于某个选中的子集，他们需要一个公钥和私钥对，<code>(pki, ski)</code>。抽签通过一个<strong>VRF(verifiable random function：可验证随机函数)</strong>实现：<code>输入x，然后返回一个随机hash(l-bit长的字符串)，和一个基于ski的证明 π。这个证明 π可使任何人知道用pki去验证该hash对应于x</code>。</p><blockquote><p>[25] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich. <code>Algorand: Scaling Byzantine Agreements for Cryptocurrencies.</code>Cryptology ePrint Archive, Report 2017/454, 2017</p></blockquote><h3 id="2-4-抗女巫攻击的身份认证"><a href="#2-4-抗女巫攻击的身份认证" class="headerlink" title="2.4 抗女巫攻击的身份认证"></a>2.4 抗女巫攻击的身份认证</h3><p>Unlike permissioned blockchains [16], where the validators are known, permissionless blockchains need to deal with the potential of Sybil attacks [19] to remain secure. Bitcoin [36] suggested the use of Proof-of-Work (PoW), where validators (aka miners) create a valid block by performing an expensive computation (iterating through a nonce and trying to bruteforce a hash of a block’s header such that it has a certain number of leading zeros). Bitcoin-NG [21] uses this PoW technique to enable a Sybil-resistant generation of identities. There are certain issues associated with PoW, such as the waste of electricity [17] and the fact that it causes recentralization [29] to mining pools. Other approaches for establishing Sybil-resistant identities such as Proof-of-Stake (PoS) [31] [25], Proof-of-Burn (PoB) [46] or Proof-of-Personhood [8] overcome PoW’s problems and are compatible with ByzCoins identity (key-block) blockchain, and in turn with OmniLedger</p><p>不像有权限的区块链<code>[16]</code>，它的验证者都是已知的，无权限的区块链需要处理<strong>女巫攻击</strong><code>[19]</code>的潜在威胁以保证安全。比特币(Bitcoin)<code>[36]</code>建议使用PoW工作量证明，其矿工（验证者）创建一个合法区块需要消耗昂贵的计算（对一个nonce进行循环迭代，对区块头hash进行暴力破解使其以特定数量的0开头）。<strong>Bitcoin-NG</strong><code>[21]</code>使用同样的PoW技术以产生抗女巫攻击的身份。PoW机制本身有一些问题，比如浪费电力以及导致矿池重新中心化的事实。其它的抵抗女巫攻击的方法还有采用诸如PoS<code>[31][25]</code>、<strong>Proof-of-Burn(PoB)</strong><code>[46]</code>、<strong>Proof-of-Personhood</strong><code>[8]</code>等可以克服PoW的问题，并且可以兼容ByzCoin的身份区块链，当然也兼容OmniLedger。</p><blockquote><p>[16] G. Danezis and S. Meiklejohn. <code>Centrally Banked Cryptocurrencies.</code> 23rd Annual Network &amp; Distributed System Security Symposium (NDSS), Feb. 2016.</p><p>[19] J. R. Douceur. <code>The Sybil Attack. In 1st International Workshop on Peer-to-Peer Systems (IPTPS),</code> Mar. 2002.</p><p>[21] I. Eyal, A. E. Gencer, E. G. Sirer, and R. van Renesse. <code>BitcoinNG: A Scalable Blockchain Protocol.</code> In 13th USENIX Symposium on Networked Systems Design and Implementation (NSDI 16), Santa Clara, CA, Mar. 2016. USENIX Association.</p><p>[31] A. Kiayias, A. Russell, B. David, and R. Oliynykov. <code>Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol.</code>Cryptology ePrint Archive, Report 2016/889, 2016</p><p>[25] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich. <code>Algorand: Scaling Byzantine Agreements for Cryptocurrencies.</code>Cryptology ePrint Archive, Report 2017/454, 2017</p><p>[46]  B. Wiki. <code>Proof of burn</code> , Sept. 2017. </p><p>[8] M. Borge, E. Kokoris-Kogias, P. Jovanovic, N. Gailly, L. Gasser, and B. Ford. <code>Proof-of-Personhood: Redemocratizing Permissionless Cryptocurrencies</code>. In 1st IEEE Security and Privacy On The Blockchain, Apr. 2017.</p></blockquote><h3 id="2-5-之前的分布式账本Elastico"><a href="#2-5-之前的分布式账本Elastico" class="headerlink" title="2.5 之前的分布式账本Elastico"></a>2.5 之前的分布式账本Elastico</h3><p>OmniLedger builds closely on Elastico [34], that previously explored sharding in permissionless ledgers. In every round, Elastico uses the least-significant bits of the PoW hash to distribute miners to different shards. After this setup, every shard runs PBFT [13] to reach consensus, and a leader shard verifies all the signatures and creates a global block.</p><p>OmniLedger和先前探讨过的在无权限账本上实现分片的Elastico是很接近的。在每一轮，Elastico利用PoW哈希中最低比特位来分发矿工给不同的分片，然后每个分片运行PBFT<code>[13]</code>来达到共识，接着领导分片(leader shard)验证所有的签名，然后创建全局区块。</p><blockquote><p>[34] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena. <code>A Secure Sharding Protocol For Open Blockchains.</code> In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS ’16, pages 17–30, New York, NY, USA, 2016. ACM.</p></blockquote><p>OmniLedger addresses several challenges that Elastico leaves unsolved. First, Elastico’s relatively small shards (e.g., 100 validators per shard in experiments) yield a high failureprobability of 2.76%1 per shard per block under a 25% adversary, which cannot safely be relaxed in a PoW system [23]. For 16 shards, the failure probability is 97% over only 6 epochs. Second, Elastico’s shard selection is not strongly bias-resistant, as miners can selectively discard PoWs to bias results [7]. Third, Elastico does not ensure transaction atomicity across shards, leaving funds in one shard locked forever if another shard rejects the transaction. Fourth, the validators constantly switch shards, forcing themselves to store the global state, which can hinder performance but provides stronger guarantees against adaptive adversaries. Finally, the latency of transaction commitment is comparable to Bitcoin (≈ 10 min.), which is far from OmniLedger’s usability goals.</p><p>omniledger解决了许多elastico没有解决的问题</p><p>第一：Elastico相对小的分片(比如实验中每个分片100个验证者)，在低于25%恶意节点时会产生每分片每区块2.76%的高失败率，这在PoW系统中是不能被容忍的。在16个分片里仅仅6个周期就有高达97%的失败率。</p><p>第二：Elastico的分片选举不是强抗偏见的，因此矿工可以<strong>选择性的忽视PoW</strong>来得到特定的结果<code>[7]</code>。</p><p>第三：Elastico不能保证<strong>跨分片时的原子性交易</strong>，当另一个分片拒绝交易时，资金会永久锁定在一个分片中。</p><p>第四：验证者总是在切换分片，导致它们需要保存全局状态，这可能会阻碍性能，但可以为自适应对手提供更强的保障。</p><p>最后，交易确认的延迟跟比特币差不多（10 分钟），这和OmniLedger的可用性差远了。</p><blockquote><p>[23] A. Gervais, G. Karame, S. Capkun, and V. Capkun. <code>Is Bitcoin a decentralized currency?</code> IEEE security &amp; privacy, 12(3):54–60, 2014.</p><p>[7] J. Bonneau, J. Clark, and S. Goldfeder. <code>On Bitcoin as a public randomness source.</code> IACR eprint archive, Oct. 2015.</p></blockquote><h2 id="3-System-Overview"><a href="#3-System-Overview" class="headerlink" title="3. System Overview"></a>3. System Overview</h2><p>This section presents the system, network and threat models, the design goals, and a roadmap towards OmniLedger that begins with a strawman design.</p><p>这一部分将会展示系统、网络、威胁模型，设计目标，以及从雏形设计得到的omniledger设计路线。</p><h3 id="3-1-系统模型"><a href="#3-1-系统模型" class="headerlink" title="3.1 系统模型"></a>3.1 系统模型</h3><p>We assume that there are n validators who process transactions and ensure the consistency of the system’s state. Each validator i has a public / private key pair (pki, ski), and we often identify i by pki. Validators are evenly distributed across m shards. We assume that the configuration parameters of a shard j are summarized in a shard-policy file. We denote by an epoch e the fixed time (e.g., a day) between global reconfiguration events where a new assignment of validators to shards is computed. The time during an epoch is counted in rounds r that do not have to be consistent between different shards. During each round, each shard processes transactions collected from clients. We assume that validators can establish identities through any Sybil-attack-resistant mechanism and commit them to the identity blockchain; to participate in epoch e validators have to register in epoch e−1. These identities are added into an identity blockchain as described in Section II-D</p><p>我们假设一共有n个验证者来处理交易，并且保证系统的状态一致。每个验证者i都有一个公私钥对，我们通常使用公钥pki来验证它。验证者被均匀地分布在m个分片中。我们假设分片j的配置参数被写在一个分片规则（shard-policy）文件中，在全局的重配置事件(即验证者到分片的重新分配)中，epoch <code>e</code>表示一个固定的时间（比如1天），一个周期的时间以<code>r</code> 轮进行表示，这个在不同的分片不需要保证一致。在每一轮中，每一个分片处理从客户端中收集来的交易。我们假设验证者可以通过抗女巫攻击机制建立认证，并且将它们提交到identity链中，为了参加第e个epoch的验证，需要在第e-1个epoch中注册。至于身份是如何加入到身份区块链中的需要参考第3.4节中的内容</p><h3 id="3-2-网络模型"><a href="#3-2-网络模型" class="headerlink" title="3.2 网络模型"></a>3.2 网络模型</h3><p>For the underlying network, we make the same assumption as prior work [31], [34], [36]. Specifically, we assume that (a) the network graph of honest validators is well connected and that (b) the communication channels between honest validators are synchronous, i.e., that if an honest validator broadcasts a message, then all honest validators receive the message within a known maximum delay Δ [39]. However, as Δ is in the scale of minutes, we cannot use it within epochs as we target latencies of seconds. Thus, all protocols inside one epoch use the partially synchronous model [13] with optimistic, exponentially increasing time-outs, whereas Δ is used for slow operations such as identity creation and shard assignment.</p><p>关于底层网络，我们与以前的网络做出相同的假设[<code>31</code>], [<code>34</code>], [<code>36</code>]，特别地，我们假设忠诚节点的网络图是连接良好的，并且两个忠诚节点之间的交流是同步的，比如，如果一个忠诚节点广播了一条消息，所有的节点都在一个已知的时延Δ内会收到这条消息。但是这个Δ是以分钟为尺度的，如果我们以秒级为尺度，那么我们将无法在一个epoch内完成。因此，在一个时间周期内的所有协议使用乐观地部分同步模型<code>[13]</code>，而<code>∆</code>则用来进行诸如身份创建和分片分配之类的缓慢操作。</p><blockquote><p>[31] A. Kiayias, A. Russell, B. David, and R. Oliynykov. <code>Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol.</code>Cryptology ePrint Archive, Report 2016/889, 2016</p><p>[34] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena. <code>A Secure Sharding Protocol For Open Blockchains.</code> In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS ’16, pages 17–30, New York, NY, USA, 2016. ACM.</p><p>[36]  S. Nakamoto. <code>Bitcoin: A Peer-to-Peer Electronic Cash System,</code> 2008. </p><p>[13] M. Castro and B. Liskov. <code>Practical Byzantine Fault Tolerance.</code> In 3rd USENIX Symposium on Operating Systems Design and Implementation (OSDI), Feb. 1999.</p></blockquote><h3 id="3-3-威胁模型"><a href="#3-3-威胁模型" class="headerlink" title="3.3 威胁模型"></a>3.3 威胁模型</h3><p>We denote the number of Byzantine validators by f and assume, that n = 4f, i.e., at most 25% 2 of the validators can be malicious at any given moment, which is similar to prior DL’s [21], [32], [34]. These malicious nodes can behave arbitrarily, e.g., they might refuse to participate or collude to attack the system. The remaining validators are honest and faithfully follow the protocol. We further assume that the adversary is mildly adaptive [31], [34] on the order of epochs, i.e., he can try to corrupt validators, but it takes some time for such corruption attempts to actually take effect.</p><p>我们假定<strong>拜占庭节点的数量是f，节点总数为n = 4f</strong>，也就是说，在任意时间内最多允许25%的节点是恶意的，这与先前的分布式账本是一致的[<code>21</code>], [<code>32</code>], [<code>34</code>]，这些恶意节点可以有任意的行为，比如说他们可以拒绝参与共识或者攻击系统。在本协议下剩余的节点则是忠诚且可信的。我们再假设对手具有适度的适应能力[<code>31</code>], [<code>34</code>]，也就是说，他可以选择黑掉任意验证者节点，但是从行为开始到产生影响需要一定时间。</p><blockquote><p>[<code>21</code>] I. Eyal, A. E. Gencer, E. G. Sirer, and R. van Renesse. <code>BitcoinNG: A Scalable Blockchain Protocol.</code> In 13th USENIX Symposium on Networked Systems Design and Implementation (NSDI 16), Santa Clara, CA, Mar. 2016. USENIX Association.</p><p>[<code>32</code>] E. Kokoris-Kogias, P. Jovanovic, N. Gailly, I. Khoffi, L. Gasser, and B. Ford. <code>Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing.</code> In Proceedings of the 25th USENIX Conference on Security Symposium, 2016.</p><p>[<code>34</code>] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena. <code>A Secure Sharding Protocol For Open Blockchains.</code> In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS ’16, pages 17–30, New York, NY, USA, 2016. ACM.</p><p>[<code>31</code>] A. Kiayias, A. Russell, B. David, and R. Oliynykov. <code>Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol.</code>Cryptology ePrint Archive, Report 2016/889, 2016</p></blockquote><p>We further assume that the adversary is computationally bounded, that cryptographic primitives are secure, and that the computational Diffie-Hellman problem is hard.</p><p>我们再假定对手是有计算边界的，那么加密原语是安全的，并且<strong>计算Diffie-Hellman问题是非常困难的</strong>。</p><h3 id="3-4-系统目标"><a href="#3-4-系统目标" class="headerlink" title="3.4 系统目标"></a>3.4 系统目标</h3><p>OmniLedger has the following primary goals with respect to decentralization, security, and scalability.</p><p>1) <strong>Full decentralization</strong>. OmniLedger does not have any single points of failure (such as trusted third parties).<br>2) <strong>Shard robustness.</strong> Each shard correctly and continuously processes transactions assigned to it.<br>3) <strong>Secure transactions.</strong> Transactions are committed atomically or eventually aborted, both within and across shards.<br>4) <strong>Scale-out.</strong> The expected throughput of OmniLedger increases linearly in the number of participating validators.<br>5) <strong>Low storage overhead.</strong> Validators do not need to store the full transaction history but only a periodically computed reference point that summarizes a shard’s state.<br>6) <strong>Low latency.</strong> OmniLedger provides low latency for transaction confirmations.</p><p>omniledger的设计目标如下：其同时具有去中心性、安全性和可扩展性</p><ol><li><strong>完全去中心化</strong>：不存在任何单点故障造成系统无法用的问题，比如可信第三方故障将导致系统不可用</li><li><strong>具有分片鲁棒性</strong>：每个分片都可<strong>持续正确地处理</strong>分配给它的交易</li><li><strong>交易安全性</strong>：分片内或跨分片的交易都能原子性地提交确认或最终取消</li><li><strong>可扩展</strong>：omniledger预期的吞吐量会随着参与者数量的增加而线性增加</li><li><strong>低存储开销</strong>：验证者不需要存储全部的历史交易，而是只需要周期性地计算reference点来总结一个分片的状态</li><li><strong>低延时</strong>：omniledger为交易确认提供了很低的延时</li></ol><h3 id="3-5-设计路线"><a href="#3-5-设计路线" class="headerlink" title="3.5 设计路线"></a>3.5 设计路线</h3><p>This section introduces SLedger, a strawman DL system that we use to outline OmniLedger’s design. Below we describe one epoch of SLedger and show how it transitions from epoch e − 1 to epoch e. </p><p>这里介绍SLedger，这是一个提供了omniledger设计思路的草案，下面将会介绍SLedger并且展示如何从第e-1个epoch转换到第e个epoch的</p><p>We start with the secure validator-assignment to shards. Permitting the validators to choose the shards they want to validate is insecure, as the adversary could focus all his validators in one shard. As a result, we need a source of randomness to ensure that the validators of one shard will be a sample of the overall system and w.h.p. will have the same fraction of malicious nodes. SLedger operates a trusted randomness beacon that broadcasts a random value rnde to all participants in each epoch e. Validators, who want to participate in SLedger starting from epoch e, have to first register to a global identity blockchain. They create their identities through a Sybil-attack-resistant mechanism in epoch e−1 and broadcast them, together with the respective proofs, on the gossip network at most Δ before epoch e − 1 ends.</p><p>我们从安全的验证者被分配到分片开始，让验证者自己选择分片是不安全的，因为有些对手会将他的验证者全放在一个分片中。因此我们需要一种随机算法来保证一个分片内分到的的验证者是系统总体的一个样本，也就是每个分片中将具有相同比例的恶意节点。SLedger使用一个可信的随机数种子，使其在epoch <code>e</code>内广播一个随机值<code>rnd[e]</code>给所有参与者，如果验证者想要从第e个epoch开始参与到SLedger，则他们需要首先在全局的身份链中进行注册，在第<code>e-1</code>个epoch中<strong>通过一个抵抗女巫攻击的机制创建身份认证</strong>，然后在gossip网络中在第e-1个epoch结束之前最多 Δ 时间来广播他们的身份以及相关的证明。</p><p>Epoch e begins with a leader, elected using randomness rnd[e−1], who requests from the already registered and active validators a (BFT) signature on a block with all identities that have been provably established so far. If at least 2/3 of these validators endorse the block, it becomes valid, and the leader appends it to the identity blockchain. Afterwards, all registered validators take rnd[e] to determine their assignment to one of the SLedger’s shards and to bootstrap their internal states from the shards’ distributed ledgers. Then, they are ready to start processing transactions using ByzCoin. The random shardassignment ensures that the ratio between malicious and honest validators in any given shard closely matches the ratio across all validators with high probability.</p><p>第e个epoch的leader由随机数rnd[e-1]选出，该leader向已经注册且活跃的验证者们请求一个区块上的（BFT）签名，这个区块具有已证明被创建的所有身份信息。如果至少有2/3的验证者都赞成这一区块，它将变成合法的区块，并且leader将会把它自己添加到身份认证链上。然后，所有注册过的验证者将会通过随机数rnd[e]来决定自己分配到SLedger中的其中一个分片上，然后从相应分片的分布式账本中同步内部状态。那么，他们就可以使用ByzCoin的共识机制来处理交易了。随机的分片分配机制保证了在一个给定分片中恶意和诚实验证者的比例与在所有验证者中的恶意和诚实的比例是最有可能相接近的。</p><p>SLedger already provides a similar functionality to OmniLedger, but it has several significant security restrictions. First, the randomness beacon is a trusted third party. Second, the system stops processing transactions during the global reconfiguration at the beginning of each epoch until enough validators have bootstrapped their internal states and third, there is no support for cross-shard transactions. SLedger’s design also falls short in performance. First, due to ByzCoin’s failure handling mechanism, its performance deteriorates when validators fail. Second, validators face high storage and bootstrapping overheads. Finally, SLedger cannot provide real-time confirmation latencies and high throughput.</p><p>SLedger已经提供了与omniledger相似的原理，但是有几个明显的安全限制</p><ul><li>第一，这个随机数种子本质上就是一个可信的第三方</li><li>第二，系统将会在每个epoch开始的全局重配置期间停止处理交易，直到有足够的验证者已经启动他们的内部状态</li><li>第三，不支持跨分片的交易</li></ul><p>SLedger在性能方便同样表现不佳</p><ul><li>第一，由于byzcoin的失败处理机制，当验证者失败的时候它的性能会恶化</li><li>第二，验证者面临着高昂的存储和启动开销</li><li>第三，SLedger不能提供实时的低延迟高吞吐的交易验证</li></ul><p>To address the security challenges, we introduce OmniLedger’s security design in Section IV:</p><p>1) In Section IV-A, we remove the trusted randomness beacon and show how validators can autonomously perform a secure sharding by using a combination of RandHound and VRF-based leader election via cryptographic sortition.<br>2) In Section IV-B, we show how to securely handle the validator assignment to shards between epochs while maintaining the ability to continuously process transactions.<br>3) In Section IV-C, we present Atomix, a novel two-step atomic commit protocol for atomically processing crossshard transactions in a Byzantine setting.</p><p>因此，针对前三条安全限制，omniledger的设计做出了以下改善：</p><ul><li>第一，在4.1节中，我们移除了这个可信的随机种子，并且演示了验证者如何通过RandHound 和 VRF-based leader election via cryptographic sortition来进行安全的leader选举。</li><li>第二，在4.2节中，我们展示了如何在跨两个epoch时安全地处理将验证者分配给分片，同时保证持续的处理交易。</li><li>第三，在4.3节中，我们展示了Atomix，一个在拜占庭环境假设下的典型的两步原子提交协议来解决跨分片交易问题。</li></ul><p>To deal with the performance challenges, we introduce OmniLedger’s performance and usability design in Section V:<br>4) In Section V-A, we introduce ByzCoinX, a variant of ByzCoin, that utilizes more robust communication patterns to<br>efficiently process transactions within shards, even if some of the validators fail, and that resolves dependencies on the transaction level to achieve better block parallelization.<br>5) In Section V-C, we introduce state blocks that summarize the shards’ states in an epoch and that enable ledger pruning to reduce storage and bootstrapping costs for validators.<br>6) In Section V-D, we show how to enable optimistic realtime transaction confirmations without sacrificing security or throughput by utilizing an intra-shard architecture with trust-but-verify transaction validation. A high-level overview of the (security) architecture of OmniLedger is illustrated in Figure 2. </p><p>为了解决性能不佳的问题，我们引入了omniledger的设计，在第5节会讲解</p><ul><li>第四，在5.1节中，我们引入了ByzCoinX，一个ByzCoin的变种，用来提供更加鲁棒的通信模式来有效地处理跨分片交易。即使有一些分片失败了，也可以在交易层面上解决依赖性以实现更好的<strong>区块并行化</strong>？？？。</li><li>第五，在5.3节中，我们引入了<strong>状态区块</strong>的概念，这个区块用来汇总分片中一个epoch的状态，并且提供账本剪枝来减少存储和验证节点启动的开销</li><li>第六，在5.4节中，我们展示通过利用trust but verify的<strong>分片内交易验证方式</strong><code>(an intra-shard architecture with trust-but-verify transaction validation)</code>，如何在不牺牲安全性或吞吐量的情况下进行乐观实时的交易确认。</li></ul><p>omniledger的安全模块的一个总览图：</p><p><img src="/2019/11/15/blockchain/03/1573972865217.png" alt="1573972865217"></p><p>OmniLedger architecture overview: At the beginning of an epoch e, all validators (shard membership is visualized through the different colors) (1) run RandHound to re-assign randomly a certain threshold of validators to new shards and assign new validators who registered to the identity blockchain in epoch e − 1. Validators ensure (2) consistency of the shards’ ledgers via ByzCoinX while clients ensure (3) consistency of their cross-shard transactions via Atomix (here the client spends inputs from shards 1 and 2 and outputs to shard 3).</p><p>omniledger结构概述：在第e个epoch开始的时候，所有的验证者（不同分片的成员使用不同颜色标注）进行下面的操作：</p><ol><li>运行RandHound以随机地给各分片重新分配一个关于验证者的特定的阈值，并且将在第e-1个epoch中注册到身份认证链上的验证者分配给各个分片</li><li>验证者通过<strong>byzcoinx来保证分片中账本的一致性</strong></li><li>客户端通过<strong>Atomix保证他们跨分片交易的一致性</strong>（在上图中，这个客户端的交易输入来自分片1和2，输出为分片3）</li></ol><h2 id="4-关于安全性的设计"><a href="#4-关于安全性的设计" class="headerlink" title="4. 关于安全性的设计"></a>4. 关于安全性的设计</h2><h3 id="4-1-基于抗bias的分布式随机数进行分片"><a href="#4-1-基于抗bias的分布式随机数进行分片" class="headerlink" title="4.1 基于抗bias的分布式随机数进行分片"></a>4.1 基于抗bias的分布式随机数进行分片</h3><p>To generate a seed for sharding securely without requiring a trusted randomness beacon [16] or binding the protocol to PoW [34], we rely on a distributed randomness generation protocol that is collectively executed by the validators.</p><p>为了在不使用可信的随机数种子或者绑定协议到pow的基础上，给安全分片生成一个随机数种子，我们需要一个分布式的随机数生成协议来正确地被验证者执行。</p><blockquote><p>[16] G. Danezis and S. Meiklejohn. <code>Centrally Banked Cryptocurrencies.</code> 23rd Annual Network &amp; Distributed System Security Symposium (NDSS), Feb. 2016.</p></blockquote><p>We require that the distributed-randomness generation protocol provide unbiasability, unpredictability, third-party verifiability, and scalability. Multiple proposals exist [7], [28], [44]. The first approach relies on Bitcoin, whereas the other two share many parts of the design; we focus on RandHound [44] due to better documentation and open-source implementation.</p><p>我们需要分布式随机数生成协议来提供抗预测性、抗偏差性、第三方可验证性、可扩展性。有许多方法来实现这一效果，比如[<code>7</code>], [<code>28</code>], [<code>44</code>]，第一种方式依赖于比特币，另外两种则共享了很多的设计思想。我们这里主要关注RandHound，因为它的文档写的比较好，而且有开源实现。</p><blockquote><p>[7] J. Bonneau, J. Clark, and S. Goldfeder. <code>On Bitcoin as a public randomness source.</code> IACR eprint archive, Oct. 2015.</p><p>[28]  T. Hanke and D. Williams. <code>Intoducing Random Beascons Using Threshold Relay Chains,</code> Sept. 2016. </p><p>[44] E. Syta, P. Jovanovic, E. Kokoris-Kogias, N. Gailly, L. Gasser, I. Khoffi, M. J. Fischer, and B. Ford. <code>Scalable Bias-Resistant Distributed Randomness.</code> In 38th IEEE Symposium on Security and Privacy, May 2017.</p></blockquote><p>Because RandHound relies on a leader to orchestrate the protocol run, we need an appropriate mechanism to select one of the validators for this role. If we use a deterministic approach to perform leader election, then an adversary might be able to enforce up to f out of n failures in the worst case by refusing to run the protocol, resulting in up to 1 / 4 n failures given our threat model. Hence, the selection mechanism must be unpredictable and unbiasable, which leads to a chicken-andegg problem as we use RandHound to generate randomness with these properties in the first place. To overcome this predicament, we combine RandHound with a VRF-based leader election algorithm [44], [25].</p><p>由于randhound依赖于一个leader来协调整个协议运行，我们需要一个合适的机制来选择一个验证者来担任这个角色。如果我们使用确定的方法来进行选举leader，那么攻击者只需要拒绝运行协议，就可以使得有f/n的几率（最高25%）失败，因此，leader选举必须是不可预测且无偏差的，但是我们第一次运行这个协议的时候也需要一个随机数，也就是会导致一个<strong>先有鸡还是先有蛋</strong>的问题。为了克服这种可预测性，我们将randhound和基于VRF的leader选择算法相结合。</p><p>At the beginning of an epoch e, each validator i computes a ticket</p><ul><li><p>第一步：在每个epoch开始的时候，每一个验证者都计算出下面的值</p><p><img src="/2019/11/15/blockchain/03/1573974828730.png" alt="1573974828730"></p><p>$ config_e $ is the configuration containing all properly registered validators of epoch e (as stored in the identity blockchain) and $v$ is a view counter. </p><ul><li>$config_e$：是在第e个epoch中所有正常注册的验证者的配置信息，它保存在身份认证链中</li><li>$v$：是一个视图计数器（view counter）</li></ul></li></ul><p>Validators then gossip these tickets with each other for a time Δ, after which they lock in the lowest-value valid ticket they have seen thus far and accept the corresponding node as the leader of the RandHound protocol run. </p><ul><li>第二步：计算出ticket值之后，验证者通过gossip在 Δ 时间内来互相广播这些ticket值，之后他们锁定一个他们迄今看到的最小的合法ticket值，使该值对应的节点为运行RandHound协议的leader</li></ul><p>If the elected node fails to start RandHound within another Δ, validators consider the current run as failed and ignore this validator for the rest of the epoch, even if he returns later on. </p><ul><li>第三步：如果被选中的节点在下一个 Δ 时间内启动失败，则所有的验证者则认为该节点失败了，并且在剩下的epoch内都忽略他，即使他后来上线了。</li></ul><p>In this case, the validators increase the view number to $v + 1$ and re-run the lottery. </p><ul><li>第四步：这种情况下，验证者将会把view数从v加到v+1，然后重新运行抽奖（选举）</li></ul><p>Once the validators have successfully completed a run of RandHound and the leader has broadcast $rnd_e$ together with its correctness proof, each of the n properly registered validators can first verify and then use $rnd_e$ to compute a permutation $π_e$ of $1, . . . , n$ and subdivide the result into m approximately equally-sized buckets, thereby determining its assignment of nodes to shards.</p><ul><li>第五步：一旦验证者成功地完成了randhound算法，并且leader已经成功广播了$rnd_e$（携带正确性证明）， <ul><li><code>n</code>中的每个合理注册的验证者就可以先验证正确性</li><li>然后用$rnd_e$来计算<code>1,...,n</code>的$π_e$排列，</li><li>再将结果分配到大小都为<code>m</code>的桶里<code>(bukets)</code>，因此决定将哪些节点分配到哪个分片 </li></ul></li></ul><p>Security Arguments: we make the following observations to informally argue the security of the above approach. Each participant can produce only a single valid ticket per view v in a given epoch e, because the VRF-based leader election starts only after the valid identities have been fixed in the identity blockchain. Furthermore, as the output of a VRF is unpredictable as long as the private key ski is kept secret, the tickets of non-colluding nodes, hence the outcome of the lottery is also unpredictable. The synchrony bound Δ guarantees that the ticket of an honest leader is seen by all other honest validators. If the adversary wins the lottery, he can decide either to comply and run the RandHound protocol or to fail, which excludes that particular node from participating for the rest of the epoch.</p><p><strong>安全论证</strong>：我们进行以下观察来用一种非正式的方法来讨论上面方案的安全性</p><ul><li><p>每一个参与者在给定epoch e的每个视图v内仅可以产生一个唯一的合法选票ticket，因为基于VRF的leader选举仅在合法的认证信息在身份认证链中固定下来之后才会进行</p></li><li><p>只要私钥ski是保密的，VRF的输出是不可预测的，因此抽奖最后的结果就是不可预测的</p></li><li><p>同步时间 Δ 保证了忠诚leader的选票可以被所有的忠诚的验证者看到</p></li><li><p>如果对手获得了选举的胜利，他可以决定遵循并运行<code>RandHound</code>协议，或者让其运行失败，这样该节点就会在此epoch之后的epoch中被排除在外。</p></li></ul><p>After a successful run of RandHound, the adversary is the first to learn the randomness, hence the sharding assignment, however his benefit is minimal. The adversary can again either decide to cooperate and publish the random value or withhold it in the hope of winning the lottery again and obtaining a sharding assignment that fits his agenda better. However, the probability that an adversary wins the lottery a times in a row is upper bounded by the exponentially decreasing term (f/n)^a. Thus, after only a few re-runs of the lottery, an honest node wins with high probability and coordinates the sharding. Finally, we remark that an adversary cannot collect random values from multiple runs and then choose the one he likes best as validators accept only the latest random value that matches their view number v.</p><ul><li>成功地运行randhound之后，对手就是第一个得到随机数的人了，但是他的收益是很小的，对手可以再一次决定是配合并且将随机数广播出去，或者保留它以期望再次赢得抽奖，并获得最符合他要求的分片分配任务。</li><li>然而，对手连续赢得a次选举的概率是按照公式$(f/n)^a$呈现指数级下降的</li><li>因此，经过几轮重新抽奖，诚实节点以高概率赢得抽奖，然后协调分片。</li><li>最后，我们认定攻击者不能在多轮抽奖中获得随机数，然后选择最符合其利益的那个，因为验证者只接受符合视图计数<code>v</code>的最新随机值。</li></ul><p>In Appendix B, we show how OmniLedger can be extended to probabilistically detect that the expected Δ does not hold and how it can still remain secure with a fall-back protocol.</p><p>在附录B中，我们将展示omniledger是如何能够扩展概率性地检测预期的<code>∆</code>不存在，以及如何回退协议保证安全。</p><h3 id="4-2-在epoch过渡期间保持可操作性"><a href="#4-2-在epoch过渡期间保持可操作性" class="headerlink" title="4.2 在epoch过渡期间保持可操作性"></a>4.2 在epoch过渡期间保持可操作性</h3><p>Recall that, in each epoch e, SLedger changes the assignments of all n validators to shards, which results in an idle phase during which the system cannot process transactions until enough validators have finished bootstrapping.</p><p>在每一个epoch e中，SLedger改变验证者到分片的分配时，会导致<strong>一段空闲期</strong>，这段时间系统不能处理交易直到有足够的验证者完成启动。</p><p>To maintain operability during transition phases, OmniLedger gradually swaps in new validators to each shard per epoch. This enables the remaining operators to continue providing service (in the honest scenario) to clients while the recently joined validators are bootstrapping. In order to achieve this continued operation we can swap-out at most 1/3 of the shard’s size (≈ n/m), however the bigger the batch is, the higher the risk gets that the number of remaining honest validators is insufficient to reach consensus and the more stress the bootstrapping of new validators causes to the network.</p><p>为保持转换阶段的可操作性，OmniLedger在每个epoch<strong>逐渐地将新的验证者切换到新的分片</strong>。这可以保证剩下的操作者可以持续提供服务给客户，同时新加入的验证者同步进行启动。为了实现这种持续的操作，我们可以转移出最多<code>1/3</code>分片大小<code>(约为n/m)</code>的验证者数量，转出数量越多，剩余的诚实节点不足够达到共识的风险就更高，而且新节点时启动的对网络的压力也越大。</p><p>To balance the chances of a temporary loss of liveness, the shard assignment of validators in OmniLedger works as follows. First, we fix a parameter $ k &lt;  \frac{1}{3}  \frac{n}{m}   $ specifying the swap-out batch, i.e., the number of validators that are swapped out at a given time. For OmniLedger, we decided to work in batches of $k = log  \frac{n}{m} $ . Then for each shard j, we derive a seed $H(j||rnd_e)$ to compute a permutation $π[j,e]$ of the shard’s validators, and we specify the permutation of the batches. We also compute another seed $H( 0||rnd_e)$ to permute and scatter the validators who joined in epoch e and to define the order in which they will do so (again, in batches of size k). After defining the random permutations, each batch waits Δ before starting to bootstrap in order to spread the load on the network. Once a validator is ready, he sends an announcement to the shard’s leader who then swaps the validator in.</p><p>为平衡临时失去活性的可能性，OmniLedger中验证者分片分配按照以下步骤工作。</p><ul><li><p>设置参数$ k &lt;  \frac{1}{3}  \frac{n}{m}   $ , 作为批次转出的数量（即特定时间转移出分片的验证者数量）。针对OmniLedger，我们决定设置 $k = log  \frac{n}{m} $</p></li><li><p>然后针对每个分片<code>j</code>，我们获得一个种子$H(j||rnd_e)$来计算分片验证者的排列$π[j,e]$，并且我们指定批次排列。</p></li><li><p>同时计算另一个种子$H(0||rnd_e)$，来置换和分散新加入第e个epoch的验证者，并定义按照什么顺序进行（大小也为<code>k</code>）。</p></li><li><p>定义好随机排列后，每批次等待时间 ∆ 再开始启动以保证分散负担到网络上。</p></li><li><p>当一个验证者准备好后，他发送一个声明给将其转入分片的leader。</p></li></ul><p>Security Arguments: During the transition phase, we ensure the safety of the BFT consensus in each shard as there are always at least$\frac{2}{3}  \frac{n}{m}$honest validators willing to participate in the consensus within each shard. And, as we use the epoch’s randomness $rnd_e$ to pick the permutation of the batches, we keep the shards’ configurations a moving target for an adaptive adversary. Finally, as long as there are $\frac{2}{3}  \frac{n}{m}$ honest and up-to-date validators, liveness is guaranteed. Whereas if this quorum is breached during transition (the new batch of honest validators has not yet updated), the liveness is lost only temporarily, until the new validators update. </p><p><strong>安全论证</strong>：</p><ul><li><p>在转换阶段，我们在每个分片保证<code>BFT</code>共识的安全性，因为在每个分片里总是至少有$\frac{2}{3}  \frac{n}{m}$数量的诚实验证者愿意参与共识。</p></li><li><p>我们使用时代随机数$rnd_e$来获得批次排列，针对自适应攻击者我们保持分片配置是一个移动目标。</p></li><li><p>只要有$\frac{2}{3}  \frac{n}{m}$诚实和保持更新的节点，分片活性就可以保证。</p></li><li><p>反之如果转换期间未达到法定人数(新批次的诚实验证者还没更新完成)，分片活性会暂时不可用直到新验证者更新完成。</p></li></ul><p>​    </p><h3 id="4-3-跨分片交易"><a href="#4-3-跨分片交易" class="headerlink" title="4.3 跨分片交易"></a>4.3 跨分片交易</h3><p>To enable value transfer between different shards thereby achieving shard interoperability, support for secure cross-shard transactions is crucial in any sharded-ledger system. We expect that the majority of transactions to be cross-shard in the traditional model where UTXOs are randomly assigned to shards for processing [16], [34], see Appendix C.</p><p>为了完成跨分片的价值交换，能够实现分片的互操作性，在任何分片型账本系统中支持安全的跨分片交易都是至关重要的。我们期望在传统模型中大多数交易是跨分片的，其中UTXO被自由地分配给分片进行处理<code>[16][34]</code>。具体参考<code>附件C</code>。</p><blockquote><p>[16] G. Danezis and S. Meiklejohn. <code>Centrally Banked Cryptocurrencies.</code> 23rd Annual Network &amp; Distributed System Security Symposium (NDSS), Feb. 2016.</p><p>[34] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena. <code>A Secure Sharding Protocol For Open Blockchains.</code> In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS ’16, pages 17–30, New York, NY, USA, 2016. ACM.</p></blockquote><p>A simple but inadequate strawman approach to a cross-shard transaction, is to concurrently send a transaction to several shards for processing because some shards might commit the transaction while others might abort. In such a case, the UTXOs at the shard who accepted the transactions are lost as there is no straightforward way to roll back a half-committed transaction, without adding exploitable race conditions.</p><p>一个针对跨分片交易的简单但不完善的草案，是<strong>将一个交易同步地发送给多个分片处理</strong>，因为有些分片会提交交易，其它的会取消。这种情况下，因为在没有添加可利用的竞争条件时，没有一种直接的方式可以回退半提交的交易，这些UTXO在接受交易的分片中被丢失。</p><p>To address this issue, we propose a novel Byzantine Shard Atomic Commit (Atomix) protocol for atomically processing transactions across shards, such that each transaction is either committed or eventually aborted. The purpose is to ensure consistency of transactions between shards, to prevent double spending and to prevent unspent funds from being locked forever. In distributed computing, this problem is known as atomic commit [47] and atomic commit protocols [27], [30] are deployed on honest but unreliable processors. Deploying such protocols in OmniLedger is unnecessarily complex, because the shards are collectively honest, do not crash infinitely, and run ByzCoin (that provides BFT consensus). Atomix improves the strawman approach with a lock-then-unlock process. We intentionally keep the shards’ logic simple and make any direct shard-to-shard communication unnecessary by tasking the client with the responsibility of driving the unlock process while permitting any other party (e.g., validators or even other clients) to fill in for the client if a specific transaction stalls after being submitted for processing.</p><p>为解决这个问题，我们提出一种新型的拜占庭分片原子提交协议<code>(Byzantine Shard Atomic Commit (Atomix))</code>来自动处理跨链交易，<strong>保证每个交易被完全提交或最终取消</strong>。目的是<strong>保证跨分片交易的一致性</strong>，以<strong>阻止双花或者未花费的资金被永久锁住</strong>。在分布式计算里，这个问题被称为原子提交<code>[47]</code>或原子提交协议<code>[27][30]</code>被部署到诚实但不可靠的处理器上。</p><blockquote><p>[47]  Wikipedia. <code>Atomic commit</code>, Feb. 2017 </p><p>[27] R. Guerraoui. <code>Non-blocking atomic commit in asynchronous distributed systems with failure detectors.</code> Distributed Computing, 15(1):17–25, 2002</p><p>[30] I. Keidar and D. Dolev. <code>Increasing the resilience of atomic commit, at no additional cost.</code> In Proceedings of the fourteenth ACM SIGACTSIGMOD-SIGART symposium on Principles of database systems, pages 245–254. ACM, 1995.</p></blockquote><p>Atomix uses the UTXO state model, see Section II-B for an overview, which enables the following simple and efficient three-step protocol, also depicted in Figure 3.</p><p><code>Atomix</code>使用UTXO状态模型，它可使下面的简单而高效的三步协议成为可能。下图就是一个解释</p><p><img src="/2019/11/15/blockchain/03/1573981360563.png" alt="1573981360563"></p><p>1) <strong>Initialize</strong>. A client creates a cross-shard transaction (crossTX for short) whose inputs spend UTXOs of some input shards (ISs) and whose outputs create new UTXOs in some output shards (OSs). The client gossips the cross-TX and it eventually reaches all ISs  </p><p>第一步：<strong>初始化</strong></p><p>一个客户端创建了一个跨链交易，输入从ISs中获取，输出将会输出到OSs中，客户端会将这个跨链交易通过gossip协议广播到所有的IS（输入分片）中</p><p>2) <strong>Lock</strong>. All input shards associated with a given cross-TX proceed as follows. First, to decide whether the inputs can be spent, each IS leader validates the transaction within his shard. If the transaction is valid, the leader marks within the state that the input is spent, logs the transaction in the shard’s ledger and gossips a proof-of-acceptance, a signed Merkle proof against the block where the transaction is included. If the transaction is rejected, the leader creates an analogous proof-of-rejection, where a special bit indicates an acceptance or rejection. The client can use each IS ledger to verify his proofs and that the transaction was indeed locked. After all ISs have processed the lock request, the client holds enough proofs to either commit the transaction or abort it and reclaim any locked funds, but not both.</p><p>第二步：<strong>锁定</strong></p><p>根据跨链交易得到的所有输入分片将会进行如下处理：</p><ol><li>确定输入是否可以被划掉，每一个输入分片的leader确认交易是否在自己的分片中</li><li>如果交易是合法的，那么leader将会将这个输入标记为spent，然后关于这个交易的这条日志将会被gossip协议广播一个 <strong>接受的证明<code>(proof-of-acceptance)</code></strong> ，这是一种包含本交易的区块的被签名的merkle树证明。</li><li>如果交易被拒绝，leader将会创建一个类似的 <strong>拒绝的证明（<code>proof-of-rejection</code>）</strong>，其中有一个特殊的比特表示拒绝或接受。</li><li>客户端可以使用每一个IS的账本来验证交易是否已被锁定</li><li>当所有的IS都进行完lock请求之后，client将会掌握足够多的的证明。他可以选择提交这个交易或者取消并清除已经建立的锁或者都不做？？</li></ol><p>3) <strong>Unlock</strong>. Depending on the outcome of the lock phase, the client is able to either commit or abort his transaction.<br>3a) Unlock to Commit. If all IS leaders issued proofs-of-acceptance, then the respective transaction can be committed. The client (or any other entity such as an IS leader after a time-out) creates and gossips an unlock-tocommit transaction that consists of the lock transaction and a proof-of-acceptance for each input UTXO. In turn, each involved OS validates the transaction and includes it in the next block of its ledger in order to update the state and enable the expenditure of the new funds.<br>3b) Unlock to Abort. If, however, even one IS issued a proof-of-rejection, then the transaction cannot be committed and has to abort. In order to reclaim the funds locked in the previous phase, the client (or any other entity) must request the involved ISs to unlock that particular transaction by gossiping an unlock-to-abort transaction that includes (at least) one proof-of-rejection for one of the input UTXOs. Upon receiving a request to unlock, the ISs’ leaders follow a similar procedure and mark the original UTXOs as spendable again.</p><p>第三步：<strong>解锁</strong></p><p>根绝加锁阶段的输出，客户端可以选择提交或中断交易</p><ul><li><strong>解锁提交</strong>：如果所有的输入分片的leader都返回了接受的证明，那么对应的交易就都可以被提交，客户端（或超时后为其它实体比如IS的leader）<strong>创建并广播一个unlock-to-commit的交易</strong>，这个交易中包含了<strong>每一个输入的UTXO中加锁的交易和接受的证明</strong>。相应的，每一个被包含的输出分片OS验证交易并且将它包含进下一个其分区账本区块中以更新其状态，并使新资金可被花费。</li><li><strong>解锁中断</strong>：相反，如果其中一个IS反馈了拒绝的证明，此时交易就不能够被提交并且会被中断。为了回收上个阶段被锁住的资金，<strong>client必须发出广播一个unlock-to-abort的交易来请求相关的IS来解锁指定交易</strong>，这个被广播的交易中应当至少<strong>包含一个对其中一个输入UTXO的拒绝的证明</strong>。一旦收到了unlock的命令，IS的leader就会进行相似的步骤来使得原来被锁住的UTXO重新变为可以花费的。</li></ul><p>We remark that, although the focus of OmniLedger is on the UTXO model, Atomix can be extended with a locking mechanism for systems where objects are long-lived and hold state (e.g., smart contracts [48]), see Appendix D for details.</p><p>我们评论一下，虽然OmniLedger专注在UTXO模型上，但是<code>Atomix</code>可以<strong>被扩展到其它的具有锁机制的系统</strong>，其中对象是长期活性和保存状态的。(比如智能合约[48]，请参考<code>附件D</code>)。</p><p><strong>Security Arguments</strong>: We informally argue the previously stated security properties of Atomix, based on the following observations. Under our assumptions, shards are honest, do not fail, eventually receive all messages and reach BFT consensus. Consequently, (1) all shards always faithfully process valid transactions; (2) if all input shards issue a proof-of-acceptance, then every output shard unlocks to commit; (3) if even one input shard issues a proof-of-rejection, then all input shards unlocks to abort; and (4) if even one input shard issues a proof-of-rejection, then no output shard unlocks to commit.</p><p>安全论证：基于下面的发现，我们来非正式地讨论它的安全性。在我们的假设下，分片是忠诚的，不会失败，最终会受到所有的信息，并且达到BFT一致。因此，</p><ol><li>所有的分片总是忠诚地处理合法的交易</li><li>如果所有的输入分片都反馈了proof-of-acceptance，此时所有的输出分片将会解锁并提交</li><li>如果哪怕有一个输入分片反馈了proof-of-rejection，此时所有的输入分片都必须解锁并中断。</li><li>如果哪怕有一个输入分片反馈了proof-of-rejection，此时没有输出分片将会被解锁并提交</li></ol><p>In Atomix, each cross-TX eventually commits or aborts. Based on (1), each input shard returns exactly one response: either a proof-of-acceptance or a proof-of-rejection. Consequently, if a client has the required number of proofs (one per each input UTXO), then the client either only holds proofs-of-acceptance (allowing the transaction to be committed as (2) holds) or not (forcing the transaction to abort as (3) and (4) holds), but not both simultaneously.</p><p>在atomix中，每一个跨分片的交易最终都会提交或中断，根据上面的第一条，每一个输入分片都会返回一个确定的结果，proof-of-acceptance或者proof-of-rejection，因此如果一个客户端已经拥有了要求的proof数量（每一个UTXO都会有一个proof），此时，客户端将对每个输入UTXO只会拥有接受证明或拒绝证明，而不会两者同时拥有。 （根据上面的34条）</p><p>In Atomix, no cross-TX can be spent twice. As shown above, cross-shard transactions are atomic and are assigned to specific shards who are solely responsible for them. Based on (1), the assigned shards do not process a transaction twice and no other shard attempts to unlock to commit.</p><p>在atomix中，没有跨分片交易可以被双花。正如前面所说的，跨分片交易都是原子性，并且只被分配给专门负责它们的特定分片。基于(1)，被分配的分片不会对同一个交易处理两次，没有其它分片会进行解锁提交。</p><p>In Atomix, if a transaction cannot be committed, then the locked funds can be reclaimed. If a transaction cannot be committed, then there must exist at least one proof-of-rejection issued by an input shard, therefore (3) must hold. Once all input shards unlock to abort, the funds become available again.</p><p>在atomix中，如果一个交易不能被提交，那么被锁定的资产将会被重新声明（也就是释放），如果一个交易不能够被提交，那么必须从输入分片中返回的结果中至少存在一个proof-of-rejection，一旦所有的输入分片都解锁并中断了，那么资产将会重新变成可用的</p><p>We remark that funds are not automatically reclaimed and a client or other entity must initiate the unlock to abort process. Although this approach poses the risk that if a client crashes indefinitely his funds remain locked, it enables a simplified protocol with minimal logic that requires no direct shard-to-shard communication. A client who crashes indefinitely is equivalent to a client who loses his private key, which prevents him from spending the corresponding UTXOs. Furthermore, any entity in the system, for example a validator in exchange for a fee, can fill in for the client to create an unlock transaction, as all necessary information is gossiped.</p><p>我们评论，资金<strong>不会被自动回收</strong>，客户端或其他实体必须启动解锁中止过程。虽然这种方法存在一种风险，就是如果客户端无限崩溃了，他的资金就被锁住了，但是它实现了不需要分片之间直接通信的具有最少逻辑的简化协议。<strong>客户端循环崩溃和客户端丢失它的私钥是一样的，会阻止他花费相关的UTXO。</strong>而且，系统中的任何实体，比如一个验证者，可以为客户端填写一个解锁交易，因为所有的信息都是经过gossip广播过的。<strong>（这里其实没有说明为什么可以，不过可以意会一下，这里的崩溃造成的结果是客户端不能够通过gossip协议来广播unlock-to-abort的交易，但是大家都知道这块是需要被解锁的，所以就代其进行如此操作，因为整个系统中的消息都是通过广播传递的）</strong></p><p>To ensure better robustness, we can also assign the shard of the smallest-valued input UTXO to be a coordinator responsible for driving the process of creating unlock transactions. Because a shard’s leader might be malicious, f + 1 validators of the shard need to send the unlock transaction to guarantee that all transactions are eventually unlocked.</p><p>为了保证更好的鲁棒性，我们可以把拥有<strong>最小输入价值的UTXO指定为一个协调器</strong>（coordinator），负责驱动创建解锁交易的执行。因为一个分片leader有可能是恶意的，<code>f+1</code>个分片中的验证者需要发送解锁交易来保证所有交易最终被解锁。 </p><p>Size of Unlock Transactions: In Atomix, the unlock transactions are larger than regular transactions as appropriate proofs for input UTXOs need to be included. OmniLedger relies on ByzCoinX (a novel BFT-consensus described in Section V-A) for processing transactions within each shard. When the shard’s validators reach an agreement on a block that contains committed transactions, they produce a collective signature whose size is independent of the number of validators. This important feature enables us to keep Atomix proofs (and consequently the unlock transactions) short, even though the validity of each transaction is checked against the signed blocks of all input UTXOs. If ByzCoinX did not use collective signatures, the size of unlock transactions would be impractical. For example, for a shard of 100 validators a collective signature would only be 77 bytes, whereas a regular signature would be 9KB, almost two order’s of magnitude larger than the size of a simple transaction (500 bytes).</p><p>用于解锁的交易的大小：在atomix中，解锁交易通常比普通的交易更大，由于不仅需要包含每个输入UTXO，并且还需需要包含每个UTXO相应的证明。OmniLedger<strong>依赖<code>ByzCoinX</code>来处理每个分片内的交易</strong>。当分片的验证者对包含已提交交易的区块达成一致时，他们产生一个集体签名，该签名的大小与验证者的数量无关。这个重要的特性可以使我们保持<code>Atomix证明</code>足够短，即使每个交易的合法性都是通过所有输入UTXO的签名区块被检查。如果ByzCoinX不使用集体签名，解锁交易的大小是不切实际的。比如，具有100个验证的分片一个集体签名只有77字节，而正常签名则有98KB，比一个简单交易大小大两个数量级。</p><h2 id="5-关于性能的设计"><a href="#5-关于性能的设计" class="headerlink" title="5. 关于性能的设计"></a>5. 关于性能的设计</h2><p>In this section, we introduce the performance sub-protocols of OmniLedger. First, we describe a scalable BFT-consensus called ByzCoinX that is more robust and more parallelizable than ByzCoin. Then, we introduce state-blocks that enable fast bootstrapping and decrease storage-costs. Finally, we propose an optional trust-but-verify validation step to provide real-time latency for low-risk transactions</p><p>在这一部分中，我们引入了omniledger中与性能相关的子协议，首先，我们将一个可扩展的BFT协议称为byzcoinx，它比byzcoin具有更强的鲁棒性和并行性。此时我们介绍state-block，它是用来保证验证者在切换分片后高速重启和降低存储开销的一个协议。最终，我们提出一个可选择的trust-but-verify验证步骤来对低风险的交易提供实时延迟。</p><h3 id="5-1-拜占庭容错"><a href="#5-1-拜占庭容错" class="headerlink" title="5.1 拜占庭容错"></a>5.1 拜占庭容错</h3><p>The original ByzCoin design offers good scalability, partially due to the usage of a tree communication pattern. Maintaining such communication trees over long time periods can be difficult, as they are quite susceptible to faults. In the event of a failure, ByzCoin falls back on a more robust all-toall communication pattern, similarly to PBFT. Consequently, the consensus’s performance deteriorates significantly, which the adversary can exploit to hinder the system’s performance.</p><p>原来的byzcoin提供了很好地可扩展性，部分原因是因为使用了<strong>组播树通信模式</strong>，长时间维护这样的组播树是一件困难的事情，因为他们容易受到故障的影响。在失败的情况下，byzcoin将会退回到更加健壮的全方位（all-to-all）通信模式，类似于PBFT，因此共识的性能急剧恶化，攻击者可以利用这个特点来影响系统的性能。</p><p>To achieve better fault tolerance in OmniLedger, without resorting to a PBFT-like all-to-all communication pattern, we introduce for ByzCoinX a new communication pattern that trades-off some of ByzCoin’s high scalability for robustness, by changing the message propagation mechanism within the consensus group to resemble a two-level tree. During the setup of OmniLedger in an epoch, the generated randomness is not only used to assign validators to shards but also to assign them evenly to groups within a shard. The number of groups g, from which the maximum group size can be derived by taking the shard size into account, is specified in the shard policy file. At the beginning of a ByzCoinX roundtrip, the protocol leader randomly selects one of the validators in each group to be the group leader responsible for managing communication between the protocol leader and the respective group members. If a group leader does not reply before a predefined timeout, the protocol leader randomly chooses another group member to replace the failed leader. As soon as the protocol leader receives more than 2 3 of the validators’ acceptances, he proceeds to the next phase of the protocol. If the protocol leader fails, all validators initiate a PBFT-like view-change procedure.</p><p>为了在omniledger中达到更好的容错性能，又不采用PBFT那种（all-to-all）通信的模式，我们引入了一种新的通信模式叫做byzcoinx，它为了健壮性会牺牲一部分byzcoin的高性能，方法是将<strong>共识组内的消息传播机制改成类似于两级树的形式</strong>，在每一个epoch建立设置的时候，产生的随机数不仅用在将验证者到分片的分配，同时也将验证者分配给分片内的相应组。组的数量<code>g</code>，其中通过考虑保存在分片策略文件中的分片大小可以导出最大的组大小。在ByzCoinX的开始轮次中，leader从每个组中随机地选出一个验证者作为组领导者，其负责管理协议领导者与各小组成员之间的通信。如果组领导者在一个预设时间内没有回复，协议领导者重新随机选择一个组领导者来代替失效的那个。一旦协议领导者接收到超过2/3的验证者认可，他就马上进入协议的下一步。如果协议领导者失效，所有验证者发起一个类似PBFT的视图改变步骤。</p><h3 id="5-2-并行区块提交"><a href="#5-2-并行区块提交" class="headerlink" title="5.2 并行区块提交"></a>5.2 并行区块提交</h3><p>We now show how ByzCoinX parallelizes block commitments in the UTXO model by carefully analyzing and handling dependencies between transactions.</p><p>我们现在通过认真分析和处理交易之间的依赖性，来展示在UTXO模型中byzcoinx是如何进行并行区块提交的。</p><p>We observe that transactions that do not conflict with each other can be committed in different blocks and consequently can be safely processed in parallel. To identify conflicting transactions, we need to analyze the dependencies that are possible between transactions. Let txA and txB denote two transactions. Then, there are two cases that need to be carefully handled: (1) both txA and txB try to spend the same UTXO and (2) an UTXO created at the output of txA is spent at the input of txB (or vice versa). To address (1) and maintain consistency, only one of the two tx can be committed. To address (2), txA has to be committed to the ledger before txB, i.e., txB has to be in a block that depends (transitively) on the block containing txA. All transactions that do not exhibit these two properties can be processed safely in parallel. In particular we remark that transactions that credit the same address do not produce a conflict, because they generate different UTXOs</p><p>我们发现互相不冲突的区块可以被提交到不同的区块中并且可以被安全地并行处理。为了区分冲突的交易，我们需要分析两个交易之间可能存在的依赖。令txA和txB在两个交易之中，同时这两个交易具有依赖性，此时，有两种情况需要被特殊处理：</p><ul><li><strong>txA和txB在同一个UTXO中被花费</strong></li><li><strong>一个UTXO是txA的输出，被txB作为输入花费（或者相反）</strong></li></ul><p>第一种问题的解决方法是：这两个tx只有一个可以被提交</p><p>第二种问题的解决方法是：txA必须先于txB被提交到账本中，也就是说，txB所在的区块必须依赖txA的区块</p><p>所有未被上述两种问题提及的交易都可以正常地被并行处理</p><p>特别地，我们认为，相同地址的交易不会产生冲突，因为他们产生不同的UTXO。</p><p>To capture the concurrent processing of blocks, we adopt a block-based directed acyclic graph (blockDAG) [33] as a data structure, where every block can have multiple parents. The ByzCoinX protocol leader enforces that each pending block includes only non-conflicting transactions and captures UTXO dependencies by adding the hashes of former blocks (i.e., backpointers) upon which a given block’s transactions depend. To decrease the number of such hashes, we remark that UTXO dependencies are transitive, enabling us to relax the requirement that blocks have to capture all UTXO dependencies directly. Instead, a given block can simply add backpointers to a set of blocks, transitively capturing all dependencies.</p><p>为了获得正在处理的区块，我们接受一个基于区块的有向无环图（blockDAG）[<code>33</code>]作为数据结构，其中的每一个区块都有多个双亲节点。byzcoinx协议的leader<strong>强制每个挂起的区块必须是没有冲突的</strong>，并通过添加当前区块中交易所依赖的上个区块的hash来捕获UTXO依赖性。为减少这类hash的数量，我们注意到UTXO依赖性是可传递的，这使得我们可放宽必须直接捕获所有UTXO依赖性的要求。相反，<strong>特定的区块可以简单添加反向指针到一个区块集</strong>，<strong>可传递性的捕获所有依赖性</strong>。</p><h3 id="5-3-分片账本剪枝"><a href="#5-3-分片账本剪枝" class="headerlink" title="5.3 分片账本剪枝"></a>5.3 分片账本剪枝</h3><p>Now we tackle the issues of an ever-growing ledger and the resulting costly bootstrapping of new validators; this is particularly urgent for high-throughput DL systems. For example, whereas Bitcoin’s blockchain grows by ≈ 144 MB per day and has a total size of about 133 GB, next-generation systems with Visa-level throughput (e.g., 4000 tx/sec and 500 B/tx) can easily produce over 150 GB per day.</p><p>现在我们来解决不断增长的账本问题，以及由此导致的新验证者启动开销过大的问题，这对高性能的去中心化账本尤其紧急。比如，比特币区块链每天增长144MB，目前的总大小是133GB，而下一代VISA级高性能的账本(比如, 4000tx/sec和500B/tx)每天就可以产生超过150GB。</p><p>To reduce the storage and bootstrapping costs for validators (whose shard assignments might change periodically), we introduce state blocks that are similar to stable checkpoints in PBFT [13] and that summarize the entire state of a shard’s ledger. To create a state block $sb_{j,e}$ for shard j in epoch e, the shard’s validators execute the following steps: At the end of e, the shard’s leader stores the UTXOs in an ordered Merkle tree and puts the Merkle tree’s root hash in the header of $sb_{j,e}$. Afterwards, the validators run consensus on the header of $sb_{j,e}$ (note that each validator can construct the same ordered Merkle tree for verification) and, if successful, the leader stores the approved header in the shard’s ledger making $sb_{j,e}$ the genesis block of epoch e + 1. Finally, the body of$sb_{j,e-1}$ (UTXOs) can be discarded safely. We keep the regular blocks of epoch e, however, until after the end of epoch e+1 for the purpose of creating transaction proofs.</p><p>为了使那些经常重新分配分片的验证者减小存储和启动开销，我们引入状态区块<code>(state blocks)</code>，它和<code>PBFT[13]</code>中的固定检查点很类似，就是汇总分片账本的全部状态。</p><p>为了在第e个epoch中为第j个分片创建状态区块$sb_{j,e}$，该分片的验证者执行以下步骤</p><ul><li>在第e个epoch结束的时候，分片的leader<strong>将本分片的所有UTXO保存到一个排序的默克尔树，并将树根哈希存入$sb_{j,e}$区块头部。</strong></li><li>然后，区块在$sb_{j,e}$的区块头上运行一致性协议（注意，每一个验证者可以构造相同排序的merkle树）</li><li>如果成功，leader将会<strong>把通过的区块头存进分片账本中，然后使$sb_{j,e}$成为第e+1个epoch的创世区块</strong></li><li>最后，$sb_{j,e}$区块主体中的UTXO可以被安全的丢弃。为了创建交易证明，我们保留第<code>e</code>个epoch的正常区块，直到第<code>e+1</code>个epoch结束。</li></ul><p>As OmniLedger’s state is split across multiple shards and as we store only the state blocks’ headers in a shard’s ledger, a client cannot prove the existence of a past transaction to another party by presenting an inclusion proof to the block where the transaction was committed. We work around this by moving the responsibility of storing transactions’ proofs-of-existence to the clients of OmniLedger. During epoch e + 1 clients can generate proofs-of-existence for transactions validated in epoch e using the normal block of epoch e and the state block. <strong>Such a proof for a given transaction tx contains the Merkle tree inclusion proof to the regular block B that committed tx in epoch e and a sequence of block headers from the state block$sb_{j,e}$ at the end of the epoch to block B.</strong> To reduce the size of these proofs, state blocks can include several multi-hop backpointers to headers of intermediate (regular) blocks similarly to skipchains [37].</p><p>因为OmniLedger的状态是拆分到多个分片的，并且我们<strong>在分片账本中仅保存状态区块的头部</strong>，客户端通过提交一个交易被提交的区块的包含证明<strong>不能向其它实体证明一个过去交易是被提交的</strong>。我们通过将用于证明交易存在的存储交易的责任转移给client，来解决这个问题。在第e+1个epoch中，客户端可以使用第<code>e</code>个epoch的常规区块和状态区块来生成第<code>e</code>个epoch已验证交易的存在证明。对于给定事务tx的此类证明包含：</p><ul><li>在第e个epoch中提交的tx的常规块B的Merkle树（这句话好绕啊。。。？？？）</li><li>一个epoch结束时状态区块$sb_{j,e}$以及常规区块B</li></ul><p>为了减少这些证明，状态区块可以包含多个多跳反向指针指向类似<code>skipchains[37]</code>的中间常规区块的头部。</p><blockquote><p>[37] K. Nikitin, E. Kokoris-Kogias, P. Jovanovic, N. Gailly, L. Gasser, I. Khoffi, J. Cappos, and B. Ford. <code>CHAINIAC: Proactive SoftwareUpdate Transparency via Collectively Signed Skipchains and Verified Builds.</code> In 26th USENIX Security Symposium (USENIX Security 17), pages 1271–1287. USENIX Association, 2017.</p></blockquote><p>Finally, if we naively implement the creation of state blocks, it stalls the epoch’s start, hence the transaction processing until $sb_{j,e}$ has been appended to the ledger. To avoid this downtime, the consistent validators of the shard in epoch e + 1 include an empty state-block at the beginning of the epoch as a placeholder; and once $sb_{j,e}$ is ready they commit it as a regular block, pointing back to the place-holder and $sb_{j,e-1}$.</p><p>最终，如果我们简单的实现了状态区块的创造，它会阻碍epoch的启动，因为直到$sb_{j,e}$被写进区块之后交易才会开始执行。为了避免这种停机时间，第e+1个epoch一开始包含了一个空的状态区块作为占位符，一旦$sb_{j,e}$准备好了，验证者就将其作为普通区块的提交，并且指向上一个占位符和$sb_{j,e-1}$</p><h3 id="5-4-Trust-but-Verify验证"><a href="#5-4-Trust-but-Verify验证" class="headerlink" title="5.4 Trust-but-Verify验证"></a>5.4 Trust-but-Verify验证</h3><p>There exists an inherent trade-off between the number of shards (and consequently the size of a shard), throughput and latency, as illustrated in Figure 4. A higher number of smaller shards results in a better performance but provides less resiliency against a more powerful attacker (25%). Because the design of OmniLedger favors security over scalability, we pessimistically assume an adversary who controls 25% of the validators and, accordingly, choose large shards at the cost of higher latency but guarantee the finality of transactions. This assumption, however, might not appropriately reflect the priorities of clients with frequent, latency-sensitive but low-value transactions (e.g., checking out at a grocery store, buying gas or paying for coffee) and who would like to have transactions processed as quickly as possible.</p><p>在分片数量、吞吐量和时延仍然存在一个平衡，如下图所示，具有大量的小分片将会使得性能变得很好但是对于更强大的攻击者（25%）提供了更低的弹性。因为omniledger的设计更加偏重于安全过于可扩展性，我们假设一个掌握25%节点的攻击者，选择较大的分片将会导致较高的时延，不过保证了最终的交易。这一假设其实是不能恰当地反映那些具有频繁使用、延迟敏感但低价值交易的客户的优先级（比如，杂货店支付，购买汽油或咖啡等），他们喜欢交易处理地越快越好。</p><p><img src="/2019/11/15/blockchain/03/1573999093184.png" alt="1573999093184"></p><p>In response to the clients’ needs, we augment the intrashard architecture (see Figure 4) by following a “trust but verify” model, where optimistic validators process transactions quickly, providing a provisional but unlikely-to-change commitment and core validators subsequently verify again the transactions to provide finality and ensure verifiability. Optimistic validators follow the usual procedures for deciding which transactions are committed in which order; but they form much smaller groups, even as small as one validator per group. Consequently, they produce smaller blocks with real-time latencies but are potentially less secure as the adversary needs to control a (proportionally) smaller number of validators to subvert their operation. As a result, some bad transactions might be committed, but ultimately core validators verify all provisional commitments, detecting any inconsistencies and their culprits, which makes it possible to punish rogue validators and to compensate the defrauded customers for the damages. The trust-but-verify approach strikes a balance for processing small transactions in real-time, as validators are unlikely to misbehave for small amounts of money.</p><p>为了满足客户的需求，我们增加一种分片内架构（如图4所示），通过遵循“trust-but-verify”模型，使乐观的验证者更快地处理交易，提供<strong>临时但不太可能改变的交易提交</strong>，然后核心的验证者随后再次核实交易以提供最终结果并确保可验证性。乐观验证者按照常规的步骤来决定<strong>哪些交易按哪种顺序提交</strong>，但是他们会组成更小的分组，甚至可能一个验证者一个组。因此他们实时地生成更小的区块，但是可能很不安全，因为攻击可能会按比例控制较小数量的验证者来破坏交易。结果是，一些不好的交易将会被提交，但是最终核心验证者验证所有提交的交易，检测任何不一致和他们的罪魁祸首，然后惩罚恶意验证者，并赔偿被欺诈的客户的损害。这种“trust-but-verify”的方法在实时处理小额交易时取得平衡，<strong>因为验证者不会因为少量的钱进行作恶</strong>。</p><p>At the beginning of an epoch e, all validators assign themselves to shards by using the per-epoch randomness, and then bootstrap their states from the respective shard’s last state block. Then, OmniLedger assigns each validator randomly to one of multiple optimistic processing groups or a single core processing group. The shard-policy file specifies the number of optimistic and core validators, as well as the number of optimistic groups. Finally, in order to guarantee that any misbehavior will be contained inside the shard, it can also define the maximum amount of optimistic validated transactions to be equal to the stake or revenue of the validators.</p><p>在第e个epoch开始的时候，所有的验证者通过每一轮的随机数将自己分配到分片中，然后从对应分片的上一个状态区块开始启动他们的状态。omniledger将每一个验证者随机分配到众多乐观处理的group中或单个核心处理group中。分片策略文件制定了乐观和核心验证者的数量，最后，为了保证所有的不正当行为都被包含在分片内，策略文件还定义了<strong>最大的乐观验证交易的数额必须等于验证者的押金或收入</strong>。</p><p>Transactions are first processed by an optimistic group that produces optimistically validated blocks. These blocks serve as input for re-validation by core validators who run concurrently and combine inputs from multiple optimistic processing groups, thus maximizing the system’s throughput (Figure 4). Valid transactions are included in a finalized block that is added to the shard’s ledger and are finally included in the state block. However, when core validators detect an inconsistency, then the respective optimistically validated transaction is excluded and the validators who signed the invalid block are identified and held accountable, e.g., by withholding any rewards or by excluding them from the system. We remark that the exact details of such punishments depend on the incentive scheme that are out of scope of this paper. Given a minimal incentive to misbehave and the quantifiable confidence in the security of optimistic validation (Figure 5), clients can choose, depending on their needs, to take advantage of realtime processing with an optimistic assurance of finality or to wait to have their transaction finalized.</p><p>先被乐观group处理的交易会生成乐观验证区块。这些区块会作为核心验证者的输入进行重新验证， 核心验证者会并行运行，并将乐观group处理后的输入区块进行重新组合以显示最大化系统吞吐量。合法的交易会被打包进行最终区块，然后加入账本并最终被包含进行状态区块。然而，当核心验证者检测到不一致性，那么对应乐观验证的交易就会被排除，对非法区块签名的验证者会被识别并追究其责任，通过<strong>扣留任何奖励或将其排除在外</strong>。我们认为具体的惩罚细节依赖于经济激励方案，不在本文范围内。给予行为不端的最小激励以及对乐观验证安全性的可量化信任（<code>参考图5</code>），客户可以根据需要选择利用实时处理和乐观的最终保证，或等待交易最终确定。</p><p><img src="/2019/11/15/blockchain/03/1573999925817.png" alt="1573999925817"></p><h2 id="6-安全性分析"><a href="#6-安全性分析" class="headerlink" title="6. 安全性分析"></a>6. 安全性分析</h2><h3 id="6-1-随机数生成"><a href="#6-1-随机数生成" class="headerlink" title="6.1 随机数生成"></a>6.1 随机数生成</h3><p>RandHound assumes an honest leader who is responsible for coordinating the protocol run and for making the produced randomness available to others. In OmniLedger, however, we cannot always guarantee that an honest leader will be selected. Although a dishonest leader cannot affect the unbiasability of the random output, he can choose to withhold the randomness if it is not to his liking, thus forcing the protocol to restart. We economically disincentivize such behavior and bound the bias by the randomized leader-election process.</p><p>randhound假设忠诚的leader负责运行协议并为其他人产生随机数。在omniledger中，我们不能总是保证选择的leader是忠诚的。尽管一个不忠诚的节点不能够影响随机输出的无偏性，当他不喜欢生成的随机数时，他可以选择将这个随机数隐藏，因此这样就导致了协议的重启。我们从经济上抑制了这种行为，并通过随机的leader选举过程限制了bias（翻译为偏见比较合理）。</p><p>The leader-election process is unpredictable as the adversary is bound by the usual cryptographic hardness assumptions and is unaware of (a) the private keys of the honest validators and (b) the input string x to the VRF function. Also, OmniLedger’s membership is unpredictable at the moment of private key selection and private keys are bound to identities. As a result, the adversary has at most m = 1/4 chance per round to control the elected leader as he controls at most 25% of all nodes. Each time an adversary-controlled leader is elected and runs RandHound the adversary can choose to accept the random output, and the sharding assignment produced by it, or to forfeit it and try again in hopes of a more favorable yet still random assignment. Consequently, the probability that an adversary controls n consecutive leaders is upper-bounded by $P [X ≥ n] = \frac{1}{4n} &lt; 10^{−λ}$. For λ = 6, the adversary will control at most 10 consecutive RandHound runs. This is an upper bound, as we do not include the exclusion of the previous leader from the consecutive elections.</p><p>leader选举的过程是不可预测的，因为对手被通常的密码学难度假设限制，并且对手不知道（a）诚实验证者的私钥和（b）VRF函数的输入字符串x。同时，omniledger的成员身份也是不可预测的，并且私钥绑定身份。结果是，对手每轮最多有1/4的机会成为选举的leader。每次对手控制的leader被选择并且运行randhound，对手可以选择接受这个随机输出，然后分片就会由这个随机数产生，或者放弃它，然后再试一次，以期获得更有利但仍是随机的分配。因此，对手连续n次成为leader的概率为：$P [X ≥ n] = \frac{1}{4n} &lt; 10^{−λ}$，假设lambda=6，对手将会最多连续10次控制randhound的运行。这是一个上限，因为我们不包括将前任领导人排除在连续选举之外。</p><h3 id="6-2-分片大小安全"><a href="#6-2-分片大小安全" class="headerlink" title="6.2 分片大小安全"></a>6.2 分片大小安全</h3><p>We previously made the assumption that each shard is collectively honest. This assumption holds as long as each shard has less than$c = \lfloor \frac{n}{3} \rfloor$malicious validators, because ByzCoinX requires $n = 3f + 1$ to provide BFT consensus.</p><p>我们前面做出的假设是每一个分片都是集体忠诚的，这个假设说的是只要每一个分片少于$c = \lfloor \frac{n}{3} \rfloor$个恶意节点，因为byzcoinx要求$n = 3f + 1$以达成BFT协议</p><p>The security of OmniLedger’s validator assignment mechanism is modeled as a random sampling problem with two possible outcomes (honest or malicious). Assuming an infinite pool of potential validators, we can use the binomial distribution (Eq. 1). We can assume random sampling due to RandHound’s unpredictability property that guarantees that each selection is completely random; this leads to the adversarial power of at most m = 0.25.</p><p>omniledger的验证者选择机制的安全性是以两种输出（忠诚或恶意）随机采样问题来保证的，假设有一个无限数量的验证者池，我们可以用二项分布来模拟，我们假设随机采样取决于randhound的不可预测性来保证每一个选择是完全随机地，这将会导致对手最多能够使得下面公式中的m=0.25</p><p><img src="/2019/11/15/blockchain/03/1574043085171.png" alt="1574043085171"></p><p>To calculate the failure rate of one shard, i.e., the probability that a shard is controlled by an adversary, we use the cumulative distributions over the shard size n, where X is the random variable that represents the number of times we pick a malicious node. Figure 5 (right) illustrates the proposed shard size, based on the power of the adversary. In a similar fashion we calculate the confidence a client can have that an optimistic validation group is honest (left).</p><p>为了计算一个分片的失败率，也就是说一个分片被对手掌控，我们使用分片大小n上的累积分布来描述，其中X是代表我们选择恶意节点的次数的随机变量。图5（在5.4节中）描述了分片大小基于对手的能力，我们以类似的方式计算出客户对乐观验证组诚实的信心（左）。</p><h3 id="6-3-Epoch-安全"><a href="#6-3-Epoch-安全" class="headerlink" title="6.3 Epoch 安全"></a>6.3 Epoch 安全</h3><p>In the last section, we modeled the security of a single shard as a random selection process that does, however, not correspond to the system’s failure probability within on epoch. Instead, the total failure rate can be approximated by the union bound over the failure rates of individual shards.</p><p>在上一个部分中，我们为单个分片设计了一个安全性模型，也就是一个随机选择过程，但是并不是针对一个epoch中系统的失败率而设计的，相反，总失败率可以通过联合对各个分片的失败率进行估计。</p><p>We argue that, given an adequately large shard size, the epoch-failure probability is negligible. We can calculate an upper bound on the total-failure probability by permitting the adversary to run RandHound multiple times and select the output he prefers. This is a stronger assumption than what RandHound permits, as the adversary cannot go back to a previously computed output if he chose to re-run RandHound. An upper bound of the epoch failure event $X_E$ is given by </p><p><img src="/2019/11/15/blockchain/03/1574043275521.png" alt="1574043275521"></p><p>where $l$ is the number of consecutive views the adversary controls,  $n$ is the number of shards and $P [X_S]$ is the failure probability of one shard as calculated in Section VI-B. For l → ∞, we get $P [X_E] ≤ \frac{4}{3}· n · P [X_S]$. More concretely, the failure probability, given a 12.5%-adversary and 16 shards, is $4 · 10^{-5}$ or one failure in 68.5 years for one-day epochs</p><p>我们认为，给定的分片大小如果足够大的话，一个epoch的失败概率就可以忽略不计，我们可以计算一个总失败率的上界，这个失败指的是允许对手运行randhound多次并且选择他想要的输出。这是一个比randhound允许更强大的假设，对手如果重新运行randound，则他不能够退回到一个以前计算的结果，一个epoch内的失败事件$X_E$的概率如上面那个公式所示</p><p>公式中的l表示的是连续被对手控制的次数和，n指的是分片的数量，$P [X_S]$指的是在6.2节中计算出来的一个分片的概率。从1到∞，我们得到$P [X_E] ≤ \frac{4}{3}· n · P [X_S]$，更具体地讲，在12.5％的对手和16个分片的情况下，故障概率为$4 · 10^{-5}$，或者说以一个epoch为1天的时间算，68.5年才会发生一次故障</p><h3 id="6-4-组通信"><a href="#6-4-组通信" class="headerlink" title="6.4 组通信"></a>6.4 组通信</h3><p>We now show that OmniLedger’s group-communication pattern has a high probability of convergence under faults. We assume that there are N nodes that are split in $\sqrt{N}$ groups of $\sqrt{N}$ nodes each.  </p><p>我们现在展示omniledger的组播树通信机制在故障下具有很高的收敛可能性。我们假设有N个节点，分成$\sqrt{N}$个分组，每个分组中有$\sqrt{N}$个节点</p><p>1) Setting the Time-Outs: In order to ensure that the shard leader will have enough time to find honest group leaders, we need to setup the view-change time-outs accordingly. OmniLedger achieves this by having two time-outs. The first    timeout $T_1$ is used by the shard leader to retry the request to non-responsive group members. The second timeout $T_2$ is used by the group members to identify a potential failure of a shard leader and to initiate a view-change [13]. To ensure that the shard leader has enough time to retry his requests, we have a fixed ratio of $T_1 = 0.1T_2$ . However, if the $T_2$ is triggered, then in the new view $T_2$ doubles (as is typical [13]) in order to contemplate for increase in the network’s asynchrony, hence $T_1$ should double to respect the ratio.</p><p>第一，设置超时时间：为了保证分片leader有足够的时间来找到忠诚的group leader，我们需要设置视图切换的超时时间。omniledger通过两个超时时间来达成这一目标。第一个超时时间$T_1$被分片leader使用，以向无响应的组成员重试该请求。第二个超时时间$T_2$被组成员使用，用来识别leader潜在的失败并发起视图切换[<code>13</code>]。为了保证分片leader有足够的时间来重试它的请求，我们设置一个固定的时间比例为：$T_1 = 0.1T_2$，然而，如果$T_2$ 被触发，那么在新的视图中$T_2$ 将会被加倍。考虑增加网络的异步性，因此$ T_1 $应该加倍以遵守该比率。</p><p>2) Reaching Consensus: We calculate the probability for a group size N = 600 where $\sqrt{N}$ = 25: Given a population of 600 nodes and a sampling size of 25, we use the hypergeometric distribution for our calculation which yields a probability of 99.93% that a given group will have less than 25 - 10 = 15 malicious nodes. A union bound over 25 groups yields a probability of 98.25% that no group will have more than 15 malicious nodes. In the worst case, where there are exactly 1/3 malicious nodes in total, we need all of the honest validators to reply. For a group that contains exactly 15 malicious nodes, the shard’s leader will find an honest group leader (for ByzCoinX) after 10 tries with a probability of $1 - ((15/24)^{10}) = 98.6%$. As a result, the total probability of failure is 1 - 0.986 ∗ 0.9825 = 0.031.</p><p>第二，达成共识：我们使用N=600来计算概率，这时的$\sqrt{N}$ = 25。我们使用超几何分布来进行计算得出给定组的少于25-10 = 15个恶意节点的概率为99.93％。绑定到25个组的联合会产生98.25％的概率，即没有一个组具有超过15个恶意节点。在最坏的情况下，有1/3的恶意节点，我们需要让所有的忠诚节点回复。对于一个包含了15个恶意节点的组来说，分片的leader随后需要通过10次尝试来找到所有的忠诚节点。因此总的失败概率为1 - 0.986 ∗ 0.9825 = 0.031.</p><p>这部分概率计算的步骤没太懂。。。</p><p>We remark that this failure does not constitute a compromise of security of OmniLedger. Rather, it represents the probability of a failure for the shard leader who is in charge of coordinating the shard’s operation. If a shard leader indeed fails, then a new shard leader will be elected having 97% probability of successfully reaching consensus.</p><p>我们认为此失败并不构成OmniLedger安全性的折衷（compromise）？相反的，它表示了用于协调分片操作的分片leader失败的概率。如果一个分片leader失败了，这时一个新的leader将会被选择，有97%的概率能够达成共识。</p><h2 id="9-近期工作"><a href="#9-近期工作" class="headerlink" title="9. 近期工作"></a>9. 近期工作</h2><p>The growing interests in scaling blockchains have produced a number of prominent systems that we compare in Table IV. ByzCoin [32] is a first step to scalable BFT consensus, but cannot scale-out. Elastico is the first open scale-out DL, however, it suffers from performance and security challenges that we have already discussed in Section II. RSCoin [16] proposes sharding as a scalable approach for centrally banked cryptocurrencies. RSCoin relies on a trusted source of randomness for sharding and auditing, making its usage problematic in trustless settings. Furthermore, to validate transactions, each shard has to coordinate with the client and instead of running BFT, RSCoin uses a simple two-phase commit, assuming that safety is preserved if the majority of validators is honest. This approach, however, does not protect from double spending attempts by a malicious client colluding with a validator.</p><p>对扩展区块链的兴趣日益浓厚，已经产生了许多杰出的系统，我们在表IV中进行了比较。 </p><ul><li>ByzCoin [<code>32</code>]是实现可扩展BFT共识的第一步，但无法向外扩展。 </li><li>Elastico[<code>34</code>]是第一个开放式横向扩展DL，但是它遭受了我们在第二部分中已经讨论过的性能和安全性挑战。 </li><li>RSCoin [<code>16</code>]提出将分片作为可扩展方法用于中央银行的加密货币。 RSCoin依靠可靠的随机性来进行分片和审核，从而使其在无信任设置中的使用成为问题。 此外，为了验证交易，每个分片必须与客户端协调，而不是运行BFT，RSCoin使用简单的两阶段提交，假设如果大多数验证者是诚实的，则可以确保安全性。 但是，这种方法不能防止恶意客户端与验证程序勾结而造成的双重支出尝试。</li></ul><p><img src="/2019/11/15/blockchain/03/1574045467799.png" alt="1574045467799"></p><p>In short, prior solutions [16], [32], [34] achieve only two out of the three desired properties; decentralization, long-term security, and scale-out, as illustrated in Figure 1. OmniLedger overcomes this issue by scaling out, as far as throughput is concerned, and by maintaining consistency to the level required for safety, without imposing a total order.</p><p>简而言之，现有解决方案[16]，[32]，[34]仅实现了三个所需特性中的两个； 去中心化，长期安全性和额扩展性，如图1所示。OmniLedger通过横向扩展（就吞吐量而言）并保持一致性至安全要求的水平（而不强加全局排序total order）来解决此问题。</p><blockquote><p>[16]G. Danezis and S. Meiklejohn. <code>Centrally Banked Cryptocurrencies.</code> 23rd Annual Network &amp; Distributed System Security Symposium (NDSS), Feb. 2016.</p><p>[32] E. Kokoris-Kogias, P. Jovanovic, N. Gailly, I. Khoffi, L. Gasser, and B. Ford. <code>Enhancing Bitcoin Security and Performance with Strong Consistency via Collective Signing.</code> In Proceedings of the 25th USENIX Conference on Security Symposium, 2016.</p><p>[34] L. Luu, V. Narayanan, C. Zheng, K. Baweja, S. Gilbert, and P. Saxena. <code>A Secure Sharding Protocol For Open Blockchains.</code> In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS ’16, pages 17–30, New York, NY, USA, 2016. ACM.</p></blockquote><p>Bitcoin-NG scales Bitcoin without changing the consensus algorithm by observing that the PoW process does not have to be the same as the transaction validation process; this results in two separate timelines: one slow for PoW and one fast for transaction validation. Although Bitcoin-NG significantly increases the throughput of Bitcoin, it is still susceptible to the same attacks as Bitcoin [24], [3].</p><p>通过观察PoW流程不必与交易验证流程相同，Bitcoin-NG可以在不更改共识算法的情况下扩展比特币。 这导致了两个单独的时间轴：一个是PoW速度较慢，另一个是事务验证快速。 尽管Bitcoin-NG大大提高了比特币的吞吐量，但它仍然容易受到与比特币相同的攻击[24]，[3]。</p><blockquote><p>[24] A. Gervais, H. Ritzdorf, G. O. Karame, and S. Capkun. <code>Tampering with the Delivery of Blocks and Transactions in Bitcoin.</code> In 22nd ACM SIGSAC Conference on Computer and Communications Security, pages 692–705. ACM, 2015.</p><p>[3] M. Apostolaki, A. Zohar, and L. Vanbever. <code>Hijacking Bitcoin: Largescale Network Attacks on Cryptocurrencies.</code> 38th IEEE Symposium on Security and Privacy, May 2017.</p></blockquote><p>Other efforts to scale blockchains include: Tendermint [9], a protocol similar to PBFT for shard-level consensus that does not scale due to its similarities to PBFT, and the Lightning Network [40], an off-chain payment protocol for Bitcoin (also compatible to OmniLedger); it limits the amount of information committed to the blockchain.</p><p>扩展区块链的其他努力包括：Tendermint [9]，类似于PBFT的分片级别共识协议，由于与PBFT的相似而无法扩展，以及Lightning Network [40]，比特币的链下支付协议（ 还与OmniLedger兼容）； 它限制了提交给区块链的信息量。</p><blockquote><p>[9]  E. Buchman. <code>Tendermint: Byzantine Fault Tolerance in the Age of Blockchains</code>, 2016. </p><p>[40]  J. Poon and T. Dryja. <code>The Bitcoin Lightning Network: Scalable OffChain Instant Payments,</code> Jan. 2016. </p></blockquote><p>Chainspace [2], enhances RSCoin with a more general smart-contract capability. Chainspace also recognizes the need for cross-shard atomic commit but devises a rather complicated algorithm because it chooses to have the shards run the protocol without the use of a client, which increases the cross-shard communication. Our approach is synergistic to Chainspace, as we focus on an open scalable UTXO style DL, whereas Chainspace focuses on sharded smart-contracts and small-scale shards that can be deployed only under weak adversaries. However, combining OmniLedger and Chainspace has great potential to create an open, scalable smart-contract platform that provides scalability and security under strong adversaries.</p><p>Chainspace [2]通过更通用的智能合约功能增强了RSCoin。 Chainspace还认识到需要进行跨分片的原子提交，但是设计了一种相当复杂的算法，因为它选择让分片在不使用客户端的情况下运行协议，从而增加了跨分片的通信。 我们的方法与Chainspace协同工作，因为我们专注于开放的可扩展UTXO样式DL，而Chainspace则专注于只能在弱对手下部署的分片智能合约和小规模分片。 但是，将OmniLedger和Chainspace结合使用具有巨大的潜力，可以创建一个开放的，可伸缩的智能合约平台，该平台可以在强大的对手下提供可伸缩性和安全性。</p><blockquote><p>[2] M. Al-Bassam, A. Sonnino, S. Bano, D. Hrycyszyn, and G. Danezis.<br><code>Chainspace: A Sharded Smart Contracts Platform.</code> arXiv preprint arXiv:1708.03778, 2017.</p></blockquote><h2 id="10-不足与展望"><a href="#10-不足与展望" class="headerlink" title="10. 不足与展望"></a>10. 不足与展望</h2><p>OmniLedger is still a proof of concept and has limitations that we want to address in future work. First, even if the epoch bootstrap does not interfere with the normal operation, its cost (in the order of minutes) is significant. We leave to future work the use of advanced cryptography, such as BLS [6] for performance improvements. Additionally, the actual throughput is dependent on the workload (see Appendix C). If all transactions touch all the shards before committing, then the system is better off with only one shard. We leave to future work the exploration of alternative ways of sharding, e.g.using locality measures. Furthermore, we rely on the fact that honest validators will detect that transactions are unfairly censored and change the leader in the case of censorship. But, further anti-censorship guarantees are needed. We provide a protocol sketch in Appendix A and leave to future work its implementation and further combination with secret sharing techniques for providing stronger guarantees. Another shortcoming of OmniLedger is that it does not formally reason around incentives of participants and focus on the usual honest or malicious devide, which can be proven unrealistic in anonymous open cryptocurrencies. Finally, the system is not suitable for highly adaptive adversaries, as the bootstrap time of an epoch is substantial and scales only moderately, thus leading to the need for day-long epochs.  </p><p>OmniLedger仍然是概念的证明，并且存在我们在将来的工作中要解决的局限性。首先，即使每个epoch启动时不干扰正常操作，其成本（以分钟为单位）也很大。我们将未来的工作留给高级加密技术使用，例如BLS [6]来提高性能。此外，实际吞吐量取决于工作负载（请参阅附录C）。如果在提交之前所有事务与所有的分片都相关，那么系统最好只使用一个分片。我们将留待以后的工作来探索其他分片方式，例如使用本地化措施。此外，我们依靠这样一个事实，即诚实的验证者将检测到交易受到不公正的审查，并在审查制度下改变领导者。但是，需要进一步的反审查保证。我们在附录A中提供了协议草图，并留作以后的工作，并与秘密共享技术进一步结合以提供更强大的保证。 OmniLedger的另一个缺点是，它没有正式地围绕参与者的动机进行推理，而是专注于通常的诚实或恶意行为，这在匿名开放式加密货币中被证明是不现实的。最后，该系统不适用于高度适应性的对手，因为一个时期的引导时间很长，而且缩放比例适中，因此一个epoch的需要一整天的时间。</p><h2 id="11-总结"><a href="#11-总结" class="headerlink" title="11. 总结"></a>11. 总结</h2><p>OmniLedger is the first DL that securely scales-out to offer a Visa-level throughput and a latency of seconds while preserving full decentralization and protecting against a Byzantine adversary. OmniLedger achieves this through a novel approach consisting of three steps. First, OmniLedger is designed with concurrency in mind; both the full system (through sharding) and each shard separately (through ByzCoinX) validate transactions in parallel, maximizing the resource utilization while preserving safety. Second, OmniLedger enables any user to transact safely with any other user, regardless of the shard they use, by deploying Atomix, an algorithm for cross-shard transactions as well as real-time validation with the introduction of a trust-but-verify approach. Finally, OmniLedger enables validators to securely and efficiently switch between shards, without being bound to a single anti-Sybil attack method and without stalling between reconfiguration events.</p><p>OmniLedger是第一个安全扩展的DL，可提供Visa级的吞吐量和几秒钟的等待时间，同时保留完全的权力下放并抵御拜占庭的对手。 OmniLedger通过包含三个步骤的新颖方法来实现这一目标。 首先，OmniLedger在设计时考虑了并发性。 整个系统（通过分片）和每个分片（通过ByzCoinX）都可以并行验证事务，从而在确保安全的同时最大程度地利用资源。 其次，OmniLedger通过部署Atomix（一种跨分片事务处理算法以及引入了trust-but-verify方法的实时验证），使任何用户都能与任何其他用户安全地进行交易，而不论他们使用的是何种碎片。 。 最终，OmniLedger使验证程序能够在碎片之间安全有效地切换，而不必局限于单一的反Sybil攻击方法，也不会在重新配置事件之间停滞。</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程10：UDP连接</title>
      <link href="/2019/11/03/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B10UDP%E8%BF%9E%E6%8E%A5/"/>
      <url>/2019/11/03/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B10UDP%E8%BF%9E%E6%8E%A5/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><h2 id="1-编程实例"><a href="#1-编程实例" class="headerlink" title="1. 编程实例"></a>1. 编程实例</h2><p>首先看一个UDP连接的例子</p><p><img src="/2019/11/03/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B10UDP%E8%BF%9E%E6%8E%A5/1572055898417.png" alt="1572055898417"></p><p>客户端在 UDP 套接字上调用 connect 函数，之后将标准输入的字符串发送到服务器端，并从服务器端接收处理后的报文。当然，和服务器端发送和接收报文是通过调用函数 sendto 和 recvfrom 来完成的。 </p><p>下面是客户端的代码</p><pre><code class="c">#include &quot;lib/common.h&quot;# define    MAXLINE     4096int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: udpclient1 &lt;IPaddress&gt;&quot;);    }    // 创建一个 UDP 套接字；    int socket_fd;    socket_fd = socket(AF_INET, SOCK_DGRAM, 0);    // 创建了一个 IPv4 地址，绑定到指定端口和 IP    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_port = htons(SERV_PORT);    inet_pton(AF_INET, argv[1], &amp;server_addr.sin_addr);    socklen_t server_len = sizeof(server_addr);    // 调用 connect 将 UDP 套接字和 IPv4 地址进行了“绑定”    // 这里 connect 函数的名称有点让人误解，其实可能更好的选择是叫做 setpeername；    if (connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len)) {        error(1, errno, &quot;connect failed&quot;);    }    struct sockaddr *reply_addr;    reply_addr = malloc(server_len);    char send_line[MAXLINE], recv_line[MAXLINE + 1];    socklen_t len;    int n;    // 是程序的主体，读取标准输入字符串。    while (fgets(send_line, MAXLINE, stdin) != NULL) {        int i = strlen(send_line);        if (send_line[i - 1] == &#39;\n&#39;) {            send_line[i - 1] = 0;        }        printf(&quot;now sending %s\n&quot;, send_line);        // 调用 sendto 发送给对端        size_t rt = sendto(socket_fd, send_line, strlen(send_line), 0, (struct sockaddr *) &amp;server_addr, server_len);        if (rt &lt; 0) {            error(1, errno, &quot;sendto failed&quot;);        }        printf(&quot;send bytes: %zu \n&quot;, rt);        len = 0;        recv_line[0] = 0;        // 调用 recvfrom 等待对端的响应        n = recvfrom(socket_fd, recv_line, MAXLINE, 0, reply_addr, &amp;len);        if (n &lt; 0)            error(1, errno, &quot;recvfrom failed&quot;);        recv_line[n] = 0;        // 把对端响应信息打印到标准输出        fputs(recv_line, stdout);        fputs(&quot;\n&quot;, stdout);    }    exit(0);}</code></pre><h2 id="2-connect"><a href="#2-connect" class="headerlink" title="2. connect"></a>2. connect</h2><p>UDP的connect操作可以对 UDP 套接字调用 connect 函数，但是UDP connect 函数的调用，并不会引起和服务器目标端的网络交互，也就是说，并不会触发所谓的”握手“报文发送和应答。 </p><p>UDP的connect的主要功能是为了让应用程序能<strong>够接收”异步错误“的信息</strong>。 </p><p>对 UDP 套接字进行 connect 操作，将 UDP 套接字建立了”上下文“，该套接字和服务器端的地址和端口产生了联系，正是这种绑定关系给了操作系统内核必要的信息，能够将操作系统内核收到的信息和对应的套接字进行关联。 </p><p>当我们调用 sendto 或者 send 操作函数时，应用程序报文被发送，我们的应用程序返回，操作系统内核接管了该报文，之后操作系统开始尝试往对应的地址和端口发送，因为<strong>对应的地址和端口不可达，一个 ICMP 报文会返回给操作系统内核</strong>，该 ICMP 报文含有目的地址和端口等信息。 </p><p>如果不进行 connect 操作，建立（UDP 套接字——目的地址 + 端口）之间的映射关系，<strong>操作系统内核就没有办法把 ICMP 不可达的信息和 UDP 套接字进行关联，也就没有办法将 ICMP 信息通知给应用程序。</strong> </p><h3 id="2-1-服务器端-connect-的例子"><a href="#2-1-服务器端-connect-的例子" class="headerlink" title="2.1 服务器端 connect 的例子"></a>2.1 服务器端 connect 的例子</h3><p>一般来说，服务器端不会主动发起 connect 操作，因为一旦如此，服务器端就只能响应一个客户端了。不过，有时候也不排除这样的情形，一旦一个客户端和服务器端发送 UDP 报文之后，该服务器端就要服务于这个唯一的客户端。 </p><pre><code class="c">#include &quot;lib/common.h&quot;static int count;static void recvfrom_int(int signo) {    printf(&quot;\nreceived %d datagrams\n&quot;, count);    exit(0);}int main(int argc, char **argv) {    // 创建UDP套接字    int socket_fd;    socket_fd = socket(AF_INET, SOCK_DGRAM, 0);    // 创建 IPv4 地址，绑定到 ANY 和对应端口    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);    server_addr.sin_port = htons(SERV_PORT);    // 绑定 UDP 套接字和 IPv4 地址    bind(socket_fd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr));    socklen_t client_len;    char message[MAXLINE];    message[0] = 0;    count = 0;    // 为该程序注册一个信号处理函数，以响应 Ctrl+C 信号量操作；    // 该函数定义在main函数的前面    signal(SIGINT, recvfrom_int);    struct sockaddr_in client_addr;    client_len = sizeof(client_addr);    // 调用 recvfrom 等待客户端报文到达，并将客户端信息保持到 client_addr 中    int n = recvfrom(socket_fd, message, MAXLINE, 0, (struct sockaddr *) &amp;client_addr, &amp;client_len);    if (n &lt; 0) {        error(1, errno, &quot;recvfrom failed&quot;);    }    message[n] = 0;    printf(&quot;received %d bytes: %s\n&quot;, n, message);    // 调用 connect 操作，将 UDP 套接字和客户端 client_addr 进行绑定；    if (connect(socket_fd, (struct sockaddr *) &amp;client_addr, client_len)) {        error(1, errno, &quot;connect failed&quot;);    }    // 并持续不断地从客户端接收报文，直到客户端发送”goodbye“报文为止。    while (strncmp(message, &quot;goodbye&quot;, 7) != 0) {        // 加上”Hi“前缀后发送给客户端        char send_line[MAXLINE];        sprintf(send_line, &quot;Hi, %s&quot;, message);        size_t rt = send(socket_fd, send_line, strlen(send_line), 0);        if (rt &lt; 0) {            error(1, errno, &quot;send failed &quot;);        }        printf(&quot;send bytes: %zu \n&quot;, rt);        size_t rc = recv(socket_fd, message, MAXLINE, 0);        if (rc &lt; 0) {            error(1, errno, &quot;recv failed&quot;);        }        count++;    }    exit(0);}</code></pre><h3 id="2-2-客户端connect的例子"><a href="#2-2-客户端connect的例子" class="headerlink" title="2.2 客户端connect的例子"></a>2.2 客户端connect的例子</h3><pre><code class="c">#include &quot;lib/common.h&quot;# define    MAXLINE     4096int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: udpclient3 &lt;IPaddress&gt;&quot;);    }    // 创建了一个 UDP 套接字    int socket_fd;    socket_fd = socket(AF_INET, SOCK_DGRAM, 0);    // 创建了一个 IPv4 地址，绑定到指定端口和 IP    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_port = htons(SERV_PORT);    inet_pton(AF_INET, argv[1], &amp;server_addr.sin_addr);    // 调用 connect 将 UDP 套接字和 IPv4 地址进行了“绑定”    socklen_t server_len = sizeof(server_addr);    if (connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len)) {        error(1, errno, &quot;connect failed&quot;);    }    char send_line[MAXLINE], recv_line[MAXLINE + 1];    int n;    // 读取标准输入字符串    while (fgets(send_line, MAXLINE, stdin) != NULL) {        int i = strlen(send_line);        if (send_line[i - 1] == &#39;\n&#39;) {            send_line[i - 1] = 0;        }        // 调用 send 发送给对端        printf(&quot;now sending %s\n&quot;, send_line);        size_t rt = send(socket_fd, send_line, strlen(send_line), 0);        if (rt &lt; 0) {            error(1, errno, &quot;send failed &quot;);        }        printf(&quot;send bytes: %zu \n&quot;, rt);        // 调用 recv 等待对端的响应        recv_line[0] = 0;        n = recv(socket_fd, recv_line, MAXLINE, 0);        if (n &lt; 0)            error(1, errno, &quot;recv failed&quot;);        recv_line[n] = 0;        // 把对端响应信息打印到标准输出        fputs(recv_line, stdout);        fputs(&quot;\n&quot;, stdout);    }    exit(0);}</code></pre><h3 id="2-3-使用connect的好处"><a href="#2-3-使用connect的好处" class="headerlink" title="2.3 使用connect的好处"></a>2.3 使用connect的好处</h3><p>一般来说，客户端通过 connect 绑定服务端的地址和端口，对 UDP 而言，可以有一定程度的性能提升。 </p><p>如果不使用 connect 方式，每次发送报文都会需要这样的过程：</p><p>连接套接字→发送报文→断开套接字→连接套接字→发送报文→断开套接字 →………</p><p>而如果使用 connect 方式，就会变成下面这样：</p><p>连接套接字→发送报文→发送报文→……→最后断开套接字</p><p>连接套接字是需要一定开销的，比如需要查找路由表信息。所以，UDP 客户端程序通过 connect 可以获得一定的性能提升。 </p><h2 id="3-问题"><a href="#3-问题" class="headerlink" title="3. 问题"></a>3. 问题</h2><ol><li><p>可以对一个 UDP 套接字进行多次 connect 操作吗? </p><p>可以</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程9：TCP的异常</title>
      <link href="/2019/11/02/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B9TCP%E7%9A%84%E5%BC%82%E5%B8%B8/"/>
      <url>/2019/11/02/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B9TCP%E7%9A%84%E5%BC%82%E5%B8%B8/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><p>故障模式大概可以分为以下几种</p><p><img src="/2019/11/02/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B9TCP%E7%9A%84%E5%BC%82%E5%B8%B8/1572173098996.png" alt="1572173098996"></p><h2 id="1-对端无-FIN-包发送"><a href="#1-对端无-FIN-包发送" class="headerlink" title="1.  对端无 FIN 包发送"></a>1.  对端无 FIN 包发送</h2><h3 id="1-1-网络中断"><a href="#1-1-网络中断" class="headerlink" title="1.1  网络中断"></a>1.1  网络中断</h3><p>很多原因都会造成网络中断，在这种情况下，TCP 程序<strong>并不能及时感知到异常信息</strong>。除非网络中的其他设备，如路由器发出一条 ICMP 报文，说明目的网络或主机不可达，这个时候通过 read 或 write 调用就会返回 Unreachable 的错误。 </p><p>可惜大多数时候并不是如此，<strong>在没有 ICMP 报文的情况下，TCP 程序并不能理解感应到连接异常</strong>。如果程序是<strong>阻塞在 read 调用上</strong>，那么很不幸，程序无法从异常中恢复。 </p><p>如果程序先调用了 write 操作发送了一段数据流，接下来阻塞在 read 调用上，结果会非常不同。</p><p>Linux 系统的 TCP 协议栈会<strong>不断尝试将发送缓冲区的数据发送出去</strong>，大概在重传 12 次、合计时间约为 9 分钟之后，协议栈会标识该连接异常，这时，<strong>阻塞的 read 调用会返回一条 TIMEOUT 的错误信息</strong>。如果此时程序还往这条连接写数据，写操作会<strong>立即失败</strong>，返回一个 SIGPIPE 信号给应用程序。 </p><h3 id="1-2-系统崩溃"><a href="#1-2-系统崩溃" class="headerlink" title="1.2  系统崩溃"></a>1.2  系统崩溃</h3><p>当系统突然崩溃，如断电时，网络连接上来不及发出任何东西。这里和通过系统调用杀死应用程序非常不同的是，<strong>没有任何 FIN 包被发送出来</strong>。这种情况和网络中断造成的结果非常类似，<strong>在没有 ICMP 报文的情况下，TCP 程序只能通过 read 和 write 调用得到网络连接异常的信息，超时错误是一个常见的结果</strong>。 </p><p>不过还有一种情况需要考虑，那就是系统在<strong>崩溃之后又重启</strong>，当<strong>重传的 TCP 分组到达重启后的系统</strong>，由于系统中没有该 TCP 分组对应的连接数据，<strong>系统会返回一个 RST 重置分节</strong>，TCP 程序通过 read 或 write 调用可以分别对 RST 进行错误处理。 </p><ul><li>如果是阻塞的 read 调用，会立即返回一个错误，错误信息为连接重置（Connection Reset）</li><li>如果是一次 write 操作，也会立即失败，应用程序会被返回一个 SIGPIPE 信号。 </li></ul><h2 id="2-对端有FIN包发送"><a href="#2-对端有FIN包发送" class="headerlink" title="2. 对端有FIN包发送"></a>2. 对端有FIN包发送</h2><p>对端如果有 FIN 包发出，可能的场景是：</p><ul><li>对端调用了 close 或 shutdown 显式地关闭了连接</li><li>对端应用程序崩溃，操作系统内核代为清理所发出的</li></ul><p>总之，在客户端，是无法区分是哪种情形的。 </p><h3 id="2-1-read-直接感知-FIN-包"><a href="#2-1-read-直接感知-FIN-包" class="headerlink" title="2.1  read 直接感知 FIN 包"></a>2.1  read 直接感知 FIN 包</h3><h3 id="2-2-没有read"><a href="#2-2-没有read" class="headerlink" title="2.2  没有read"></a>2.2  没有read</h3>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程8：TCP数据传输</title>
      <link href="/2019/11/01/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B8TCP%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/"/>
      <url>/2019/11/01/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B8TCP%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><h2 id="1-TCP的动态数据传输"><a href="#1-TCP的动态数据传输" class="headerlink" title="1. TCP的动态数据传输"></a>1. TCP的动态数据传输</h2><p>socket编程 write 或者 send 方法来进行数据流的发送，但是调用这些接口并不意味着数据被真正发送到网络上，其实，这些数据只是<strong>从应用程序中被拷贝到了系统内核的套接字缓冲区中</strong>（发送缓冲区），等待协议栈的处理。至于这些数据是什么时候被发送出去的，对应用程序来说，是无法预知的。对这件事情真正负责的，是运行于操作系统<strong>内核的 TCP 协议栈</strong>实现模块。 </p><h3 id="1-1-流量控制和生产者-消费者模型"><a href="#1-1-流量控制和生产者-消费者模型" class="headerlink" title="1.1 流量控制和生产者-消费者模型"></a>1.1 流量控制和生产者-消费者模型</h3><p>TCP的发送窗口和接收窗口模型，叫做“TCP 的生产者 - 消费者”模型。</p><p>发送窗口和接收窗口是 TCP 连接的双方，一个作为生产者，一个作为消费者，为了达到一致协同的生产 - 消费速率、而产生的算法模型实现。</p><p>作为 TCP 发送端，也就是生产者，不能忽略 TCP 的接收端，也就是消费者的实际状况，不管不顾地把数据包都传送过来。如果都传送过来，消费者来不及消费，必然会丢弃，这又反过使得生产者又重传，发送更多的数据包，最后导致网络崩溃。 </p><h3 id="1-2-拥塞控制和数据传输"><a href="#1-2-拥塞控制和数据传输" class="headerlink" title="1.2 拥塞控制和数据传输"></a>1.2 拥塞控制和数据传输</h3><p> TCP 的生产者 - 消费者模型，只是在考虑<strong>单个连接</strong>的数据传递，但是， TCP 数据包是需要经过网卡、交换机、核心路由器等一系列的网络设备的，网络设备本身的能力也是有限的，当多个连接的数据包同时在网络上传送时，势必会发生带宽争抢、数据丢失等，这样，TCP 就必须<strong>考虑多个连接共享在有限的带宽上，兼顾效率和公平性的控制</strong>，这就是拥塞控制的本质。 </p><p>在 TCP 协议中，<strong>拥塞控制</strong>是通过<strong>拥塞窗口</strong>来完成的，拥塞窗口的大小会随着网络状况实时调整。</p><p>拥塞控制常用的算法有“<strong>慢启动</strong>”，它通过一定的规则，慢慢地将网络发送数据的速率增加到一个阈值。超过这个阈值之后，慢启动就结束了，另一个叫做“拥塞避免”的算法登场。在这个阶段，TCP 会不断地探测网络状况，并随之不断调整拥塞窗口的大小。 </p><p>在任何一个时刻，TCP 发送缓冲区的数据是否能真正发送出去，至少取决于两个因素，</p><ul><li><strong>发送窗口大小</strong>： 反映了作为单 TCP 连接、点对点之间的流量控制模型，与接收端共同协调来调整</li><li><strong>拥塞窗口大小</strong>：反映了作为多个 TCP 连接共享带宽的拥塞控制模型，是发送端独立地根据网络状况来动态调整的。 </li></ul><p>而 TCP 协议中总是<strong>取两者中最小值作为判断依据</strong>。比如当前发送的字节为 100，发送窗口的大小是 200，拥塞窗口的大小是 80，那么取 200 和 80 中的最小值，就是 80，当前发送的字节数显然是大于拥塞窗口的，结论就是不能发送出去。 </p><h3 id="1-3-优化"><a href="#1-3-优化" class="headerlink" title="1.3 优化"></a>1.3 优化</h3><ol><li><p><strong>接收方根据自身情况动态调整发送窗口的大小</strong></p><p>接收方不能在自己的缓存刚有一点空闲就要求发送方发送数据，而是需要在自己的缓冲区达到一定值的时候才能继续请求发送方发送</p></li><li><p><strong>限制大批量小数据包同时发送（Nagle算法）</strong></p><p>在任何一个时刻，未被确认的小数据包不能超过一个。这里的小数据包，指的是长度小于最大报文段长度 MSS 的 TCP 分组。这样，发送端就可以把接下来连续的几个小数据包存储起来，等待接收到前一个小数据包的 ACK 分组之后，再将数据一次性发送出去。 </p></li><li><p><strong>延时ACK</strong>：</p><p>在<strong>接收端</strong>进行优化，在收到数据后并不马上回复，而是<strong>累计需要发送的 ACK 报文</strong>，等到有数据需要发送给对端时，将累计的 ACK捎带一并发送出去。当然，延时 ACK 机制，不能无限地延时下去，否则发送端误认为数据包没有发送成功，引起重传，反而会占用额外的网络带宽。 </p></li></ol><h3 id="1-4-Nagle-延时ACK"><a href="#1-4-Nagle-延时ACK" class="headerlink" title="1.4 Nagle + 延时ACK"></a>1.4 Nagle + 延时ACK</h3><p>将这两种方法同时使用可能会出现一些问题。比如，客户端分两次将一个请求发送出去。</p><ul><li>请求的第一部分报文未被确认，Nagle 算法开始起作用，将第二部分阻塞。</li><li>同时延时 ACK 在服务器端起作用，假设延时时间为 200ms，服务器等待 200ms 后，对请求的第一部分进行确认，发送ACK；</li><li>客户端收到了ACK后，Nagle 算法解除请求第二部分的阻止，让第二部分得以发送出去，服务器端在收到之后，进行处理应答，同时将第二部分的确认捎带发送出去。</li></ul><p><img src="/2019/11/01/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B8TCP%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/1572162138470.png" alt="1572162138470"></p><p> Nagle 算法和延时确认组合在一起，增大了处理时延，实际上，两个优化彼此在阻止对方。从上面的例子可以看到，在有些情况下 Nagle 算法并不适用， 比如对时延敏感的应用。 </p><p><strong>解决方法</strong>：</p><p><strong>1. 禁用Nagle</strong></p><pre><code class="c">int on = 1; setsockopt(sock, IPPROTO_TCP, TCP_NODELAY, (void *)&amp;on, sizeof(on));</code></pre><p>除非我们对此有十足的把握，否则不要轻易改变默认的 TCP Nagle 算法。因为在现代操作系统中，针对 Nagle 算法和延时 ACK 的优化已经非常成熟了，有可能在禁用 Nagle 算法之后，性能问题反而更加严重。 </p><p> <strong>2. 将写操作合并</strong></p><p>在写数据之前，将数据合并到缓冲区，批量发送出去，这是一个比较好的做法。</p><p>不过，有时候<strong>数据会存储在两个不同的缓存中</strong>，对此，我们可以使用如下的方法来进行数据的读写操作，从而避免 Nagle 算法引发的副作用。 </p><pre><code class="c">ssize_t writev(int filedes, const struct iovec *iov, int iovcnt)ssize_t readv(int filedes, const struct iovec *iov, int iovcnt);</code></pre><p>第二个参数都是指向某个 iovec 结构数组的一个指针，其中 iovec 结构定义如下： </p><pre><code class="c">struct iovec {    void *iov_base; /* starting address of buffer */    size_t　iov_len; /* size of buffer */};</code></pre><p>下面是具体的使用方法</p><pre><code class="c">int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: tcpclient &lt;IPaddress&gt;&quot;);    }    int socket_fd;    socket_fd = socket(AF_INET, SOCK_STREAM, 0);    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_port = htons(SERV_PORT);    inet_pton(AF_INET, argv[1], &amp;server_addr.sin_addr);    socklen_t server_len = sizeof(server_addr);    int connect_rt = connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len);    if (connect_rt &lt; 0) {        error(1, errno, &quot;connect failed &quot;);    }    char buf[128];    struct iovec iov[2];    // 使用了 iovec 数组，分别写入了两个不同的字符串，一个是“hello,”，另一个通过标准输入读入。    char *send_one = &quot;hello,&quot;;    iov[0].iov_base = send_one;    iov[0].iov_len = strlen(send_one);    iov[1].iov_base = buf;    while (fgets(buf, sizeof(buf), stdin) != NULL) {        iov[1].iov_len = strlen(buf);        int n = htonl(iov[1].iov_len);        if (writev(socket_fd, iov, 2) &lt; 0)            error(1, errno, &quot;writev failure&quot;);    }    exit(0);}</code></pre><h3 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h3><ul><li><strong>发送窗口</strong>用来控制发送和接收端的流量；<strong>阻塞窗口</strong>用来控制多条连接公平使用的有限带宽。</li><li>小数据包加剧了网络带宽的浪费，为了解决这个问题，引入了如 Nagle 算法、延时 ACK 等机制。</li><li>在程序设计层面，不要多次频繁地发送小报文，如果有，可以使用 writev 批量发送。 </li></ul><h2 id="2-TCP数据流"><a href="#2-TCP数据流" class="headerlink" title="2. TCP数据流"></a>2. TCP数据流</h2><h3 id="2-1-TCP-是一种流式协议"><a href="#2-1-TCP-是一种流式协议" class="headerlink" title="2.1 TCP 是一种流式协议"></a>2.1 TCP 是一种流式协议</h3><p>在发送端，调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中，至于什么时候真正被发送，取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件。</p><p>也就是说，<strong>不能假设</strong>每次 send 调用发送的数据，都会<strong>作为一个整体完整地被发送出去</strong>。如果我们考虑实际网络传输过程中的各种影响，假设发送端陆续调用 send 函数先后发送 network 和 program 报文，那么实际的发送很有可能是这个样子的。 </p><ol><li><p>一次性将 network 和 program 在一个 TCP 分组中发送出去 </p><pre><code>...xxxnetworkprogramxxx...</code></pre></li><li><p>program 的部分随 network 在一个 TCP 分组中发送出去 </p><pre><code>TCP组1：...xxxxxnetworkproTCP组2：gramxxxxxxxxxx...</code></pre></li></ol><ol start="3"><li><p>network 的一部分随 TCP 分组被发送出去，另一部分和 program 一起随另一个 TCP 分组发送出去 </p><pre><code>TCP组1：...xxxxxxxxxxxnetTCP组2：workprogramxxx...</code></pre></li></ol><p>也就是说，我们在发送数据的时候，不应该假设“数据流和 TCP 分组是一种映射关系”。 每次发送的数据不一定在同一个分组中。</p><p>我们知道，<strong>接收端缓冲区</strong>保留了没有被取走的数据，随着应用程序不断从接收端缓冲区读出数据，接收端缓冲区就可以容纳更多新的数据。如果我们使用 recv 从接收端缓冲区读取数据，发送端缓冲区的数据是以字节流的方式存在的，无论发送端如何构造 TCP 分组，接收端最终受到的字节流总是像下面这样： </p><pre><code>xxxxxxxxxxxxxxxxxnetworkprogramxxxxxxxxxxxx</code></pre><ol><li>第一，这里 netwrok 和 program 的顺序肯定是会保持的，也就是说，<strong>先调用 send 函数发送的字节，总在后调用 send 函数发送字节的前面</strong>，这个是由 TCP 严格保证的；</li><li>第二，发送过程中<strong>如果有 TCP 分组丢失</strong>，但是其后续分组陆续到达，那么 TCP 协议栈会<strong>缓存后续分组，直到前面丢失的分组到达，</strong>最终，形成可以被应用程序读取的数据流。 </li></ol><h3 id="2-2-网络字节排序"><a href="#2-2-网络字节排序" class="headerlink" title="2.2 网络字节排序"></a>2.2 网络字节排序</h3><p>这里有一个有趣的问题，如果需要传输数字，比如 0x0201，对应的二进制为 00000010000000001，那么两个字节的数据到底是先传 0x01，还是相反？ </p><p> 不同的系统就会有两种存法</p><ul><li>将 0x02 高字节存放在起始地址，这个叫做大端字节序（Big-Endian）</li><li>将 0x01 低字节存放在起始地址，这个叫做小端字节序（Little-Endian）</li></ul><p><img src="/2019/11/01/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B8TCP%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/1572170918169.png" alt="1572170918169"></p><p>在网络传输中，<strong>必须保证双方都用同一种标准来表达</strong>。这个标准就涉及到了网络字节序的选择问题，对于网络字节序，必须二选一。可以看到<strong>网络协议使用的是大端字节序</strong>。 </p><p>为了保证网络字节序一致，POSIX 标准提供了如下的转换函数： </p><pre><code class="c">uint16_t htons (uint16_t hostshort);uint16_t ntohs (uint16_t netshort);uint32_t htonl (uint32_t hostlong);uint32_t ntohl (uint32_t netlong);</code></pre><ul><li><p>n 代表的就是 network</p></li><li><p>h 代表的是 host</p></li><li><p>s 表示的是 short，表示 16 位整数</p></li><li><p>l 表示的是 long，表示 32 位整数 </p></li></ul><h3 id="2-3-报文读取和解析"><a href="#2-3-报文读取和解析" class="headerlink" title="2.3 报文读取和解析"></a>2.3 报文读取和解析</h3><p>报文是以字节流的形式呈现给应用程序的，因此需要进行特定的读取和解析操作。实际上，要完成这两种操作，需要知道两个信息：报文格式、报文长度。</p><p>获取报文格式有两种方法，</p><ul><li><strong>方法1</strong>：发送端把要发送的报文长度预先通过报文告知给接收端</li><li><strong>方法2</strong>：通过一些特殊的字符来进行边界的划分。 </li></ul><p>下面分别对这两种方式进行解释</p><h4 id="2-3-1-显式传递报文长度"><a href="#2-3-1-显式传递报文长度" class="headerlink" title="2.3.1 显式传递报文长度"></a>2.3.1 显式传递报文长度</h4><p>显式编码报文长度</p><p><img src="/2019/11/01/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B8TCP%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/1572171535580.png" alt="1572171535580"></p><p>这个报文的格式很简单，首先 4 个字节大小的<strong>消息长度</strong>，其目的是将真正发送的字节流的大小显式通过报文告知接收端，接下来是 4 个字节大小的消息类型，而真正需要发送的数据则紧随其后。 </p><p><strong>客户端发送报文</strong></p><p>客户端发送报文的代码如下：</p><pre><code class="c">int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: tcpclient &lt;IPaddress&gt;&quot;);    }    int socket_fd;    socket_fd = socket(AF_INET, SOCK_STREAM, 0);    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_port = htons(SERV_PORT);    inet_pton(AF_INET, argv[1], &amp;server_addr.sin_addr);    socklen_t server_len = sizeof(server_addr);    int connect_rt = connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len);    if (connect_rt &lt; 0) {        error(1, errno, &quot;connect failed &quot;);    }    // 将前面提到的报文格式转化为结构体描述    struct {        u_int32_t message_length;        u_int32_t message_type;        char buf[128];    } message;    int n;    // 从标准输入读入数据    while (fgets(message.buf, sizeof(message.buf), stdin) != NULL) {        // 对消息长度、类型进行了初始化        n = strlen(message.buf);        // 这里使用了 htonl 函数将字节大小转化为了网络字节顺序        message.message_length = htonl(n);        message.message_type = 1;        if (send(socket_fd, (char *) &amp;message, sizeof(message.message_length) + sizeof(message.message_type) + n, 0) &lt;            0)            error(1, errno, &quot;send failure&quot;);    }    exit(0);}</code></pre><p><strong>服务器端解析报文</strong></p><pre><code class="c">static int count;static void sig_int(int signo) {    printf(&quot;\nreceived %d datagrams\n&quot;, count);    exit(0);}int main(int argc, char **argv) {    int listenfd;    listenfd = socket(AF_INET, SOCK_STREAM, 0);    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);    server_addr.sin_port = htons(SERV_PORT);    int on = 1;    setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on));    int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr));    if (rt1 &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    int rt2 = listen(listenfd, LISTENQ);    if (rt2 &lt; 0) {        error(1, errno, &quot;listen failed &quot;);    }    signal(SIGPIPE, SIG_IGN);    int connfd;    struct sockaddr_in client_addr;    socklen_t client_len = sizeof(client_addr);    if ((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    char buf[128];    count = 0;    while (1) {        // 调用 read_message 函数进行报文解析工作，并把报文的主体通过标准输出打印出来。        int n = read_message(connfd, buf, sizeof(buf));        if (n &lt; 0) {            error(1, errno, &quot;error read message&quot;);        } else if (n == 0) {            error(1, 0, &quot;client closed \n&quot;);        }        buf[n] = 0;        printf(&quot;received %d bytes: %s\n&quot;, n, buf);        count++;    }    exit(0);}</code></pre><p>可以看到，上面服务器使用read_message函数进行报文的读取与解析，这里针对read_message函数进行解释，但是在说这个函数之前，先看一下readn函数。</p><p><strong>readn函数</strong>：</p><p>读取报文预设大小的字节，readn 调用会一直循环，尝试读取预设大小的字节，如果接收缓冲区数据空，readn 函数会阻塞在那里，直到有数据到达。 </p><pre><code class="c">size_t readn(int fd, void *buffer, size_t length) {    // 使用 count 来表示还需要读取的字符数    size_t count;    ssize_t nread;    char *ptr;    ptr = buffer;    count = length;    // 如果 count 一直大于 0，说明还没有满足预设的字符大小，循环就会继续。    while (count &gt; 0) {        nread = read(fd, ptr, count);        if (nread &lt; 0) {            if (errno == EINTR)                continue;            else                return (-1);        }         // 返回值为 0 的情形是 EOF，表示对方连接终止        else if (nread == 0)            break;                /* EOF */        // 读取的字符数减去这次读到的字符数，同时移动缓冲区指针        count -= nread;        ptr += nread;    }    return (length - count);        /* return &gt;= 0 */}</code></pre><p><strong>read_message函数</strong></p><pre><code class="c">size_t read_message(int fd, char *buffer, size_t length) {    u_int32_t msg_length;    u_int32_t msg_type;    int rc;    // 通过调用 readn 函数获取 4 个字节的消息长度数据    rc = readn(fd, (char *) &amp;msg_length, sizeof(u_int32_t));    if (rc != sizeof(u_int32_t))        return rc &lt; 0 ? -1 : 0;    msg_length = ntohl(msg_length);    // 通过调用 readn 函数获取 4 个字节的消息类型数据    rc = readn(fd, (char *) &amp;msg_type, sizeof(msg_type));    if (rc != sizeof(u_int32_t))        return rc &lt; 0 ? -1 : 0;    // 判断消息的长度是不是太大，如果大到本地缓冲区不能容纳，则直接返回错误    if (msg_length &gt; length) {        return -1;    }    // 调用 readn 一次性读取已知长度的消息体    rc = readn(fd, buffer, msg_length);    if (rc != msg_length)        return rc &lt; 0 ? -1 : 0;    return rc;}</code></pre><h4 id="2-3-2-特殊字符作边界确定报文长度"><a href="#2-3-2-特殊字符作边界确定报文长度" class="headerlink" title="2.3.2  特殊字符作边界确定报文长度"></a>2.3.2  特殊字符作边界确定报文长度</h4><p><img src="/2019/11/01/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B8TCP%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/1572172465307.png" alt="1572172465307"></p><p>上面是HTTP的例子，HTTP 通过设置<strong>回车符</strong>、<strong>换行符</strong>做为 HTTP 报文协议的边界。 </p><p>下面的 read_line 函数就是在尝试读取一行数据，也就是读到回车符\r，或者读到回车换行符\r\n为止。这个函数每次尝试读取一个字节。</p><pre><code class="c">int read_line(int fd, char *buf, int size) {    int i = 0;    char c = &#39;\0&#39;;    int n;    while ((i &lt; size - 1) &amp;&amp; (c != &#39;\n&#39;)) {        n = recv(fd, &amp;c, 1, 0);        if (n &gt; 0) {            // 读到了回车符\r            if (c == &#39;\r&#39;) {                // 看有没有换行符                n = recv(fd, &amp;c, 1, MSG_PEEK);                if ((n &gt; 0) &amp;&amp; (c == &#39;\n&#39;))                    // 读取这个换行符                    recv(fd, &amp;c, 1, 0);                else                    c = &#39;\n&#39;;            }            // 将字符放到缓冲区，并移动指针            buf[i] = c;            i++;        } else            c = &#39;\n&#39;;    }    buf[i] = &#39;\0&#39;;    return (i);}</code></pre><h3 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h3><p> TCP 数据流特性决定了<strong>字节流本身是没有边界的</strong>，一般我们通过显式编码报文长度的方式，以及选取特殊字符区分报文边界的方式来进行报文格式的设计。而对报文解析的工作就是要在知道报文格式的情况下，有效地对报文信息进行还原。 </p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程7：TCP连接状态</title>
      <link href="/2019/10/31/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B7TCP%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81/"/>
      <url>/2019/10/31/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B7TCP%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><h2 id="1-检测TCP的连接状态"><a href="#1-检测TCP的连接状态" class="headerlink" title="1. 检测TCP的连接状态"></a>1. 检测TCP的连接状态</h2><h3 id="1-1-TCP-Keep-Alive-选项"><a href="#1-1-TCP-Keep-Alive-选项" class="headerlink" title="1.1  TCP Keep-Alive 选项"></a>1.1  TCP Keep-Alive 选项</h3><p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，<strong>TCP 保活机制</strong>会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。 </p><p>上述的可定义变量，分别被称为保活时间、保活时间间隔和保活探测次数。在 Linux 系统中，这些变量分别对应 sysctl 变量：</p><ul><li>net.ipv4.tcp_keepalive_time：保活时间，默认7200秒（2小时）</li><li>net.ipv4.tcp_keepalive_intvl：保活时间间隔，默认75秒</li><li>net.ipv4.tcp_keepalve_probes：保活探测次数，默认9次探测</li></ul><p>如果开启了TCP保活机制，则需要根据对端程序的不同状态确定不同的操作，对端程序一般有以下三种不同的状态：</p><ol><li><p><strong>正常工作</strong></p><p>当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。 </p></li><li><p><strong>崩溃并重启</strong></p><p>当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。 </p></li><li><p><strong>程序崩溃，或由于其他原因导致报文不可达</strong></p><p>当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。 </p></li></ol><p>TCP 保活机制默认是关闭的，当我们选择打开时，可以分别在连接的两个方向上开启，也可以单独在一个方向上开启。</p><ul><li>开启服务器端到客户端的检测，可以在客户端非正常断连的情况下清除在服务器端保留的“脏数据”；</li><li>开启客户端到服务器端的检测，可以在服务器无响应的情况下，重新发起连接。 </li></ul><h3 id="1-2-应用层“探活”"><a href="#1-2-应用层“探活”" class="headerlink" title="1.2 应用层“探活”"></a>1.2 应用层“探活”</h3><p>如果使用 TCP 自身的 keep-Alive 机制，在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个“死亡”连接，2 小时+75 秒×9 。</p><p>实际上，对很多对时延要求敏感的系统中，这个时间间隔是不可接受的。 因此可以在应用层的程序中通过定时器 + PING-PONG机制来实现应用层“探活”。</p><p><strong>1. 定时器</strong></p><p>可以通过系统IO复用自身的机制实现</p><p><strong>2. PING-PONG机制</strong> </p><p>需要保活的一方，比如客户端，在保活时间达到后，发起对连接的 PING 操作，如果服务器端对 PING 操作有回应，则重新设置保活时间，否则对探测次数进行计数，如果最终探测次数达到了保活探测次数预先设置的值之后，则认为连接已经无效。 </p><h3 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h3><p>虽然 TCP 没有提供系统的保活能力，让应用程序可以方便地感知连接的存活，但是，可以在应用程序里灵活地建立这种机制。</p><p>一般来说，这种机制的建立依赖于系统定时器，以及恰当的应用层报文协议。比如，使用<strong>心跳包</strong>就是这样一种保持 Keep Alive 的机制。 </p><h2 id="A-附录"><a href="#A-附录" class="headerlink" title="A. 附录"></a>A. 附录</h2><h3 id="A-1-代码实现一个应用层探活"><a href="#A-1-代码实现一个应用层探活" class="headerlink" title="A.1 代码实现一个应用层探活"></a>A.1 代码实现一个应用层探活</h3><p><strong>1. 消息格式的设置</strong></p><pre><code class="c">typedef struct {    u_int32_t type;    char data[1024];} messageObject;#define MSG_PING          1#define MSG_PONG          2#define MSG_TYPE1        11#define MSG_TYPE2        21</code></pre><p> 这里设计了MSG_PING、MSG_PONG、MSG_TYPE 1和MSG_TYPE 2四种消息类型 </p><p><strong>2. 客户端代码</strong></p><pre><code class="c">#include &quot;lib/common.h&quot;#include &quot;message_objecte.h&quot;#define    MAXLINE     4096#define    KEEP_ALIVE_TIME  10#define    KEEP_ALIVE_INTERVAL  3#define    KEEP_ALIVE_PROBETIMES  3int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: tcpclient &lt;IPaddress&gt;&quot;);    }    // 创建socket    int socket_fd;    socket_fd = socket(AF_INET, SOCK_STREAM, 0);    // 创建了IPv4目标地址，其实就是服务器端地址，注意这里使用的是传入参数作为服务器地址    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_port = htons(SERV_PORT);    inet_pton(AF_INET, argv[1], &amp;server_addr.sin_addr);    // 向服务器端发起连接    socklen_t server_len = sizeof(server_addr);    int connect_rt = connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len);    if (connect_rt &lt; 0) {        error(1, errno, &quot;connect failed &quot;);    }    char recv_line[MAXLINE + 1];    int n;    fd_set readmask;    fd_set allreads;    struct timeval tv;    int heartbeats = 0;    // 设置保活时间为KEEP_ALIVE_TIME    tv.tv_sec = KEEP_ALIVE_TIME;    tv.tv_usec = 0;    // 初始化 select 函数的套接字    messageObject messageObject;    FD_ZERO(&amp;allreads);    FD_SET(socket_fd, &amp;allreads);    for (;;) {        readmask = allreads;        // 调用 select 函数，感知 I/O 事件        // 这里的 I/O 事件除了套接字上的读操作之外，还有在KEEP_ALIVE_TIME设置的超时事件        // 当 KEEP_ALIVE_TIME 这段时间到达之后，select 函数会返回 0，即rc=0        int rc = select(socket_fd + 1, &amp;readmask, NULL, NULL, &amp;tv);        if (rc &lt; 0) {            error(1, errno, &quot;select failed&quot;);        }        if (rc == 0) {            if (++heartbeats &gt; KEEP_ALIVE_PROBETIMES) {                error(1, 0, &quot;connection dead\n&quot;);            }            printf(&quot;sending heartbeat #%d\n&quot;, heartbeats);            // 通过传送一个类型为 MSG_PING 的消息对象来完成 PING 操作            messageObject.type = htonl(MSG_PING);            rc = send(socket_fd, (char *) &amp;messageObject, sizeof(messageObject), 0);            // 判断发送是否成功            if (rc &lt; 0) {                error(1, errno, &quot;send failure&quot;);            }            tv.tv_sec = KEEP_ALIVE_INTERVAL;            continue;        }        // 客户端在接收到服务器端程序之后的处理        if (FD_ISSET(socket_fd, &amp;readmask)) {            n = read(socket_fd, recv_line, MAXLINE);            // 读取数据失败            if (n &lt; 0) {                error(1, errno, &quot;read error&quot;);            }             // 读取数据成功            else if (n == 0) {                // 这里其实是需要对报文进行解析后处理的                // 只有是 PONG 类型的回应，我们才认为是 PING 探活的结果。                error(1, 0, &quot;server terminated \n&quot;);            }            // 走到这里说明收到了服务器端的报文，那么连接就是正常的。            printf(&quot;received heartbeat, make heartbeats to 0 \n&quot;);            // 对探活计数器和探活时间都置零，等待下一次探活时间的来临。            heartbeats = 0;            tv.tv_sec = KEEP_ALIVE_TIME;        }    }}</code></pre><p><strong>3. 服务器端代码</strong></p><p>服务器端的程序接受一个参数，这个参数设置的比较大，可以模拟连接没有响应的情况。服务器端程序在接收到客户端发送来的各种消息后，进行处理，其中如果发现是 PING 类型的消息，在休眠一段时间后回复一个 PONG 消息，告诉客户端：”嗯，我还活着。“当然，如果这个休眠时间很长的话，那么客户端就无法快速知道服务器端是否存活，这是我们模拟连接无响应的一个手段而已，实际情况下，应该是系统崩溃，或者网络异常。 </p><pre><code class="c">#include &quot;lib/common.h&quot;#include &quot;message_objecte.h&quot;static int count;int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: tcpsever &lt;sleepingtime&gt;&quot;);    }    int sleepingTime = atoi(argv[1]);    // 创建套接字    int listenfd;    listenfd = socket(AF_INET, SOCK_STREAM, 0);    // 绑定该套接字到本地端口和 ANY 地址上    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);    server_addr.sin_port = htons(SERV_PORT);    // 分别调用 listen 和 accept 完成被动套接字转换和监听。    int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr));    if (rt1 &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    int rt2 = listen(listenfd, LISTENQ);    if (rt2 &lt; 0) {        error(1, errno, &quot;listen failed &quot;);    }    int connfd;    struct sockaddr_in client_addr;    socklen_t client_len = sizeof(client_addr);    if ((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    messageObject message;    count = 0;    for (;;) {        // 从建立的连接套接字上读取数据，解析报文        int n = read(connfd, (char *) &amp;message, sizeof(messageObject));        if (n &lt; 0) {            error(1, errno, &quot;error read&quot;);        } else if (n == 0) {            error(1, 0, &quot;client closed \n&quot;);        }        printf(&quot;received %d bytes\n&quot;, n);        count++;        // 根据消息类型进行不同的处理        switch (ntohl(message.type)) {            case MSG_TYPE1 :                printf(&quot;process  MSG_TYPE1 \n&quot;);                break;            case MSG_TYPE2 :                printf(&quot;process  MSG_TYPE2 \n&quot;);                break;            // 收到PING类型的消息的处理方法            case MSG_PING: {                messageObject pong_message;                pong_message.type = MSG_PONG;                sleep(sleepingTime);                // 调用 send 函数发送一个 PONG 报文，向客户端表示”还活着“的意思                ssize_t rc = send(connfd, (char *) &amp;pong_message, sizeof(pong_message), 0);                if (rc &lt; 0)                    error(1, errno, &quot;send failure&quot;);                break;            }            default :                error(1, 0, &quot;unknown message type (%d)\n&quot;, ntohl(message.type));        }    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程6：关闭连接</title>
      <link href="/2019/10/30/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B6%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/"/>
      <url>/2019/10/30/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B6%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><h2 id="1-四次挥手"><a href="#1-四次挥手" class="headerlink" title="1. 四次挥手"></a>1. 四次挥手</h2><p><img src="/2019/10/30/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B6%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/1572081082791.png" alt="1572081082791"></p><p>CLOSED：无连接是活动的或正在进行</p><p>FIN_WAIT1：应用说它已经完成</p><p>FIN_WAIT2：另一边已同意释放</p><p>ITMED_WAIT：等待所有分组死掉</p><p>CLOSING：两边同时尝试关闭</p><p>TIME_WAIT：另一边已初始化一个释放</p><p>LAST_ACK：等待所有分组死掉</p><p><strong>流程描述</strong>：</p><ol><li><p>主机 1 先发送 FIN 报文，并且进入FIN_WAIT_1状态</p></li><li><p>主机 2 接收到这个状态后进入 CLOSE_WAIT 状态，并发送一个 ACK 应答</p></li><li><p>同时，主机 2 通过 read 调用获得 EOF，并将此结果通知应用程序进行主动关闭操作，发送 FIN 报文。</p></li><li><p>主机 1 在接收到 FIN 报文后发送 ACK 应答，此时主机 1 进入 TIME_WAIT 状态。 </p></li></ol><h2 id="2-TIME-WAIT"><a href="#2-TIME-WAIT" class="headerlink" title="2. TIME_WAIT"></a>2. TIME_WAIT</h2><blockquote><p>让我们先从一例线上故障说起。在一次升级线上应用服务之后，我们发现该服务的可用性变得时好时坏，一段时间可以对外提供服务，一段时间突然又不可以，大家都百思不得其解。运维同学登录到服务所在的主机上，使用 netstat 命令查看后才发现，主机上有成千上万处于 TIME_WAIT 状态的连接。 </p><p><strong>每个连接会占用一个本地端口</strong>，当在高并发的情况下，TIME_WAIT 状态的连接多到把<strong>本机可用的端口耗尽</strong>，应用服务对外表现的症状，就是不能正常工作了。当过了一段时间之后，处于 TIME_WAIT 的连接被系统回收并关闭后，释放出本地端口可供使用，应用服务对外表现为，可以正常工作。这样周而复始，便会出现了一会儿不可以，过一两分钟又可以正常工作的现象。 </p></blockquote><h3 id="2-1-TIME-WAIT的时间"><a href="#2-1-TIME-WAIT的时间" class="headerlink" title="2.1 TIME_WAIT的时间"></a>2.1 TIME_WAIT的时间</h3><p>主机 1 <strong>在 TIME_WAIT 停留持续时间是固定的</strong>，是最长分节生命期 MSL（maximum segment lifetime）的两倍，一般称之为 2MSL。和大多数 BSD 派生的系统一样，Linux 系统里有一个硬编码的字段，名称为TCP_TIMEWAIT_LEN，其值为 60 秒。<strong>也就是说，Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。</strong> </p><p>过了这个时间之后，主机 1 就进入 CLOSED 状态。一定要记住一点，<strong>只有发起连接终止的一方会进入 TIME_WAIT 状态</strong>。 </p><h3 id="2-2-TIME-WAIT的作用"><a href="#2-2-TIME-WAIT的作用" class="headerlink" title="2.2 TIME_WAIT的作用"></a>2.2 TIME_WAIT的作用</h3><p><img src="/2019/10/30/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B6%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/1572081893007.png" alt="1572081893007"></p><p>为什么不直接进入 CLOSED 状态，而要停留在 TIME_WAIT 这个状态？ </p><ol><li><p>首先，这样做是为了<strong>确保最后的 ACK 能让被动关闭方接收</strong>，从而帮助其正常关闭。</p><p>TCP 在设计的时候，做了充分的容错性设计，比如，TCP 假设报文会出错，需要重传。</p><p><strong>如果图中主机 1 的 ACK 报文没有传输成功，那么主机 2 就会重新发送 FIN 报文。</strong>如果主机 1 没有维护 TIME_WAIT 状态，而直接进入 CLOSED 状态，它就失去了当前状态的上下文，只能回复一个 RST 操作，从而导致被动关闭方出现错误。</p><p>现在主机 1 知道自己处于 TIME_WAIT 的状态，就可以在接收到 FIN 报文之后，重新发出一个 ACK 报文，使得主机 2 可以进入正常的 CLOSED 状态。 </p></li><li><p>与<strong>连接“化身”</strong>和<strong>报文迷走</strong>有关系，为了让旧连接的重复分节在网络中自然消失。 </p><p>在网络中，经常会发生报文经过一段时间才能到达目的地的情况（称为迷走）。如果迷走报文到达时，发现 TCP 连接四元组（源 IP，源端口，目的 IP，目的端口）所代表的连接不复存在，那么很简单，这个报文自然丢弃。 </p><p>但是，如果在原连接中断后，又产生和一个原先的连接四元组完全相同的新连接（连接“化身”），如果迷失报文经过一段时间到达了这个端口，那么这个报文会被误认为是的新连接一个 TCP 分节，这样就会对 TCP 通信产生影响。 </p></li></ol><p>所以，TCP 就设计出了这么一个机制，经过 2MSL 这个时间，<strong>足以让两个方向上的分组都被丢弃，使得原来连接的分组在网络中都自然消失，再出现的分组一定都是新化身所产生的</strong>。 </p><h3 id="2-3-TIME-WAIT的危害"><a href="#2-3-TIME-WAIT的危害" class="headerlink" title="2.3 TIME_WAIT的危害"></a>2.3 TIME_WAIT的危害</h3><ol><li><p>内存资源的占用</p><p>这个目前看来不是太严重，基本可以忽略。 </p></li><li><p>对端口资源的占用 </p><p>一个 TCP 连接至少消耗一个本地端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000 ，也可以通过net.ipv4.ip_local_port_range指定，如果 TIME_WAIT 状态过多，会导致无法创建新连接。 </p></li></ol><h3 id="2-4-Address-already-in-use错误"><a href="#2-4-Address-already-in-use错误" class="headerlink" title="2.4  Address already in use错误"></a>2.4  Address already in use错误</h3><p><strong>每次用Ctrl+C来kill掉该服务器进程并重新启动的时候，都会出现bind错误：error:98，Address already in use。然而再kill掉该进程，再次重新启动的时候，就bind成功了</strong>。</p><p><strong>原因</strong>：</p><p>Linux下的TIME_WAIT大概是2分钟，服务器被kill掉之后没有释放掉的资源就是端口，这个端口会进入TIME_WAIT状态，可以使用<strong>SO_REUSEADDR</strong>来控制地址复用错误的情况</p><ul><li><p>SO_REUSEADDR允许启动一个监听服务器并捆绑其众所周知的端口，即使以前建立的将该端口用作他们的本地端口的连接仍存在。</p></li><li><p>允许在同一端口上启动同一服务器的多个实例，只要每个实例捆绑一个不同的本地IP地址即可。</p></li><li><p>O_REUSEADDR 允许单个进程捆绑同一端口到多个套接字上，只要每次捆绑指定不同的本地IP地址即可。</p></li><li><p>SO_REUSEADDR允许完全重复的捆绑：当一个IP地址和端口号已绑定到某个套接字上时，如果传输协议支持，同样的IP地址和端口还可以捆绑到另一个套接字上。一般来说本特性仅支持UDP套接字。</p></li></ul><p>因此可以使用下面的代码来实现控制</p><pre><code class="c">int on = 1;setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on));</code></pre><p><strong>服务器端程序，都应该设置 SO_REUSEADDR 套接字选项</strong>，以便服务端程序可以在<strong>极短时间内复用同一个端口</strong>启动。 同时要注意，<strong>SO_REUSEADDR是直接复用TIME_WAIT状态的连接，上一次连接的旧数据包会被忽略掉。</strong> </p><p> TCP 连接是通过四元组唯一区分的，只要客户端不使用相同的源端口，连接服务器是没有问题的，即使使用了相同的端口，根据序列号或者时间戳，也是可以区分出新旧连接的。 </p><p>而且，TCP 的机制绝对<strong>不允许在相同的地址和端口上绑定不同的服务器</strong>，即使我们设置 SO_REUSEADDR 套接字选项，也不可能在 ANY 通配符地址下和端口 9527 上重复启动两个服务器实例。如果我们启动第二个服务器实例，不出所料会得到Address already in use的报错，即使当前还没有任何一条有效 TCP 连接产生。 </p><p>一个问题：对于UDP连接来说， 设置 SO_REUSEADDR 套接字选项有哪些场景和好处呢？ </p><blockquote><p>使用场景比较多的是组播网络，好处是，如我们在接收组播流的时候，比如用ffmpeg拉取了一个组播流，但是还想用ffmpeg拉取相同的组播流，这个时候就需要地址重用了 </p></blockquote><p>又一个问题：在服务器端程序中，设置 SO_REUSEADDR 套接字选项时，需要在 bind 函数之前对监听字进行设置，想一想，为什么不是对已连接的套接字进行设置呢？ </p><h3 id="2-5-优化TIME-WAIT"><a href="#2-5-优化TIME-WAIT" class="headerlink" title="2.5 优化TIME_WAIT"></a>2.5 优化TIME_WAIT</h3><ol><li><p>net.ipv4.tcp_max_tw_buckets </p><p>表示系统同时保持TIME_WAIT套接字的最大数量，<strong>如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。</strong>默认为18000，改为5000。这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。 </p></li></ol><ol start="2"><li><p>调低 TCP_TIMEWAIT_LEN，重新编译系统 </p><p> 这个方法是一个不错的方法，就是将TIME_WAIT的时间长度缩小，缺点是需要“一点”内核方面的知识，能够重新编译内核。</p></li></ol><ol start="3"><li><p>SO_LINGER 的设置 </p><p>可以通过设置套接字选项，来设置调用 close 或者 shutdown 关闭连接时的行为。 </p><pre><code class="c">int setsockopt(int sockfd,                int level,                int optname,                const void *optval,               socklen_t optlen);</code></pre><pre><code class="c">struct linger {　    int　 l_onoff;　　　　/* 0=off, nonzero=on */　    int　 l_linger;　　　　/* linger time, POSIX specifies units as seconds */}</code></pre><ul><li>如果l_onoff为 0，那么关闭本选项。l_linger的值被忽略，这对应了默认行为，close 或 shutdown 立即返回。如果在套接字发送缓冲区中有数据残留，系统会将试着把这些数据发送出去。</li><li>如果l_onoff为非 0， 且l_linger值也为 0，那么调用 close 后，会立该发送一个 RST 标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了 TIME_WAIT 状态，直接关闭。这种关闭的方式称为“强行关闭”。 在这种情况下，排队数据不会被发送，被动关闭方也不知道对端已经彻底断开。只有当被动关闭方正阻塞在recv()调用上时，接受到 RST 时，会立刻得到一个“connet reset by peer”的异常。 </li></ul><p>设置方法：</p><pre><code class="c">struct linger so_linger;so_linger.l_onoff = 1;so_linger.l_linger = 0;setsockopt(s,SOL_SOCKET,SO_LINGER, &amp;so_linger,sizeof(so_linger));</code></pre><ul><li>如果l_onoff为非 0， 且l_linger的值也非 0，那么调用 close 后，调用 close 的线程就将阻塞，直到数据被发送出去，或者设置的l_linger计时时间到。 </li></ul><p>第二种可能为跨越 TIME_WAIT 状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。 </p></li></ol><ol start="4"><li><p>net.ipv4.tcp_tw_reuse：更安全的设置 </p><p>表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；</p><pre><code class="c">net.ipv4.tcp_tw_reuse = 1</code></pre><p>这个是重点，表示<strong>开启重用</strong>。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；</p><p>使用这个选项，需要<strong>打开对 TCP 时间戳的支持</strong>，即net.ipv4.tcp_timestamps=1（默认即为 1）。 </p><p>由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为<strong>重复的数据包会因为时间戳过期被自然丢弃</strong>。 </p></li></ol><h2 id="3-四次挥手的总结"><a href="#3-四次挥手的总结" class="headerlink" title="3. 四次挥手的总结"></a>3. 四次挥手的总结</h2><ol><li>TIME_WAIT 的引入是为了让 TCP 报文得以自然消失，同时为了让被动关闭方能够正常关闭；</li><li>不要试图使用SO_LINGER设置套接字选项，跳过 TIME_WAIT；</li><li>现代 Linux 系统引入了更安全可控的方案，可以帮助我们尽可能地复用 TIME_WAIT 状态的连接。 </li></ol><h2 id="4-发起关闭连接"><a href="#4-发起关闭连接" class="headerlink" title="4. 发起关闭连接"></a>4. 发起关闭连接</h2><p>一个 TCP 连接需要经过三次握手进入数据传输阶段，最后来到连接关闭阶段。在最后的连接关闭阶段，我们需要重点关注的是“半连接”状态。因为 TCP 是双向的，这里说的方向，指的是数据流的写入 - 读出的方向。 </p><ul><li>客户端到服务器端的方向，指的是客户端通过套接字接口，向服务器端发送 TCP 报文；</li><li>而服务器端到客户端方向则是另一个传输方向。</li></ul><p>在绝大数情况下，TCP 连接都是<strong>先关闭一个方向</strong>，此时<strong>另外一个方向还是可以正常进行数据传输</strong>。 </p><p><strong>例子</strong></p><p>客户端主动发起连接的中断，将自己到服务器端的数据流方向关闭，此时，客户端不再往服务器端写入数据，服务器端读完客户端数据后就不会再有新的报文到达。</p><p>但这并不意味着，TCP 连接已经完全关闭，很有可能的是，服务器端正在对客户端的最后报文进行处理，比如去访问数据库，存入一些数据；或者是计算出某个客户端需要的值。当完成这些操作之后，服务器端把结果通过套接字写给客户端，我们说这个套接字的状态此时是“半关闭”的。最后，服务器端才有条不紊地关闭剩下的半个连接，结束这一段 TCP 连接的使命。 </p><p>也就是说，<strong>客户端发起关闭连接请求之后可以保证自己不再向服务器发送数据，但是无法保证服务器不会再向客户端传输数据。</strong></p><p>在socket编程中，关闭连接的请求有两种类型：close和shutdown</p><h3 id="4-1-close"><a href="#4-1-close" class="headerlink" title="4.1 close"></a>4.1 close</h3><pre><code class="c">int close(int sockfd)</code></pre><p>作用：对已连接的套接字执行 close 操作就可以，若成功则返回 0，若出错则返回 -1。</p><p>这个函数会对套接字引用计数减1，一旦发现套接字引用计数到 0，就会对套接字进行彻底释放，并且会关闭<strong>TCP 两个方向的数据流</strong>。  </p><blockquote><p><strong>套接字引用计数</strong>：因为套接字可以被多个进程共享，每个套接字都有一个引用计数，如果通过 fork 的方式产生子进程，引用计数 +1， 如果调用一次 close 函数，引用计数就会 -1。</p><p><strong>关闭两个方向的数据流</strong>：</p><ul><li><p>在输入方向：系统内核会将该套接字设置为不可读，任何读操作都会返回异常。 </p></li><li><p>在输出方向：系统内核尝试将发送缓冲区的数据发送给对端，并最后向对端发送一个 FIN 报文，接下来如果再对该套接字进行写操作会返回异常。 </p><p>如果对端没有检测到套接字已关闭，还继续发送报文，就会收到一个 RST 报文，告诉对端：“Hi, 我已经关闭了，别再给我发数据了。” </p></li></ul></blockquote><p>close 函数并不能帮助我们关闭连接的一个方向，那么如何在需要的时候关闭一个方向呢？幸运的是，设计 TCP 协议的人帮我们想好了解决方案，这就是 shutdown 函数。 </p><h3 id="4-2-shutdown"><a href="#4-2-shutdown" class="headerlink" title="4.2 shutdown"></a>4.2 shutdown</h3><pre><code class="c">int shutdown(int sockfd, int howto)</code></pre><p>对已连接的套接字执行 shutdown 操作，若成功则返回 0，若出错则返回 -1。</p><p>howto 是这个函数的设置选项，它的设置有三个主要选项：  </p><ol><li><p><strong>SHUT_RD(0)</strong>：</p><p>关闭连接的“读”方向，对该套接字进行读操作直接返回 EOF。</p><p>从数据角度来看，套接字上接收缓冲区已有的数据将被丢弃，如果再有新的数据流到达，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。 </p></li><li><p><strong>SHUT_WR(1)</strong>：</p><p>关闭连接的“写”方向，这就是常被称为”半关闭“的连接。</p><p>此时，<strong>不管套接字引用计数的值是多少，都会直接关闭连接的写方向</strong>。套接字上<strong>发送缓冲区已有的数据将被立即发送出去，并发送一个 FIN 报文给对端</strong>。应用程序如果对该套接字进行写操作会报错。 </p></li><li><p><strong>SHUT_RDWR</strong>(2)：</p><p>关闭套接字的读和写两个方向。 </p><p>相当于 SHUT_RD 和 SHUT_WR 操作各一次。</p></li></ol><h3 id="4-3-两种方式对比及SIGPIPE"><a href="#4-3-两种方式对比及SIGPIPE" class="headerlink" title="4.3 两种方式对比及SIGPIPE"></a>4.3 两种方式对比及SIGPIPE</h3><p><img src="/2019/10/30/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B6%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/f283b804c7e33e25a900fedc8c36f09a.png" alt="img"></p><p><strong>第一个差别</strong>：</p><ul><li>close 会<strong>关闭连接，并释放所有连接对应的资源</strong>。</li><li>shutdown 并<strong>不会释放掉套接字和所有的资源</strong>。</li></ul><p><strong>第二个差别</strong>：</p><ul><li>close 存在引用计数的概念，并不一定导致该套接字不可用；</li><li>shutdown 则不管引用计数，<strong>直接使得该套接字不可用</strong>，如果有别的进程企图使用该套接字，将会受到影响。</li></ul><p><strong>第三个差别</strong>：</p><ul><li>close 的引用计数导致<strong>不一定会发出 FIN</strong> 结束报文，</li><li>shutdown 则<strong>总是会发出 FIN</strong> 结束报文，这在我们打算关闭连接通知对端的时候，是非常重要的。 </li></ul><p><strong>SIGPIPE</strong></p><p>假设server和client 已经建立了连接，客户端调用了close, 发送FIN 段给服务器（其实不一定会发送FIN段，close不能保证，只有当某个sockfd的<strong>引用计数为0，close 才会发送FIN段</strong>，否则只是将引用计数减1而已）。</p><p>也就是说只有当所有进程（可能fork多个子进程都打开了这个套接字）都关闭了这个套接字，close 才会发送FIN 段），此时客户端不能再通过socket发送和接收数据，此时服务器调用read，如果接收到FIN 段会返回0。</p><p>但服务器此时还是可以write 给客户端的，write调用只负责把数据交给TCP发送缓冲区就可以成功返回了，所以不会出错，而客户端收到数据后应答一个RST段，表示服务器已经不能接收数据，连接重置，<strong>服务器收到RST段后无法立刻通知应用层，只把这个状态保存在TCP协议层</strong>。如果服务器再次调用write发数据给客户端，由于TCP协议层已经处于RST状态了，因此<strong>不会将数据发出</strong>，而是<strong>发一个SIGPIPE信号</strong>给应用层，SIGPIPE信号的<strong>缺省处理动作是终止程序</strong>。</p><p>简单地说，当客户端 close 一个连接时，若服务器继续向服务器发数据，服务器会收到一个 RST 响应，服务器再往这个客户端发送数据时，系统会发出一个 SIGPIPE 信号给服务器，导致服务器进程退出。</p><p>（以上的客户端与服务器互换位置也是没有问题的）</p><p><strong>在大多数情况下，会优选 shutdown 来完成对连接一个方向的关闭，待对端处理完之后，再完成另外一个方向的关闭。在很多情况下，连接的一端需要一直感知连接的状态，如果连接无效了，应用程序可能需要报错，或者重新发起连接等。</strong> </p><h3 id="4-4-资源问题"><a href="#4-4-资源问题" class="headerlink" title="4.4 资源问题"></a>4.4 资源问题</h3><p>为什么调用exit以后不需要调用close，shutdown？</p><p>因为在调用exit之后进程会退出，而进程相关的所有的资源，文件，内存，信号等内核分配的资源都会被释放，在linux中，一切皆文件，本身socket就是一种文件类型，内核会为每一个打开的文件创建file结构并维护指向改结构的引用计数，每一个进程结构中都会维护本进程打开的文件数组，数组下标就是fd，内容就指向上面的file结构，close本身就可以用来操作所有的文件，做的事就是，删除本进程打开的文件数组中指定的fd项，并把指向的file结构中的引用计数减一，等引用计数为0的时候，就会调用内部包含的文件操作close，针对于socket，它内部的实现应该就是调用shutdown，只是参数是关闭读写端，从而比较粗暴的关闭连接。 </p><h2 id="附录A-close和shutdown的编程"><a href="#附录A-close和shutdown的编程" class="headerlink" title="附录A close和shutdown的编程"></a>附录A close和shutdown的编程</h2><h3 id="A-1-客户端"><a href="#A-1-客户端" class="headerlink" title="A.1 客户端"></a>A.1 客户端</h3><p>服务器端的程序相对较为复杂，在下面用代码实现</p><pre><code class="c"># include &quot;lib/common.h&quot;# define    MAXLINE     4096int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: graceclient &lt;IPaddress&gt;&quot;);    }    // 创建一个socket    int socket_fd;    socket_fd = socket(AF_INET, SOCK_STREAM, 0);    // 设置连接的目标服务器 IPv4 地址，绑定到指定的 IP 和端口；    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_port = htons(SERV_PORT);    inet_pton(AF_INET, argv[1], &amp;server_addr.sin_addr);    // 使用创建的套接字，向目标 IPv4 地址发起连接请求；    socklen_t server_len = sizeof(server_addr);    int connect_rt = connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len);    if (connect_rt &lt; 0) {        error(1, errno, &quot;connect failed &quot;);    }    char send_line[MAXLINE], recv_line[MAXLINE + 1];    int n;    fd_set readmask;    fd_set allreads;    // 为使用 select 做准备，初始化描述字集合    FD_ZERO(&amp;allreads);    FD_SET(0, &amp;allreads);    FD_SET(socket_fd, &amp;allreads);    // 主体部分，使用 select 多路复用观测在连接套接字和标准输入上的 I/O 事件    for (;;) {        readmask = allreads;        int rc = select(socket_fd + 1, &amp;readmask, NULL, NULL, NULL);        if (rc &lt;= 0)            error(1, errno, &quot;select failed&quot;);        // 当连接套接字上有数据可读，将数据读入到程序缓冲区中。        if (FD_ISSET(socket_fd, &amp;readmask)) {            n = read(socket_fd, recv_line, MAXLINE);            // 如果有异常则报错退出            if (n &lt; 0) {                error(1, errno, &quot;read error&quot;);            } else if (n == 0) { // 如果读到服务器端发送的 EOF 则正常退出                error(1, 0, &quot;server terminated \n&quot;);            }            recv_line[n] = 0;            fputs(recv_line, stdout);            fputs(&quot;\n&quot;, stdout);        }        // 当标准输入上有数据可读，读入后进行判断。        if (FD_ISSET(0, &amp;readmask)) {            if (fgets(send_line, MAXLINE, stdin) != NULL) {                // 如果输入的是“shutdown”，则关闭标准输入的 I/O 事件感知，                // 并调用 shutdown 函数关闭写方向；                if (strncmp(send_line, &quot;shutdown&quot;, 8) == 0) {                    FD_CLR(0, &amp;allreads);                    if (shutdown(socket_fd, 1)) {                        error(1, errno, &quot;shutdown failed&quot;);                    }                }                 // 如果输入的是”close“，则调用 close 函数关闭连接；                else if (strncmp(send_line, &quot;close&quot;, 5) == 0) {                    FD_CLR(0, &amp;allreads);                    if (close(socket_fd)) {                        error(1, errno, &quot;close failed&quot;);                    }                    sleep(6);                    exit(0);                }                 // 处理正常的输入                else {                    int i = strlen(send_line);                    // 将回车符截掉                    if (send_line[i - 1] == &#39;\n&#39;) {                        send_line[i - 1] = 0;                    }                    printf(&quot;now sending %s\n&quot;, send_line);                    // 调用 write 函数，通过套接字将数据发送给服务器端                    size_t rt = write(socket_fd, send_line, strlen(send_line));                    if (rt &lt; 0) {                        error(1, errno, &quot;write failed &quot;);                    }                    printf(&quot;send bytes: %zu \n&quot;, rt);                }            }        }    }}</code></pre><h3 id="A-2-服务器端"><a href="#A-2-服务器端" class="headerlink" title="A.2 服务器端"></a>A.2 服务器端</h3><p>连接建立之后，打印出接收的字节，并重新格式化后，发送给客户端。 服务器端程序有一点需要注意，那就是对 SIGPIPE 这个信号的处理。</p><pre><code class="c">#include &quot;lib/common.h&quot;static int count;static void sig_int(int signo) {    printf(&quot;\nreceived %d datagrams\n&quot;, count);    exit(0);}int main(int argc, char **argv) {    // 创建一个 TCP 套接字    int listenfd;    listenfd = socket(AF_INET, SOCK_STREAM, 0);    // 设置了本地服务器 IPv4 地址，绑定到了 ANY 地址和指定的端口    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);    server_addr.sin_port = htons(SERV_PORT);    // 使用创建的套接字，对它执行 bind、listen 和 accept 操作，完成连接建立    int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr));    if (rt1 &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    int rt2 = listen(listenfd, LISTENQ);    if (rt2 &lt; 0) {        error(1, errno, &quot;listen failed &quot;);    }    signal(SIGINT, sig_int);    signal(SIGPIPE, SIG_IGN);    int connfd;    struct sockaddr_in client_addr;    socklen_t client_len = sizeof(client_addr);    if ((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    char message[MAXLINE];    count = 0;    for (;;) {        int n = read(connfd, message, MAXLINE);        if (n &lt; 0) {            error(1, errno, &quot;error read&quot;);        } else if (n == 0) {            error(1, 0, &quot;client closed \n&quot;);        }        // 显示收到的字符串        message[n] = 0;        printf(&quot;received %d bytes: %s\n&quot;, n, message);        count++;        // 对原字符串进行重新格式化        char send_line[MAXLINE];        sprintf(send_line, &quot;Hi, %s&quot;, message);        sleep(5);        int write_nc = send(connfd, send_line, strlen(send_line), 0);        printf(&quot;send bytes: %zu \n&quot;, write_nc);        if (write_nc &lt; 0) {            error(1, errno, &quot;error write&quot;);        }    }}</code></pre><h3 id="A-3-SIGPIPE问题"><a href="#A-3-SIGPIPE问题" class="headerlink" title="A.3 SIGPIPE问题"></a>A.3 SIGPIPE问题</h3><p><img src="/2019/10/30/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B6%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/f283b804c7e33e25a900fedc8c36f09a.png" alt="img"></p><p>在客户端 close 掉整个连接之后，服务器端接收到 SIGPIPE 信号，直接退出。客户端并没有收到服务器端的应答数据。  </p><p>当服务器 close 一个连接时，若 client 继续向服务器发数据，根据 TCP 协议的规定，客户端会收到一个 RST 响应，client再往这个服务器发送数据时，系统会发出一个 SIGPIPE 信号给客户端进程，导致客户端进程退出。</p><p>具体分析可以结合 TCP 的“四次握手”关闭。TCP 是全双工的信道，可以看作两条单双工的信道，TCP 连接两端的两个端点各负责一条。当对端调用 close 时，虽然默认行为是关闭整个两个信道，但本端只是收到 FIN 包，按照 TCP 协议的语义，表示对端只是关闭了其所负责的那一条单工信道，本端仍然可以接收数据。也就是说，因为 TCP 协议的限制，一个端点无法获知对端的 socket 是调用了 close 还是 shutdown。</p><p>因为客户端调用 close 函数关闭了整个连接，当服务器端发送的“Hi, data1”分组到底时，客户端给回送一个 RST 分组；服务器端再次尝试发送“Hi, data2”第二个应答分组时，系统内核通知 SIGPIPE 信号。这是因为，在 RST 的套接字进行写操作，会直接触发 SIGPIPE 信号。 </p><h3 id="A-4-SO-REUSEADDR"><a href="#A-4-SO-REUSEADDR" class="headerlink" title="A.4 SO_REUSEADDR"></a>A.4 SO_REUSEADDR</h3><p>服务器端发起的关闭连接操作，将会使得服务器对应的 TCP 连接变为 TME_WAIT 状态，从而导致两分钟内该端口不可使用</p><p>下面是更改过后的服务器端代码</p><pre><code class="c">nt main(int argc, char **argv) {    int listenfd;    listenfd = socket(AF_INET, SOCK_STREAM, 0);    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);    server_addr.sin_port = htons(SERV_PORT);    // 在 bind 监听套接字之前，调用 setsockopt 方法，设置重用套接字选项：    int on = 1;    setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on));    int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr));    if (rt1 &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    int rt2 = listen(listenfd, LISTENQ);    if (rt2 &lt; 0) {        error(1, errno, &quot;listen failed &quot;);    }    signal(SIGPIPE, SIG_IGN);    int connfd;    struct sockaddr_in client_addr;    socklen_t client_len = sizeof(client_addr);    if ((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) {        error(1, errno, &quot;bind failed &quot;);    }    char message[MAXLINE];    count = 0;    for (;;) {        int n = read(connfd, message, MAXLINE);        if (n &lt; 0) {            error(1, errno, &quot;error read&quot;);        } else if (n == 0) {            error(1, 0, &quot;client closed \n&quot;);        }        message[n] = 0;        printf(&quot;received %d bytes: %s\n&quot;, n, message);        count++;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程5：网络工具</title>
      <link href="/2019/10/29/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B5%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"/>
      <url>/2019/10/29/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B5%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><ul><li>ping 可以用来帮助我们进行网络连通性的探测。</li><li>ifconfig，用来显示当前系统中的所有网络设备。</li><li>netstat 和 lsof 可以查看活动的连接状况。</li><li>tcpdump 可以对各种奇怪的环境进行抓包，进而帮我们了解报文，排查问题。 </li></ul><h2 id="1-ping"><a href="#1-ping" class="headerlink" title="1. ping"></a>1. ping</h2><pre><code>$ ping www.sina.com.cnPING www.sina.com.cn (202.102.94.124) 56(84) bytes of data.64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=1 ttl=63 time=8.64 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=2 ttl=63 time=11.3 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=3 ttl=63 time=8.66 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=4 ttl=63 time=13.7 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=5 ttl=63 time=8.22 ms64 bytes from www.sina.com.cn (202.102.94.124): icmp_seq=6 ttl=63 time=7.99 ms^C--- www.sina.com.cn ping statistics ---6 packets transmitted, 6 received, 0% packet loss, time 5006msrtt min/avg/max/mdev = 7.997/9.782/13.795/2.112 ms</code></pre><p><img src="/2019/10/29/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B5%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/1572071080886.png" alt="1572071080886"></p><p>ping 这个命名来自于声呐探测，在网络上用来完成对网络连通性的探测。</p><p>ping 是基于 ICMP 的协议开发的，ICMP 又是一种基于 IP 协议的控制协议，翻译为网际控制协议 。</p><p>ICMP 在 IP 报文后加入了新的内容，这些内容包括：</p><ul><li>类型：即 ICMP 的类型, 其中 ping 的请求类型为 0，应答为 8。</li><li>代码：进一步划分 ICMP 的类型, 用来查找产生错误的原因。</li><li>校验和：用于检查错误的数据。</li><li>标识符：通过标识符来确认是谁发送的控制协议，可以是进程 ID。</li><li>序列号：唯一确定的一个报文，前面 ping 名字执行后显示的 icmp_seq 就是这个值。 </li></ul><p>ICMP 协议为我们侦测网络问题提供了非常好的支持。另外一种对路由的检测命令 Traceroute 也是通过 ICMP 协议来完成的 </p><h2 id="2-ifconfig"><a href="#2-ifconfig" class="headerlink" title="2. ifconfig"></a>2. ifconfig</h2><pre><code>vagrant@ubuntu-xenial-01:~$ ifconfigcni0      Link encap:Ethernet  HWaddr 0a:58:0a:f4:00:01          inet addr:10.244.0.1  Bcast:0.0.0.0  Mask:255.255.255.0          inet6 addr: fe80::401:b4ff:fe51:bcf9/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1450  Metric:1          RX packets:2133 errors:0 dropped:0 overruns:0 frame:0          TX packets:2216 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000          RX bytes:139381 (139.3 KB)  TX bytes:853302 (853.3 KB)docker0   Link encap:Ethernet  HWaddr 02:42:93:0f:f7:11          inet addr:172.17.0.1  Bcast:0.0.0.0  Mask:255.255.0.0          inet6 addr: fe80::42:93ff:fe0f:f711/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:653 errors:0 dropped:0 overruns:0 frame:0          TX packets:685 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0          RX bytes:49542 (49.5 KB)  TX bytes:430826 (430.8 KB)enp0s3    Link encap:Ethernet  HWaddr 02:54:ad:ea:60:2e          inet addr:10.0.2.15  Bcast:10.0.2.255  Mask:255.255.255.0          inet6 addr: fe80::54:adff:feea:602e/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:7951 errors:0 dropped:0 overruns:0 frame:0          TX packets:4123 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000          RX bytes:5081047 (5.0 MB)  TX bytes:385600 (385.6 KB)</code></pre><p>Windows 有一个 ipconfig 命令，用来显示当前的网络设备列表。事实上，Linux 有一个对应的命令叫做 ifconfig，也用来显示当前系统中的所有网络设备，通俗一点的说，就是<strong>网卡列表</strong>。 </p><pre><code>Link encap:Ethernet HWaddr 02:54:ad:ea:60:2e# 表明这是一个以太网设备，MAC 地址为 02:54:ad:ea:60:2e。</code></pre><h2 id="3-netstat"><a href="#3-netstat" class="headerlink" title="3. netstat"></a>3. netstat</h2><p>使用 netstat 可以获得当前所有的连接详情，包括源、目的IP、端口号，连接状态等信息，就可以使用下面这行命令： </p><pre><code>netstat -alepn</code></pre><p>netstat 会把所有 IPv4 形态的 TCP，IPV6 形态的 TCP、UDP 以及 UNIX 域（本地套接字）的套接字都显示出来。对于 TCP 类型来说，最大的好处是可以清楚地看到一条 TCP 连接的四元组（源地址、源端口、目的地地址和目的端口）。 </p><pre><code>tcp        0      0 127.0.0.1:2379          127.0.0.1:52464         ESTABLISHED 0          27710       3496/etcd</code></pre><p>它表达的意思是本地 127.0.0.1 的端口 52464 连上本地 127.0.0.1 的端口 2379，状态为 ESTABLISHED，本地进程为 etcd，进程为 3496。</p><h2 id="4-lsof"><a href="#4-lsof" class="headerlink" title="4. lsof"></a>4. lsof</h2><p>lsof 的常见用途之一是<strong>找出在指定的 IP 地址或者端口上打开套接字的进程</strong>，而使用 netstat 则可以得到 IP 地址和端口使用的情况，以及各个 TCP 连接的状态。</p><p>可以通过lsof来查看到底是谁打开了这个文件</p><pre><code>lsof /var/run/docker.sock</code></pre><p>lsof 还有一个非常常见的用途。如果我们启动了一个服务器程序，发现这个服务器需要绑定的端口地址已经被占用，内核报出“该地址已在使用”的出错信息，我们可以使用 lsof 找出正在使用该端口的那个进程。比如下面这个代码，就帮我们找到了使用 8080 端口的那个进程，从而帮助我们定位问题。</p><pre><code>lsof -i :8080</code></pre><h2 id="5-tcpdump"><a href="#5-tcpdump" class="headerlink" title="5. tcpdump"></a>5. tcpdump</h2><p>tcpdump是一个网络抓包工具，通过设置tcpdump的指令来进行相应的抓包操作。</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程3：UDP协议使用socket</title>
      <link href="/2019/10/28/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3UDP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/"/>
      <url>/2019/10/28/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3UDP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><h2 id="0-UDP网络编程流程"><a href="#0-UDP网络编程流程" class="headerlink" title="0. UDP网络编程流程"></a>0. UDP网络编程流程</h2><p><img src="/2019/10/28/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3UDP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/1572055898417.png" alt="1572055898417"></p><h2 id="1-收发报文"><a href="#1-收发报文" class="headerlink" title="1. 收发报文"></a>1. 收发报文</h2><p>从上图可以看出，服务器端和客户端收发报文的代码是一样的，都是通过recvfrom和sendto这两个函数实现。</p><pre><code class="c">#include &lt;sys/socket.h&gt;ssize_t recvfrom(int sockfd,                  void *buff,                  size_t nbytes,                  int flags, 　　　　　　　　　　                 struct sockaddr *from,                  socklen_t *addrlen); </code></pre><ol><li>sockfd：本地创建的套接字</li><li>buff：指向本地的缓存</li><li>nbytes：最大接收数据字节</li><li>flags：与IO相关的参数</li><li>from与addrlen： 返回对端发送方的地址和端口等信息。这和 TCP 非常不一样，TCP 是通过 accept 函数拿到的描述字信息来决定对端的信息。另外 UDP 报文每次接收都会获取对端的信息，也就是说报文和报文之间是没有上下文的。 </li><li>返回值：实际接收的字节数</li></ol><pre><code class="c">#include &lt;sys/socket.h&gt;ssize_t sendto(int sockfd,                const void *buff,                size_t nbytes,                int flags,                const struct sockaddr *to,                socklen_t addrlen);</code></pre><ol><li>sockfd：本地创建的套接字描述符</li><li>buff：指向发送的缓存</li><li>nbytes：表示发送字节数</li><li>flags：设置为 0</li><li>to、addrlen：发送的对方地址和端口等信息  </li><li>返回值：实际接收的字节数</li></ol><h2 id="2-服务器端"><a href="#2-服务器端" class="headerlink" title="2. 服务器端"></a>2. 服务器端</h2><p>流程：</p><ol><li>创建UDP的socket</li><li>绑定到本地端口</li><li>调用recvfrom函数等待客户端报文发送</li></ol><p>下面是一个服务器端的代码例子</p><pre><code class="c">#include &quot;lib/common.h&quot;static int count;static void recvfrom_int(int signo) {    printf(&quot;\nreceived %d datagrams\n&quot;, count);    exit(0);}int main(int argc, char **argv) {    // 创建一个套接字，注意这里的套接字类型是“SOCK_DGRAM”，表示的是 UDP 数据报。    int socket_fd;    socket_fd = socket(AF_INET, SOCK_DGRAM, 0);    // 绑定数据报套接字到本地的一个端口上。    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_addr.s_addr = htonl(INADDR_ANY);    server_addr.sin_port = htons(SERV_PORT);    bind(socket_fd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr));    socklen_t client_len;    char message[MAXLINE];    count = 0;    // 为该服务器创建了一个信号处理函数，以便在响应“Ctrl+C”退出时，打印出收到的报文总数。    signal(SIGINT, recvfrom_int);    struct sockaddr_in client_addr;    client_len = sizeof(client_addr);    // 是该服务器端的主体，通过调用 recvfrom 函数获取客户端发送的报文，    // 之后对收到的报文进行重新改造，加上“Hi”的前缀，再通过 sendto 函数发送给客户端对端。    for (;;) {        int n = recvfrom(socket_fd, message, MAXLINE, 0, (struct sockaddr *) &amp;client_addr, &amp;client_len);        message[n] = 0;        printf(&quot;received %d bytes: %s\n&quot;, n, message);        char send_line[MAXLINE];        sprintf(send_line, &quot;Hi, %s&quot;, message);        sendto(socket_fd, send_line, strlen(send_line), 0, (struct sockaddr *) &amp;client_addr, client_len);        count++;    }}</code></pre><h2 id="3-客户端"><a href="#3-客户端" class="headerlink" title="3. 客户端"></a>3. 客户端</h2><p>流程：</p><ol><li>创建UDP的socket</li><li>调用sendto函数往目标地址和端口发送UDP报文</li><li>自此客户端和服务器端进入相互应答的过程</li></ol><p>代码例子：</p><pre><code class="c">#include &quot;lib/common.h&quot;# define    MAXLINE     4096int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: udpclient &lt;IPaddress&gt;&quot;);    }    // 创建一个类型为“SOCK_DGRAM”的套接字。    int socket_fd;    socket_fd = socket(AF_INET, SOCK_DGRAM, 0);    // 初始化目标服务器的地址和端口    struct sockaddr_in server_addr;    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sin_family = AF_INET;    server_addr.sin_port = htons(SERV_PORT);    inet_pton(AF_INET, argv[1], &amp;server_addr.sin_addr);    socklen_t server_len = sizeof(server_addr);    struct sockaddr *reply_addr;    reply_addr = malloc(server_len);    char send_line[MAXLINE], recv_line[MAXLINE + 1];    socklen_t len;    int n;    // 从标准输入中读取的字符进行处理后，调用 sendto 函数发送给目标服务器端，    // 然后再次调用 recvfrom 函数接收目标服务器发送过来的新报文，并将其打印到标准输出上。    while (fgets(send_line, MAXLINE, stdin) != NULL) {        int i = strlen(send_line);        if (send_line[i - 1] == &#39;\n&#39;) {            send_line[i - 1] = 0;        }        printf(&quot;now sending %s\n&quot;, send_line);        size_t rt = sendto(socket_fd, send_line, strlen(send_line), 0, (struct sockaddr *) &amp;server_addr, server_len);        if (rt &lt; 0) {            error(1, errno, &quot;send failed &quot;);        }        printf(&quot;send bytes: %zu \n&quot;, rt);        len = 0;        n = recvfrom(socket_fd, recv_line, MAXLINE, 0, reply_addr, &amp;len);        if (n &lt; 0)            error(1, errno, &quot;recvfrom failed&quot;);        recv_line[n] = 0;        fputs(recv_line, stdout);        fputs(&quot;\n&quot;, stdout);    }    exit(0);}</code></pre><h2 id="4-TCP与UDP对比"><a href="#4-TCP与UDP对比" class="headerlink" title="4. TCP与UDP对比"></a>4. TCP与UDP对比</h2><p>首先，UDP 是一种“数据报”协议，而 TCP 是一种面向连接的“数据流”协议。 UDP 是无连接的数据报程序，和 TCP 不同，不需要三次握手建立一条连接。UDP 程序通过 recvfrom 和 sendto 函数直接收发数据报报文。 </p><ol><li><p><strong>TCP</strong></p><p>TCP 可以用日常生活中<strong>打电话</strong>的场景打比方，前面也多次用到了这样的例子。在这个例子中，拨打号码，接通电话，开始交流，分别对应了 TCP 的三次握手和报文传送。一旦双方的连接建立，那么双方对话时，一定知道彼此是谁。这个时候我们就说，这种对话是有上下文的。 </p></li><li><p><strong>UDP</strong></p><p>UDP 可以用<strong>邮寄明信片</strong>来打比方。在这个例子中，发信方在明信片中填上了接收方的地址和邮编，投递到邮局的邮筒之后，就可以不管了。发信方也可以给这个接收方再邮寄第二张、第三张，甚至是第四张明信片，但是这几张明信片之间是没有任何关系的，他们的到达顺序也是不保证的，有可能最后寄出的第四张明信片最先到达接收者的手中，因为没有序号，接收者也不知道这是第四张寄出的明信片；而且，即使接收方没有收到明信片，也没有办法重新邮寄一遍该明信片。 </p></li></ol><p><strong>对比</strong></p><ul><li><p>TCP 是一个面向连接的协议，TCP 在 IP 报文的基础上，增加了诸如重传、确认、有序传输、拥塞控制等能力，通信的双方是<strong>在一个确定的上下文中工作的</strong>。</p></li><li><p>UDP 没有这样一个确定的上下文，它是一个<strong>不可靠的通信协议</strong>，没有重传和确认，没有有序控制，也没有拥塞控制。可以简单地理解为，在 IP 报文的基础上，UDP 增加的能力有限。UDP 不保证报文的有效传递，不保证报文的有序，也就是说使用 UDP 的时候，我们需要做好丢包、重传、报文组装等工作。 </p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程4：本地套接字</title>
      <link href="/2019/10/28/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B4%E6%9C%AC%E5%9C%B0socket/"/>
      <url>/2019/10/28/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B4%E6%9C%AC%E5%9C%B0socket/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><p>本地套接字是 IPC，也就是<strong>本地进程间通信</strong>的一种实现方式。除了本地套接字以外，其它技术，诸如<strong>管道</strong>、<strong>共享消息队列</strong>等也是进程间通信的常用方法，但因为本地套接字开发便捷，接受度高，所以普遍适用于在同一台主机上进程间通信的各种场景。 </p><p>本地套接字是一种特殊类型的套接字，和 TCP/UDP 套接字不同。对比如下：</p><ul><li>TCP/UDP 即使在本地地址通信，也要走系统网络协议栈</li><li>本地套接字，严格意义上说提供了一种单主机跨进程间调用的手段，减少了协议栈实现的复杂度，效率比 TCP/UDP 套接字都要高许多。</li><li>类似的 IPC 机制还有 UNIX 管道、共享内存和 RPC 调用等。 </li></ul><p>本地地址实际上就是本地套接字专属的</p><p><img src="/2019/10/28/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B4%E6%9C%AC%E5%9C%B0socket/1572058378683.png" alt="1572058378683"></p><h2 id="1-TCP-服务器端"><a href="#1-TCP-服务器端" class="headerlink" title="1. TCP 服务器端"></a>1. TCP 服务器端</h2><pre><code class="c">#include  &quot;lib/common.h&quot;int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: unixstreamserver &lt;local_path&gt;&quot;);    }    int listenfd, connfd;    socklen_t clilen;    struct sockaddr_un cliaddr, servaddr;    // 这里创建的套接字类型，注意是 AF_LOCAL，并且使用字节流格式SOCK_STREAM。    // TCP 的类型是 AF_INET 和字节流类型；UDP 的类型是 AF_INET 和数据报类型。在前面的文章中，我们提到 AF_UNIX 也是可以的，基本上可以认为和 AF_LOCAL 是等价的。    listenfd = socket(AF_LOCAL, SOCK_STREAM, 0);    if (listenfd &lt; 0) {        error(1, errno, &quot;socket create failed&quot;);    }    // 创建了一个本地地址，这里的本地地址和 IPv4、IPv6 地址可以对应，数据类型为 sockaddr_un，    // 这个数据类型中的 sun_family 需要填写为 AF_LOCAL，    // 最为关键的是需要对 sun_path 设置一个本地文件路径。    // 我们这里还做了一个 unlink 操作，以便把存在的文件删除掉，这样可以保持幂等性。    char *local_path = argv[1];    unlink(local_path);    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sun_family = AF_LOCAL;    strcpy(servaddr.sun_path, local_path);    // 执行bind操作，与TCP的服务器端程序类似    if (bind(listenfd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr)) &lt; 0) {        error(1, errno, &quot;bind failed&quot;);    }    // 执行listen操作，监听在一个本地文件路径标识的套接字上    if (listen(listenfd, LISTENQ) &lt; 0) {        error(1, errno, &quot;listen failed&quot;);    }    clilen = sizeof(cliaddr);    if ((connfd = accept(listenfd, (struct sockaddr *) &amp;cliaddr, &amp;clilen)) &lt; 0) {        if (errno == EINTR)            error(1, errno, &quot;accept failed&quot;);        /* back to for() */        else            error(1, errno, &quot;accept failed&quot;);    }    char buf[BUFFER_SIZE];    // 使用 read 和 write 函数从套接字中按照字节流的方式读取和发送数据。    while (1) {        bzero(buf, sizeof(buf));        if (read(connfd, buf, BUFFER_SIZE) == 0) {            printf(&quot;client quit&quot;);            break;        }        printf(&quot;Receive: %s&quot;, buf);        char send_line[MAXLINE];        sprintf(send_line, &quot;Hi, %s&quot;, buf);        int nbytes = sizeof(send_line);        if (write(connfd, send_line, nbytes) != nbytes)            error(1, errno, &quot;write error&quot;);    }    close(listenfd);    close(connfd);    exit(0);}</code></pre><p>关于本地文件路径，需要明确一点，它必须是“绝对路径”，这样的话，编写好的程序可以在任何目录里被启动和管理。如果是“相对路径”，为了保持同样的目的，这个程序的启动路径就必须固定，这样一来，对程序的管理反而是一个很大的负担。</p><p>另外还要明确一点，<strong>这个本地文件，必须是一个“文件”，不能是一个“目录”</strong>。如果文件不存在，后面 bind 操作时会自动创建这个文件。 </p><h2 id="2-TCP-客户端"><a href="#2-TCP-客户端" class="headerlink" title="2. TCP 客户端"></a>2. TCP 客户端</h2><pre><code class="c">#include &quot;lib/common.h&quot;int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: unixstreamclient &lt;local_path&gt;&quot;);    }    int sockfd;    struct sockaddr_un servaddr;    // 创建了一个本地套接字，和前面服务器端程序一样，用的也是字节流类型 SOCK_STREAM。    sockfd = socket(AF_LOCAL, SOCK_STREAM, 0);    if (sockfd &lt; 0) {        error(1, errno, &quot;create socket failed&quot;);    }    // 初始化目标服务器端的地址。    // 在 TCP 编程中，使用的是服务器的 IP 地址和端口作为目标    // 在本地套接字中则使用文件路径作为目标标识    // sun_path 这个字段标识的是目标文件路径，所以这里需要对 sun_path 进行初始化。    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sun_family = AF_LOCAL;    strcpy(servaddr.sun_path, argv[1]);    // 发起对目标套接字的 connect 调用，不过由于是本地套接字，并不会有三次握手。    if (connect(sockfd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr)) &lt; 0) {        error(1, errno, &quot;connect failed&quot;);    }    char send_line[MAXLINE];    bzero(send_line, MAXLINE);    char recv_line[MAXLINE];    // 从标准输入中读取字符串，向服务器端发送，之后将服务器端传输过来的字符打印到标准输出上。    while (fgets(send_line, MAXLINE, stdin) != NULL) {        int nbytes = sizeof(send_line);        if (write(sockfd, send_line, nbytes) != nbytes)            error(1, errno, &quot;write error&quot;);        if (read(sockfd, recv_line, MAXLINE) == 0)            error(1, errno, &quot;server terminated prematurely&quot;);        fputs(recv_line, stdout);    }    exit(0);}</code></pre><p>本地字节流套接字和 TCP 服务器端、客户端编程最大的差异就是<strong>套接字类型的不同</strong>。本地字节流套接字识别服务器不再通过 IP 地址和端口，而是通过本地文件。 </p><h2 id="3-运行场景"><a href="#3-运行场景" class="headerlink" title="3. 运行场景"></a>3. 运行场景</h2><h3 id="3-1-只启动客户端"><a href="#3-1-只启动客户端" class="headerlink" title="3.1 只启动客户端"></a>3.1 只启动客户端</h3><pre><code>$ ./unixstreamclient /tmp/unixstream.sockconnect failed: No such file or directory (2)</code></pre><p>由于没有启动服务器端，没有一个本地套接字在 /tmp/unixstream.sock 这个文件上监听，客户端直接报错，提示我们没有文件存在。 </p><h3 id="3-2-服务器监听在无权限的文件上"><a href="#3-2-服务器监听在无权限的文件上" class="headerlink" title="3.2 服务器监听在无权限的文件上"></a>3.2 服务器监听在无权限的文件上</h3><pre><code>$ ./unixstreamserver /var/lib/unixstream.sockbind failed: Permission denied (13)</code></pre><p>这个结果告诉我们启动服务器端程序的用户，必须对本地监听路径有权限。 ，如果使用root权限或者加上权限之后，就可以正常运行了。</p><p>同时，在 /var/lib 下创建了一个本地文件，大小为 0，而且文件的最后结尾有一个（=）号。其实这就是 bind 的时候自动创建出来的文件。 </p><p> 如果我们使用 netstat 命令查看 <strong>UNIX 域套接字</strong>，就会发现 unixstreamserver 这个进程，监听在 /var/lib/unixstream.sock 这个文件路径上。 </p><p><img src="/2019/10/28/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B4%E6%9C%AC%E5%9C%B0socket/1572059254012.png" alt="1572059254012"></p><h2 id="4-UDP-服务器端"><a href="#4-UDP-服务器端" class="headerlink" title="4. UDP 服务器端"></a>4. UDP 服务器端</h2><p>代码：</p><pre><code class="c">#include  &quot;lib/common.h&quot;int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: unixdataserver &lt;local_path&gt;&quot;);    }    // 创建本地套接字，这里创建的套接字类型，注意是 AF_LOCAL，协议类型为 SOCK_DGRAM。    int socket_fd;    socket_fd = socket(AF_LOCAL, SOCK_DGRAM, 0);    if (socket_fd &lt; 0) {        error(1, errno, &quot;socket create failed&quot;);    }    struct sockaddr_un servaddr;    char *local_path = argv[1];    unlink(local_path);    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sun_family = AF_LOCAL;    strcpy(servaddr.sun_path, local_path);    // 绑定到本地地址，而且这里bind 到本地地址之后，没有再调用 listen 和 accept    // 这其实和 UDP 的性质一样。    if (bind(socket_fd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr)) &lt; 0) {        error(1, errno, &quot;bind failed&quot;);    }    char buf[BUFFER_SIZE];    struct sockaddr_un client_addr;    socklen_t client_len = sizeof(client_addr);    // 使用 recvfrom 和 sendto 来进行数据报的收发，不再是 read 和 send，    // 这其实也和 UDP 网络程序一致。    while (1) {        bzero(buf, sizeof(buf));        if (recvfrom(socket_fd, buf, BUFFER_SIZE, 0, (struct sockadd *) &amp;client_addr, &amp;client_len) == 0) {            printf(&quot;client quit&quot;);            break;        }        printf(&quot;Receive: %s \n&quot;, buf);        char send_line[MAXLINE];        bzero(send_line, MAXLINE);        sprintf(send_line, &quot;Hi, %s&quot;, buf);        size_t nbytes = strlen(send_line);        printf(&quot;now sending: %s \n&quot;, send_line);        if (sendto(socket_fd, send_line, nbytes, 0, (struct sockadd *) &amp;client_addr, client_len) != nbytes)            error(1, errno, &quot;sendto error&quot;);    }    close(socket_fd);    exit(0);}</code></pre><h2 id="5-UDP-客户端"><a href="#5-UDP-客户端" class="headerlink" title="5. UDP 客户端"></a>5. UDP 客户端</h2><pre><code class="c">#include &quot;lib/common.h&quot;int main(int argc, char **argv) {    if (argc != 2) {        error(1, 0, &quot;usage: unixdataclient &lt;local_path&gt;&quot;);    }    int sockfd;    struct sockaddr_un client_addr, server_addr;    sockfd = socket(AF_LOCAL, SOCK_DGRAM, 0);    if (sockfd &lt; 0) {        error(1, errno, &quot;create socket failed&quot;);    }    bzero(&amp;client_addr, sizeof(client_addr));        /* bind an address for us */    client_addr.sun_family = AF_LOCAL;    strcpy(client_addr.sun_path, tmpnam(NULL));    if (bind(sockfd, (struct sockaddr *) &amp;client_addr, sizeof(client_addr)) &lt; 0) {        error(1, errno, &quot;bind failed&quot;);    }    bzero(&amp;server_addr, sizeof(server_addr));    server_addr.sun_family = AF_LOCAL;    strcpy(server_addr.sun_path, argv[1]);    char send_line[MAXLINE];    bzero(send_line, MAXLINE);    char recv_line[MAXLINE];    while (fgets(send_line, MAXLINE, stdin) != NULL) {        int i = strlen(send_line);        if (send_line[i - 1] == &#39;\n&#39;) {            send_line[i - 1] = 0;        }        size_t nbytes = strlen(send_line);        printf(&quot;now sending %s \n&quot;, send_line);        if (sendto(sockfd, send_line, nbytes, 0, (struct sockaddr *) &amp;server_addr, sizeof(server_addr)) != nbytes)            error(1, errno, &quot;sendto error&quot;);        int n = recvfrom(sockfd, recv_line, MAXLINE, 0, NULL, NULL);        recv_line[n] = 0;        fputs(recv_line, stdout);        fputs(&quot;\n&quot;, stdout);    }    exit(0);}</code></pre><p>这个程序和 UDP 网络编程的例子基本是一致的，我们可以把它当做是<strong>用本地文件替换了 IP 地址和端口</strong>的 UDP 程序，不过，这里还是有一个非常大的不同的。这个不同点就：将本地套接字 bind 到本地一个路径上，然而 UDP 客户端程序是不需要这么做的。本地数据报套接字这么做的原因是，它需要指定一个本地路径，以便在服务器端回包时，可以正确地找到地址；而在 UDP 客户端程序里，数据是可以通过 UDP 包的本地地址和端口来匹配的。 </p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程2：TCP协议使用socket</title>
      <link href="/2019/10/27/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2TCP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/"/>
      <url>/2019/10/27/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2TCP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><h2 id="0-TCP网络编程流程"><a href="#0-TCP网络编程流程" class="headerlink" title="0. TCP网络编程流程"></a>0. TCP网络编程流程</h2><p>还是下面的这张图，现在从编程使用的角度来详细理解这张图</p><p><img src="/2019/10/27/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2TCP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/1571886827623.png" alt="1571886827623"></p><h2 id="1-服务器端"><a href="#1-服务器端" class="headerlink" title="1. 服务器端"></a>1. 服务器端</h2><h3 id="1-1-创建socket"><a href="#1-1-创建socket" class="headerlink" title="1.1 创建socket"></a>1.1 创建socket</h3><p>要创建一个socket，需要用下面的函数</p><pre><code class="c++">int socket(int domain, int type, int protocol)</code></pre><ul><li><p><strong>domain</strong>： </p><p>PF_INET、PF_INET6 以及 PF_LOCAL 等，表示套接字的类型。</p></li><li><p><strong>type</strong>： </p><ul><li>SOCK_STREAM: 表示的是字节流，对应 TCP；</li><li>SOCK_DGRAM： 表示的是数据报，对应 UDP；</li><li>SOCK_RAW: 表示的是原始套接字。  </li></ul></li><li><p><strong>protocol</strong>：</p><p>原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成。protocol 目前一般写成 0 即可。 </p></li><li><p><strong>返回值</strong>：创建一个全新的socket描述字</p></li></ul><h3 id="1-2-设置bind"><a href="#1-2-设置bind" class="headerlink" title="1.2 设置bind"></a>1.2 设置bind</h3><pre><code class="c++">bind(int fd, sockaddr * addr, socklen_t len)</code></pre><p>bind 函数后面的第二个参数是通用地址格式<code>sockaddr * addr</code>，接收的是通用地址格式，实际上传入的参数可能是 IPv4、IPv6 或者本地套接字格式。<strong>bind 函数会根据 len 字段判断</strong>传入的参数 addr 该怎么解析，len 字段表示的就是传入的地址长度。 </p><p>对于使用者来说，每次需要将 IPv4、IPv6 或者本地套接字格式转化为通用套接字格式，就像下面的 IPv4 套接字地址格式的例子一样： </p><pre><code class="c++">struct sockaddr_in name;bind (sock, (struct sockaddr *) &amp;name, sizeof (name)</code></pre><p>可根据该地址结构的<strong>前两个字节</strong>判断出是哪种地址。为了处理长度可变的结构，需要读取函数里的第三个参数，也就是 len 字段，这样就可以对地址进行解析和判断了。 </p><p>设置 bind 的时候，对地址和端口可以有多种处理方式。</p><p>把地址设置成本机的 IP 地址，这相当告诉操作系统内核，仅仅对目标 IP 是本机 IP 地址的 IP 包进行处理。但是这样写的程序在部署时有一个问题，就是IP地址可能并不固定。这个时候，可以利用<strong>通配地址</strong>的能力帮助我们解决这个问题。通配地址相当于告诉操作系统内核：“只要目标地址是自己的都可以。”比如一台机器有两块网卡，IP 地址分别是 202.61.22.55 和 192.168.1.11，那么向这两个 IP 请求的请求包都会被我们编写的应用程序处理。 </p><p><strong>设置通配地址</strong></p><pre><code class="c++">struct sockaddr_in name;name.sin_addr.s_addr = htonl (INADDR_ANY); /* IPV4通配地址 */name.sin6_addr.s_addr = htonl (IN6ADDR_ANY); /* IPV6通配地址 */</code></pre><p> 除了地址，还有端口。如果把端口设置成 0，就相当于把端口的选择权交给操作系统内核来处理，操作系统内核会根据一定的算法选择一个空闲的端口，完成套接字的绑定。这在服务器端不常使用。</p><p>一般来说，服务器端的程序一定<strong>要绑定到一个众所周知的端口上</strong>。服务器端的 IP 地址和端口数据，相当于打电话拨号时需要知道的对方号码，如果没有电话号码，就没有办法和对方建立连接。 </p><h3 id="1-3-设置listen"><a href="#1-3-设置listen" class="headerlink" title="1.3 设置listen"></a>1.3 设置listen</h3><pre><code class="c++">int listen (int socketfd, int backlog)</code></pre><ul><li><p><strong>socketfd</strong>：</p><p>套接字描述符</p></li><li><p><strong>backlog</strong>：</p><p>未完成连接队列的大小，这个参数的大小决定了<strong>可以接收的并发数目</strong>。这个参数越大，并发数目理论上也会越大。但是参数过大也会占用过多的系统资源，一些系统，比如 Linux 并不允许对这个参数进行改变。  </p></li><li><p><strong>返回值</strong>： </p><p>经过listen设置的一个全新的socket描述字。</p></li></ul><h3 id="1-4-设置accept"><a href="#1-4-设置accept" class="headerlink" title="1.4 设置accept"></a>1.4 设置accept</h3><p>accept 这个函数的作用就是连接建立之后，<strong>操作系统内核和应用程序之间的桥梁</strong>。 </p><pre><code class="c">int accept(int listensockfd, struct sockaddr *cliaddr, socklen_t *addrlen)</code></pre><ul><li><p><strong>listensockfd</strong>：</p><p>是套接字，可以叫它为 <strong>listen 套接字</strong>，因为这就是前面通过 bind，listen 一系列操作而得到的套接字 </p></li><li><p><strong>cliaddr</strong>：</p><p>是通过指针方式获取的客户端的地址，可以将它看做一个后面会用到的返回值</p></li><li><p><strong>addrlen</strong>：</p><p>告诉我们地址的大小，这可以理解成当我们拿起电话机时，看到了来电显示，知道了对方的号码</p></li><li><p><strong>返回值</strong>： </p><p>一个全新的socket描述字，代表了与客户端的连接 。</p></li></ul><p><strong>注意</strong>：和这个函数相关的有两个套接字描述字：</p><ul><li>第一个是监听套接字描述字 listensockfd，它是作为输入参数存在的；</li><li>第二个是返回的已连接套接字描述字。 </li></ul><p>将这两个套接字分开的原因是：一个用于监听的listen套接字一直存在，它要为成千上万的客户服务，直到这个监听套接字关闭。<br>而一旦一个客户和服务器连接成功，完成了 TCP 三次握手，操作系统内核就为这个客户生成一个<strong>已连接套接字</strong>，让应用服务器使用这个已连接套接字和客户进行通信处理。如果应用服务器完成了对这个客户的服务，比如一次网购下单，一次付款成功，那么关闭的就是<strong>已连接套接字</strong>，这样就完成了 TCP 连接的释放。<br>请注意，这个时候释放的<strong>只是这一个客户连接</strong>，其它被服务的客户连接可能还存在。最重要的是，监听套接字一直都处于“监听”状态，等待新的客户请求到达并服务。 </p><h3 id="1-5-一个创建IPv4套接字的例子"><a href="#1-5-一个创建IPv4套接字的例子" class="headerlink" title="1.5 一个创建IPv4套接字的例子"></a>1.5 一个创建IPv4套接字的例子</h3><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;int make_socket (uint16_t port){  int sock;  struct sockaddr_in name;  /* 创建字节流类型的IPV4 socket. */  sock = socket (PF_INET, SOCK_STREAM, 0);  if (sock &lt; 0)    {      perror (&quot;socket&quot;);      exit (EXIT_FAILURE);    }  /* 绑定到port和ip. */  name.sin_family = AF_INET; /* IPV4 */  name.sin_port = htons (port);  /* 指定端口 */  name.sin_addr.s_addr = htonl (INADDR_ANY); /* 通配地址 */  /* 把IPV4地址转换成通用地址格式，同时传递长度 */  if (bind (sock, (struct sockaddr *) &amp;name, sizeof (name)) &lt; 0)    {      perror (&quot;bind&quot;);      exit (EXIT_FAILURE);    }  return sock}</code></pre><h2 id="2-客户端"><a href="#2-客户端" class="headerlink" title="2. 客户端"></a>2. 客户端</h2><h3 id="2-1-创建socket"><a href="#2-1-创建socket" class="headerlink" title="2.1 创建socket"></a>2.1 创建socket</h3><p>与服务器端的创建socket的方法完全一致，不再重复说明</p><h3 id="2-2-使用connect"><a href="#2-2-使用connect" class="headerlink" title="2.2 使用connect"></a>2.2 使用connect</h3><pre><code class="c++">int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen)</code></pre><ul><li><p><strong>sockfd</strong>：</p><p>连接套接字，通过前面讲述的 socket 函数创建</p></li><li><p><strong>servaddr</strong>：</p><p>指向套接字地址结构的指针，套接字地址结构必须含有服务器的 IP 地址和端口号。 </p></li><li><p><strong>addrlen</strong>：</p><p>该结构的大小 </p></li></ul><p>客户在调用函数 connect 前不必非得调用 bind 函数，因为，<strong>内核会确定源 IP 地址</strong>，并按照一定的算法<strong>选择一个临时端口作为源端口</strong>。 </p><p>如果是 <strong>TCP 套接字</strong>，那么调用 connect 函数将激发 TCP 的三次握手过程，而且仅在连接建立成功或出错时才返回。其中出错返回可能有以下几种情况： </p><ol><li><p><strong>收到TIMEOUT</strong>：</p><p>三次握手无法建立，客户端发出的 SYN 包没有任何响应，于是返回 TIMEOUT 错误。这种情况比较常见的原因是对应的服务端 IP 写错。 </p></li><li><p><strong>收到 RST（复位）</strong></p><p>这时候客户端会立即返回 CONNECTION REFUSED 错误。这种情况比较常见于客户端发送连接请求时的请求端口写错，因为 RST 是 TCP 在发生错误时发送的一种 TCP 分节。产生 RST 的三个条件是：目的地为某端口的 SYN 到达，然而该端口上没有正在监听的服务器（如前所述）；TCP 想取消一个已有连接；TCP 接收到一个根本不存在的连接上的分节。 </p></li><li><p><strong>目的不可达</strong>：</p><p>客户发出的 SYN 包在网络上引起了”destination unreachable”，即目的不可达的错误。这种情况比较常见的原因是客户端和服务器端路由不通。 </p></li></ol><h2 id="2-5-一个问题"><a href="#2-5-一个问题" class="headerlink" title="2.5 一个问题"></a>2.5 一个问题</h2><p>一段数据流从应用程序发送端，一直到应用程序接收端，总共经过了多少次拷贝？ </p><p><img src="/2019/10/27/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2TCP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/1572079784093.png" alt="1572079784093"></p><p><strong>发送端</strong>：</p><ol><li><p>当应用程序将数据送到发送缓冲区时，调用的是 send 或 write 方法，如果缓存中没有空间，系统调用就会失败或者阻塞。我们说，这个动作事实上是一次”显式拷贝“。而在这之后，数据将会按照 TCP/IP 的分层再次进行拷贝，这层的拷贝对我们来说就不是显式的了。 </p></li><li><p>接下来轮到 TCP 协议栈工作，创建 Packet 报文，并把报文发送到传输队列中（qdisc），传输队列是一个典型的 FIFO 队列，队列的最大值可以通过 ifocnfig 命令输出的 txqueuelen 来查看。通常情况下，这个值有几千报文大小。 </p></li><li><p>TX ring 在网络驱动和网卡之间，也是一个传输请求的队列。 </p></li><li><p>网卡作为物理设备工作在物理层，主要工作是把要发送的报文保存到内部的缓存中，并发送出去。 </p></li></ol><p><strong>接收端</strong>：</p><ol><li>报文首先到达网卡，由网卡保存在自己的接收缓存中</li><li>接下来报文被发送至网络驱动和网卡之间的 RX ring，网络驱动从 RX ring 获取报文 ，然后把报文发送到上层。  </li><li>网络驱动和上层之间没有缓存，因为网络驱动使用 Napi 进行数据传输。因此，可以认为上层直接从 RX ring 中读取报文。 </li><li>最后，报文的数据保存在套接字接收缓存中，应用程序从套接字接收缓存中读取数据。 </li></ol><h2 id="3-TCP三次握手"><a href="#3-TCP三次握手" class="headerlink" title="3. TCP三次握手"></a>3. TCP三次握手</h2><h3 id="3-1-流程"><a href="#3-1-流程" class="headerlink" title="3.1 流程"></a>3.1 流程</h3><p><img src="/2019/10/27/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2TCP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/1571967874610.png" alt="1571967874610"></p><p>LISTEN：服务器在等待进入呼叫</p><p>SYN_RECV：一个连接请求已经到达，等待确认</p><p>SYN_SENT：应用已经开始，打开一个连接</p><p>ESTABLISHED：正常数据传输状态</p><p><strong>服务器端</strong>：</p><ul><li>通过 socket，bind 和 listen 完成了被动套接字的准备工作，被动的意思就是等着别人来连接</li><li>调用 accept，就会阻塞在这里，等待客户端的连接来临；</li></ul><p><strong>客户端</strong>：</p><ul><li>通过调用 socket 和 connect 函数之后，也会阻塞在这里。</li><li>接下来的事情是由操作系统内核完成的，更具体一点的说，是操作系统内核网络协议栈在工作。 </li></ul><p><strong>步骤</strong>：</p><ol><li>客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号 j，客户端进入 <strong>SYNC_SENT</strong> 状态； </li><li>服务器端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 j+1，表示对 SYN 包 j 的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为 k，服务器端进入 <strong>SYNC_RCVD</strong> 状态； </li><li>客户端协议栈收到 ACK 之后，使得应用程序从 connect 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 <strong>ESTABLISHED</strong>，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据为 k+1； </li><li>应答包到达服务器端后，服务器端协议栈使得 accept 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务器端也进入 <strong>ESTABLISHED</strong> 状态。 </li></ol><p>形象一点的比喻是这样的，有 A 和 B 想进行通话：</p><ul><li><p>A 先对 B 说：“喂，你在么？我在的，我的口令是 j。”</p></li><li><p>B 收到之后大声回答：“我收到你的口令 j 并准备好了，你准备好了吗？我的口令是 k。”</p></li><li><p>A 收到之后也大声回答：“我收到你的口令 k 并准备好了，我们开始吧。”</p></li></ul><p>可以看到，这样的应答过程总共进行了三次，这就是 TCP 连接建立之所以被叫为“三次握手”的原因了。 </p><h3 id="3-2-为什么需要三次握手"><a href="#3-2-为什么需要三次握手" class="headerlink" title="3.2 为什么需要三次握手"></a>3.2 为什么需要三次握手</h3><p><strong>理解1</strong></p><blockquote><p>tcp连接的<strong>双方要确保各自的收发消息的能力都是正常的</strong>。</p></blockquote><p>客户端第一次发送握手消息到服务端，<br>服务端接收到握手消息后把ack和自己的syn一同发送给客户端，这是第二次握手，<br>当客户端接收到服务端发送来的第二次握手消息后，客户端可以确认“服务端的收发能力OK，客户端的收发能力OK”，但是服务端只能确认“客户端的发送OK，服务端的接收OK”，<br>所以还需要第三次握手，客户端收到服务端的第二次握手消息后，发起第三次握手消息，服务端收到客户端发送的第三次握手消息后，就能够确定“服务端的发送OK，客户端的接收OK”，<br>至此，客户端和服务端都能够确认自己和对方的收发能力OK，，tcp连接建立完成。 </p><p><strong>理解2</strong></p><blockquote><p>由于双方要实现可靠传输，<strong>需要获悉对方的SYN</strong>（ 同步序号 ）。</p></blockquote><p>为了实现可靠传输，发送方和接收方始终需要同步( SYNchronize )序号。 需要注意的是， 序号并不是从 0 开始的， 而是由发送方随机选择的初始序列号 ( Initial Sequence Number, ISN )开始 。 由于 TCP 是一个双向通信协议， 通信双方都有能力发送信息， 并接收响应。 因此， 通信双方都需要随机产生一个初始的序列号， 并且把这个起始值告诉对方。</p><p>于是， 这个过程就变成了下面这样。<br><img src="/2019/10/27/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2TCP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/1571968505306.png" alt="1571968505306"></p><p>理解3</p><blockquote><p><strong>保证通信正常需要一个来回</strong>，而客户端与服务器端分别都需要一个来回，合并起来就是三次</p></blockquote><ol><li>信道不安全，可能挂掉或者不通，因此保证通信需要一来一回</li><li>客户端的来回和服务端的来回 共四次 这是最多四次</li><li>客户端的回和服务端的来合并成一个，就是那个sync k ack j+1</li></ol><p>其实这个问题有点像一群人里面有两个爸爸和两个孩子，问一共有多少人一样，有一个人可以同时承担两个角色就相当于这里一次握手同时实现了两次操作的效果。</p><h2 id="4-发送数据"><a href="#4-发送数据" class="headerlink" title="4. 发送数据"></a>4. 发送数据</h2><p>发送时常用的函数有三个：</p><pre><code class="c">ssize_t write (int socketfd, const void *buffer, size_t size);ssize_t send (int socketfd, const void *buffer, size_t size, int flags);ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags)</code></pre><ol><li><p>write</p><p>常见的文件写函数，如果把 socketfd 换成文件描述符，就是普通的文件写入。 </p></li><li><p>send</p><p>发送带外数据，就需要使用第二个带 flag 的函数。所谓带外数据，是一种基于 TCP 协议的紧急数据，用于客户端 - 服务器在特定场景下的紧急处理。 </p></li><li><p>sendmsg</p><p>指定<strong>多重缓冲区</strong>传输数据，就需要使用这个函数，以结构体 msghdr 的方式发送数据。 </p></li></ol><h3 id="4-1发送缓冲区"><a href="#4-1发送缓冲区" class="headerlink" title="4.1发送缓冲区"></a>4.1发送缓冲区</h3><p>当 TCP 三次握手成功，TCP 连接成功建立后，操作系统内核会<strong>为每一个连接创建配套的基础设施</strong>，比如发送缓冲区。发送缓冲区的大小可以通过套接字选项来改变，当我们的应用程序调用 write 函数时，实际所做的事情是把数据从应用程序中拷贝到操作系统内核的发送缓冲区中，并不一定是把数据通过套接字写出去。 </p><ol><li>第一种情况：操作系统内核的发送缓冲区足够大，可以直接容纳这份数据，那么程序从 write 调用中退出，返回写入的字节数就是应用程序的数据大小。 </li><li>第二种情况：操作系统内核的发送缓冲区是够大了，不过还有数据没有发送完，或者数据发送完了，但是操作系统内核的发送缓冲区不足以容纳应用程序数据，在这种情况下，操作系统内核并不会返回，也不会报错，而是<strong>应用程序被阻塞</strong>，也就是说<strong>应用程序在 write 函数调用处停留，不直接返回</strong>。术语“挂起”也表达了相同的意思，不过“挂起”是从操作系统内核角度来说的。 </li></ol><p>实际上，每个操作系统内核的处理是不同的。大部分 UNIX 系统的做法是<strong>一直等到</strong>可以把应用程序数据<strong>完全放到</strong>操作系统内核的发送<strong>缓冲区中</strong>，再从系统调用中返回。 </p><p>当 TCP 连接建立之后，发送缓冲区就开始运作起来。可以把它想象成一条包裹流水线，有个聪明且忙碌的工人不断地从流水线上取出包裹（数据），这个工人会按照 TCP/IP 的语义，将取出的包裹（数据）封装成 TCP 的 MSS 包，以及 IP 的 MTU 包，最后走数据链路层将数据发送出去。</p><p>这样我们的发送缓冲区就又空了一部分，于是又可以继续从应用程序搬一部分数据到发送缓冲区里，这样一直进行下去，到某一个时刻，应用程序的数据可以完全放置到发送缓冲区里。</p><p>在这个时候，write 阻塞调用返回。注意返回的时刻，应用程序数据并没有全部被发送出去，发送缓冲区里还有部分数据，这部分数据会在稍后由操作系统内核通过网络发送出去。 </p><p><img src="/2019/10/27/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B2TCP%E5%8D%8F%E8%AE%AE%E4%BD%BF%E7%94%A8socket/1572054315442.png" alt="1572054315442"></p><h2 id="5-读取数据"><a href="#5-读取数据" class="headerlink" title="5. 读取数据"></a>5. 读取数据</h2><p>在 UNIX 的世界里万物都是文件，这就意味着可以将套接字描述符传递给那些原先为处理本地文件而设计的函数。这些函数包括 read 和 write 交换数据的函数。 </p><p>read函数：</p><pre><code class="c">ssize_t read (int socketfd, void *buffer, size_t size)</code></pre><p>几个参数的含义：</p><ol><li>socketfd：套接字描述字，也就是从这个套接字里面读取</li><li>buffer：存储结果的地方</li><li>size：从套接字里读取的字节数量</li></ol><blockquote><p>read 函数要求操作系统内核从套接字描述字 socketfd读取最多size个字节，并将结果存储到 buffer 中。返回值告诉我们实际读取的字节数目，也有一些特殊情况，如果返回值为 0，表示 EOF（end-of-file），这在网络中表示对端发送了 FIN 包，要处理断连的情况；如果返回值为 -1，表示出错。当然，如果是非阻塞 I/O，情况会略有不同 </p></blockquote><h2 id="附录A-code"><a href="#附录A-code" class="headerlink" title="附录A.  code"></a>附录A.  code</h2><h3 id="A-1-服务器端读取数据"><a href="#A-1-服务器端读取数据" class="headerlink" title="A.1 服务器端读取数据"></a>A.1 服务器端读取数据</h3><pre><code class="c">#include &quot;lib/common.h&quot;void read_data(int sockfd) {    ssize_t n;    char buf[1024];    int time = 0;    for (;;) {        fprintf(stdout, &quot;block in read\n&quot;);        if ((n = readn(sockfd, buf, 1024)) == 0)            return;        time++;        fprintf(stdout, &quot;1K read for %d \n&quot;, time);        usleep(1000);    }}int main(int argc, char **argv) {    int listenfd, connfd;    socklen_t clilen;    struct sockaddr_in cliaddr, servaddr;    listenfd = socket(AF_INET, SOCK_STREAM, 0);    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sin_family = AF_INET;    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);    servaddr.sin_port = htons(12345);    /* bind到本地地址，端口为12345 */    bind(listenfd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr));    /* listen的backlog为1024 */    listen(listenfd, 1024);    /* 循环处理用户请求 */    for (;;) {        clilen = sizeof(cliaddr);        connfd = accept(listenfd, (struct sockaddr *) &amp;cliaddr, &amp;clilen);        read_data(connfd);   /* 读取数据 */        close(connfd);          /* 关闭连接套接字，注意不是监听套接字*/    }}</code></pre><ul><li>21-35 行先后创建了 socket 套接字，bind 到对应地址和端口，并开始调用 listen 接口监听；</li><li>38-42 行循环等待连接，通过 accept 获取实际的连接，并开始读取数据；</li><li>8-15 行实际每次读取 1K 数据，之后休眠 1 秒，用来模拟服务器端处理时延。 </li></ul><h3 id="A-2-客户端发送数据"><a href="#A-2-客户端发送数据" class="headerlink" title="A.2 客户端发送数据"></a>A.2 客户端发送数据</h3><pre><code class="c++">#include &quot;lib/common.h&quot;#define MESSAGE_SIZE 102400void send_data(int sockfd) {    char *query;    query = malloc(MESSAGE_SIZE + 1);    for (int i = 0; i &lt; MESSAGE_SIZE; i++) {        query[i] = &#39;a&#39;;    }    query[MESSAGE_SIZE] = &#39;\0&#39;;    const char *cp;    cp = query;    size_t remaining = strlen(query);    while (remaining) {        int n_written = send(sockfd, cp, remaining, 0);        fprintf(stdout, &quot;send into buffer %ld \n&quot;, n_written);        if (n_written &lt;= 0) {            error(1, errno, &quot;send failed&quot;);            return;        }        remaining -= n_written;        cp += n_written;    }    return;}int main(int argc, char **argv) {    int sockfd;    struct sockaddr_in servaddr;    if (argc != 2)        error(1, 0, &quot;usage: tcpclient &lt;IPaddress&gt;&quot;);    sockfd = socket(AF_INET, SOCK_STREAM, 0);    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sin_family = AF_INET;    servaddr.sin_port = htons(12345);    inet_pton(AF_INET, argv[1], &amp;servaddr.sin_addr);    int connect_rt = connect(sockfd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr));    if (connect_rt &lt; 0) {        error(1, errno, &quot;connect failed &quot;);    }    send_data(sockfd);    exit(0);}</code></pre><ul><li>31-37 行先后创建了 socket 套接字，调用 connect 向对应服务器端发起连接请求</li><li>43 行在连接建立成功后，调用 send_data 发送数据</li><li>6-11 行初始化了一个长度为 MESSAGE_SIZE 的字符串流</li><li>16-25 行调用 send 函数将 MESSAGE_SIZE 长度的字符串流发送出去 </li></ul><h2 id="附录B-总结"><a href="#附录B-总结" class="headerlink" title="附录B. 总结"></a>附录B. 总结</h2><p>这一讲重点讲述了通过 send 和 read 来收发数据包，需要牢记以下两点：</p><ul><li>对于 send 来说，返回成功仅仅表示数据写到发送缓冲区成功，并不表示对端已经成功收到。</li><li>对于 read 来说，需要循环读取数据，并且需要考虑 EOF 等异常条件。 </li></ul>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络编程1：基础部分</title>
      <link href="/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/"/>
      <url>/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《网络编程实战》的内容总结！</p><h2 id="1-网络分层"><a href="#1-网络分层" class="headerlink" title="1. 网络分层"></a>1. 网络分层</h2><p><img src="/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/1571885227435.png" alt="1571885227435"></p><h2 id="2-unix系统"><a href="#2-unix系统" class="headerlink" title="2. unix系统"></a>2. unix系统</h2><p><img src="/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/1571885455788.png" alt="1571885455788"></p><p> <img src="/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/df2b6d77a0a46e3d9b068f6d517a15bb.png" alt="img"> </p><p><strong>SVR4</strong>（UNIX System V Release 4）是 AT&amp;T 的 UNIX 系统实验室的一个商业产品。它基本上是一个操作系统的大杂烩，这个操作系统之所以重要，是因为它是 System III/V 分支各家商业化 UNIX 操作系统的“先祖”，包括 IBM 的 AIX、HP 的 HP-UX、SGI 的 IRIX、Sun（后被 Oracle 收购）的 Solaris 等等。 </p><p><strong>Solaris</strong> 是由 Sun Microsystems（现为 Oracle）开发的 UNIX 系统版本，它基于 SVR4，并且在商业上获得了不俗的成绩。2005 年，Sun Microsystems 开源了 Solaris 操作系统的大部分源代码，作为 OpenSolaris 开放源代码操作系统的一部分。相对于 Linux，这个开源操作系统的进展比较一般。 </p><p><strong>BSD</strong>（Berkeley Software Distribution），我们上面已经介绍过了，是由加州大学伯克利分校的计算机系统研究组（CSRG）研究开发和分发的。4.2BSD 于 1983 年问世，其中就包括了网络编程套接口相关的设计和实现，4.3BSD 则于 1986 年发布，正是由于 TCP/IP 和 BSD 操作系统的完美拍档，才有了 TCP/IP 逐渐成为事实标准的这一历史进程。 </p><p><strong>macOS</strong> 系统又被称为 Darwin，它已被验证过就是一个 UNIX 操作系统。如果打开 Mac 系统的 socket.h 头文件定义，你会明显看到 macOS 系统和 BSD 千丝万缕的联系，说明这就是从 BSD 系统中移植到 macOS 系统来的。 </p><p><strong>Minix</strong>：刚才提到了 UNIX 操作系统不开源的问题，那么有没有一开始就开源的 UNIX 操作系统呢？这里就要提到 Linux 发展的第三个机遇，Minix 操作系统，它在早期是 Linux 发展的重要指引。这个操作系统是由一个叫做安迪·塔能鲍姆（Andy Tanenbaum）的教授开发的，他的本意是用来做 UNIX 教学的，甚至有人说，如果 Minix 操作系统也完全走社区开放的道路，那么未必有现在的 Linux 操作系统。当然，这些话咱们就权当做是马后炮了。Linux 早期从 Minix 中借鉴了一些思路，包括最早的文件系统等。 </p><p><strong>GNU</strong>：Linux 操作系统得以发展还有一个非常重要的因素，那就是 GNU（GNU’s NOT UNIX），它的创始人就是鼎鼎大名的理查·斯托曼（Richard Stallman）。斯托曼的想法是设计一个完全自由的软件系统，用户可以自由使用，自由修改这些软件系统。 </p><p><strong>LINUX</strong>： GNU 是这么解释为什么应该叫 GNU/Linux 的：“大多数基于 Linux 内核发布的操作系统，基本上都是 GNU 操作系统的修改版。 </p><p><img src="/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/1571885926693.png" alt="1571885926693"></p><h2 id="3-socket"><a href="#3-socket" class="headerlink" title="3. socket"></a>3. socket</h2><p><img src="/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/1571886827623.png" alt="1571886827623"></p><p>上面这张图中表示的是客户端与服务器工作的逻辑架构，这幅图的真正用意在于引入 socket 的概念，下面所有的操作，都是通过 socket 来完成的。无论是客户端的 connect，还是服务端的 accept，或者 read/write 操作等，socket 是用来<strong>建立连接，传输数据的唯一途径</strong>。 </p><h3 id="3-1-准备阶段"><a href="#3-1-准备阶段" class="headerlink" title="3.1 准备阶段"></a>3.1 准备阶段</h3><p><strong>服务器端</strong>：</p><ol><li>socket：初始化socket</li><li>bind：绑定操作，将自己的服务绑定在一个众所周知的地址和端口上</li><li>listen：将原先的socket转换成服务端的socket</li><li>accept：客户端阻塞在这里，并且在这里等待客户端请求的到来</li></ol><p><strong>客户端</strong>：</p><ol><li>socket：初始化socket</li><li>connect：通过这一步向服务器绑定过的那个地址+端口发起连接请求</li></ol><h3 id="3-2-连接请求"><a href="#3-2-连接请求" class="headerlink" title="3.2 连接请求"></a>3.2 连接请求</h3><p>这里的连接请求通过TCP三次握手来进行，在后面详细说明</p><h3 id="3-3-数据传输"><a href="#3-3-数据传输" class="headerlink" title="3.3 数据传输"></a>3.3 数据传输</h3><p><strong>客户端</strong>：</p><ol><li>向内核发起写请求：客户端向OS内核发起write字节流的操作</li><li>网络传输：内核协议栈将字节流通过网络设备传递到服务器端</li></ol><p><strong>服务器端</strong>：</p><ol><li>获取信息：服务器端从内核获得信息</li><li>读入进程：将字节流从内核读入到进程中，并开始业务逻辑的处理。</li></ol><p>需要注意的是，一旦连接建立，数据的传输就不再是单向的，而是双向的，这也是 TCP 的一个显著特性。 </p><h3 id="3-4-关闭连接"><a href="#3-4-关闭连接" class="headerlink" title="3.4 关闭连接"></a>3.4 关闭连接</h3><p>当客户端完成和服务器端的交互后，比如执行一次 Telnet 操作，或者一次 HTTP 请求，需要和服务器端<strong>断开连接</strong>时，就会执行 close 函数，</p><ol><li>操作系统内核此时会通过原先的连接链路向服务器端发送一个 FIN 包，</li><li>服务器收到之后执行被动关闭，这时候整个链路处于半关闭状态，</li><li>此后，服务器端也会执行 close 函数，整个链路才会真正关闭。</li><li>半关闭的状态下，发起 close 请求的一方在没有收到对方 FIN 包之前都认为连接是正常的；而在全关闭的状态下，双方都感知连接已经关闭。</li></ol><h2 id="4-socket的地址格式及比较"><a href="#4-socket的地址格式及比较" class="headerlink" title="4. socket的地址格式及比较"></a>4. socket的地址格式及比较</h2><h3 id="4-1-socket地址格式"><a href="#4-1-socket地址格式" class="headerlink" title="4.1 socket地址格式"></a>4.1 socket地址格式</h3><pre><code class="c++">/* POSIX.1g 规范规定了地址族为2字节的值.  */typedef unsigned short int sa_family_t;/* 描述通用套接字地址  */struct sockaddr{    sa_family_t sa_family;  /* 地址族.  16-bit*/    char sa_data[14];   /* 具体的地址值 112-bit */}; </code></pre><p>第一个字段是<strong>地址族</strong>，它表示使用什么样的方式对地址进行解释和保存，好比电话簿里的手机格式，或者是固话格式，这两种格式的长度和含义都是不同的。地址族在 glibc 里的定义非常多，常用的有以下几种：</p><ol><li><p>AF_LOCAL：表示的是本地地址，对应的是 Unix 套接字，这种情况一般用于本地 socket 通信，很多情况下也可以写成 AF_UNIX、AF_FILE；</p></li><li><p>AF_INET：因特网使用的 IPv4 地址；</p></li><li><p>AF_INET6：因特网使用的 IPv6 地址。 </p></li></ol><p>这里的 <strong>AF_ 表示的含义是 Address Family</strong>，但是很多情况下，我们也会看到以 PF_ 表示的宏，比如 PF_INET、PF_INET6 等，实际上 <strong>PF_ 的意思是 Protocol Family</strong>，也就是协议族的意思。</p><p>我们用 AF_xxx 这样的值来初始化 socket 地址，用 PF_xxx 这样的值来初始化 socket。我们在 &lt;sys/socket.h&gt; 头文件中可以清晰地看到，这两个值本身就是一一对应的。</p><pre><code class="c++">/* 各种地址族的宏定义  */#define AF_UNSPEC PF_UNSPEC#define AF_LOCAL  PF_LOCAL#define AF_UNIX   PF_UNIX#define AF_FILE   PF_FILE#define AF_INET   PF_INET#define AF_AX25   PF_AX25#define AF_IPX    PF_IPX#define AF_APPLETALK  PF_APPLETALK#define AF_NETROM PF_NETROM#define AF_BRIDGE PF_BRIDGE#define AF_ATMPVC PF_ATMPVC#define AF_X25    PF_X25#define AF_INET6  PF_INET6</code></pre><h3 id="4-2-IPv4套接字地址格式"><a href="#4-2-IPv4套接字地址格式" class="headerlink" title="4.2 IPv4套接字地址格式"></a>4.2 IPv4套接字地址格式</h3><pre><code class="c++">/* IPV4套接字地址，32bit值.  */typedef uint32_t in_addr_t;struct in_addr{    in_addr_t s_addr;};/* 描述IPV4的套接字地址格式  */struct sockaddr_in{    sa_family_t sin_family; /* 16-bit */    in_port_t sin_port;     /* 端口口  16-bit*/    struct in_addr sin_addr;    /* Internet address. 32-bit */    /* 这里仅仅用作占位符，不做实际用处  */    unsigned char sin_zero[8];};</code></pre><p>首先可以发现和 sockaddr 一样，都有一个 16-bit 的 sin_family 字段，对于 IPv4 来说这个值就是 AF_INET。 </p><p>接下来是端口号，我们可以看到端口号最多是 16-bit，也就是说最大支持 2 的 16 次方，这个数字是 65536，所以我们应该知道支持寻址的端口号最多就是 65535。</p><p>关于端口，这里重点阐述一下保留端口。所谓保留端口就是大家约定俗成的，已经被对应服务广为使用的端口，比如 ftp 的 21 端口，ssh 的 22 端口，http 的 80 端口等。一般而言，大于 5000 的端口可以作为我们自己应用程序的端口使用。 </p><p>下面是glibc的保留端口信息</p><pre><code class="c++">/* Standard well-known ports.  */enum  {    IPPORT_ECHO = 7,    /* Echo service.  */    IPPORT_DISCARD = 9,   /* Discard transmissions service.  */    IPPORT_SYSTAT = 11,   /* System status service.  */    IPPORT_DAYTIME = 13,  /* Time of day service.  */    IPPORT_NETSTAT = 15,  /* Network status service.  */    IPPORT_FTP = 21,    /* File Transfer Protocol.  */    IPPORT_TELNET = 23,   /* Telnet protocol.  */    IPPORT_SMTP = 25,   /* Simple Mail Transfer Protocol.  */    IPPORT_TIMESERVER = 37, /* Timeserver service.  */    IPPORT_NAMESERVER = 42, /* Domain Name Service.  */    IPPORT_WHOIS = 43,    /* Internet Whois service.  */    IPPORT_MTP = 57,    IPPORT_TFTP = 69,   /* Trivial File Transfer Protocol.  */    IPPORT_RJE = 77,    IPPORT_FINGER = 79,   /* Finger service.  */    IPPORT_TTYLINK = 87,    IPPORT_SUPDUP = 95,   /* SUPDUP protocol.  */    IPPORT_EXECSERVER = 512,  /* execd service.  */    IPPORT_LOGINSERVER = 513, /* rlogind service.  */    IPPORT_CMDSERVER = 514,    IPPORT_EFSSERVER = 520,    /* UDP ports.  */    IPPORT_BIFFUDP = 512,    IPPORT_WHOSERVER = 513,    IPPORT_ROUTESERVER = 520,    /* Ports less than this value are reserved for privileged processes.  */    IPPORT_RESERVED = 1024,    /* Ports greater this value are reserved for (non-privileged) servers.  */    IPPORT_USERRESERVED = 5000</code></pre><h3 id="4-3-IPv6套接字地址格式"><a href="#4-3-IPv6套接字地址格式" class="headerlink" title="4.3 IPv6套接字地址格式"></a>4.3 IPv6套接字地址格式</h3><pre><code class="c++">struct sockaddr_in6  {    sa_family_t sin6_family; /* 16-bit */    in_port_t sin6_port;  /* 传输端口号 # 16-bit */    uint32_t sin6_flowinfo; /* IPv6流控信息 32-bit*/    struct in6_addr sin6_addr;  /* IPv6地址128-bit */    uint32_t sin6_scope_id; /* IPv6域ID 32-bit */  };</code></pre><p>整个结构体长度是 28 个字节，其中流控信息和域 IP 先不用管，这两个字段，一个在 glibc 的官网上根本没出现，另一个是当前未使用的字段。这里的地址族显然应该是 AF_INET6，端口同 IPv4 地址一样，关键的地址从 32 位升级到 128 位，这个数字就大到恐怖了，完全解决了寻址数字不够的问题。 </p><p>请注意，以上无论 IPv4 还是 IPv6 的地址格式都是<strong>因特网套接字</strong>的格式，还有一种本地套接字格式，用来做为本地进程间的通信， 也就是前面提到的 AF_LOCAL。 </p><pre><code class="c++">struct sockaddr_un {    unsigned short sun_family; /* 固定为 AF_LOCAL */    char sun_path[108];   /* 路径名 */};</code></pre><h3 id="4-4-几种套接字地址格式比较"><a href="#4-4-几种套接字地址格式比较" class="headerlink" title="4.4 几种套接字地址格式比较"></a>4.4 几种套接字地址格式比较</h3><p><img src="/2019/10/26/networkProgram/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B1/1571965218185.png" alt="1571965218185"></p><p> unix系统有一种一统天下的简洁之美:一切皆文件，socket也是文件。 </p><ol><li><p>像sock_addr的结构体里描述的那样，几种套接字都要有地址族和地址两个字段。这容易理解，你要与外部通信，肯定要至少告诉计算机对方的地址和使用的是哪一种地址。与远程计算机的通信还需要一个端口号。而本地socket的不同之处在于不需要端口号，那么就有了问题2;</p></li><li><p>本地socket本质上是在<strong>访问本地的文件系统</strong>，所以自然不需要端口。远程socket是直接<strong>将一段字节流发送到远程计算机的一个进程</strong>，而远程计算机可能<strong>同时有多个进程在监听</strong>，所以用端口号标定要发给哪一个进程。 </p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> 网络编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统的一致性与共识</title>
      <link href="/2019/09/12/distribute/01/"/>
      <url>/2019/09/12/distribute/01/</url>
      
        <content type="html"><![CDATA[<p>@[toc]</p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文只从概念上讨论一致性与共识的相关概念以及分类，不涉及具体的一致性、共识算法的实现，具体的算法实现计划进行论文详细的翻译以及理解。</p><hr><h2 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>分布式系统中有多个服务节点，给定一系列的操作，在约定协议的保障下，使他们<strong>对外界呈现的状态是一致的</strong>，也就是说，<strong>保证集群中的所有服务节点中的数据完全相同</strong>，并且能够<strong>对某个提案（proposal）达成一致</strong>。</p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul><li><p><strong>分布式事务一致性</strong>：操作序列在多个服务节点中的执行顺序是一致的</p></li><li><p><strong>分布式数据一致性</strong>：数据在多份副本中存储时，各副本中的数据是一致的</p></li><li><p>因此，能够保证分布式事务的一致性，就可以保证数据的一致性。我们通常讨论的一致性指的就是数据一致性。</p></li></ul><h3 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h3><p>分布式系统达成一致的过程，有如下三个需要满足的性质：</p><ul><li><p><strong>可终止性（termination）</strong>: 一致的结果应当在有限的时间内能够完成</p><blockquote><p>这时系统能够正常使用的前提，但是现实生活中的这一点并不是总能够得到保障的，比如有时候打电话会无法连接等</p></blockquote></li><li><p><strong>约同性（agreement）</strong>: 不同的节点最终完成决策的结果是相同的</p><blockquote><p>意味着系统<strong>要么不给出结果</strong>，<strong>任何给出的结果都必定是达成了共识的</strong>，也就是安全性。</p></blockquote></li><li><p><strong>合法性（validity）</strong>: 最终达成一致的值必须是某个节点提出的提案</p></li></ul><p><strong>总结</strong>：如果一个由节点提出的提案，能在有限的时间内，达到一致性的结果，就说这个提案达到了一致性。</p><h3 id="分类-1"><a href="#分类-1" class="headerlink" title="分类"></a>分类</h3><p>因为一致性的分类比较多，先写一个目录，再在后面详细介绍</p><blockquote><ol><li>严格一致性（理想的一致性）</li><li>强一致性<ol><li>顺序一致性（sequential consistency）</li><li>线性一致性（linearizability）</li></ol></li><li>弱一致性</li><li>最终一致性（属于弱一致性）<ol><li>因果一致性（causal consistency）</li><li>读己之所写（read your writes）</li><li>会话一致性（session consistency）</li><li>单调读一致性（monotonic read consistency）</li><li>单调写一致性（monotonic write consistency）</li></ol></li></ol></blockquote><ol><li><p><strong>严格一致性</strong></p><ul><li><p><strong>定义</strong>：对于数据项x的任何<strong>读操作</strong>将返回<strong>最近一次对x进行的写操作的结果</strong>所对应的值</p></li><li><p><strong>问题</strong>：它依赖于绝对的全局时间，对于所有的进程来说，<strong><em>所有的写操作都是瞬间可见的</em></strong>，系统维持着一个绝对的全局时间顺序。如果一个数据项被改变，那么无论数据项改变之后多久执行操作，无论哪些进程执行读操作，无论这些进程的位置如何，所有在该数据项上执行的后续操作都将读取最新的数据。</p></li><li><p><strong>可行性分析</strong>：严格一致性要求系统不发生任何故障，而且所有节点之间的通信无须任何时间，所有的读写操作都是瞬间可见的。但是这时<strong>候整个系统就等价于一台机器了</strong>。因此在现实生活中，这种一致性是不可能达到的。</p><p>越强的一致性往往会造成越弱的处理性能，以及越差的可扩展性。</p></li></ul></li><li><p><strong>强一致性</strong></p><p>需要满足的要求为：当分布式系统中<strong>更新操作完成之后</strong>，任何多个线程或进程，访问系统都会获得最新的值。反过来也就意味着，<strong>只要上次的更新操作没有处理完，就不能让用户读取数据</strong>。</p><p>一般来说，强一致性包括下面两类：</p><ul><li><p><strong>顺序一致性</strong>：保证所有进程</p><blockquote><p>假设有两个线程（线程1和线程2）分别运行在两个CPU上，有2个初始值为0的全局共享变量x和y，两个线程分别执行下面两条命令：</p><p>初始条件：$x=y=0$</p><table><thead><tr><th align="center">x线程1</th><th align="center">线程2</th></tr></thead><tbody><tr><td align="center">$x=1$</td><td align="center">$y=1$</td></tr><tr><td align="center">$r_1=y$</td><td align="center">$r_2=x$</td></tr></tbody></table><p>因为多线程的程序时交错执行的，没有固定的顺序，因此程序可能有如下几种执行的顺序：</p><table><thead><tr><th>执行1</th><th>执行2</th><th>执行3</th></tr></thead><tbody><tr><td>$x=1$ <br>$r_1=y$ <br>$y=1$ <br>$r_2=x$ <br>结果：$r_1=0,r_2=1$</td><td>$y=1$<br>$r_2=x$<br>$x=1$<br>r_1=y<br>结果：$r_1=1,r_2=0$</td><td>$x=1$<br>$y=1$<br>$r_1=y$<br>$r_2=x$<br>结果：$r_1=1,r_2=1$</td></tr></tbody></table><p>以上三种情况虽然没有包含所有的执行顺序，但是已经包含了所有可能出现的结果。这个程序不可能出现结果为$r_1=0,r_2=0$的结果。</p></blockquote><p>因此，所谓的顺序一致性，就是规定了以下两个条件</p><ul><li><p>每个线程内部的指令都是按照程序规定的顺序执行的</p><blockquote><p>线程1中两条语句在线程中一定是按照规定的顺序执行的</p></blockquote></li><li><p>所有线程所看见的整个程序的总体执行顺序是一样的</p><blockquote><p>比如有两个线程，每个线程的执行顺序都必须是执行1，执行2，执行3的一个，如果一个线程是执行1，则其他线程的执行顺序也必须是执行1，而不能是后面两个</p></blockquote></li></ul><p>总结：顺序一致性，<strong>要求所有线程所看见的整个程序的总体执行顺序是一样的</strong>，顺序一致性保证的是<strong>对一系列地址访问的一致性</strong>。</p></li><li><p><strong>线性一致性</strong>：假设操作具有一个全局有效时钟的时间戳，但是这个时钟仅有有限的精度，要求时间戳在前面的进程先执行，线性化是根据一系列同步时钟来确定序列顺序的。</p></li></ul></li><li><p><strong>弱一致性</strong></p><p>系统并不保证后续进程或进程的访问都会返回最新的更新的值。系统在<strong>数据成功写入之后</strong>，<strong>不承诺立刻会读到最新写入的值，也不承诺多久会读到</strong>。但是会尽可能保证在某个时间级别之后，让数据达到一致性的状态。也就是说，<strong>如果能够容忍后续的部分或者全部访问不到，则就是弱一致性</strong>。</p></li><li><p><strong>最终一致性</strong></p><p>是弱一致性的一种特定形式，系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值，也就是说，<strong>如果经过一段时间后要求能够访问到更新后的值，就是最终一致性</strong>。最终一致性有很多变种，下面进行介绍：</p><ol><li><p>因果一致性</p><blockquote><p>如果进程A在更新完某个数据项之后<strong>通知了进程B</strong>，那么进程B之后对该数据项的访问应该能够获取到进程A更新后的最新值，并且如果进程B要对改数据进行更新操作，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A没有因果关系的进程C的数据访问则没有这样的限制</p></blockquote></li><li><p>读己之所写</p><blockquote><p>进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，<strong>对于单个数据获取者来说，其读取到的数据，一定不会比自己上次写入的值旧</strong>。</p></blockquote></li><li><p>会话一致性</p><blockquote><p>对系统数据的<strong>访问过程框定在一个会话当中</strong>，系统能保证在同一个有效的会话中实现“读己之所写”的一致性。</p></blockquote></li><li><p>单调读一致性</p><blockquote><p>如果一个进程从系统中读取一个数据项的某个值后，那么系统对于该进程<strong>后续的任何数据访问都不应该返回更旧的值</strong>。</p></blockquote></li><li><p>单调写一致性</p><blockquote><p>一个系统需要能够保证来自同一个进程的写操作被顺序地执行。</p></blockquote></li></ol></li></ol><p>实现强一致性往往需要准确的计时设备，高精度的石英钟的漂移率为$10^{-7}$，最准确的原子震荡时钟的漂移率为$10^{-13}$，谷歌提出的方案可以让不同数据中心的时间偏差控制在10ms之内，虽然方案粗暴有效，但是成本较高。</p><p>由于强一致性很难实现，然而很多时候实际的需求并没有严格要求强一致性，因此可以适当放宽对一致性的要求，从而降低系统的实现难度，转而使用弱一致性。</p><hr><h2 id="共识（Consensus）"><a href="#共识（Consensus）" class="headerlink" title="共识（Consensus）"></a>共识（Consensus）</h2><h3 id="共识的定义"><a href="#共识的定义" class="headerlink" title="共识的定义"></a>共识的定义</h3><p>描述了分布式系统中多个节点之间，<strong>彼此对某个状态达成一致结果</strong>的过程。 </p><h3 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h3><p>共识算法解决的是<strong>对某个提案（proposal）达成一致意见的过程</strong>。</p><blockquote><p><strong>提案（proposal）</strong>：在分布式系统中概念十分宽泛，比如多个事件发生的顺序、某个key对应的value等等，可以认为，<strong>任何可以达成一致的信息都是一个proposal</strong>。</p></blockquote><p>对于分布式系统来讲，各个节点通常都是相同的确定性状态机模型（因此共识又称为状态机复制问题，state-machine replication），<strong>从相同的初始状态开始接受相同顺序的指令，则可以保证相同的结果状态。</strong>因此，系统中多个节点最关键的是对多个事件的顺序进行共识（即排序）。</p><p>共识算法的正确性要求是在运行中满足协定性、终止性、合法性三个条件的，并且所有的进程都有自己的初始值。<strong>如果只有一个进程有初始值，则这个进程被称为源进程，那么就是一个拜占庭共识问题。</strong>此时的完备性表述为：如果源进程是不作恶的，那么所有不作恶的节点决定值应该与源进程的初始值相同。</p><p>对于分布式系统来讲，各个节点通常都是确定性状态机模型（又称为状态机复制问题），只要保证从相同的初始状态开始接收相同顺序的指令，则可以保证相同的结果状态。因此，系统中多个节点最关键的是对多个事件的顺序进行共识（排序）</p><p><strong>共识算法可以分为</strong></p><ul><li><p><strong>Crash Fault Tolerance（CFT）类算法</strong></p><p>属于非拜占庭错误的情况（系统内的节点不会作恶），已经存在一些经典的解决算法，包括paxos，raft及其变种等，这类容错算法的性能较好，容忍不超过一半的故障节点</p></li><li><p><strong>Byzantine Fault Tolerance（BFT）类算法</strong></p><p>这种情况下，考虑系统中的节点作恶的问题，</p><p>一般包括PBFT为代表的<strong>确定性系列算法</strong>，PoW为代表的<strong>概率算法</strong>。</p><p>对于确定性算法，一旦达成对某个结果的共识，就不可逆转，即共识就是最终结果。</p><p>对于概率类算法，共识结果是临时的，随着时间的推移或者某种强化，共识结果被推翻的概率越来越小，称为事实上的最终结果。</p><p>拜占庭容错算法往往性能较差，容忍不超过1/3的故障节点，此外，XFT（Cross Fault Tolerance）等算法可以提供类似CFT的处理响应速度，并且能够在大多数节点正常工作的时候提供BFT保障。</p></li></ul><h2 id="对比一致性与共识性"><a href="#对比一致性与共识性" class="headerlink" title="对比一致性与共识性"></a>对比一致性与共识性</h2><p><strong>一致性问题</strong>：要研究客户端B怎么才能读取到客户端A做的修改，然后二者的数据可以达成一致。</p><p><strong>共识</strong>：是在一个或多个进程提议了一个值应当是什么之后，采用一种大家都认可的方法，使得系统中所有进程都对这个值达成一致意见。</p><p>这样的的协商过程在分布式视同中很常见，比如选主（leader election）问题中，所有进程对leader达成一致，互斥问题（mutual exclusion）中对于哪个进程进入临界区达成一致，原子组播（Atomic broadcast）中进程对消息传递的顺序达成一致。对于这些问题有一些特定的算法，但是分布式共识问题探讨更一般的形式，一旦能够解决分布式的共识问题，以上的问题就都可以得到解决。</p><p>一致性有强弱之分，可以分为严格一致性、强一致性、弱一致性，对外表现为分布式系统最终以何种形式达到一致性，共识问题则没有强弱之分，因为共识的最终目标就是让所有节点达成一致。只要能达成一致，就是共识。</p><p>共识方法在某种程度上可以看做是实现强一致性的一种方法，实际上工业界中有很多以共识算法作为核心组件的多副本状态机实现，本质上就是利用了共识算法保证了所有副本的操作日志具有完全相同的顺序，从而实现了副本的一致性。但是，即使在这样的场景下，讨论一个共识算法的一致性也是不合适的，因为分布式最终的一致性不单单取决于共识算法，共识算法只是解决了其中的一个问题。</p><p><a href="https://zhuanlan.zhihu.com/p/68743917" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/68743917</a></p><p><a href="https://www.iminho.me/wiki/docs/blockchain_guide/README.md" target="_blank" rel="noopener">https://www.iminho.me/wiki/docs/blockchain_guide/README.md</a></p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议学习（五）HTTPS与安全</title>
      <link href="/2019/08/05/http/030205/"/>
      <url>/2019/08/05/http/030205/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《透视HTTP协议》的内容总结！</p><p>@[toc]</p><h2 id="1-HTTPS"><a href="#1-HTTPS" class="headerlink" title="1. HTTPS"></a>1. HTTPS</h2><p>https的默认端口为443，其请求 - 应答模式、报文结构、请求方法、URI、头字段、连接管理等等都完全沿用 HTTP，与HTTP唯一不同的就是将不安全的明文变成了安全的密文</p><p>HTTPS 把 HTTP 下层的传输协议<strong>由 TCP/IP 换成了 SSL/TLS</strong>，由“HTTP over TCP/IP”变成了“HTTP over SSL/TLS”，让 HTTP 运行在了安全的 SSL/TLS 协议上，收发报文不再使用 Socket API，而是调用专门的安全接口。</p><p>因此，整个通信架构就变成了下面图中的样子</p><p><img src="/2019/08/05/http/030205/50d57e18813e18270747806d5d73f0a3.png" alt="img"> </p><p>因此，只有HTTPS与HTTP的唯一一点不同就是SSL/TLS。</p><h2 id="2-SSL-TLS"><a href="#2-SSL-TLS" class="headerlink" title="2. SSL/TLS"></a>2. SSL/TLS</h2><p>SSL 即安全套接层（Secure Sockets Layer），<strong>在 OSI 模型中处于第 5 层（会话层）</strong>，由网景公司于 1994 年发明，有 v2 和 v3 两个版本，而 v1 因为有严重的缺陷从未公开过。</p><p>SSL 发展到 v3 时已经证明了它自身是一个非常好的安全通信协议，于是互联网工程组 IETF 在 1999 年把它改名为 TLS（传输层安全，Transport Layer Security），正式标准化，版本号从 1.0 重新算起，所以 TLS1.0 实际上就是 SSLv3.1。</p><h3 id="2-1-TLS的密码套件"><a href="#2-1-TLS的密码套件" class="headerlink" title="2.1 TLS的密码套件"></a>2.1 TLS的密码套件</h3><p>浏览器和服务器在使用 TLS 建立连接时需要选择一组恰当的加密算法来实现安全通信，这些算法的组合被称为“密码套件”（cipher suite，也叫加密套件）。</p><p>TLS 的密码套件命名非常规范，格式很固定。基本的形式是“密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法”，比如下面这个密码套件：</p><pre><code>ECDHE-RSA-AES256-GCM-SHA384</code></pre><ul><li>握手时使用 ECDHE 算法进行<strong>密钥交换</strong>，</li><li>用 RSA <strong>签名和身份认证</strong>，</li><li><strong>握手后的通信</strong>使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM，</li><li><strong>摘要算法</strong> SHA384 用于消息认证和产生随机数。</li></ul><h3 id="2-2-OpenSSL"><a href="#2-2-OpenSSL" class="headerlink" title="2.2 OpenSSL"></a>2.2 OpenSSL</h3><p>是一个著名的开源密码学程序库和工具包，几乎支持所有公开的加密算法和协议，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，包括常用的 Web 服务器 Apache、Nginx 等。</p><h2 id="3-密码学概念"><a href="#3-密码学概念" class="headerlink" title="3. 密码学概念"></a>3. 密码学概念</h2><h3 id="3-1-对称加密"><a href="#3-1-对称加密" class="headerlink" title="3.1 对称加密"></a>3.1 对称加密</h3><p>TLS 里有非常多的对称加密算法可供选择，比如 RC4、DES、3DES、AES、ChaCha20 等，但前三种算法都被认为是不安全的，通常都禁止使用，目前常用的只有 AES 和 ChaCha20。</p><h4 id="3-1-1-加密算法"><a href="#3-1-1-加密算法" class="headerlink" title="3.1.1 加密算法"></a>3.1.1 加密算法</h4><ul><li><p><strong>AES</strong></p><p>意思是“高级加密标准”（Advanced Encryption Standard），密钥长度可以是 128、192 或 256。它是 DES 算法的替代者，安全强度很高，性能也很好，而且有的硬件还会做特殊优化，所以非常流行，是应用最广泛的对称加密算法。</p></li><li><p><strong>ChaCha20</strong></p><p>是 Google 设计的另一种加密算法，密钥长度固定为 256 位，纯软件运行性能要超过 AES，曾经在移动客户端上比较流行，但 ARMv8 之后也加入了 AES 硬件优化，所以现在不再具有明显的优势，但仍然算得上是一个不错算法。</p></li></ul><p>严格来说，对称加密算法还可以分为块加密算法和流加密算法。DES、AES属于块加密，RC4, ChaCha20属于流加密。</p><h4 id="3-1-2-加密分组模式"><a href="#3-1-2-加密分组模式" class="headerlink" title="3.1.2 加密分组模式"></a>3.1.2 加密分组模式</h4><p>分组模式可以让算法<strong>用固定长度的密钥加密任意长度的明文</strong>，把小秘密（即密钥）转化为大秘密（即密文）。</p><p>最早有 ECB、CBC、CFB、OFB 等几种分组模式，但都陆续被发现有安全漏洞，所以现在基本都不怎么用了。最新的分组模式被称为 AEAD（Authenticated Encryption with Associated Data），在加密的同时增加了认证的功能，常用的是 <strong>GCM、CCM 和 Poly1305</strong>。</p><p>将上面的组合起来，就可以的得到TLS密码套件中的对称加密算法</p><p>比如</p><ul><li>AES128-GCM，意思是密钥长度为 <strong>128 位的 AES 算法</strong>，使用的<strong>分组模式是 GCM</strong>；</li><li>ChaCha20-Poly1305 的意思是 ChaCha20 算法，使用的分组模式是 Poly1305。</li></ul><h3 id="3-2-非对称加密"><a href="#3-2-非对称加密" class="headerlink" title="3.2 非对称加密"></a>3.2 非对称加密</h3><h4 id="3-2-1-密钥交换"><a href="#3-2-1-密钥交换" class="headerlink" title="3.2.1 密钥交换"></a>3.2.1 密钥交换</h4><p>由于使用对称加密是无法解决密钥交换问题的，因此考虑使用非对称加密。</p><p>非对称加密可以解决“密钥交换”的问题。网站秘密保管私钥，在网上任意分发公钥，你想要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。而黑客因为没有私钥，所以就无法破解密文。</p><h4 id="3-2-2-非对称加密算法"><a href="#3-2-2-非对称加密算法" class="headerlink" title="3.2.2 非对称加密算法"></a>3.2.2 非对称加密算法</h4><ul><li><p><strong>RSA</strong></p><p>RSA 可能是其中最著名的一个，几乎可以说是非对称加密的代名词，它的安全性基于“整数分解”的数学难题，使用两个超大素数的乘积作为生成密钥的材料，想要从公钥推算出私钥是非常困难的。</p><p>10 年前 RSA 密钥的推荐长度是 1024，但随着计算机运算能力的提高，现在 1024 已经不安全，普遍认为至少要 2048 位。</p></li><li><p><strong>ECC</strong></p><p>基于“椭圆曲线离散对数”的数学难题，使用特定的曲线方程和基点生成公钥和私钥，子算法 <strong>ECDHE 用于密钥交换</strong>，<strong>ECDSA 用于数字签名</strong>。</p><blockquote><p>ECC虽然定义了公钥和私钥，但是不能直接实现密钥交换和身份认证，需要搭配DH、RS等算法，形成专门的ECDHE和ECDSA。RSA比较特殊，本身既支持密钥交换，也支持身份认证。</p></blockquote><p>目前比较常用的两个曲线是 P-256（secp256r1，在 OpenSSL 称为 prime256v1）和 x25519。</p><ul><li>P-256 是 NIST（美国国家标准技术研究所）和 NSA（美国国家安全局）推荐使用的曲线，</li><li>而 x25519 被认为是最安全、最快速的曲线。</li></ul><blockquote><p>比起 RSA，ECC 在安全强度和性能上都有明显的优势。</p><p>160 位的 ECC 相当于 1024 位的 RSA，而 224 位的 ECC 则相当于 2048 位的 RSA。因为密钥短，所以相应的计算量、消耗的内存和带宽也就少，加密解密的性能就上去了，对于现在的移动互联网非常有吸引力。</p><p>比特币、以太坊等区块链技术里也用到了ECC，他们选择的曲线是secp256k1</p></blockquote><p><img src="/2019/08/05/http/030205/1575258643028.png" alt="1575258643028"></p></li></ul><ul><li><p><strong>混合加密</strong></p><p>TLS 里使用混合加密方式：</p><ul><li>在通信刚开始的时候使用非对称算法，比如 RSA、ECDHE，首先解决密钥交换的问题。</li><li>然后用随机数产生对称算法使用的“<strong>会话密钥</strong>”（session key），再用公钥加密。因为会话密钥很短，通常只有 16 字节或 32 字节，所以慢一点也无所谓。</li><li>对方拿到密文后用私钥解密，取出会话密钥。这样，双方就实现了对称密钥的安全交换，后续就不再使用非对称加密，全都使用对称加密。</li></ul><p><img src="/2019/08/05/http/030205/1575258792285.png" alt="1575258792285"> </p></li></ul><p>这样混合加密就解决了对称加密算法的密钥交换问题，而且安全和性能兼顾，完美地实现了机密性。</p><h3 id="3-3-数字签名"><a href="#3-3-数字签名" class="headerlink" title="3.3 数字签名"></a>3.3 数字签名</h3><h4 id="3-3-1-摘要算法"><a href="#3-3-1-摘要算法" class="headerlink" title="3.3.1 摘要算法"></a>3.3.1 摘要算法</h4><p>目前 TLS 推荐使用的是 SHA-1 的后继者：SHA-2。SHA-2 实际上是一系列摘要算法的统称，总共有 6 种，常用的有 SHA224、SHA256、SHA384，分别能够生成 28 字节、32 字节、48 字节的摘要。</p><p>摘要算法可以保证数据的完整性，将消息进行摘要后加在明文后面，然后统一进行加密。也就是下面这张图中所表示的流程：</p><p><img src="/2019/08/05/http/030205/c2e10e9afa1393281b5633b1648f2696.png" alt="img"> </p><h4 id="3-3-2-数字签名"><a href="#3-3-2-数字签名" class="headerlink" title="3.3.2 数字签名"></a>3.3.2 数字签名</h4><p>使用<strong>私钥再加上摘要算法</strong>，就能够实现“数字签名”，同时实现“<strong>身份认证</strong>”和“<strong>不可否认</strong>”。</p><p>数字签名的原理，就是使用私钥加密、公钥解密。但又因为非对称加密效率太低，所以<strong>私钥只加密原文的摘要</strong>，这样运算量就小的多，而且得到的数字签名也很小，方便保管和传输。</p><p>签名和公钥一样完全公开，任何人都可以获取。但这个签名只有用私钥对应的公钥才能解开，拿到摘要后，再比对原文验证完整性，就可以像签署文件一样证明消息确实是你发的。</p><p><img src="/2019/08/05/http/030205/1575267225589.png" alt="1575267225589"></p><p>只要你和网站互相交换公钥，就可以用“签名”和“验签”来确认消息的真实性，<strong>因为私钥保密</strong>，黑客不能伪造签名，就能够保证通信双方的身份。</p><h3 id="3-4-数字证书与CA"><a href="#3-4-数字证书与CA" class="headerlink" title="3.4 数字证书与CA"></a>3.4 数字证书与CA</h3><p>前面提到的一系列工作都有一个没有解决的问题，那就是<strong>公钥的信任问题</strong>。因为谁都可以发布公钥，所以就缺少一种防范黑客伪造公钥的方法。</p><p>可以用类似密钥交换的方法来解决公钥认证问题，<strong>用别的私钥来给公钥签名</strong>，显然，这又会陷入“无穷递归”。因此，在这里，将会设置一个递归的终点，也就是找一个<strong>公认的可信第三方，让它作为“信任的起点，递归的终点”，构建起公钥的信任链</strong>。</p><p>这个“第三方”就是我们常说的 <strong>CA（Certificate Authority，证书认证机构）</strong>。它就像网络世界里的公安局、教育部、公证中心，具有极高的可信度，由它来给各个公钥签名，用自身的信誉来保证公钥无法伪造，是可信的。</p><h4 id="3-4-1-数字证书的定义"><a href="#3-4-1-数字证书的定义" class="headerlink" title="3.4.1 数字证书的定义"></a>3.4.1 数字证书的定义</h4><p>CA 对公钥的签名认证也是有格式的，不是简单地把公钥绑定在持有者身份上就完事了，还要包含序列号、用途、颁发者、有效时间等等，把这些打成一个包再签名，完整地证明公钥关联的各种信息，形成“数字证书”（Certificate）</p><p>签发的证书分 DV、OV、EV 三种，区别在于可信程度。DV 是最低的，只是域名级别的可信，背后是谁不知道。EV 是最高的，经过了法律和审计的严格核查，可以证明网站拥有者的身份（在浏览器地址栏会显示出公司的名字，例如 Apple、GitHub 的网站）。</p><p><strong>CA如何证明自己？</strong></p><p>这还是信任链的问题。小一点的 CA 可以让大 CA 签名认证，但链条的最后，也就是 Root CA，就只能自己证明自己了，这个就叫“自签名证书”（Self-Signed Certificate）或者“根证书”（Root Certificate）。你必须相信，否则整个证书信任链就走不下去了。</p><p><img src="/2019/08/05/http/030205/1575267644560.png" alt="1575267644560"></p><p>有了这个证书体系，操作系统和浏览器都内置了各大 CA 的根证书，上网的时候只要服务器发过来它的证书，就可以验证证书里的签名，顺着证书链（Certificate Chain）一层层地验证，直到找到根证书，就能够确定证书是可信的，从而里面的公钥也是可信的。</p><h3 id="3-5-证书体系PKI"><a href="#3-5-证书体系PKI" class="headerlink" title="3.5 证书体系PKI"></a>3.5 证书体系PKI</h3><p>证书体系（PKI，Public Key Infrastructure）虽然是目前整个网络世界的安全基础设施，但绝对的安全是不存在的，它也有弱点，还是关键的“信任”二字。</p><p>如果 CA 失误或者被欺骗，签发了错误的证书，虽然证书是真的，可它代表的网站却是假的。</p><p>还有一种更危险的情况，CA 被黑客攻陷，或者 CA 有恶意，因为它（即根证书）是信任的源头，整个信任链里的所有证书也就都不可信了。</p><p>针对第一种，开发出了 <strong>CRL（证书吊销列表，Certificate revocation list）</strong>和 <strong>OCSP（在线证书状态协议，Online Certificate Status Protocol）</strong>，及时废止有问题的证书。</p><p>对于第二种，因为涉及的证书太多，就只能操作系统或者浏览器从根上“下狠手”了，<strong>撤销对 CA 的信任</strong>，列入“黑名单”，这样它颁发的所有证书就都会被认为是不安全的。</p><p>总结一下3.3-3.5节的内容，可以得到下面几条结论：</p><ul><li>摘要算法用来实现完整性，能够为数据生成独一无二的“指纹”，常用的算法是 SHA-2；</li><li>数字签名是私钥对摘要的加密，可以由公钥解密后验证，实现身份认证和不可否认；</li><li>公钥的分发需要使用数字证书，必须由 CA 的信任链来验证，否则就是不可信的；</li><li>作为信任链的源头 CA 有时也会不可信，解决办法有 CRL、OCSP，还有终止信任。</li></ul><h2 id="4-TLS-1-2-连接过程"><a href="#4-TLS-1-2-连接过程" class="headerlink" title="4. TLS 1.2 连接过程"></a>4. TLS 1.2 连接过程</h2><p><strong>HTTPS建立连接</strong></p><p>浏览器首先要从 URI 里提取出协议名和域名。因为协议名是“https”，所以浏览器就知道了端口号是默认的 443，它再用 DNS 解析域名，得到目标的 IP 地址，然后就可以使用三次握手与网站建立 TCP 连接了。</p><p>在 HTTP 协议里，建立连接后，浏览器会立即发送请求报文。但现在是 HTTPS 协议，它<strong>需要再用另外一个“握手”过程</strong>，在 TCP 上建立安全连接，之后才是收发 HTTP 报文。</p><h3 id="4-1-TLS协议的组成"><a href="#4-1-TLS协议的组成" class="headerlink" title="4.1 TLS协议的组成"></a>4.1 TLS协议的组成</h3><p>TLS协议包含了以下几个子协议，可以理解为TLS是由几个不同职责的模块组成的。</p><ul><li><p><strong>记录协议（Record Protocol）</strong></p><p>规定了 TLS 收发数据的基本单位：记录（record）。它有点像是 TCP 里的 segment，所有的其他子协议都需要通过记录协议发出。但多个记录数据可以在一个 TCP 包里一次性发出，也并不需要像 TCP 那样返回 ACK。</p></li><li><p><strong>警报协议（Alert Protocol）</strong></p><p>职责是向对方发出警报信息，有点像是 HTTP 协议里的状态码。比如，protocol_version 就是不支持旧版本，bad_certificate 就是证书有问题，收到警报后另一方可以选择继续，也可以立即终止连接。</p></li><li><p><strong>握手协议（Handshake Protocol）</strong></p><p>是 TLS 里最复杂的子协议，要比 TCP 的 SYN/ACK 复杂的多，浏览器和服务器会在握手过程中协商 TLS 版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统。</p></li><li><p><strong>变更密码规范协议（Change Cipher Spec Protocol）</strong></p><p>它就是一个“通知”，告诉对方，后续的数据都将使用加密保护。那么反过来，在它之前，数据都是明文的。</p></li></ul><p>下面这张图描述了TLS的握手过程</p><p><img src="/2019/08/05/http/030205/69493b53f1b1d540acf886ebf021a26c.png" alt="img"></p><h3 id="4-2-ECDHE-握手过程"><a href="#4-2-ECDHE-握手过程" class="headerlink" title="4.2 ECDHE 握手过程 "></a>4.2 ECDHE 握手过程 <img src="/2019/08/05/http/030205/9caba6d4b527052bbe7168ed4013011e.png" alt="img"></h3><ul><li><p>在 TCP 建立连接之后，浏览器会首先发一个“Client Hello”消息，也就是跟服务器“打招呼”。里面有客户端的版本号、支持的密码套件，还有一个随机数（Client Random），用于后续生成会话密钥。</p><pre><code>Handshake Protocol: Client Hello    Version: TLS 1.2 (0x0303)    Random: 1cbf803321fd2623408dfe…    Cipher Suites (17 suites)        Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f)        Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)</code></pre></li><li><p>服务器收到“Client Hello”后，会返回一个“Server Hello”消息。把版本号对一下，也给出一个随机数（Server Random），然后从客户端的列表里选一个作为本次通信使用的密码套件，在这里它选择了“TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384”。</p><pre><code>Handshake Protocol: Server Hello    Version: TLS 1.2 (0x0303)    Random: 0e6320f21bae50842e96…    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)</code></pre><p>服务器为了证明自己的身份，就把证书也发给了客户端（Server Certificate）。接下来是一个关键的操作，因为服务器选择了 ECDHE 算法，所以它会在证书后发送“Server Key Exchange”消息，里面是椭圆曲线的公钥（Server Params），用来实现密钥交换算法，再加上自己的私钥签名认证。</p><pre><code>Handshake Protocol: Server Key Exchange    EC Diffie-Hellman Server Params        Curve Type: named_curve (0x03)        Named Curve: x25519 (0x001d)        Pubkey: 3b39deaf00217894e...        Signature Algorithm: rsa_pkcs1_sha512 (0x0601)        Signature: 37141adac38ea4...</code></pre><p>之后是“Server Hello Done”消息，服务器说：“我的信息就是这些，打招呼完毕。”</p><p>这样第一个消息往返就结束了（两个 TCP 包），结果是客户端和服务器通过明文共享了三个信息：</p><ul><li>Client Random</li><li>Server Random</li><li>Server Params</li></ul></li><li><p>客户端这时也拿到了服务器的证书，开始走证书链逐级验证，确认证书的真实性，再用证书公钥验证签名，就确认了服务器的身份。</p><p>然后，客户端按照密码套件的要求，也生成一个椭圆曲线的公钥（Client Params），用“Client Key Exchange”消息发给服务器。</p><pre><code>Handshake Protocol: Client Key Exchange    EC Diffie-Hellman Client Params        Pubkey: 8c674d0e08dc27b5eaa…</code></pre><p>现在客户端和服务器手里都拿到了密钥交换算法的两个参数（Client Params、Server Params），就用 ECDHE 算法一阵算，算出了一个新的东西，叫“Pre-Master”，其实也是一个随机数。</p><p>现在客户端和服务器手里有了三个随机数：Client Random、Server Random 和 Pre-Master。用这三个作为原始材料，就可以生成用于加密会  话的主密钥，叫“Master Secret”。而黑客因为拿不到“Pre-Master”，所以也就得不到主密钥。</p><blockquote><p>为什么非要三个随机数呢？</p><p>这就必须说 TLS 的设计者考虑得非常周到了，他们不信任客户端或服务器伪随机数的可靠性，为了保证真正的“完全随机”“不可预测”，把三个不可靠的随机数混合起来，那么“随机”的程度就非常高了，足够让黑客难以猜测。</p><p>“Master Secret”的计算方式如下：</p><pre><code>master_secret = PRF(pre_master_secret, &quot;master secret&quot;,                    ClientHello.random + ServerHello.random)</code></pre><p>这里的“PRF”就是伪随机数函数，它基于密码套件里的最后一个参数，比如这次的 SHA384，通过摘要算法来再一次强化“Master Secret”的随机性。</p></blockquote><p>主密钥有 48 字节，但它也不是最终用于通信的会话密钥，还会再用 PRF 扩展出更多的密钥，比如客户端发送用的会话密钥（client_write_key）、服务器发送用的会话密钥（server_write_key）等等，避免只用一个密钥带来的安全隐患。</p></li><li><p>有了主密钥和派生的会话密钥，握手就快结束了。客户端发一个“Change Cipher Spec”，然后再发一个“Finished”消息，把之前所有发送的数据做个摘要，再加密一下，让服务器做个验证。</p></li><li><p>服务器也是同样的操作，发“Change Cipher Spec”和“Finished”消息，双方都验证加密解密 OK，握手正式结束，后面就收发被加密的 HTTP 请求和响应了。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> HTTP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议学习（四）cookie、缓存、代理机制</title>
      <link href="/2019/07/20/http/030204/"/>
      <url>/2019/07/20/http/030204/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《透视HTTP协议》的内容总结！</p><p>@[toc]</p><h2 id="1-cookie机制"><a href="#1-cookie机制" class="headerlink" title="1. cookie机制"></a>1. cookie机制</h2><h3 id="1-1-cookie的简介与流程"><a href="#1-1-cookie的简介与流程" class="headerlink" title="1.1 cookie的简介与流程"></a>1.1 cookie的简介与流程</h3><p> HTTP Cookie（也叫Web Cookie或浏览器Cookie）是<strong>服务器发送到用户浏览器并保存在本地的一小块数据</strong>，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie<strong>使基于无状态的HTTP协议记录稳定的状态信息成为了可能</strong>。 </p><p>cookie机制的运行需要两个字段：响应头字段 <code>Set-Cookie</code> 和请求头字段 <code>Cookie</code>。</p><ul><li><strong>客户端</strong>第一次访问服务器的时候，由服务器生成一个独特的身份标识数据，格式是 <code>key=value</code>，把这个数据放进 <code>Set-Cookie</code> 字段里，随响应报文一同发送给浏览器。</li><li><strong>浏览器</strong>收到响应报文，看到里面有 Set-Cookie，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进 Cookie 字段里发给服务器。</li></ul><blockquote><p>服务器有时会在响应头里添加多个 Set-Cookie，存储多个<code>key=value</code>。但浏览器这边发送时不需要用多个 Cookie 字段，只要在一行里用<code>;</code>隔开就行。</p></blockquote><p>也就是下面这个流程</p><p><img src="/2019/07/20/http/030204/9f6cca61802d65d063e24aa9ca7c38a4.png" alt="img"></p><h3 id="1-2-cookie的属性"><a href="#1-2-cookie的属性" class="headerlink" title="1.2 cookie的属性"></a>1.2 cookie的属性</h3><p>Cookie 就是服务器委托浏览器存储在客户端里的一些数据，而这些数据通常都会记录用户的关键识别信息。所以，就需要在 <code>key=value</code> 外再用一些手段来保护，防止外泄或窃取，这些手段就是 Cookie 的属性。</p><ul><li><p><strong>生存周期</strong></p><p>Cookie 的生存周期，也就是它的有效期，让它只能在一段时间内可用，一旦超过这个期限浏览器就认为是 Cookie 失效，在存储里删除，也不会发送给服务器。</p><ol><li><strong>Expires</strong>：俗称“<strong>过期时间</strong>”，用的是绝对时间点，可以理解为“截止日期”</li><li><strong>Max-Age</strong>：相对时间，单位是秒，浏览器用<strong>收到报文的时间点再加上 Max-Age</strong>，就可以得到失效的绝对时间。</li></ol><p>Expires 和 Max-Age <strong>可以同时出现</strong>，两者的失效时间可以一致，也可以不一致，但浏览器会<strong>优先采用 Max-Age</strong> 计算失效期。</p></li><li><p><strong>作用域</strong></p><p>让浏览器<strong>仅发送给特定的服务器和 URI</strong>，避免被其他网站盗用。</p><ol><li><strong>Domain</strong>：指定了 Cookie 所属的域名</li><li><strong>Path</strong>：指定了 Cookie 所属的路径</li></ol><p>浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie。</p><blockquote><p>使用这两个属性可以为不同的域名和路径分别设置各自的 Cookie，比如“/19-1”用一个 Cookie，“/19-2”再用另外一个 Cookie，两者互不干扰。不过现实中为了省事，通常 Path 就用一个“/”或者直接省略，表示域名下的任意路径都允许使用 Cookie，让服务器自己去挑。</p></blockquote></li><li><p><strong>安全性</strong></p><ol><li><p><strong>HttpOnly</strong></p><p>属性“HttpOnly”会告诉浏览器，此 Cookie <strong>只能通过浏览器 HTTP 协议传输，禁止其他方式访问</strong>，浏览器的 JS 引擎就会禁用 document.cookie 等一切相关的 API，脚本攻击也就无从谈起了。</p></li><li><p><strong>SameSite</strong></p><p>另一个属性“SameSite”可以防范“跨站请求伪造”（XSRF）攻击，设置成“SameSite=Strict”可以<strong>严格限定 Cookie 不能随着跳转链接跨站发送</strong>，而“SameSite=Lax”则略宽松一点，<strong>允许 GET/HEAD 等安全方法，但禁止 POST 跨站发送</strong>。</p></li><li><p><strong>Secure</strong></p><p>表示这个 Cookie <strong>仅能用 HTTPS 协议加密传输</strong>，明文的 HTTP 协议会禁止发送。但 <strong>Cookie 本身不是加密的，浏览器里还是以明文的形式存在</strong>。</p></li></ol></li></ul><h3 id="1-3-cookie的应用"><a href="#1-3-cookie的应用" class="headerlink" title="1.3 cookie的应用"></a>1.3 cookie的应用</h3><ol><li><p><strong>身份识别</strong>：用于保存用户的登录信息，实现会话事务。</p><blockquote><p>比如，你用账号和密码登录某电商，登录成功后网站服务器就会发给浏览器一个 Cookie，内容大概是“name=yourid”，这样就成功地把身份标签贴在了你身上。之后你在网站里随便访问哪件商品的页面，浏览器都会自动把身份 Cookie 发给服务器，所以服务器总会知道你的身份，一方面免去了重复登录的麻烦，另一方面也能够自动记录你的浏览记录和购物下单（在后台数据库或者也用 Cookie），实现了“状态保持”。</p></blockquote></li><li><p><strong>广告跟踪</strong>：广告商网站通过浏览记录、cookie收集了个人信息，将这些信息卖个其他的商户，当访问这些商户的网站时就可以根据喜好进行广告推送。</p></li></ol><h2 id="2-缓存机制"><a href="#2-缓存机制" class="headerlink" title="2. 缓存机制"></a>2. 缓存机制</h2><p>缓存（Cache）是计算机领域里的一个重要概念，是优化系统性能的利器。</p><p>由于链路漫长，网络时延不可控，浏览器使用 HTTP 获取资源的成本较高。所以，非常有必要把“来之不易”的数据缓存起来，下次再请求的时候尽可能地复用。这样，就<strong>可以避免多次请求 - 应答的通信成本，节约网络带宽，也可以加快响应速度</strong>。</p><h3 id="2-1-缓存何时生效"><a href="#2-1-缓存何时生效" class="headerlink" title="2.1 缓存何时生效"></a>2.1 缓存何时生效</h3><p>在点击浏览器的“前进”“后退”按钮，此时不会发送网络请求，而是读取的磁盘上的缓存。在“前进”“后退”“跳转”这些重定向动作中浏览器用最基本的请求头，没有“Cache-Control”，所以就会检查缓存，直接利用之前的资源，不再进行网络通信。</p><h3 id="2-2-服务器的缓存控制"><a href="#2-2-服务器的缓存控制" class="headerlink" title="2.2 服务器的缓存控制"></a>2.2 服务器的缓存控制</h3><ul><li>浏览器发现缓存无数据，于是发送请求，向服务器获取资源；</li><li>服务器响应请求，返回资源，同时标记资源的有效期； </li><li>浏览器缓存资源，等待下次重用。</li></ul><p>服务器标记<strong>资源有效期</strong>使用的头字段是<code>Cache-Control</code>，里面的值<code>max-age=30</code>就是资源的有效时间，相当于告诉浏览器，“这个页面只能缓存 30 秒，之后就算是过期，不能用。”</p><blockquote><p>这里的 max-age 是“生存时间”（又叫“新鲜度”“缓存寿命”，类似 TTL，Time-To-Live），<strong>时间的计算起点是响应报文的创建时刻</strong>（即 Date 字段，也就是离开服务器的时刻），而不是客户端收到报文的时刻，也就是说包含了在链路传输过程中所有节点所停留的时间。</p><p>比如，服务器设定“max-age=5”，但因为网络质量很糟糕，等浏览器收到响应报文已经过去了 4 秒，那么这个资源在客户端就最多能够再存 1 秒钟，之后就会失效。</p></blockquote><p>“max-age”是 HTTP 缓存控制最常用的属性，此外在响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存：</p><ul><li><strong>no-store</strong>：不允许缓存，用于某些变化非常频繁的数据，例如秒杀页面；</li><li><strong>no-cache</strong>：它的字面含义容易与 no-store 搞混，实际的意思并不是不允许缓存，而是可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本；</li><li><strong>must-revalidate</strong>：又是一个和 no-cache 相似的词，它的意思是如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证。</li></ul><p>以上三种缓存控制流程可以用下面这张图来表示</p><p><img src="/2019/07/20/http/030204/1575252303612.png" alt="1575252303612"></p><h3 id="2-3-客户端的缓存控制"><a href="#2-3-客户端的缓存控制" class="headerlink" title="2.3 客户端的缓存控制"></a>2.3 客户端的缓存控制</h3><p>其实不止服务器可以发“Cache-Control”头，浏览器也可以发“Cache-Control”，也就是说请求 - 应答的双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略。</p><p><strong>刷新</strong></p><p>当点击浏览器的“刷新”按钮的时候，浏览器会在请求头里加一个<code>Cache-Control: max-age=0</code>。因为 <code>max-age</code> 是“生存时间”，所以设置 <code>max-age=0</code> 后浏览器就不会使用缓存，而是向服务器发请求。服务器看到 <code>max-age=0</code>，也就会用一个最新生成的报文回应浏览器。</p><p><strong>刷新与强制刷新</strong></p><ul><li><p>F5 和 Ctrl+R 都是普通刷新，若页面<strong>之前访问过，就会发一个空请求到服务器</strong>，服务器返回 304 Not Modified，表示资源未更新，可以使用浏览器缓存。</p></li><li><p>强制刷新 (ctrl+F5) 则<strong>不管浏览器是否缓存，都要重新去源站服务器请求资源</strong>，成功则返回 200。</p></li></ul><h3 id="2-4-条件请求"><a href="#2-4-条件请求" class="headerlink" title="2.4 条件请求"></a>2.4 条件请求</h3><p>浏览器用 <code>Cache-Control</code> 做缓存控制只能是刷新数据，不能很好地利用缓存数据，又因为缓存会失效，使用前还必须要<strong>去服务器验证是否是最新版</strong>。</p><p>浏览器可以用两个连续的请求组成“验证动作”：</p><ul><li>先是一个 HEAD，获取资源的修改时间等元信息，然后与缓存数据比较，</li><li>如果没有改动就使用缓存，节省网络流量，否则就再发一个 GET 请求，获取最新的版本。</li></ul><p>但这样的两个请求网络成本太高了，所以 HTTP 协议就<strong>定义了一系列“If”开头的“条件请求”字段</strong>，专门用来<strong>检查验证资源是否过期</strong>，把两个请求才能完成的工作合并在一个请求里做。而且，验证的责任也交给服务器，浏览器只需“坐享其成”。</p><p>条件请求一共有 5 个头字段，我们最常用的是 <code>if-Modified-Since</code> 和 <code>If-None-Match</code> 这两个。需要第一次的响应报文预先提供 <code>Last-modified</code> 和 <code>ETag</code> ，然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的。如果资源没有变，服务器就回应一个“304 Not Modified”，表示缓存依然有效，浏览器就可以更新一下有效期，然后放心大胆地使用缓存了。</p><p><img src="/2019/07/20/http/030204/b239d0804be630ce182e24ea9e4ab237.png" alt="img"> </p><h4 id="2-4-1-Last-Modified"><a href="#2-4-1-Last-Modified" class="headerlink" title="2.4.1 Last-Modified"></a>2.4.1 Last-Modified</h4><p>标准的HTTP请求头标签，用于记录页面的最后修改时间。</p><blockquote><p>在浏览器<strong>第一次请求某一个URL时</strong>，服务器端的返回状态会是200，内容是你请求的资源，同时有一个 <code>Last-Modified</code> 的属性标记此文件在服务期端最后被修改的时间，格式类似这样：</p><pre><code>Last-Modified: Fri, 12 May 2006 18:53:33 GMT</code></pre><p>后面跟的时间是服务器存储的文件修改时间</p></blockquote><p>Last-Modified与Etag类似。不过<strong>Last-Modified表示响应资源在服务器最后修改时间而已</strong>。</p><p>比如，一个文件在<strong>一秒内修改了多次</strong>，但因为修改时间是秒级，所以这一秒内的新版本无法区分。</p><p>再比如，一个文件定期更新，但有时会是同样的内容，实际上没有变化，用修改时间就会误以为发生了变化，传送给浏览器就会浪费带宽。</p><h4 id="2-4-2-if-Modified-Since"><a href="#2-4-2-if-Modified-Since" class="headerlink" title="2.4.2 if-Modified-Since"></a>2.4.2 if-Modified-Since</h4><p>标准的HTTP请求头标签，用于记录页面的最后修改时间。</p><blockquote><p>客户端第二次请求此URL时，根据 HTTP 协议的规定，浏览器会向服务器传送 <code>If-Modified-Since</code> 报头，询问该时间之后文件是否有被修改过：</p><pre><code>If-Modified-Since: Fri, 12 May 2006 18:53:33 GMT</code></pre><p>后面跟的时间是本地浏览器存储的文件修改时间</p><ul><li><p><strong>服务器端的资源没有变化</strong>，则时间一致，自动返回HTTP状态码304（Not Changed.）状态码，内容为空，客户端接到之后，就直接把本地缓存文件显示到浏览器中，这样就节省了传输数据量。</p></li><li><p><strong>服务器端资源发生改变或者重启服务器时</strong>，时间不一致，就返回HTTP状态码200和新的文件内容，客户端接到之后，会丢弃旧文件，把新文件缓存起来，并显示到浏览器中。</p></li></ul><p>以上操作可以保证不向客户端重复发出资源，也保证当服务器有变化时，客户端能够得到最新的资源。</p></blockquote><h4 id="2-4-3-ETag-与-If-None-Match"><a href="#2-4-3-ETag-与-If-None-Match" class="headerlink" title="2.4.3 ETag 与 If-None-Match"></a>2.4.3 ETag 与 If-None-Match</h4><p>ETag 是“实体标签”（Entity Tag）的缩写，是资源的一个唯一标识，主要是用来<strong>解决修改时间无法准确区分文件变化的问题</strong>。说白了，ETag为资源实体的哈希值。即ETag就是<strong>服务器生成的一个标记，用来标识返回值是否有变化</strong>。</p><p>Etag是属于HTTP <strong>1.1</strong>属性，它是由<strong>服务器生成</strong>返回给前端，</p><p>当<strong>第一次</strong>发起HTTP请求时，<strong>服务器</strong>会返回一个<strong>Etag</strong>。</p><p>在<strong>第二次</strong>发起<strong>同一个请求</strong>时，客户端会<strong>同时</strong>发送一个<strong>If-None-Match</strong>，而它的值就是<strong>Etag</strong>的值（此处由发起请求的客户端来设置）。 </p><p>然后，<strong>服务器会比</strong>对这个客服端发送过来的Etag<strong>是否与服务器的相同</strong>，</p><ul><li><p>如果<strong>相同</strong>，就将<strong>If-None-Match</strong>的值设为<strong>false</strong>，返回状态为<strong>304</strong>，<strong>客户端</strong>继续<strong>使用本地缓存</strong>，不解析服务器返回的数据（这种场景服务器也不返回数据，因为服务器的数据没有变化嘛）</p></li><li><p>如果不<strong>相同</strong>，就将<strong>If-None-Match</strong>的值设为<strong>true</strong>，返回状态为<strong>200，客户端重新解析服务器返回的数据</strong></p></li></ul><h2 id="3-代理服务"><a href="#3-代理服务" class="headerlink" title="3. 代理服务"></a>3. 代理服务</h2><p> 代理其实就相当于是在浏览器和服务器之间的一个中间商。</p><p><img src="/2019/07/20/http/030204/28237ef93ce0ddca076d2dc19c16fdf9.png" alt="img"></p><p>所谓的“代理服务”就是指服务本身不生产内容，而是处于中间位置转发上下游的请求和响应，具有双重身份：</p><ul><li>面向下游的用户时，表现为服务器，代表源服务器响应客户端的请求；</li><li>面向上游的源服务器时，又表现为客户端，代表客户端发送请求。</li></ul><h3 id="3-1-代理服务的作用"><a href="#3-1-代理服务的作用" class="headerlink" title="3.1 代理服务的作用"></a>3.1 代理服务的作用</h3><p><strong>负载均衡</strong>：因为在面向客户端时屏蔽了源服务器，客户端看到的只是代理服务器，源服务器究竟有多少台、是哪些 IP 地址都不知道。于是代理服务器就可以掌握请求分发的“大权”，决定由后面的哪台服务器来响应请求。</p><p><strong>健康检查</strong>：使用“心跳”等机制监控后端服务器，发现有故障就及时“踢出”集群，保证服务高可用；</p><p><strong>安全防护</strong>：保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载；</p><p><strong>加密卸载</strong>：对外网使用 SSL/TLS 加密通信认证，而在安全的内网不加密，消除加解密成本；</p><p><strong>数据过滤</strong>：拦截上下行的数据，任意指定策略修改请求或者响应；</p><p><strong>内容缓存</strong>：暂存、复用服务器响应。</p><h3 id="3-2-代理相关头字段"><a href="#3-2-代理相关头字段" class="headerlink" title="3.2 代理相关头字段"></a>3.2 代理相关头字段</h3><p><strong>Via</strong></p><p>Via 是一个通用字段，请求头或响应头里都可以出现。<strong>每当报文经过一个代理节点，代理服务器就会把自身的信息追加到字段的末尾</strong>，就像是经手人盖了一个章。</p><p><img src="/2019/07/20/http/030204/52a3bd760584972011f6be1a5258e2d7.png" alt="img"></p><p>上图中有两个代理，proxy1 和 proxy2。</p><ul><li>客户端发送请求会经过这两个代理，依次添加就是“Via:  proxy1, proxy2”，</li><li>服务器返回响应报文的时候就要反过来走，头字段就是“Via:  proxy2,  proxy1”。 </li></ul><p>Via 字段只解决了客户端和源服务器判断是否存在代理的问题，还不能知道对方的真实信息。</p><p><strong>X-Forwarded-For</strong></p><p>字面意思是“为谁而转发”，形式上和“Via”差不多，也是每经过一个代理节点就会在字段里追加一个信息。但“Via”追加的是代理主机名（或者域名），而“X-Forwarded-For”<strong>追加的是请求方的 IP 地址</strong>。所以，在字段里最左边的 IP 地址就客户端的地址。</p><p><strong>X-Real-IP</strong></p><p>是另一种获取客户端真实 IP 的手段，它的作用很简单，就是<strong>记录客户端 IP 地址，没有中间的代理信息</strong>，相当于是“X-Forwarded-For”的简化版。如果客户端和源服务器之间只有一个代理，那么这两个字段的值就是相同的。</p><p><strong>X-Forwarded-Host</strong> 和 <strong>X-Forwarded-Proto</strong>，它们的作用与 <strong>X-Real-IP</strong> 类似，只记录客户端的信息，分别是客户端请求的原始域名和原始协议名。</p><p>下面是一个真实HTTP请求中这些字段的信息</p><p><img src="/2019/07/20/http/030204/c5aa6d5f82e8cc1a35772293972446e7.png" alt="img"> </p><p>步骤：</p><ol><li><p>客户端 55061 先用三次握手连接到代理的 80 端口，然后发送 GET 请求；</p></li><li><p>代理不直接生产内容，所以就代表客户端，用 55063 端口连接到源服务器，也是三次握手；</p></li><li><p>代理成功连接源服务器后，发出了一个 HTTP/1.0 的 GET 请求；</p></li><li><p>因为 HTTP/1.0 默认是短连接，所以源服务器发送响应报文后立即用四次挥手关闭连接；</p></li><li><p>代理拿到响应报文后再发回给客户端，完成了一次代理服务。</p></li></ol><h3 id="3-3-代理协议"><a href="#3-3-代理协议" class="headerlink" title="3.3 代理协议"></a>3.3 代理协议</h3><p>有了“X-Forwarded-For”等头字段，<strong>源服务器就可以拿到准确的客户端信息了</strong>。但对于代理服务器来说它并不是一个最佳的解决方案。有两个原因：</p><ul><li><p>首先，因为通过“X-Forwarded-For”操作代理信息必须要解析 HTTP 报文头，这对于代理来说成本比较高，原本只需要简单地转发消息就好，而现在却必须要费力解析数据再修改数据，会降低代理的转发性能。</p></li><li><p>另一个问题是“X-Forwarded-For”等头<strong>必须要修改原始报文</strong>，而有些情况下是不允许甚至不可能的（比如使用 HTTPS 通信被加密）。</p></li></ul><p>所以就出现了一个专门的“代理协议”（The PROXY protocol），它由知名的代理软件 HAProxy 所定义，也是一个“事实标准”，被广泛采用（注意并不是 RFC）。<strong>它可以在不改动原始报文的情况下传递客户端的真实 IP</strong>。</p><p>“代理协议”<strong>在 HTTP 报文前增加了一行 ASCII 码文本，相当于又多了一个头</strong>。</p><p>这一行文本其实非常简单，开头必须是“PROXY”五个大写字母，然后是“TCP4”或者“TCP6”，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行（\r\n）结束。</p><blockquote><p>例如下面的这个例子，在 GET 请求行前多出了 PROXY 信息行，客户端的真实 IP 地址是“1.1.1.1”，端口号是 55555。</p><pre><code>PROXY TCP4 1.1.1.1 2.2.2.2 55555 80\r\nGET / HTTP/1.1\r\nHost: www.xxx.com\r\n\r\n</code></pre><p>服务器看到这样的报文，只要解析第一行就可以拿到客户端地址，不需要再去理会后面的 HTTP 数据，省了很多事情。</p></blockquote><p>不过代理协议并不支持“X-Forwarded-For”的链式地址形式，所以拿到客户端地址后再如何处理就需要代理服务器与后端自行约定。</p><h2 id="4-缓存代理"><a href="#4-缓存代理" class="headerlink" title="4. 缓存代理"></a>4. 缓存代理</h2><p>缓存代理就是<strong>支持缓存控制的代理服务</strong>。</p><p><img src="/2019/07/20/http/030204/5e8d10b5758685850aeed2a473a6cdc2.png" alt="img"> </p><p>在没有缓存的时候，代理服务器每次都是直接转发客户端和服务器的报文，中间不会存储任何数据，只有最简单的中转功能。</p><p>加上缓存之后，代理服务收到源服务器发来的响应数据后需要做两件事。</p><ul><li>第一个是把报文转发给客户端，</li><li>第二个就是把报文存入自己的 Cache 里。</li></ul><p>下一次再有相同的请求，代理服务器就可以直接发送 304 或者缓存数据，不必再从源服务器那里获取。这样就降低了客户端的等待时间，同时节约了源服务器的网络带宽。</p><h3 id="4-1-源服务器的缓存控制"><a href="#4-1-源服务器的缓存控制" class="headerlink" title="4.1 源服务器的缓存控制"></a>4.1 源服务器的缓存控制</h3><p>服务器端的“Cache-Control”属性：max-age、no-store、no-cache 和 must-revalidate可以约束客户端，也可以约束代理。</p><p>但客户端和代理是不一样的，客户端的缓存只是用户自己使用，而代理的缓存可能会为非常多的客户端提供服务。所以，需要对它的缓存再多一些限制条件。</p><p>首先，我们要区分客户端上的缓存和代理上的缓存，可以使用两个新属性“private”和“public”。</p><ul><li>“private”表示缓存只能在客户端保存，是用户“私有”的，不能放在代理上。</li><li>“public”的意思就是缓存完全开放，谁都可以存，谁都可以用。</li></ul><p>其次，缓存失效后的重新验证也要区分开（即使用条件请求“Last-modified”和“ETag”）</p><ul><li>“must-revalidate”是只要过期就必须回源服务器验证</li><li>“proxy-revalidate”只要求代理的缓存过期后必须验证，客户端不必回源，只验证到代理这个环节就行了。</li></ul><p>此外，缓存的生存时间可以使用新的“s-maxage”（s 是 share 的意思，注意 maxage 中间没有“-”）。</p><ul><li>这个字段只限定在代理上能够存多久，而客户端仍然使用“max-age”。</li></ul><p>还有一个代理专用的属性“no-transform”，它禁止缓存服务器对缓存下来的数据进行修改。</p><ul><li>代理有时候会对缓存下来的数据做一些优化，比如把图片生成 png、webp 等几种格式，方便今后的请求处理，而“no-transform”就会禁止这样做，不许“偷偷摸摸搞小动作”。</li></ul><p>以上这些控制信息，可以用下面的这个流程图进行详细的解释</p><p><img src="/2019/07/20/http/030204/1575256191001.png" alt="1575256191001"></p><h3 id="4-2-客户端的缓存控制"><a href="#4-2-客户端的缓存控制" class="headerlink" title="4.2 客户端的缓存控制"></a>4.2 客户端的缓存控制</h3><p><img src="/2019/07/20/http/030204/1575256295777.png" alt="1575256295777"> </p><p>max-age、no-store、no-cache 这三个属性在2.2节中已经说明了，在这里，这三个属性同样作用于代理和源服务器。</p><ul><li><strong>max-stale</strong>：意思是如果代理上的缓存过期了也可以接受，但不能过期太多，超过 x 秒也会不要。相当于延长了过期时间，是可以接受的过期时间</li><li><strong>min-fresh</strong>：意思是缓存必须有效，而且必须在 x 秒内有效。相当于缩短了过期时间， 是可以接受的新鲜时间 </li><li><strong>only-if-cached</strong>：表示<strong>只接受代理缓存的数据，不接受源服务器的响应</strong>。如果代理上没有缓存或者缓存过期，就应该给客户端返回一个 504（Gateway Timeout）。</li></ul><blockquote><p>比如，草莓上贴着标签“max-age=5”，现在已经在冰柜里存了 7 天。如果有请求“max-stale=2”，意思是过期两天也能接受，所以刚好能卖出去。</p><p>但要是“min-fresh=1”，这是绝对不允许过期的，就不会买走。这时如果有另外一个菠萝是“max-age=10”，那么“7+1&lt;10”，在一天之后还是新鲜的，所以就能卖出去。</p></blockquote><h3 id="4-3-Vary字段"><a href="#4-3-Vary字段" class="headerlink" title="4.3 Vary字段"></a>4.3 Vary字段</h3><p>它是内容协商的结果，相当于报文的一个版本标记。同一个请求，经过内容协商后可能会有不同的字符集、编码、浏览器等版本。比如，<code>Vary: Accept-Encoding</code>， <code>Vary: User-Agent</code>，缓存代理必须要存储这些不同的版本。</p><p>当再收到相同的请求时，代理就读取缓存里的“Vary”，对比请求头里相应的 <code>Accept-Encoding</code>，<code>User-Agent</code> 等字段，如果和上一个请求的完全匹配，比如都是“gzip”“Chrome”，就表示版本一致，可以返回缓存的数据。</p><h3 id="4-4-Purge字段"><a href="#4-4-Purge字段" class="headerlink" title="4.4 Purge字段"></a>4.4 Purge字段</h3><p>另一个问题是“Purge”，也就是“缓存清理”，它对于代理也是非常重要的功能，例如：</p><ul><li>过期的数据应该及时淘汰，避免占用空间；</li><li>源站的资源有更新，需要删除旧版本，主动换成最新版（即刷新）；</li><li>有时候会缓存了一些本不该存储的信息，例如网络谣言或者危险链接，必须尽快把它们删除。</li></ul><p>清理缓存的方法有很多，比较常用的一种做法是使用自定义请求方法“PURGE”，发给代理服务器，要求删除 URI 对应的缓存数据。</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> HTTP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议学习（三）数据传输与连接</title>
      <link href="/2019/07/10/http/030203/"/>
      <url>/2019/07/10/http/030203/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《透视HTTP协议》的内容总结！</p><p>@[toc]</p><h2 id="1-HTTP报文的body"><a href="#1-HTTP报文的body" class="headerlink" title="1. HTTP报文的body"></a>1. HTTP报文的body</h2><h3 id="1-1-数据类型与编码"><a href="#1-1-数据类型与编码" class="headerlink" title="1.1 数据类型与编码"></a>1.1 数据类型与编码</h3><p><strong>这部分说明的是MIME-type和Encoding type的对比</strong></p><p>HTTP 协议是<strong>应用层的协议</strong>，数据到达之后工作只能说是完成了一半，还必须要<strong>告诉上层应用这是什么数据</strong>才行，否则上层应用就会“不知所措”。</p><blockquote><p>在 HTTP 协议诞生之前就已经有了针对这种问题的解决方案，不过它是用在电子邮件系统里的，让电子邮件可以发送 ASCII 码以外的任意数据，方案的名字叫做“<strong>多用途互联网邮件扩展</strong>”（Multipurpose Internet Mail Extensions），简称为 MIME。</p></blockquote><p>HTTP <strong>取了MIME中的一部分，用来标记 body 的数据类型</strong>，这就是我们平常总能听到的“MIME type” </p><p>在 HTTP 里经常遇到的几个MIME type类别有以下几种：</p><ul><li>text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。</li><li>image：即图像文件，有 image/gif、image/jpeg、image/png 等。</li><li>audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。</li><li>application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，像刚才说的“黑盒”，就会是 application/octet-stream，即不透明的二进制数据。</li></ul><p>HTTP <strong>在传输时为了节约带宽，有时候还会压缩数据</strong>，并且使用<code>Encoding type</code>，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。</p><p>比起 MIME type 来说，Encoding type 就少了很多，常用的只有下面三种：</p><ul><li>gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；</li><li>deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；</li><li>br：一种专门为 HTTP 优化的新压缩算法（Brotli）。</li></ul><h3 id="1-2-数据类型使用的头字段"><a href="#1-2-数据类型使用的头字段" class="headerlink" title="1.2 数据类型使用的头字段"></a>1.2 数据类型使用的头字段</h3><p>在1.1中，为了说明body的数据类型，定义了两种不同的描述方式，HTTP 协议为此定义了两个 Accept 请求头字段和两个 Content 实体头字段，用于客户端和服务器进行“内容协商”。</p><p>这两个字段是这样定义的：</p><ul><li><strong>Accept请求头字段</strong>：客户端用 Accept 头告诉服务器希望接收什么样的数据</li><li><strong>Content实体头字段</strong>：服务器用 Content 头告诉客户端实际发送了什么样的数据。</li></ul><p><img src="/2019/07/10/http/030203/5191bce1329efa157a6cc37ab9e789b9.png" alt="img"> </p><ul><li><p><strong>使用MIME type</strong></p><p>Accept 字段标记的是客户端可理解的 MIME type，可以用<code>,</code>做分隔符列出多个类型，让服务器有更多的选择余地，例如下面的这个头：</p><pre><code>Accept: text/html,application/xml,image/webp,image/png</code></pre><p>也就是说，客户端向服务器请求 <code>html, xml, webp, png</code> 这四种类型的数据</p><p>相应的，服务器会在响应报文里用头字段 Content-Type 告诉实体数据的真实类型：</p><pre><code>Content-Type: text/htmlContent-Type: image/png</code></pre><p>这样浏览器看到报文里的类型是“text/html”就知道是 HTML 文件，会调用排版引擎渲染出页面，看到“image/png”就知道是一个 PNG 文件，就会在页面上显示出图像。</p></li><li><p><strong>使用Encoding type</strong></p><p>与MIME type类似，使用Encoding type的一个例子如下所示：</p><pre><code>Accept-Encoding: gzip, deflate, brContent-Encoding: gzip</code></pre><p>不过这两个字段是可以省略的</p><ul><li>如果请求报文里没有 Accept-Encoding 字段，就表示客户端不支持压缩数据；</li><li>如果响应报文里没有 Content-Encoding 字段，就表示响应数据没有被压缩。</li></ul></li></ul><h3 id="1-3-语言类型与编码"><a href="#1-3-语言类型与编码" class="headerlink" title="1.3 语言类型与编码"></a>1.3 语言类型与编码</h3><p><strong>语言类型</strong></p><p>指的就是人类使用的自然语言，例如英语、汉语、日语等，而这些自然语言可能还有下属的地区性方言，所以在<strong>需要明确区分的时候也要使用 <code>type-subtype</code> 的形式</strong>，不过这里的格式与数据类型不同，分隔符不是<code>/</code>，而是<code>-</code>。</p><blockquote><p>举几个例子：en 表示任意的英语，en-US 表示美式英语，en-GB 表示英式英语，而 zh-CN 就表示我们最常使用的汉语。</p></blockquote><p><strong>编码</strong></p><p>一般来说，编码通常都是使用<strong>遵循 UTF-8 字符编码方式的 Unicode 字符集</strong>。</p><blockquote><p>在计算机发展的早期，各个国家和地区的人们“各自为政”，发明了许多字符编码方式来处理文字，比如英语世界用的 ASCII、汉语世界用的 GBK、BIG5，日语世界用的 Shift_JIS 等。同样的一段文字，用一种编码显示正常，换另一种编码后可能就会变得一团糟。所以后来就出现了 Unicode 和 UTF-8，把世界上所有的语言都容纳在一种编码方案里，<strong>遵循 UTF-8 字符编码方式的 Unicode 字符集</strong>也成为了互联网上的标准字符集。</p></blockquote><p><strong>语言类型的协商</strong></p><p>HTTP 协议也使用 Accept 请求头字段和 Content 实体头字段，用于客户端和服务器就语言与编码进行“内容协商”。</p><ul><li><p>Accept请求头字段：</p><pre><code>Accept-Language: zh-CN, zh, en</code></pre><p>这个请求头会告诉服务器：“最好给我 zh-CN 的汉语文字，如果没有就用其他的汉语方言，如果还没有就给英文”。也就是说，上面的这个说明顺序是有优先级的。</p></li><li><p>Content实体头字段：</p><pre><code>Content-Language: zh-CN</code></pre><p>这就是服务器返回的确定语言类型</p></li></ul><p><strong>编码的协商</strong></p><p>字符集在 HTTP 里使用的请求头字段是 <code>Accept-Charset</code>，但<strong>响应头里却没有对应的 <code>Content-Charset</code>，而是在 <code>Content-Type</code> 字段的数据类型后面用<code>charset=xxx</code>来表示</strong>，这点需要特别注意。</p><ul><li><p>Accept请求头字段：</p><pre><code>Accept-Charset: gbk, utf-8</code></pre></li><li><p>content实体头字段：</p><pre><code>Content-Type: text/html; charset=utf-8</code></pre></li></ul><h3 id="1-4-内容协商的质量值"><a href="#1-4-内容协商的质量值" class="headerlink" title="1.4 内容协商的质量值"></a>1.4 内容协商的质量值</h3><p>在 HTTP 协议里用 Accept、Accept-Encoding、Accept-Language 等请求头字段进行内容协商的时候，还可以<strong>用一种特殊的 <code>q</code> 参数表示权重来设定优先级</strong>，这里的“q”是“quality factor”的意思。</p><p>权重的最大值是 1，最小值是 0.01，默认值是 1，如果值是 0 就表示拒绝。具体的形式是在数据类型或语言代码后面加一个<code>;</code>，然后是<code>q=value</code>。</p><p>这里要提醒的是<code>;</code>的用法，在大多数编程语言里<code>;</code>的断句语气要强于<code>,</code>，而在 HTTP 的内容协商里却恰好反了过来，<code>;</code>的意义是小于<code>,</code>的。</p><p>例如下面的Accept字段（Accept字段是MIME type）</p><pre><code>Accept: text/html,application/xml;q=0.9,*/*;q=0.8</code></pre><p><strong>内容协商的结果</strong></p><p>内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。但有的时候，服务器会在响应头里多加一个 Vary 字段，记录服务器在内容协商时参考的请求头字段，给出一点信息，例如：</p><pre><code>Vary: Accept-Encoding,User-Agent,Accept</code></pre><p>这个 Vary 字段表示服务器依据了 Accept-Encoding、User-Agent 和 Accept 这三个头字段，然后决定了发回的响应报文。</p><p>Vary 字段可以认为是响应报文的一个特殊的“版本标记”。每当 Accept 等请求头变化时，Vary 也会随着响应报文一起变化。也就是说，同一个 URI 可能会有多个不同的“版本”，主要用在传输链路中间的代理服务器实现缓存服务。</p><h3 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h3><p>总结下来，可以用一张图来表示</p><p><img src="/2019/07/10/http/030203/b2118315a977969ddfcc7ab9d26cb358.png" alt="img"></p><ul><li><p>数据类型表示实体数据的内容是什么，使用的是 MIME type，相关的头字段是 Accept 和 Content-Type；</p></li><li><p>数据编码表示实体数据的压缩方式，相关的头字段是 Accept-Encoding 和 Content-Encoding；</p></li><li><p>语言类型表示实体数据的自然语言，相关的头字段是 Accept-Language 和 Content-Language；</p></li><li><p>字符集表示实体数据的编码方式，相关的头字段是 Accept-Charset 和 Content-Type；</p></li><li><p>客户端需要在请求头里使用 Accept 等头字段与服务器进行“内容协商”，要求服务器返回最合适的数据；</p></li><li><p>Accept 等头字段可以用“,”顺序列出多个可能的选项，还可以用“;q=”参数来精确指定权重。  </p></li></ul><h2 id="2-HTTP传输大文件"><a href="#2-HTTP传输大文件" class="headerlink" title="2. HTTP传输大文件"></a>2. HTTP传输大文件</h2><h3 id="2-1-数据压缩"><a href="#2-1-数据压缩" class="headerlink" title="2.1 数据压缩"></a>2.1 数据压缩</h3><p>前面说到的使用Encoding的方法可以对数据进行压缩，但是缺点是gzip等压缩算法对文本文件效果比较好，但是对于其他的多媒体文件，本身就已经是高度压缩的，因此使用gzip等压缩方法压缩是没有特别好的效果的。</p><p><strong>压缩 HTML 等文本文件是传输大文件最基本的方法</strong>；</p><h3 id="2-2-分块传输"><a href="#2-2-分块传输" class="headerlink" title="2.2 分块传输"></a>2.2 分块传输</h3><p>这样浏览器和服务器都不用在内存里保存文件的全部，<strong>每次只收发一小部分</strong>，网络也不会被大文件长时间占用，内存、带宽等资源也就节省下来了。</p><p>这种“化整为零”的思路在 HTTP 协议里就是<strong>“chunked”分块传输编码</strong>，在响应报文里用头字段<code>Transfer-Encoding: chunked</code>来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。</p><p>分块传输也可以用于“流式数据”，例如由数据库动态生成的表单页面，这种情况下 body 数据的长度是未知的，<strong>无法在头字段<code>Content-Length</code>里给出确切的长度，所以也只能用 chunked 方式分块发送</strong>。</p><blockquote><p><code>Transfer-Encoding: chunked</code>和<code>Content-Length</code>这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输<strong>要么是长度已知，要么是长度未知</strong>（chunked），这一点一定要记住。</p></blockquote><p><strong>编码规则</strong></p><ul><li>每个分块包含两个部分，长度头和数据块（即下图中的<strong>分块长度</strong>和<strong>分块数据</strong>）；</li><li>长度头是以 CRLF（回车换行，即<code>\r\n</code>）结尾的一行明文，用 16 进制数字表示长度；</li><li>数据块紧跟在长度头后，最后也用 CRLF 结尾，但数据不包含 CRLF；</li><li>最后用一个长度为 0 的块表示结束，即<code>0\r\n\r\n</code></li></ul><p>用一张示意图表示如下：</p><p><img src="/2019/07/10/http/030203/25e7b09cf8cb4eaebba42b4598192410.png" alt="img"> </p><p><strong>分块传输可以流式收发数据，节约内存和带宽，使用响应头字段“Transfer-Encoding: chunked”来表示，分块的格式是 16 进制长度头 + 数据块；</strong></p><h3 id="2-3-范围请求"><a href="#2-3-范围请求" class="headerlink" title="2.3 范围请求"></a>2.3 范围请求</h3><p>范围请求，允许<strong>客户端在请求头里使用专用字段来表示只获取文件的一部分</strong>。</p><ul><li><p>服务器必须在响应头里使用字段 <code>Accept-Ranges: bytes</code> 明确告知客户端：“我是支持范围请求的”。</p></li><li><p>如果服务器不支持范围请求，可以发送 <code>Accept-Ranges: none</code>，或者干脆不发送 <code>Accept-Ranges</code> 字段。</p></li></ul><p>请求头 Range 是 HTTP 范围请求的专用字段，格式是<code>bytes=x-y</code>，其中的 x 和 y 是以字节为单位的数据范围。</p><p>要注意 x、y 表示的是“<strong>偏移量</strong>”，范围必须从 0 计数，以字节为单位计算。</p><blockquote><p>例如前 10 个字节表示为“0-9”，第二个 10 字节表示为“10-19”，而“0-10”实际上是前 11 个字节。</p></blockquote><p>Range 的格式也很灵活，起点 x 和终点 y 可以省略，能够很方便地表示正数或者倒数的范围。假设文件是 100 个字节，那么：</p><ul><li>“0-”表示从文档起点到文档终点，相当于“0-99”，即整个文件；</li><li>“10-”是从第 10 个字节开始到文档末尾，相当于“10-99”；</li><li>“-1”是文档的最后一个字节，相当于“99-99”；</li><li>“-10”是从文档末尾倒数 10 个字节，相当于“90-99”。</li></ul><p><strong>服务器收到Range字段后的操作</strong></p><ol><li>它必须检查范围是否合法，比如文件只有 100 个字节，但请求“200-300”，这就是范围越界了。服务器就会返回状态码 416，意思是“你的范围请求有误，我无法处理，请再检查一下”。</li><li>如果范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码<code>206 Partial Content</code>，和 200 的意思差不多，但表示 body 只是原数据的一部分。</li><li>服务器要添加一个响应头字段 <code>Content-Range</code>，告诉片段的实际偏移量和资源的总大小，格式是 <code>bytes x-y/length</code>，与 Range 头区别在没有<code>=</code>，范围后多了总长度。例如，对于“0-10”的范围请求，值就是 <code>bytes 0-10/100</code>。</li><li>发送数据，直接把片段用 TCP 发给客户端，一个范围请求就算是处理完了。</li></ol><blockquote><p>例如，下面这个请求，就是使用Range获取前32个字节</p><pre><code>GET /16-2 HTTP/1.1Host: www.chrono.comRange: bytes=0-31</code></pre><p>返回数据如下：</p><pre><code>HTTP/1.1 206 Partial ContentContent-Length: 32Accept-Ranges: bytesContent-Range: bytes 0-31/96// this is a plain text json doc</code></pre></blockquote><p>常用的下载工具里的多段下载、断点续传也是基于它实现的，要点是：</p><ul><li>先发个 HEAD，看服务器是否支持范围请求，同时获取文件的大小；</li><li>开 N 个线程，每个线程使用 Range 字段划分出各自负责下载的片段，发请求传输数据；</li><li>下载意外中断也不怕，不必重头再来一遍，只要根据上次的下载记录，用 Range 请求剩下的那一部分就可以了。</li></ul><p><strong>范围请求可以只获取部分数据，即“分块请求”，实现视频拖拽或者断点续传，使用请求头字段“Range”和响应头字段“Content-Range”，响应状态码必须是 206；</strong></p><h3 id="2-4-多段数据"><a href="#2-4-多段数据" class="headerlink" title="2.4 多段数据"></a>2.4 多段数据</h3><p>范围请求一次只获取一个片段，它还<strong>支持在 Range 头里使用多个“x-y”，一次性获取多个片段数据。</strong></p><p>这种情况需要使用一种特殊的 MIME 类型：<code>multipart/byteranges</code>，表示报文的 body 是由多段字节序列组成的，并且还要用一个参数<code>boundary=xxx</code>给出段之间的分隔标记。</p><p>多段数据的格式与分块传输也比较类似，但它需要用分隔标记 boundary 来区分不同的片段，可以通过图来对比一下。</p><p><img src="/2019/07/10/http/030203/fffa3a65e367c496428f3c0c4dac8a37.png" alt="img"> </p><p>每一个分段必须以<code>- -boundary</code>开始（前面加两个“-”），之后要用<code>Content-Type</code>和<code>Content-Range</code>标记这段数据的类型和所在范围，然后就像普通的响应头一样以回车换行结束，再加上分段数据，最后用一个<code>--boundary--</code>（前后各有两个<code>-</code>）表示所有的分段结束。</p><p>例如：</p><pre><code>GET /16-2 HTTP/1.1Host: www.chrono.comRange: bytes=0-9, 20-29</code></pre><p>得到的结果如下所示：</p><pre><code>HTTP/1.1 206 Partial ContentContent-Type: multipart/byteranges; boundary=00000000001Content-Length: 189Connection: keep-aliveAccept-Ranges: bytes--00000000001Content-Type: text/plainContent-Range: bytes 0-9/96// this is--00000000001Content-Type: text/plainContent-Range: bytes 20-29/96ext json d--00000000001--</code></pre><p>报文里的“- -00000000001”就是多段的分隔符，使用它客户端就可以很容易地区分出多段 Range 数据。</p><p><strong>可以一次请求多个范围，这时候响应报文的数据类型是“multipart/byteranges”，body 里的多个部分会用 boundary 字符串分隔。</strong></p><h2 id="3-连接管理"><a href="#3-连接管理" class="headerlink" title="3. 连接管理"></a>3. 连接管理</h2><h3 id="3-1-短连接"><a href="#3-1-短连接" class="headerlink" title="3.1 短连接"></a>3.1 短连接</h3><p>因为<strong>客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态</strong>，所以就被称为“<strong>短连接</strong>”（short-lived connections）。早期的 HTTP 协议也被称为是“<strong>无连接</strong>”的协议。</p><blockquote><p><strong>短连接的缺点:</strong></p><p>在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。TCP 建立连接要有“三次握手”，发送 3 个数据包，需要 1 个 RTT；关闭连接是“四次挥手”，4 个数据包需要 2 个 RTT。</p><p>而 HTTP 的一次简单“请求 - 响应”通常只需要 4 个包，如果不算服务器内部的处理时间，最多是 2 个 RTT。这么算下来，浪费的时间就是“3÷5=60%”，有三分之二的时间被浪费掉了，传输效率低得惊人。</p><p>也就是说，建立连接和关闭连接所需要的开销是比较大的，频繁地进行建立、断开连接会导致性能的急剧下降。<strong>短连接的缺点严重制约了服务器的服务能力，导致它无法处理更多的请求</strong>。</p><img src="/2019/07/10/http/030203/54315ed9ac37fbc6547258040f00a80c.png" alt="img" style="zoom:50%;"> </blockquote><h3 id="3-2-长连接"><a href="#3-2-长连接" class="headerlink" title="3.2 长连接"></a>3.2 长连接</h3><p>“长连接”的通信方式，也叫“<strong>持久连接</strong>”（persistent connections）、“<strong>连接保活</strong>”（keep alive）、“<strong>连接复用</strong>”（connection reuse）。</p><p>其实解决办法也很简单，用的就是“<strong>成本均摊</strong>”的思路，既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上。这样虽然不能改善 TCP 的连接效率，但基于“分母效应”，每个“请求 - 应答”的无效时间就会降低不少，整体传输效率也就提高了。</p><p>对比短连接，其实就是下面这张图中所描述的内容</p><p><img src="/2019/07/10/http/030203/57b3d80234a1f1b8c538a376aa01d3b4.png" alt="img"> </p><p><strong>长连接的缺点</strong>：</p><p>因为 TCP 连接长时间不关闭，<strong>服务器必须在内存里保存它的状态</strong>，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗尽服务器的资源，导致服务器无法为真正有需要的用户提供服务。</p><h3 id="3-3-连接相关的头字段"><a href="#3-3-连接相关的头字段" class="headerlink" title="3.3 连接相关的头字段"></a>3.3 连接相关的头字段</h3><p>由于长连接对性能的改善效果非常显著，所以<strong>在 HTTP/1.1 中的连接都会默认启用长连接</strong>。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接，在这个连接上收发数据。</p><p>可以在请求头中明确地指定需要使用长连接，也就是增加一个字段 <strong>Connection</strong>，值是“<strong>keep-alive</strong>”。</p><p>下面从各种不同的情况中分析客户端与服务器的设置。</p><ul><li><strong>客户端</strong><ol><li>向服务器发送的请求中如果包含<code>connection: keep-alive</code>，则后续的请求都会重复利用第一次打开的连接。</li><li>如果客户端发送的请求中包含的是<code>connection: close</code>字段，则表示<strong>此次通信之后</strong>就关闭连接。</li></ol></li><li><strong>服务器</strong><ol><li>如果支持长连接，不管客户端是否显式要求，它总会在响应报文中放一个<code>connection: keep-alive</code>的字段来告诉客户端自己支持长连接。服务器看到这个字段，就知道客户端要主动关闭连接，于是<strong>在响应报文里也加上这个字段</strong>，发送之后就调用 Socket API 关闭 TCP 连接。</li><li>服务器端通常不会主动断开连接，但是也可以设置一些策略来关闭连接<ul><li>使用 <code>keepalive_timeout</code> 指令，<strong>设置长连接的超时时间</strong>，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。</li><li>使用 <code>keepalive_requests</code> 指令，<strong>设置长连接上可发送的最大请求次数</strong>。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。</li></ul></li></ol></li></ul><h3 id="3-4-队头阻塞"><a href="#3-4-队头阻塞" class="headerlink" title="3.4 队头阻塞"></a>3.4 队头阻塞</h3><p>“队头阻塞”的意思是：如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本。与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。</p><p>因为 HTTP 规定报文必须是“一发一收”，这就<strong>形成了一个先进先出的“串行”队列</strong>。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。</p><p><img src="/2019/07/10/http/030203/1575248490669.png" alt="1575248490669"> </p><p><strong>性能优化</strong></p><p>因为队头阻塞的原因是HTTP的模型造成的，因此在这种模型不可变的情况下可以采用<strong>并发连接</strong>、<strong>域名分片</strong>来解决这种问题。</p><ul><li>并发连接：在服务器中多设置一些处理端口，进行并发处理，这样即使有某一个端口被阻塞，其他端口的处理也不会受到影响。</li><li>域名分片：在 HTTP/1.1 中，每个域名能打开的连接是受到限制的，大概为 6 - 8 个，具体取决于浏览器实现。如果你实在要加载大量资源，其中一个方法就是<strong>从多个域名中获取资源</strong>，这就是域名分片 (<em>domain sharding</em>)。</li></ul><h2 id="4-重定向与跳转"><a href="#4-重定向与跳转" class="headerlink" title="4. 重定向与跳转"></a>4. 重定向与跳转</h2><h3 id="4-1-跳转"><a href="#4-1-跳转" class="headerlink" title="4.1 跳转"></a>4.1 跳转</h3><ul><li><p><strong>主动跳转</strong></p><p>由客户端发起，在获取响应内容后会切换显示内容，渲染出新的URI指向这个页面。</p></li><li><p><strong>被动跳转</strong></p><p>由服务器发起，也叫作<strong>重定向</strong>。</p></li></ul><h3 id="4-2-重定向"><a href="#4-2-重定向" class="headerlink" title="4.2 重定向"></a>4.2 重定向</h3><p>在HTTP返回的状态码可以得知，301是永久重定向，302是临时重定向，浏览器收到这两个状态码后就会跳转到新的URI。</p><p>比如下面这个，在请求<code>/18-1</code>之后，会立即跳转到<code>index.html</code>页面，从下图可以看出，虽然是重定向，可实际上是发送了两次HTTP请求，第一个请求返回302，第二个请求被重定向到了<code>index.html</code>中。</p><p><img src="/2019/07/10/http/030203/ad5eb7546ee7ef62a9987120934b592d.png" alt="img"> </p><p>第一个响应报文如下：</p><p><img src="/2019/07/10/http/030203/a4276db758bf90f63fd5a5c2357af4ac.png" alt="img"> </p><p>其中有一个Location字段，它属于响应字段，必须出现在<strong>响应报文</strong>里。但只有配合 301/302 状态码才有意义，它标记了服务器要求重定向的 URI，这里就是要求浏览器跳转到“index.html”。</p><p>浏览器收到 301/302 报文，会检查响应头里有没有“Location”。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求，相当于自动替我们点击了这个链接。</p><blockquote><p>在“Location”里的 URI 既可以使用绝对 URI，也可以使用相对 URI。所谓“绝对 URI”，就是完整形式的 URI，包括 scheme、host:port、path 等。所谓“相对 URI”，就是省略了 scheme 和 host:port，只有 path 和 query 部分，是不完整的，但可以从请求上下文里计算得到。</p></blockquote><h3 id="4-3-重定向状态码"><a href="#4-3-重定向状态码" class="headerlink" title="4.3 重定向状态码"></a>4.3 重定向状态码</h3><ul><li><p>301 </p><p>俗称“<strong>永久重定向</strong>”（Moved Permanently），意思是原 URI 已经“永久”性地不存在了，今后的所有请求都必须改用新的 URI。</p><blockquote><p>浏览器看到 301，就知道原来的 URI“过时”了，就会做适当的优化。比如历史记录、更新书签，下次可能就会直接用新的 URI 访问，省去了再次跳转的成本。搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI。</p></blockquote></li><li><p>302</p><p>俗称“<strong>临时重定向</strong>”（“Moved Temporarily”），意思是原 URI 处于“临时维护”状态，新的 URI 是起“顶包”作用的“临时工”。</p><blockquote><p>浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，所以<strong>只会执行简单的跳转页面，不记录新的 URI</strong>，也不会有其他的多余动作，下次访问还是用原 URI。</p></blockquote></li><li><p>303</p><p><strong>See Other</strong>：类似 302，但要求重定向后的请求改为 GET 方法，访问一个结果页面，避免 POST/PUT 重复操作；</p></li><li><p>307</p><p><strong>Temporary Redirect</strong>：类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确；</p></li><li><p>308</p><p><strong>Permanent Redirect</strong>：类似 307，不允许重定向后的请求变动，但它是 301“永久重定向”的含义。</p></li></ul><h3 id="4-4-问题"><a href="#4-4-问题" class="headerlink" title="4.4 问题"></a>4.4 问题</h3><ul><li><p>性能损耗</p><p>很明显，重定向的机制决定了<strong>一个跳转会有两次请求 - 应答</strong>，比正常的访问多了一次。</p><blockquote><p>虽然 301/302 报文很小，但大量的跳转对服务器的影响也是不可忽视的。站内重定向还好说，可以长连接复用，<strong>站外重定向就要开两个连接</strong>，如果网络连接质量差，那成本可就高多了，会严重影响用户的体验。所以重定向应当适度使用，决不能滥用。</p></blockquote></li><li><p>循环跳转</p><p>如果重定向的策略设置欠考虑，可能会出现“A=&gt;B=&gt;C=&gt;A”的无限循环，不停地在这个链路里转圈圈，后果可想而知。所以 HTTP 协议特别规定，<strong>浏览器必须具有检测“循环跳转”的能力</strong>，在发现这种情况时应当停止发送请求并给出错误提示。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> HTTP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议学习（二）基础</title>
      <link href="/2019/07/01/http/030202/"/>
      <url>/2019/07/01/http/030202/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《透视HTTP协议》的内容总结！</p><p>@[toc]</p><h2 id="1-使用HTTP收发数据的流程"><a href="#1-使用HTTP收发数据的流程" class="headerlink" title="1. 使用HTTP收发数据的流程"></a>1. 使用HTTP收发数据的流程</h2><h3 id="1-1-使用IP地址访问web服务器"><a href="#1-1-使用IP地址访问web服务器" class="headerlink" title="1.1 使用IP地址访问web服务器"></a>1.1 使用IP地址访问web服务器</h3><ul><li>浏览器从地址栏的输入中获得服务器的 IP 地址和端口号；</li><li>浏览器用 TCP 的三次握手与服务器建立连接；</li><li>浏览器向服务器发送拼好的报文；</li><li>服务器收到报文后处理请求，同样拼好报文再发给浏览器；</li><li>浏览器解析报文，渲染输出页面。</li></ul><h3 id="1-2-使用域名访问web服务器"><a href="#1-2-使用域名访问web服务器" class="headerlink" title="1.2 使用域名访问web服务器"></a>1.2 使用域名访问web服务器</h3><p>在进行上面的操作之前，首先需要使用DNS将域名解析成IP地址，正常情况下的域名解析流程如下：</p><ul><li>先查询<strong>浏览器的域名缓存</strong></li><li>再查询<strong>本机</strong>的域名解析文件hosts</li><li>如果还没有，则请求DNS服务器进行IP解析，如果某个DNS服务器解析失败则会使用其他DNS服务器解析，<strong>DNS解析返回的IP可能是一个CDN的地址</strong>。如果都没有办法解析则会返回错误。</li></ul><h2 id="2-HTTP报文结构"><a href="#2-HTTP报文结构" class="headerlink" title="2. HTTP报文结构"></a>2. HTTP报文结构</h2><p>TCP报文在实际要传输的数据之前添加了一个20字节的头部数据，这个头部数据用来存储TCP协议的额外信息。有了这个附加的头部信息，消息才能够被传递，消息到达目的地后，将头部去掉，就可以拿到真正的数据了。</p><p><img src="/2019/07/01/http/030202/174bb72bad50127ac84427a72327f095.png" alt="img"> </p><p><img src="/2019/07/01/http/030202/1574913191928.png" alt="1574913191928"></p><h3 id="2-1-一个例子"><a href="#2-1-一个例子" class="headerlink" title="2.1 一个例子"></a>2.1 一个例子</h3><p><img src="/2019/07/01/http/030202/1574933498674.png" alt="1574933498674"></p><ul><li><p>第一行“GET / HTTP/1.1”就是<strong>请求行</strong></p></li><li><p>后面的“Host”“Connection”等等都属于 <strong>header</strong></p></li><li><p>报文的最后是一个空白行结束</p></li><li><p>没有 body。</p></li></ul><p>下面对下面这些内容进行详细的介绍</p><h3 id="2-2-请求行"><a href="#2-2-请求行" class="headerlink" title="2.2 请求行"></a>2.2 请求行</h3><p>它简要地描述了<strong>客户端想要如何操作服务器端的资源</strong>。</p><p>请求行由三部分构成：</p><ul><li><strong>请求方法</strong>（Method）：是一个动词，如 GET/POST，表示对资源的操作；</li><li><strong>请求目标</strong>（URI）：通常是一个 URI，标记了请求方法要操作的资源；</li><li><strong>版本号</strong>（Version）：表示报文使用的 HTTP 协议版本。</li></ul><p>这三个部分通常使用空格（SP）来分隔，最后要用 CRLF 换行表示结束。</p><p><img src="/2019/07/01/http/030202/36108959084392065f36dff3e12967b9.png" alt="img"> </p><p>以下面这个请求行的例子来看：</p><pre><code>GET / HTTP/1.1</code></pre><ul><li><code>GET</code>：请求方法</li><li><code>/</code>：请求目标</li><li><code>HTTP/1.1</code>：版本号</li></ul><p>把这三部分连起来，意思就是“服务器你好，我想获取网站根目录下的默认文件，我用的协议版本号是 1.1，请不要用 1.0 或者 2.0 回复我。”</p><h3 id="2-3-状态行"><a href="#2-3-状态行" class="headerlink" title="2.3 状态行"></a>2.3 状态行</h3><p>状态行是服务器返回给客户端的响应报文中的内容</p><p>状态行要简单一些，由以下三部分组成</p><ul><li><strong>版本号</strong>（Version）：表示报文使用的 HTTP 协议版本；</li><li><strong>状态码</strong>（Status Code）：一个三位数，用代码的形式表示处理的结果，比如 200 是成功；</li><li><strong>原因</strong>（Reason）：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。</li></ul><p>这三个部分也是用空格（SP）分隔开，最后是一个换行CRLF</p><p><img src="/2019/07/01/http/030202/a1477b903cd4d5a69686683c0dbc3300.png" alt="img"> </p><p>下面是一个例子：</p><pre><code>HTTP/1.1 200 OKHTTP/1.1 404 Not Found</code></pre><ul><li><code>HTTP/1.1</code>：版本号</li><li><code>200</code>和<code>404</code>：状态码</li><li><code>OK</code>和<code>Not Found</code>：原因</li></ul><h3 id="2-4-头部字段"><a href="#2-4-头部字段" class="headerlink" title="2.4 头部字段"></a>2.4 头部字段</h3><p>请求行或状态行加上头部字段就构成了HTTP报文中完整的请求头或响应头。这两者之间的区别只有请求行和响应行不同，其他部分的内容都是一样的。</p><ul><li>请求头的结构：</li></ul><p><img src="/2019/07/01/http/030202/1fe4c1121c50abcf571cebd677a8bdea.png" alt="img"> </p><ul><li>响应头结构：</li></ul><p><img src="/2019/07/01/http/030202/cb0d1d2c56400fe9c9988ee32842b175.png" alt="img"> </p><p>头部字段是 key-value 的形式，key 和 value 之间用“:”分隔，最后用 CRLF 换行表示字段结束。</p><p>比如在“Host: 127.0.0.1”这一行里 key 就是“Host”，value 就是“127.0.0.1”。</p><p>不过使用头字段需要注意下面几点：</p><ul><li><p>字段名不区分大小写，例如“Host”也可以写成“host”，但首字母大写的可读性更好；</p></li><li><p>字段名里不允许出现空格，可以使用连字符“-”，但<strong>不能使用下划线“_”</strong>。</p><p>例如，“test-name”是合法的字段名，而“test name”“test_name”是不正确的字段名；</p></li><li><p>字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格；</p><p>例如下面这两种写法，只有第一种是对的。</p><pre><code>GET /09-1 HTTP/1.1Host:   www.chrono.comGET /09-1 HTTP/1.1Host : www.chrono.com（错误，host后面必须直接跟冒号，不能加空格）</code></pre></li><li><p>字段的顺序是没有意义的，可以任意排列不影响语义；</p></li><li><p>字段原则上不能重复，除非这个字段本身的语义允许，例如 Set-Cookie。</p></li></ul><p>HTTP的头部字段是很多的，但是基本上可以分为以下几类：</p><ol><li><strong>通用字段</strong>：在请求头和响应头里都可以出现；</li><li><strong>请求字段</strong>：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；</li><li><strong>响应字段</strong>：仅能出现在响应头里，补充说明响应报文的信息；</li><li><strong>实体字段</strong>：它实际上属于通用字段，但专门描述 body 的额外信息。</li></ol><p>其中有几个比较特殊的字段：</p><ul><li><p><strong>Host 字段</strong>，它属于<strong>请求字段</strong>，只能出现在<strong>请求头</strong>里，它同时也是唯一一个 HTTP/1.1 规范里要求<strong>必须出现的字段</strong>，也就是说，如果请求头里没有 Host，那这就是一个错误的报文。</p><p>Host 字段告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用 Host 字段来选择，有点像是一个简单的“路由重定向”。例如在 127.0.0.1 上有三个虚拟主机：<code>www.chrono.com, www.metroid.net, origin.io</code>。那么当使用域名的方式访问时，就必须要用 Host 字段来区分这三个 IP 相同但域名不同的网站，否则服务器就会找不到合适的虚拟主机，无法处理。</p></li><li><p><strong>User-Agent</strong>，属于<strong>请求字段</strong>，只出现在<strong>请求头</strong>里。它使用一个字符串来描述发起 HTTP 请求的客户端，<strong>服务器可以依据它来返回最合适此浏览器显示的页面</strong>。但由于历史的原因，User-Agent 非常混乱，每个浏览器都自称是“Mozilla”“Chrome”“Safari”，企图使用这个字段来互相“伪装”，导致 User-Agent 变得越来越长，最终变得毫无意义。不过有的比较“诚实”的爬虫会在 User-Agent 里用“spider”标明自己是爬虫，所以可以利用这个字段实现简单的反爬虫策略。</p></li><li><p><strong>Date 字段</strong>，是一个<strong>通用字段</strong>，但<strong>通常出现在响应头里</strong>，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。 </p></li><li><p><strong>Server 字段</strong>，是<strong>响应字段</strong>，只能出现在<strong>响应头</strong>里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号。Server 字段也<strong>不是必须要出现的</strong>，因为这会把服务器的一部分信息暴露给外界，如果这个版本恰好存在 bug，那么黑客就有可能利用 bug 攻陷服务器。所以，有的网站响应头里要么没有这个字段，要么就给出一个完全无关的描述信息。</p><p>比如 GitHub，它的 Server 字段里就看不出是使用了 Apache 还是 Nginx，只是显示为“GitHub.com”。</p><img src="/2019/07/01/http/030202/f1970aaecad58fb18938e262ea7f311c.png" alt="img" style="zoom: 25%;"> </li><li><p><strong>Content-Length</strong>，属于<strong>实体字段</strong>，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输。</p></li></ul><h2 id="3-请求方法"><a href="#3-请求方法" class="headerlink" title="3. 请求方法"></a>3. 请求方法</h2><p>目前 HTTP/1.1 规定了八种方法，单词都必须是大写的形式。</p><ul><li>GET：获取资源，可以理解为读取或者下载数据；</li><li>HEAD：获取资源的元信息；</li><li>POST：向资源提交数据，相当于写入或上传数据；</li><li>PUT：类似 POST；</li><li>DELETE：删除资源；</li><li>CONNECT：建立特殊的连接隧道；</li><li>OPTIONS：列出可对资源实行的方法；</li><li>TRACE：追踪请求 - 响应的传输路径。</li></ul><p><img src="/2019/07/01/http/030202/3cdc8ac71b80929f4a94dfeb9ffe4b6d.jpg" alt="img"> </p><h3 id="3-1-GET-HEAD"><a href="#3-1-GET-HEAD" class="headerlink" title="3.1 GET / HEAD"></a>3.1 GET / HEAD</h3><p>GET的含义是从服务器获取资源，搭配其他的头字段就可以对资源进行更加精细的操作，比如：</p><ul><li>在 URI 后使用“#”，就可以在获取页面后直接定位到某个标签所在的位置；</li><li>使用 If-Modified-Since 字段就变成了“有条件的请求”，仅当资源被修改时才会执行获取动作；</li><li>使用 Range 字段就是“范围请求”，只获取资源的一部分数据。</li></ul><p>HEAD的方法与处理机制与GET是一样的，只不过不返回实体数据，只会传回响应头，也就是只传回元数据。可以将HEAD方法看成是GET方法的一个轻量级版本。它的响应头与GET方法的响应头是完全一样的。比如说有时候只需要查看一个资源是否存在，只需要使用HEAD就可以了，不需要使用GET来实际获取这个资源。</p><h3 id="3-2-POST-PUT"><a href="#3-2-POST-PUT" class="headerlink" title="3.2 POST / PUT"></a>3.2 POST / PUT</h3><p>GET 和 HEAD 方法是从服务器获取数据，而 POST 和 PUT 方法则是相反操作，<strong>向 URI 指定的资源提交数据，数据就放在报文的 body 里</strong>。</p><p>PUT 的作用与 POST 类似，也可以向服务器提交数据，但与 POST 存在微妙的不同：</p><ul><li>POST 表示的是“新建”“create”的含义，</li><li>PUT 是“修改”“update”的含义。</li></ul><p>在实际应用中，PUT 用到的比较少。而且，因为它与 POST 的语义、功能太过近似，有的服务器甚至就直接禁止使用 PUT 方法，只用 POST 方法上传数据。</p><h3 id="3-3-DELETE"><a href="#3-3-DELETE" class="headerlink" title="3.3 DELETE"></a>3.3 DELETE</h3><p>该方法指示服务器删除资源，因为这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记。当然，更多的时候服务器就直接不处理 DELETE 请求。</p><h3 id="3-4-CONNECT"><a href="#3-4-CONNECT" class="headerlink" title="3.4 CONNECT"></a>3.4 CONNECT</h3><p>是一个比较特殊的方法，要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色。</p><h3 id="3-5-OPTIONS"><a href="#3-5-OPTIONS" class="headerlink" title="3.5 OPTIONS"></a>3.5 OPTIONS</h3><p>要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回。它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持。</p><h3 id="3-6-TRACE"><a href="#3-6-TRACE" class="headerlink" title="3.6 TRACE"></a>3.6 TRACE</h3><p>多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用。</p><h3 id="3-7-安全与幂等"><a href="#3-7-安全与幂等" class="headerlink" title="3.7 安全与幂等"></a>3.7 安全与幂等</h3><p><strong>安全</strong></p><p>在 HTTP 协议里，所谓的“<strong>安全</strong>”是指<strong>请求方法不会“破坏”服务器上的资源，即不会对服务器上的资源造成实质的修改</strong>。</p><p>只有 GET 和 HEAD 方法是“安全”的，因为它们是“只读”操作，只要服务器不故意曲解请求方法的处理方式，无论 GET 和 HEAD 操作多少次，服务器上的数据都是“安全的”。而 POST/PUT/DELETE 操作会修改服务器上的资源，增加或删除数据，所以是“不安全”的。</p><p><strong>幂等</strong></p><p>所谓的“<strong>幂等</strong>”实际上是一个数学用语，被借用到了 HTTP 协议里，意思是<strong>多次执行相同的操作，结果也都是相同的，即多次“幂”后结果“相等”。</strong></p><h2 id="4-URI"><a href="#4-URI" class="headerlink" title="4. URI"></a>4. URI</h2><p>URI 本质上是一个字符串，这个字符串的作用是<strong>唯一地标记资源的位置或者名字</strong>。</p><h3 id="4-1-基本组成"><a href="#4-1-基本组成" class="headerlink" title="4.1 基本组成"></a>4.1 基本组成</h3><p><img src="/2019/07/01/http/030202/46581d7e1058558d8e12c1bf37d30d2a.png" alt="img"> </p><ul><li><p><code>scheme</code>，翻译成中文叫“方案名”或者“协议名”，表示资源应该使用哪种协议来访问。</p><p>常用的scheme为<strong>http</strong>或者<strong>https</strong>，此外还有其他不是很常见的 scheme，例如 <strong>ftp</strong>、<strong>ldap</strong>、<strong>file</strong>、<strong>news</strong> 等。</p></li><li><p><code>://</code>，将scheme与后面的部分分隔开，相当于一个分隔符</p></li><li><p><code>host:port</code>，这部分被称为“<strong>authority</strong>”，表示资源所在的主机名，通常的形式是“host:port”，即<strong>主机名加端口号</strong>。</p><p>其中，主机名必须要有，其形式可以是IP地址或者域名。端口号则有时候可以省略，此时浏览器根据scheme使用的默认端口号。</p><blockquote><p>HTTP 的默认端口号是 80</p><p>HTTPS 的默认端口号是 443</p></blockquote></li><li><p><code>path</code>，URI 里 path 采用了类似文件系统“目录”“路径”的表示方式，因为早期互联网上的计算机多是 UNIX 系统，所以采用了 UNIX 的“/”风格。其实也比较好理解，它与 scheme 后面的“://”是一致的。</p><blockquote><p>URI 的 path 部分必须以“/”开始，也就是必须包含“/”，不要把“/”误认为属于前面 authority。</p><p>例如下面的这些</p><pre><code>http://nginx.orghttp://www.chrono.com:8080/11-1https://tools.ietf.org/html/rfc7230file:///D:/http_study/www/</code></pre><ul><li>第一个，使用http协议，主机名为<code>nginx.org</code>，端口号省略，默认为80，资源路径path省略了，这里默认是根目录<code>/</code></li><li>第二个，使用http协议，主机名为<code>www.chrono.com</code>，端口为8080，目录为根目录下的11-1</li><li>第三个，使用https协议，主机名为<code>ttols.ietf.org</code>，端口省略，默认为443，目录为根目录下的<code>html/rfc7230</code></li><li>第四个，使用file协议，表示是本地文件，这里有三个<code>/</code>，实际上并不是真的就用了三。这三个斜杠里的前两个属于 URI 特殊分隔符<code>://</code>，然后后面的<code>/D:/http_study/www/</code>是路径，而中间的主机名被“省略”了。这实际上<strong>是 file 类型 URI 的“特例”，它允许省略主机名</strong>，默认是本机 <code>localhost</code>。</li></ul></blockquote></li><li><p><code>?query</code>，这部分实际上就是扩展的功能了。表示的是查询参数，这部分在4.2中详细说明</p><p><img src="/2019/07/01/http/030202/20ac5ee55b8ee30527492c8abb60ff9f.png" alt="img"> </p></li></ul><p>在 HTTP 报文里的 URI“/11-1”与浏览器里输入的<code>http://www.chrono.com/11-1</code>有很大的不同，协议名和主机名都不见了，只剩下了后面的部分。</p><p>这是因为<strong>协议名和主机名已经分别出现在了请求行的版本号和请求头的 Host 字段里</strong>，没有必要再重复。</p><p><strong>结论</strong>：客户端和服务器看到的 URI 是不一样的。客户端看到的必须是完整的 URI，使用特定的协议去连接特定的主机，而服务器看到的只是报文请求行里被删除了协议名和主机名的 URI。</p><h3 id="4-2-URI的查询参数"><a href="#4-2-URI的查询参数" class="headerlink" title="4.2 URI的查询参数"></a>4.2 URI的查询参数</h3><p>如果不加查询参数，只用<code>协议+主机名+端口号+路径</code>的方式，其实是可以精确的定位到任意资源的，不过对于这些资源，如果有一些附加的请求，则是没有办法实现的，这里就需要用到查询参数。</p><p>查询参数在 path 之后，用一个<code>?</code>开始，但不包含<code>?</code>，表示对资源附加的额外要求。这是个很形象的符号，比<code>://</code>要好的多，很明显地表示了“查询”的含义。</p><p>查询参数 query 有一套自己的格式，是多个<code>key=value</code>的字符串，这些 KV 值用字符<code>&amp;</code>连接，浏览器和客户端都可以按照这个格式把长串的查询参数解析成可理解的字典或关联数组形式。</p><pre><code>http://www.chrono.com:8080/11-1?uid=1234&amp;name=mario&amp;referer=xxx</code></pre><p>下面是一个实际使用的例子：</p><pre><code>https://search.jd.com/Search?keyword=openresty&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=openresty&amp;psort=3&amp;click=0</code></pre><p><img src="/2019/07/01/http/030202/1574994316629.png" alt="1574994316629"></p><h3 id="4-3-URI完整组成"><a href="#4-3-URI完整组成" class="headerlink" title="4.3 URI完整组成"></a>4.3 URI完整组成</h3><p><img src="/2019/07/01/http/030202/ff41d020c7a27d1e8191057f0e658b38.png" alt="img"> </p><p>可以看出这里的URI完整组成比前面多了两部分</p><ul><li><p><code>user:passwd@</code>，<strong>身份信息</strong>，位于协议名之后、主机名之前。表示<strong>登录主机时的用户名和密码</strong>，但现在已经不推荐使用这种形式了（RFC7230），因为它把敏感信息以明文形式暴露出来，存在严重的安全隐患。</p></li><li><p><code>#fragment</code>，<strong>片段标识符</strong>，位于查询参数后，它是 URI 所定位的资源内部的一个“锚点”或者说是“标签”，浏览器可以<strong>在获取资源后直接跳转到它指示的位置</strong>。</p><p>但片段标识符仅能由浏览器这样的客户端使用，服务器是看不到的。也就是说，<strong>浏览器永远不会把带“#fragment”的 URI 发送给服务器，服务器也永远不会用这种方式去处理资源的片段。</strong></p></li></ul><h3 id="4-4-URI的编码"><a href="#4-4-URI的编码" class="headerlink" title="4.4 URI的编码"></a>4.4 URI的编码</h3><p>在 URI 里只能使用 ASCII 码，但如果想要在 URI 里使用汉语、日语、“@&amp;?”等起界定符作用的字符，就需要引入<strong>编码机制</strong>，<strong>对于 ASCII 码以外的字符集和特殊字符做一个特殊的操作，把它们转换成与 URI 语义不冲突的形式。</strong>这在 RFC 规范里称为“escape”和“unescape”，俗称“转义”。</p><p>URI 转义的规则有点“简单粗暴”，直接<strong>把非 ASCII 码或特殊字符转换成十六进制字节值，然后前面再加上一个“%”</strong>。例如：</p><ul><li><p>空格被转义成“%20”</p></li><li><p>“?”被转义成“%3F”</p></li><li><p>中文、日文等则通常使用 UTF-8 编码后再转义</p><p>例如“银河”会被转义成“%E9%93%B6%E6%B2%B3”。</p></li></ul><p>有了这个编码规则后，URI 就可以支持任意的字符集用任何语言来标记资源。不过我们在浏览器的地址栏里通常是不会看到这些转义后的“乱码”的，这实际上是浏览器一种“友好”表现，隐藏了 URI 编码后的“丑陋一面”。</p><h2 id="5-响应状态码"><a href="#5-响应状态码" class="headerlink" title="5. 响应状态码"></a>5. 响应状态码</h2><p>HTTP 报文里请求行的组成部分，包括请求方法和 URI。有了请求行，加上后面的头字段就形成了请求头，可以通过 TCP/IP 协议发送给服务器。</p><p>服务器收到请求报文，解析后需要进行处理，具体的业务逻辑多种多样，但最后必定是拼出一个响应报文发回客户端。</p><p>下图是状态行的结构：</p><p><img src="/2019/07/01/http/030202/a1477b903cd4d5a69686683c0dbc3300-1574996961973.png" alt="img"> </p><p>目前 RFC 标准里规定的状态码是三位数，所以取值范围就是从 000 到 999。</p><p>RFC 标准把状态码分成了五类，用数字的第一位表示分类，而 0<del>99 不用，这样状态码的实际可用范围就大大缩小了，由 000</del>999 变成了 100~599。</p><ul><li>1××：<strong>提示信息</strong>，表示目前是协议处理的中间状态，还需要后续的操作；</li><li>2××：<strong>成功</strong>，报文已经收到并被正确处理；</li><li>3××：<strong>重定向</strong>，资源位置发生变动，需要客户端重新发送请求；</li><li>4××：<strong>客户端错误</strong>，请求报文有误，服务器无法处理；</li><li>5××：<strong>服务器错误</strong>，服务器在处理请求时内部发生了错误。</li></ul><p>客户端作为请求的发起方，获取响应报文后，需要通过状态码知道请求是否被正确处理，是否要再次发送请求，如果出错了原因又是什么。这样才能进行下一步的动作，要么发送新请求，要么改正错误重发请求。</p><p>服务器端作为请求的接收方，也应该很好地运用状态码。在处理请求时，选择最恰当的状态码回复客户端，告知客户端处理的结果，指示客户端下一步应该如何行动。特别是在出错的时候，尽量不要简单地返 400、500 这样意思含糊不清的状态码。</p><h3 id="5-1-提示信息：1××"><a href="#5-1-提示信息：1××" class="headerlink" title="5.1 提示信息：1××"></a>5.1 提示信息：1××</h3><p>1××类状态码属于提示信息，是协议处理的中间状态，实际能够用到的时候很少。</p><ul><li><p><code>101 Switching Protocols</code></p><p>它的意思是客户端使用 Upgrade 头字段，要求<strong>在 HTTP 协议的基础上改成其他的协议继续通信</strong>，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了。</p></li></ul><h3 id="5-2-成功：2××"><a href="#5-2-成功：2××" class="headerlink" title="5.2 成功：2××"></a>5.2 成功：2××</h3><p>2××类状态码表示服务器收到并成功处理了客户端的请求，这也是客户端最愿意看到的状态码。</p><ul><li><p><code>200 OK</code></p><p>是最常见的成功状态码，表示一切正常，服务器如客户端所期望的那样返回了处理结果，<strong>如果是非 HEAD 请求，通常在响应头后都会有 body 数据。</strong></p></li><li><p><code>204 No Content</code></p><p>是另一个很常见的成功状态码，它的含义与“200 OK”基本相同，但<strong>响应头后没有 body 数据</strong>。所以对于 Web 服务器来说，正确地区分 200 和 204 是很必要的。</p></li><li><p><code>206 Partial Content</code></p><p>是 HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。</p><p>状态码 206 通常还会伴随着头字段<code>Content-Range</code>，表示<strong>响应报文里 body 数据的具体范围</strong>，供客户端确认，例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节。</p></li></ul><h3 id="5-3-重定向：3××"><a href="#5-3-重定向：3××" class="headerlink" title="5.3 重定向：3××"></a>5.3 重定向：3××</h3><p>3××类状态码表示客户端请求的资源发生了变动，客户端必须用新的 URI 重新发送请求获取资源，也就是通常所说的“重定向”，包括著名的 301、302 跳转。</p><ul><li><p><code>301 Moved Permanently</code></p><p>俗称“<strong>永久重定向</strong>”，含义是此次请求的资源已经不存在了，需要改用改用新的 URI 再次访问。</p></li><li><p><code>302 Found</code></p><p>俗称“<strong>临时重定向</strong>”，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。</p><p>301 和 302 都会在<strong>响应头里使用字段 Location 指明后续要跳转的 URI</strong>，最终的效果很相似，浏览器都会重定向到新的 URI。两者的根本区别在于语义，一个是“永久”，一个是“临时”，所以在场景、用法上差距很大。</p><blockquote><ul><li>比如，你的网站升级到了 HTTPS，原来的 HTTP 不打算用了，这就是“永久”的，所以要配置 301 跳转，把所有的 HTTP 流量都切换到 HTTPS。</li><li>再比如，今天夜里网站后台要系统维护，服务暂时不可用，这就属于“临时”的，可以配置成 302 跳转，把流量临时切换到一个静态通知页面，浏览器看到这个 302 就知道这只是暂时的情况，不会做缓存优化，第二天还会访问原来的地址。</li></ul></blockquote></li><li><p><code>304 Not Modified</code></p><p>是一个比较有意思的状态码，它用于 If-Modified-Since 等条件请求，<strong>表示资源未修改，用于缓存控制</strong>。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“缓存重定向”）。301、302 和 304 分别涉及了 HTTP 协议里重要的“<strong>重定向跳转</strong>”和“<strong>缓存控制</strong>”。</p></li></ul><h3 id="5-4-客户端错误：4××"><a href="#5-4-客户端错误：4××" class="headerlink" title="5.4 客户端错误：4××"></a>5.4 客户端错误：4××</h3><p>4××类状态码表示客户端发送的请求报文有误，服务器无法处理，它就是真正的“错误码”含义了。 </p><ul><li><p><code>400 Bad Request</code></p><p>是一个通用的错误码，表示<strong>请求报文有错误，但具体错误未知。</strong>是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误，客户端看到 400 只会是“一头雾水”“不知所措”。所以，在开发 Web 应用时应当尽量避免给客户端返回 400，而是要用其他更有明确含义的状态码。</p></li><li><p><code>403 Forbidden</code></p><p>实际上不是客户端的请求出错，而是<strong>表示服务器禁止访问资源</strong>。原因可能多种多样，例如信息敏感、法律禁止等，如果服务器友好一点，可以在 body 里详细说明拒绝请求的原因，不过现实中通常都是直接给一个“闭门羹”。</p></li><li><p><code>404 Not Found</code></p><p>原意是<strong>资源在本服务器上未找到，所以无法提供给客户端</strong>。但现在已经被“用滥了”，只要服务器“不高兴”就可以给出个 404，而我们也无从得知后面到底是真的未找到，还是有什么别的原因，某种程度上它比 403 还要令人讨厌。</p></li></ul><p>4××里剩下的一些代码较明确地说明了错误的原因，都很好理解，开发中常用的有：</p><ul><li><code>405 Method Not Allowed</code>：不允许使用某些方法操作资源，例如不允许 POST 只能 GET；</li><li><code>406 Not Acceptable</code>：资源无法满足客户端请求的条件，例如请求中文但只有英文；</li><li><code>408 Request Timeout</code>：请求超时，服务器等待了过长的时间；</li><li><code>409 Conflict</code>：多个请求发生了冲突，可以理解为多线程并发时的竞态；</li><li><code>413 Request Entity Too Large</code>：请求报文里的 body 太大；</li><li><code>414 Request-URI Too Long</code>：请求行里的 URI 太大；</li><li><code>429 Too Many Requests</code>：客户端发送了太多的请求，通常是由于服务器的限连策略；</li><li><code>431 Request Header Fields Too Large</code>：请求头某个字段或总体太大；</li></ul><h3 id="5-5-服务器错误：5××"><a href="#5-5-服务器错误：5××" class="headerlink" title="5.5 服务器错误：5××"></a>5.5 服务器错误：5××</h3><p>5××类状态码表示<strong>客户端请求报文正确，但服务器在处理时内部发生了错误，无法返回应有的响应数据</strong>，是服务器端的“错误码”。</p><ul><li><p><code>500 Internal Server Error</code></p><p>与 400 类似，也是一个<strong>通用的错误码</strong>，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析。</p></li><li><p><code>501 Not Implemented</code></p><p>表示<strong>客户端请求的功能还不支持</strong>，这个错误码比 500 要“温和”一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了。</p></li><li><p><code>502 Bad Gateway</code></p><p>通常是服务器作为网关或者代理时返回的错误码，表示<strong>服务器自身工作正常，访问后端服务器时发生了错误</strong>，但具体的错误原因也是不知道的。</p></li><li><p><code>503 Service Unavailable</code></p><p>表示<strong>服务器当前很忙，暂时无法响应服务</strong>，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503。503 是一个“临时”的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以 503 响应报文里通常还会有一个“Retry-After”字段，指示客户端可以在多久以后再次尝试发送请求。</p></li></ul><h2 id="6-特点"><a href="#6-特点" class="headerlink" title="6. 特点"></a>6. 特点</h2><h3 id="6-1-灵活可扩展"><a href="#6-1-灵活可扩展" class="headerlink" title="6.1 灵活可扩展"></a>6.1 灵活可扩展</h3><p>首先， HTTP 协议是一个“<strong>灵活可扩展</strong>”的<strong>传输协议</strong>。</p><p>HTTP 协议最初诞生的时候就比较简单，本着开放的精神只规定了报文的基本格式，比如用空格分隔单词，用换行分隔字段，“header+body”等，报文里的各个组成部分都没有做严格的语法语义限制，可以由开发者任意定制。所以，HTTP 协议就随着互联网的发展一同成长起来了。</p><p>在这个过程中，HTTP 协议逐渐增加了请求方法、版本号、状态码、头字段等特性。而 body 也不再限于文本形式的 TXT 或 HTML，而是能够传输图片、音频视频等任意数据，这些都是源于它的“灵活可扩展”的特点。</p><p>总的来说，HTTP 是灵活可扩展的，可以任意添加头字段实现任意功能； </p><h3 id="6-2-可靠传输"><a href="#6-2-可靠传输" class="headerlink" title="6.2 可靠传输"></a>6.2 可靠传输</h3><p>第二个特点， HTTP 协议是一个“可靠”的传输协议。</p><p><strong>因为 HTTP 协议是基于 TCP/IP 的，而 TCP 本身是一个“可靠”的传输协议，所以 HTTP 自然也就继承了这个特性，能够在请求方和应答方之间“可靠”地传输数据。</strong></p><p>HTTP 是可靠传输协议，基于 TCP/IP 协议“尽量”保证数据的送达；</p><h3 id="6-3-应用层协议"><a href="#6-3-应用层协议" class="headerlink" title="6.3 应用层协议"></a>6.3 应用层协议</h3><p>第三个特点，HTTP 协议是一个应用层的协议。</p><p>在 TCP/IP 诞生后的几十年里，虽然出现了许多的应用层协议，但它们都仅关注很小的应用领域，局限在很少的应用场景。</p><p>例如 FTP 只能传输文件、SMTP 只能发送邮件、SSH 只能远程登录等，在通用的数据传输方面“完全不能打”。</p><p>因此总结就是，HTTP 是应用层协议，比 FTP、SSH 等更通用功能更多，能够传输任意数据；</p><h3 id="6-4-请求-应答"><a href="#6-4-请求-应答" class="headerlink" title="6.4 请求-应答"></a>6.4 请求-应答</h3><p>请求 - 应答模式也明确了 HTTP 协议里通信双方的定位，永远是<strong>请求方先发起连接和请求，是主动的，而应答方只有在收到请求后才能答复，是被动的，如果没有请求时不会有任何动作</strong>。</p><p>HTTP 使用了请求 - 应答模式，<strong>客户端主动发起请求，服务器被动回复请求</strong>；</p><h3 id="6-5-无状态"><a href="#6-5-无状态" class="headerlink" title="6.5 无状态"></a>6.5 无状态</h3><p>“无状态”形象地来说就是“<strong>没有记忆能力</strong>”。</p><p>每个请求都是互相独立、毫无关联的，协议不要求客户端或服务器记录请求相关的信息。</p><h2 id="7-优缺点总结"><a href="#7-优缺点总结" class="headerlink" title="7. 优缺点总结"></a>7. 优缺点总结</h2><h3 id="7-1-简单灵活易扩展"><a href="#7-1-简单灵活易扩展" class="headerlink" title="7.1 简单灵活易扩展"></a>7.1 简单灵活易扩展</h3><p>HTTP 最大的优点是简单、灵活和易于扩展；</p><h3 id="7-2-应用广泛、环境成熟"><a href="#7-2-应用广泛、环境成熟" class="headerlink" title="7.2 应用广泛、环境成熟"></a>7.2 应用广泛、环境成熟</h3><p>HTTP 拥有成熟的软硬件环境，应用的非常广泛，是互联网的基础设施；</p><h3 id="7-3-无状态"><a href="#7-3-无状态" class="headerlink" title="7.3 无状态"></a>7.3 无状态</h3><ul><li><p><strong>无状态的好处</strong></p><p>因为服务器没有“记忆能力”，所以就<strong>不需要额外的资源来记录状态信息</strong>，不仅实现上会简单一些，而且还能<strong>减轻服务器的负担</strong>，能够把更多的 CPU 和内存用来对外提供服务。</p><p>而且，“无状态”也表示服务器都是相同的，没有“状态”的差异，所以可以<strong>很容易地组成集群</strong>，让负载均衡把请求转发到任意一台服务器，不会因为状态不一致导致处理出错，使用“堆机器”的“笨办法”轻松实现高并发高可用。</p></li><li><p><strong>无状态的缺点</strong></p><p><strong>无法支持需要连续多个步骤的“事务”操作</strong>。例如电商购物，首先要登录，然后添加购物车，再下单、结算、支付，这一系列操作都需要知道用户的身份才行，但“无状态”服务器是不知道这些请求是相互关联的，每次都得问一遍身份信息，不仅麻烦，而且还增加了不必要的数据传输量。</p></li></ul><p>HTTP 是无状态的，可以轻松实现集群化，扩展性能，但有时也需要用 Cookie 技术来实现“有状态”；</p><h3 id="7-4-明文"><a href="#7-4-明文" class="headerlink" title="7.4 明文"></a>7.4 明文</h3><p>“明文”意思就是协议里的报文（准确地说是 header 部分）不使用二进制数据，而是用简单可阅读的文本形式。</p><p>对比 TCP、UDP 这样的二进制协议，它的优点显而易见，不需要借助任何外部工具，用浏览器、Wireshark 或者 tcpdump 抓包后，直接用肉眼就可以很容易地查看或者修改，为我们的开发调试工作带来极大的便利。</p><p>HTTP 是明文传输，数据完全肉眼可见，能够方便地研究分析，但也容易被窃听；</p><h3 id="7-5-不安全"><a href="#7-5-不安全" class="headerlink" title="7.5 不安全"></a>7.5 不安全</h3><p>HTTP 是不安全的，无法验证通信双方的身份，也不能判断报文是否被篡改；</p><h3 id="7-6-性能"><a href="#7-6-性能" class="headerlink" title="7.6 性能"></a>7.6 性能</h3><p>现在互联网的特点是移动和高并发，不能保证稳定的连接质量，所以在 TCP 层面上 HTTP 协议有时候就会表现的不够好。而“请求 - 应答”模式则加剧了 HTTP 的性能问题，这就是著名的“<strong>队头阻塞</strong>”（Head-of-line blocking），当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。</p><p>为了解决这个问题，就诞生出了一个专门的研究课题“Web 性能优化”，HTTP 官方标准里就有“缓存”一章（RFC7234），非官方的“花招”就更多了，例如切图、数据内嵌与合并，域名分片、JavaScript“黑科技”等等。</p><p>HTTP 的性能不算差，但不完全适应现在的互联网，还有很大的提升空间。</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> HTTP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议学习（一）概念</title>
      <link href="/2019/06/14/http/030201/"/>
      <url>/2019/06/14/http/030201/</url>
      
        <content type="html"><![CDATA[<p>注：本系列的所有内容均为极客时间《透视HTTP协议》的内容总结！</p><p>@[toc]</p><h2 id="0-定义"><a href="#0-定义" class="headerlink" title="0. 定义"></a>0. 定义</h2><p>HTTP的定义是：<strong>H</strong>yper<strong>T</strong>ext <strong>T</strong>ransfer <strong>P</strong>rotocol，即超文本传输协议。</p><p>所以从这个定义入手，可以对概念进行一些分析：</p><ul><li>超文本：超文本的意思是超越了普通文本的文本，它是<strong>文字、图片、音频和视频等的混合体</strong>，最关键的是含有“超链接”，<strong>能够从一个“超文本”跳跃到另一个“超文本”</strong>，形成复杂的非线性、网状的结构关系。</li><li>传输：把一堆东西从 A 点搬到 B 点，或者从 B 点搬到 A 点，即“A&lt;===&gt;B”，这样的过程就叫做传输。HTTP是<strong>专门用来在两点之间传输数据</strong>，不能用于广播、寻址或路由。</li><li>协议：HTTP 是一个用在计算机世界里的协议。它<strong>使用计算机能够理解的语言</strong>确立了一种计算机之间<strong>交流通信的规范</strong>，以及相关的<strong>各种控制和错误处理方式</strong>。</li></ul><p>下面这张图中就展示了HTTP的整个概念框架：</p><p><img src="/2019/06/14/http/030201/5102fc33d04b59b36971a5e487779864.png" alt="img"> </p><h2 id="1-各种概念"><a href="#1-各种概念" class="headerlink" title="1. 各种概念"></a>1. 各种概念</h2><h3 id="1-1-“万维网”（World-Wide-Web）"><a href="#1-1-“万维网”（World-Wide-Web）" class="headerlink" title="1.1 “万维网”（World Wide Web）"></a>1.1 “万维网”（World Wide Web）</h3><p>它基于 HTTP 协议，传输 HTML 等超文本资源，能力也就被限制在 HTTP 协议之内。</p><h3 id="1-2-BT、magnet"><a href="#1-2-BT、magnet" class="headerlink" title="1.2 BT、magnet"></a>1.2 BT、magnet</h3><p>这两种是P2P下载的方式，其中BT需要一个中心化的tracker服务器来提供种子，而magnet则不需要。</p><h3 id="1-3-浏览器"><a href="#1-3-浏览器" class="headerlink" title="1.3 浏览器"></a>1.3 浏览器</h3><p>浏览器实际上是HTTP的请求方，向HTTP服务器去请求数据</p><h3 id="1-4-web服务器"><a href="#1-4-web服务器" class="headerlink" title="1.4 web服务器"></a>1.4 web服务器</h3><p>HTTP是一个传输协议，因此，需要一个响应方，在这里，HTTP的响应方就是web服务器。web服务器有以下这些：</p><ul><li><strong>Apache</strong> 是老牌的服务器，到今天已经快 25 年了，功能相当完善，相关的资料很多，学习门槛低，是许多创业者建站的入门产品。</li><li><strong>Nginx</strong> 是 Web 服务器里的后起之秀，特点是高性能、高稳定，且易于扩展。自 2004 年推出后就不断蚕食 Apache 的市场份额，在高流量的网站里更是不二之选。</li><li>此外，还有 Windows 上的 <strong>IIS</strong>、Java 的 <strong>Jetty/Tomcat</strong> 等，因为性能不是很高，所以在互联网上应用得较少。</li></ul><h3 id="1-5-CDN"><a href="#1-5-CDN" class="headerlink" title="1.5 CDN"></a>1.5 CDN</h3><p>全称是“Content Delivery Network”，翻译过来就是“<strong>内容分发网络</strong>”。它应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求。</p><p>CDN可以缓存源站的数据，让浏览器的请求不用“千里迢迢”地到达源站服务器，直接在“半路”就可以获取响应。如果 CDN 的调度算法很优秀，更可以找到离用户最近的节点，大幅度缩短响应时间。</p><h3 id="1-6-爬虫"><a href="#1-6-爬虫" class="headerlink" title="1.6 爬虫"></a>1.6 爬虫</h3><p>是一种可以自动访问 Web 资源的应用程序。无论是“爬虫”还是“反爬虫”，用到的基本技术都是两个，一个是 HTTP，另一个就是 HTML。</p><h3 id="1-7-HTML"><a href="#1-7-HTML" class="headerlink" title="1.7 HTML"></a>1.7 HTML</h3><p>是 HTTP 协议传输的主要内容之一，它描述了超文本页面，用各种“标签”定义文字、图片等资源和排版布局，最终由浏览器“渲染”出可视化页面。</p><p>HTML 目前有两个主要的标准，HTML4 和 HTML5。<strong>广义上的 HTML 通常是指 HTML、JavaScript、CSS 等前端技术的组合</strong>，能够实现比传统静态页面更丰富的动态页面。</p><h3 id="1-8-Web-Service"><a href="#1-8-Web-Service" class="headerlink" title="1.8 Web Service"></a>1.8 Web Service</h3><p>Web  Service 是一种由 W3C 定义的应用服务开发规范（其中的W3C是一种标准），使用 client-server 主从架构，通常使用 WSDL 定义服务接口，使用 HTTP 协议传输 XML 或 SOAP 消息，也就是说，它是一个基于 Web（HTTP）的服务架构技术，既可以运行在内网，也可以在适当保护后运行在外网。</p><h3 id="1-9-WAF"><a href="#1-9-WAF" class="headerlink" title="1.9 WAF"></a>1.9 WAF</h3><p>意思是“网络应用防火墙”。与硬件“防火墙”类似，它是应用层面的“防火墙”，<strong>专门检测 HTTP 流量，是防护 Web 应用的安全技术。</strong></p><p>WAF 通常位于 Web 服务器<strong>之前</strong>，可以阻止如 SQL 注入、跨站脚本等攻击，目前应用较多的一个开源项目是 ModSecurity，它能够完全集成进 Apache 或 Nginx。</p><p> <img src="/2019/06/14/http/030201/1e7533f765d2ede0abfab73cf6b57781.png" alt="img"> </p><h3 id="1-10-TCP-IP"><a href="#1-10-TCP-IP" class="headerlink" title="1.10 TCP/IP"></a>1.10 TCP/IP</h3><p>是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。</p><p>这个协议栈有四层：</p><ul><li>最上层是“应用层”</li><li>最下层是“链路层”</li><li>TCP 属于“传输层”，是“<strong>T</strong>ransmission <strong>C</strong>ontrol <strong>P</strong>rotocol”的缩写，意思是“传输控制协议”，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础。</li><li>IP 属于“网际层”。是<strong>I</strong>nternet <strong>P</strong>rotocol的缩写，主要目的是<strong>解决寻址和路由问题</strong>，以及<strong>如何在两点间传送数据包</strong>。IP 协议使用“IP 地址”的概念来定位互联网上的每一台计算机。</li></ul><p>HTTP 是一个”传输协议”，但它实际上是一个<strong>应用层协议</strong>。它不关心寻址、路由、数据完整性等传输细节，而要求这些工作都由下层来处理。因为互联网上最流行的是 TCP/IP 协议，而它刚好满足 HTTP 的要求，所以互联网上的 HTTP 协议就运行在了 TCP/IP 上，HTTP 也就可以更准确地称为“HTTP over TCP/IP”。</p><h3 id="1-11-DNS"><a href="#1-11-DNS" class="headerlink" title="1.11 DNS"></a>1.11 DNS</h3><p>DNS指的是<strong>D</strong>omain <strong>N</strong>ame <strong>S</strong>ystem，即域名系统。用有意义的名字来作为 IP 地址的等价替代。在 DNS 中，“域名”（Domain Name）又称为“主机名”（Host），为了更好地标记不同国家或组织的主机，让名字更好记，所以被设计成了一个有层次的结构。</p><p>域名用“.”分隔成多个单词，级别从左到右逐级升高，最右边的被称为“顶级域名”。对于顶级域名，有表示商业公司的“com”、表示教育机构的“edu”，表示国家的“cn”“uk”等。</p><p>但想要使用 TCP/IP 协议来通信仍然要使用 IP 地址，所以需要把域名做一个转换，“映射”到它的真实 IP，这就是所谓的“域名解析”。</p><h3 id="1-12-URI-URL"><a href="#1-12-URI-URL" class="headerlink" title="1.12 URI/URL"></a>1.12 URI/URL</h3><p>URI（<strong>U</strong>niform <strong>R</strong>esource <strong>I</strong>dentifier），中文名称是 统一资源标识符，使用它就能够唯一地标记互联网上资源。</p><p>URI 另一个更常用的表现形式是 URL（<strong>U</strong>niform <strong>R</strong>esource <strong>L</strong>ocator）， 统一资源定位符，也就是我们俗称的“网址”，它实际上是 URI 的一个子集，不过因为这两者几乎是相同的，差异不大，所以通常不会做严格的区分。</p><p>下面是一个URI的例子：</p><pre><code>http://nginx.org/en/download.html</code></pre><p>可见，一个URI中包含了以下三个部分：</p><ul><li><strong>协议名</strong>：访问该资源应当使用的协议，在这里是“http”</li><li><strong>主机名</strong>：即互联网上主机的标记，可以是域名或 IP 地址，在这里是“nginx.org”</li><li><strong>路径</strong>：即资源在主机上的位置，使用“/”分隔多级目录，在这里是“/en/download.html”</li></ul><h3 id="1-13-HTTPS"><a href="#1-13-HTTPS" class="headerlink" title="1.13 HTTPS"></a>1.13 HTTPS</h3><p>HTTPS的全称是<strong>“HTTP over SSL/TLS”</strong>，也就是<strong>运行在 SSL/TLS 协议上的 HTTP</strong>。它是一个负责加密通信的安全协议，建立在 TCP/IP 之上，所以也是个可靠的传输协议，可以被用作 HTTP 的下层。</p><p>SSL 的全称是“<strong>S</strong>ecure <strong>S</strong>ocket <strong>L</strong>ayer”，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即“<strong>T</strong>ransport <strong>L</strong>ayer <strong>S</strong>ecurity”，但由于历史的原因还是有很多人称之为 SSL/TLS，或者直接简称为 SSL。</p><p>SSL 使用了许多密码学最先进的研究成果，综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道，为 HTTP 套上一副坚固的盔甲。</p><h3 id="1-14-代理"><a href="#1-14-代理" class="headerlink" title="1.14 代理"></a>1.14 代理</h3><p>代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为“中转站”，既可以转发客户端的请求，也可以转发服务器的应答。</p><p>代理有很多的种类，常见的有：</p><ul><li>匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器；</li><li>透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端；</li><li>正向代理：靠近客户端，代表客户端向服务器发送请求；</li><li>反向代理：靠近服务器端，代表服务器响应客户端的请求；</li></ul><p>CDN，实际上就是一种代理，它代替源站服务器响应客户端的请求，通常扮演着透明代理和反向代理的角色。</p><p>由于代理在传输过程中插入了一个“中间层”，所以可以在这个环节做很多有意思的事情，比如：</p><ul><li>负载均衡：把访问请求均匀分散到多台机器，实现访问集群化；</li><li>内容缓存：暂存上下行的数据，减轻后端的压力；</li><li>安全防护：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器；</li><li>数据处理：提供压缩、加密等额外的功能。</li></ul><p>关于 HTTP 的代理还有一个特殊的“代理协议”（proxy protocol），它由知名的代理软件 HAProxy 制订，但并不是 RFC 标准。</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
          <category> HTTP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
